{
  "description": "**Note:** almost all functions in the ``numpy.lib`` namespace\nare also present in the main ``numpy`` namespace.  Please use the\nfunctions as ``np.<funcname>`` where possible.\n\n``numpy.lib`` is mostly a space for implementing functions that don't\nbelong in core or in another NumPy submodule with a clear purpose\n(e.g. ``random``, ``fft``, ``linalg``, ``ma``).\n\nMost contains basic functions that are used by several submodules and are\nuseful to have in the main name-space.",
  "functions": [
    {
      "name": "Arrayterator",
      "signature": "Arrayterator(var, buf_size=None)",
      "docstring": {
        "description": "Buffered iterator for big arrays.\n\n`Arrayterator` creates a buffered iterator for reading big arrays in small\ncontiguous blocks. The class is useful for objects stored in the\nfile system. It allows iteration over the object *without* reading\neverything in memory; instead, small blocks are read and iterated over.\n\n`Arrayterator` can be used with any object that supports multidimensional\nslices. This includes NumPy arrays, but also variables from\nScientific.IO.NetCDF or pynetcdf for example.",
        "parameters": {
          "var": {
            "type": "array_like",
            "description": "The object to iterate over."
          },
          "buf_size": {
            "type": "int, optional",
            "description": "The buffer size. If `buf_size` is supplied, the maximum amount of\n    data that will be read into memory is `buf_size` elements.\n    Default is None, which will read as many element as possible\n    into memory.\n\nAttributes\n----------\nvar\nbuf_size\nstart\nstop\nstep\nshape\nflat"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "ndenumerate : Multidimensional array iterator.\nflatiter : Flat array iterator.\nmemmap : Create a memory-map to an array stored in a binary file on disk.",
        "notes": "The algorithm works by first finding a \"running dimension\", along which\nthe blocks will be extracted. Given an array of dimensions\n``(d1, d2, ..., dn)``, e.g. if `buf_size` is smaller than ``d1``, the\nfirst dimension will be used. If, on the other hand,\n``d1 < buf_size < d1*d2`` the second dimension will be used, and so on.\nBlocks are extracted along this dimension, and when the last block is\nreturned the process continues from the next dimension, until all\nelements have been read.",
        "examples": ">>> a = np.arange(3 * 4 * 5 * 6).reshape(3, 4, 5, 6)\n>>> a_itor = np.lib.Arrayterator(a, 2)\n>>> a_itor.shape\n(3, 4, 5, 6)\n\nNow we can iterate over ``a_itor``, and it will return arrays of size\ntwo. Since `buf_size` was smaller than any dimension, the first\ndimension will be iterated over first:\n\n>>> for subarr in a_itor:\n...     if not subarr.all():\n...         print(subarr, subarr.shape) # doctest: +SKIP\n>>> # [[[[0 1]]]] (1, 1, 1, 2)"
      }
    },
    {
      "name": "DataSource",
      "signature": "DataSource(destpath='.')",
      "docstring": {
        "description": "DataSource(destpath='.')\n\nA generic data source file (file, http, ftp, ...).\n\nDataSources can be local files or remote files/URLs.  The files may\nalso be compressed or uncompressed. DataSource hides some of the\nlow-level details of downloading the file, allowing you to simply pass\nin a valid file path (or URL) and obtain a file object.",
        "parameters": {
          "destpath": {
            "type": "str or None, optional",
            "description": "Path to the directory where the source file gets downloaded to for\n    use.  If `destpath` is None, a temporary directory will be created.\n    The default path is the current directory."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "URLs require a scheme string (``http://``) to be used, without it they\nwill fail::\n\n    >>> repos = np.DataSource()\n    >>> repos.exists('www.google.com/index.html')\n    False\n    >>> repos.exists('http://www.google.com/index.html')\n    True\n\nTemporary directories are deleted when the DataSource is deleted.",
        "examples": "::\n\n    >>> ds = np.DataSource('/home/guido')\n    >>> urlname = 'http://www.google.com/'\n    >>> gfile = ds.open('http://www.google.com/')\n    >>> ds.abspath(urlname)\n    '/home/guido/www.google.com/index.html'\n\n    >>> ds = np.DataSource(None)  # use with temporary file\n    >>> ds.open('/home/guido/foobar.txt')\n    <open file '/home/guido.foobar.txt', mode 'r' at 0x91d4430>\n    >>> ds.abspath('/home/guido/foobar.txt')\n    '/tmp/.../home/guido/foobar.txt'"
      }
    },
    {
      "name": "NumpyVersion",
      "signature": "NumpyVersion(vstring)",
      "docstring": {
        "description": "Parse and compare numpy version strings.\n\nNumPy has the following versioning scheme (numbers given are examples; they\ncan be > 9 in principle):\n\n- Released version: '1.8.0', '1.8.1', etc.\n- Alpha: '1.8.0a1', '1.8.0a2', etc.\n- Beta: '1.8.0b1', '1.8.0b2', etc.\n- Release candidates: '1.8.0rc1', '1.8.0rc2', etc.\n- Development versions: '1.8.0.dev-f1234afa' (git commit hash appended)\n- Development versions after a1: '1.8.0a1.dev-f1234afa',\n                                 '1.8.0b2.dev-f1234afa',\n                                 '1.8.1rc1.dev-f1234afa', etc.\n- Development versions (no git hash available): '1.8.0.dev-Unknown'\n\nComparing needs to be done against a valid version string or other\n`NumpyVersion` instance. Note that all development versions of the same\n(pre-)release compare equal.\n\n.. versionadded:: 1.9.0",
        "parameters": {
          "vstring": {
            "type": "str",
            "description": "NumPy version string (``np.__version__``)."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ">>> from numpy.lib import NumpyVersion\n>>> if NumpyVersion(np.__version__) < '1.7.0':\n...     print('skip')\n>>> # skip\n\n>>> NumpyVersion('1.7')  # raises ValueError, add \".0\"\nTraceback (most recent call last):\n    ...\nValueError: Not a valid numpy version string"
      }
    },
    {
      "name": "RankWarning",
      "signature": "RankWarning(...)",
      "docstring": {
        "description": "Issued by `polyfit` when the Vandermonde matrix is rank deficient.\n\nFor more information, a way to suppress the warning, and an example of\n`RankWarning` being issued, see `polyfit`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "add_docstring",
      "signature": "add_docstring(...)",
      "docstring": {
        "description": "add_docstring(obj, docstring)\n\nAdd a docstring to a built-in obj if possible.\nIf the obj already has a docstring raise a RuntimeError\nIf this routine does not know how to add a docstring to the object\nraise a TypeError",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "add_newdoc",
      "signature": "add_newdoc(place, obj, doc, warn_on_python=True)",
      "docstring": {
        "description": "Add documentation to an existing object, typically one defined in C\n\nThe purpose is to allow easier editing of the docstrings without requiring\na re-compile. This exists primarily for internal use within numpy itself.",
        "parameters": {
          "place": {
            "type": "str",
            "description": "The absolute name of the module to import from"
          },
          "obj": {
            "type": "str",
            "description": "The name of the object to add documentation to, typically a class or\n    function name"
          },
          "doc": {
            "type": "{str, Tuple[str, str], List[Tuple[str, str]]}",
            "description": "If a string, the documentation to apply to `obj`\n\n    If a tuple, then the first element is interpreted as an attribute of\n    `obj` and the second as the docstring to apply - ``(method, docstring)``\n\n    If a list, then each element of the list should be a tuple of length\n    two - ``[(method1, docstring1), (method2, docstring2), ...]``"
          },
          "warn_on_python": {
            "type": "bool",
            "description": "If True, the default, emit `UserWarning` if this is used to attach\n    documentation to a pure-python object."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "This routine never raises an error if the docstring can't be written, but\nwill raise an error if the object being documented does not exist.\n\nThis routine cannot modify read-only docstrings, as appear\nin new-style classes or built-in functions. Because this\nroutine never raises an error the caller must check manually\nthat the docstrings were changed.\n\nSince this function grabs the ``char *`` from a c-level str object and puts\nit into the ``tp_doc`` slot of the type of `obj`, it violates a number of\nC-API best-practices, by:\n\n- modifying a `PyTypeObject` after calling `PyType_Ready`\n- calling `Py_INCREF` on the str and losing the reference, so the str\n  will never be released\n\nIf possible it should be avoided.",
        "examples": ""
      }
    },
    {
      "name": "add_newdoc_ufunc",
      "signature": "_add_newdoc_ufunc(...)",
      "docstring": {
        "description": "add_ufunc_docstring(ufunc, new_docstring)\n\nReplace the docstring for a ufunc with new_docstring.\nThis method will only work if the current docstring for\nthe ufunc is NULL. (At the C level, i.e. when ufunc->doc is NULL.)",
        "parameters": {
          "ufunc": {
            "type": "numpy.ufunc",
            "description": "A ufunc whose current doc is NULL."
          },
          "new_docstring": {
            "type": "string",
            "description": "The new docstring for the ufunc."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "This method allocates memory for new_docstring on\nthe heap. Technically this creates a mempory leak, since this\nmemory will not be reclaimed until the end of the program\neven if the ufunc itself is removed. However this will only\nbe a problem if the user is repeatedly creating ufuncs with\nno documentation, adding documentation via add_newdoc_ufunc,\nand then throwing away the ufunc.",
        "examples": ""
      }
    },
    {
      "name": "angle",
      "signature": "angle(z, deg=False)",
      "docstring": {
        "description": "Return the angle of the complex argument.",
        "parameters": {
          "z": {
            "type": "array_like",
            "description": "A complex number or sequence of complex numbers."
          },
          "deg": {
            "type": "bool, optional",
            "description": "Return angle in degrees if True, radians if False (default)."
          }
        },
        "returns": "angle : ndarray or scalar\n    The counterclockwise angle from the positive real axis on the complex\n    plane in the range ``(-pi, pi]``, with dtype as numpy.float64.\n\n    .. versionchanged:: 1.16.0\n        This function works on subclasses of ndarray like `ma.array`.",
        "raises": "",
        "see_also": "arctan2\nabsolute",
        "notes": "Although the angle of the complex number 0 is undefined, ``numpy.angle(0)``\nreturns the value 0.",
        "examples": ">>> np.angle([1.0, 1.0j, 1+1j])               # in radians\narray([ 0.        ,  1.57079633,  0.78539816]) # may vary\n>>> np.angle(1+1j, deg=True)                  # in degrees\n45.0"
      }
    },
    {
      "name": "append",
      "signature": "append(arr, values, axis=None)",
      "docstring": {
        "description": "Append values to the end of an array.",
        "parameters": {
          "arr": {
            "type": "array_like",
            "description": "Values are appended to a copy of this array."
          },
          "values": {
            "type": "array_like",
            "description": "These values are appended to a copy of `arr`.  It must be of the\n    correct shape (the same shape as `arr`, excluding `axis`).  If\n    `axis` is not specified, `values` can be any shape and will be\n    flattened before use."
          },
          "axis": {
            "type": "int, optional",
            "description": "The axis along which `values` are appended.  If `axis` is not\n    given, both `arr` and `values` are flattened before use."
          }
        },
        "returns": "append : ndarray\n    A copy of `arr` with `values` appended to `axis`.  Note that\n    `append` does not occur in-place: a new array is allocated and\n    filled.  If `axis` is None, `out` is a flattened array.",
        "raises": "",
        "see_also": "insert : Insert elements into an array.\ndelete : Delete elements from an array.",
        "notes": "",
        "examples": ">>> np.append([1, 2, 3], [[4, 5, 6], [7, 8, 9]])\narray([1, 2, 3, ..., 7, 8, 9])\n\nWhen `axis` is specified, `values` must have the correct shape.\n\n>>> np.append([[1, 2, 3], [4, 5, 6]], [[7, 8, 9]], axis=0)\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n>>> np.append([[1, 2, 3], [4, 5, 6]], [7, 8, 9], axis=0)\nTraceback (most recent call last):\n    ...\nValueError: all the input arrays must have same number of dimensions, but\nthe array at index 0 has 2 dimension(s) and the array at index 1 has 1\ndimension(s)"
      }
    },
    {
      "name": "apply_along_axis",
      "signature": "apply_along_axis(func1d, axis, arr, *args, **kwargs)",
      "docstring": {
        "description": "Apply a function to 1-D slices along the given axis.\n\nExecute `func1d(a, *args, **kwargs)` where `func1d` operates on 1-D arrays\nand `a` is a 1-D slice of `arr` along `axis`.\n\nThis is equivalent to (but faster than) the following use of `ndindex` and\n`s_`, which sets each of ``ii``, ``jj``, and ``kk`` to a tuple of indices::\n\n    Ni, Nk = a.shape[:axis], a.shape[axis+1:]\n    for ii in ndindex(Ni):\n        for kk in ndindex(Nk):\n            f = func1d(arr[ii + s_[:,] + kk])\n            Nj = f.shape\n            for jj in ndindex(Nj):\n                out[ii + jj + kk] = f[jj]\n\nEquivalently, eliminating the inner loop, this can be expressed as::\n\n    Ni, Nk = a.shape[:axis], a.shape[axis+1:]\n    for ii in ndindex(Ni):\n        for kk in ndindex(Nk):\n            out[ii + s_[...,] + kk] = func1d(arr[ii + s_[:,] + kk])",
        "parameters": {
          "func1d": {
            "type": "function (M,) -> (Nj...)",
            "description": "This function should accept 1-D arrays. It is applied to 1-D\n    slices of `arr` along the specified axis."
          },
          "axis": {
            "type": "integer",
            "description": "Axis along which `arr` is sliced."
          },
          "arr": {
            "type": "ndarray (Ni..., M, Nk...)",
            "description": "Input array."
          },
          "args": {
            "type": "any",
            "description": "Additional arguments to `func1d`."
          },
          "kwargs": {
            "type": "any",
            "description": "Additional named arguments to `func1d`.\n\n    .. versionadded:: 1.9.0"
          }
        },
        "returns": "out : ndarray  (Ni..., Nj..., Nk...)\n    The output array. The shape of `out` is identical to the shape of\n    `arr`, except along the `axis` dimension. This axis is removed, and\n    replaced with new dimensions equal to the shape of the return value\n    of `func1d`. So if `func1d` returns a scalar `out` will have one\n    fewer dimensions than `arr`.",
        "raises": "",
        "see_also": "apply_over_axes : Apply a function repeatedly over multiple axes.",
        "notes": "",
        "examples": ">>> def my_func(a):\n...     \"\"\"Average first and last element of a 1-D array\"\"\"\n...     return (a[0] + a[-1]) * 0.5\n>>> b = np.array([[1,2,3], [4,5,6], [7,8,9]])\n>>> np.apply_along_axis(my_func, 0, b)\narray([4., 5., 6.])\n>>> np.apply_along_axis(my_func, 1, b)\narray([2.,  5.,  8.])\n\nFor a function that returns a 1D array, the number of dimensions in\n`outarr` is the same as `arr`.\n\n>>> b = np.array([[8,1,7], [4,3,9], [5,2,6]])\n>>> np.apply_along_axis(sorted, 1, b)\narray([[1, 7, 8],\n       [3, 4, 9],\n       [2, 5, 6]])\n\nFor a function that returns a higher dimensional array, those dimensions\nare inserted in place of the `axis` dimension.\n\n>>> b = np.array([[1,2,3], [4,5,6], [7,8,9]])\n>>> np.apply_along_axis(np.diag, -1, b)\narray([[[1, 0, 0],\n        [0, 2, 0],\n        [0, 0, 3]],\n       [[4, 0, 0],\n        [0, 5, 0],\n        [0, 0, 6]],\n       [[7, 0, 0],\n        [0, 8, 0],\n        [0, 0, 9]]])"
      }
    },
    {
      "name": "apply_over_axes",
      "signature": "apply_over_axes(func, a, axes)",
      "docstring": {
        "description": "Apply a function repeatedly over multiple axes.\n\n`func` is called as `res = func(a, axis)`, where `axis` is the first\nelement of `axes`.  The result `res` of the function call must have\neither the same dimensions as `a` or one less dimension.  If `res`\nhas one less dimension than `a`, a dimension is inserted before\n`axis`.  The call to `func` is then repeated for each axis in `axes`,\nwith `res` as the first argument.",
        "parameters": {
          "func": {
            "type": "function",
            "description": "This function must take two arguments, `func(a, axis)`."
          },
          "a": {
            "type": "array_like",
            "description": "Input array."
          },
          "axes": {
            "type": "array_like",
            "description": "Axes over which `func` is applied; the elements must be integers."
          }
        },
        "returns": "apply_over_axis : ndarray\n    The output array.  The number of dimensions is the same as `a`,\n    but the shape can be different.  This depends on whether `func`\n    changes the shape of its output with respect to its input.",
        "raises": "",
        "see_also": "apply_along_axis :\n    Apply a function to 1-D slices of an array along the given axis.",
        "notes": "This function is equivalent to tuple axis arguments to reorderable ufuncs\nwith keepdims=True. Tuple axis arguments to ufuncs have been available since\nversion 1.7.0.",
        "examples": ">>> a = np.arange(24).reshape(2,3,4)\n>>> a\narray([[[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11]],\n       [[12, 13, 14, 15],\n        [16, 17, 18, 19],\n        [20, 21, 22, 23]]])\n\nSum over axes 0 and 2. The result has same number of dimensions\nas the original array:\n\n>>> np.apply_over_axes(np.sum, a, [0,2])\narray([[[ 60],\n        [ 92],\n        [124]]])\n\nTuple axis arguments to ufuncs are equivalent:\n\n>>> np.sum(a, axis=(0,2), keepdims=True)\narray([[[ 60],\n        [ 92],\n        [124]]])"
      }
    },
    {
      "name": "array_split",
      "signature": "array_split(ary, indices_or_sections, axis=0)",
      "docstring": {
        "description": "Split an array into multiple sub-arrays.\n\nPlease refer to the ``split`` documentation.  The only difference\nbetween these functions is that ``array_split`` allows\n`indices_or_sections` to be an integer that does *not* equally\ndivide the axis. For an array of length l that should be split\ninto n sections, it returns l % n sub-arrays of size l//n + 1\nand the rest of size l//n.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "split : Split array into multiple sub-arrays of equal size.",
        "notes": "",
        "examples": ">>> x = np.arange(8.0)\n>>> np.array_split(x, 3)\n[array([0.,  1.,  2.]), array([3.,  4.,  5.]), array([6.,  7.])]\n\n>>> x = np.arange(9)\n>>> np.array_split(x, 4)\n[array([0, 1, 2]), array([3, 4]), array([5, 6]), array([7, 8])]"
      }
    },
    {
      "name": "asarray_chkfinite",
      "signature": "asarray_chkfinite(a, dtype=None, order=None)",
      "docstring": {
        "description": "Convert the input to an array, checking for NaNs or Infs.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input data, in any form that can be converted to an array.  This\n    includes lists, lists of tuples, tuples, tuples of tuples, tuples\n    of lists and ndarrays.  Success requires no NaNs or Infs."
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "By default, the data-type is inferred from the input data."
          },
          "order": {
            "type": "{'C', 'F', 'A', 'K'}, optional",
            "description": "Memory layout.  'A' and 'K' depend on the order of input array a.\n    'C' row-major (C-style),\n    'F' column-major (Fortran-style) memory representation.\n    'A' (any) means 'F' if `a` is Fortran contiguous, 'C' otherwise\n    'K' (keep) preserve input order\n    Defaults to 'C'."
          }
        },
        "returns": "out : ndarray\n    Array interpretation of `a`.  No copy is performed if the input\n    is already an ndarray.  If `a` is a subclass of ndarray, a base\n    class ndarray is returned.",
        "raises": "ValueError\n    Raises ValueError if `a` contains NaN (Not a Number) or Inf (Infinity).",
        "see_also": "asarray : Create and array.\nasanyarray : Similar function which passes through subclasses.\nascontiguousarray : Convert input to a contiguous array.\nasfarray : Convert input to a floating point ndarray.\nasfortranarray : Convert input to an ndarray with column-major\n                 memory order.\nfromiter : Create an array from an iterator.\nfromfunction : Construct an array by executing a function on grid\n               positions.",
        "notes": "",
        "examples": "Convert a list into an array.  If all elements are finite\n``asarray_chkfinite`` is identical to ``asarray``.\n\n>>> a = [1, 2]\n>>> np.asarray_chkfinite(a, dtype=float)\narray([1., 2.])\n\nRaises ValueError if array_like contains Nans or Infs.\n\n>>> a = [1, 2, np.inf]\n>>> try:\n...     np.asarray_chkfinite(a)\n... except ValueError:\n...     print('ValueError')\n...\nValueError"
      }
    },
    {
      "name": "asfarray",
      "signature": "asfarray(a, dtype=<class 'numpy.float64'>)",
      "docstring": {
        "description": "Return an array converted to a float type.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "The input array."
          },
          "dtype": {
            "type": "str or dtype object, optional",
            "description": "Float type code to coerce input array `a`.  If `dtype` is one of the\n    'int' dtypes, it is replaced with float64."
          }
        },
        "returns": "out : ndarray\n    The input `a` as a float ndarray.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ">>> np.asfarray([2, 3])\narray([2.,  3.])\n>>> np.asfarray([2, 3], dtype='float')\narray([2.,  3.])\n>>> np.asfarray([2, 3], dtype='int8')\narray([2.,  3.])"
      }
    },
    {
      "name": "average",
      "signature": "average(a, axis=None, weights=None, returned=False, *, keepdims=<no value>)",
      "docstring": {
        "description": "Compute the weighted average along the specified axis.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Array containing data to be averaged. If `a` is not an array, a\n    conversion is attempted."
          },
          "axis": {
            "type": "None or int or tuple of ints, optional",
            "description": "Axis or axes along which to average `a`.  The default,\n    axis=None, will average over all of the elements of the input array.\n    If axis is negative it counts from the last to the first axis.\n\n    .. versionadded:: 1.7.0\n\n    If axis is a tuple of ints, averaging is performed on all of the axes\n    specified in the tuple instead of a single axis or all the axes as\n    before."
          },
          "weights": {
            "type": "array_like, optional",
            "description": "An array of weights associated with the values in `a`. Each value in\n    `a` contributes to the average according to its associated weight.\n    The weights array can either be 1-D (in which case its length must be\n    the size of `a` along the given axis) or of the same shape as `a`.\n    If `weights=None`, then all data in `a` are assumed to have a\n    weight equal to one.  The 1-D calculation is::\n\n        avg = sum(a * weights) / sum(weights)\n\n    The only constraint on `weights` is that `sum(weights)` must not be 0."
          },
          "returned": {
            "type": "bool, optional",
            "description": "Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)\n    is returned, otherwise only the average is returned.\n    If `weights=None`, `sum_of_weights` is equivalent to the number of\n    elements over which the average is taken."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\n    in the result as dimensions with size one. With this option,\n    the result will broadcast correctly against the original `a`.\n    *Note:* `keepdims` will not work with instances of `numpy.matrix`\n    or other classes whose methods do not support `keepdims`.\n\n    .. versionadded:: 1.23.0"
          }
        },
        "returns": "retval, [sum_of_weights] : array_type or double\n    Return the average along the specified axis. When `returned` is `True`,\n    return a tuple with the average as the first element and the sum\n    of the weights as the second element. `sum_of_weights` is of the\n    same type as `retval`. The result dtype follows a genereal pattern.\n    If `weights` is None, the result dtype will be that of `a` , or ``float64``\n    if `a` is integral. Otherwise, if `weights` is not None and `a` is non-\n    integral, the result type will be the type of lowest precision capable of\n    representing values of both `a` and `weights`. If `a` happens to be\n    integral, the previous rules still applies but the result dtype will\n    at least be ``float64``.",
        "raises": "ZeroDivisionError\n    When all weights along axis are zero. See `numpy.ma.average` for a\n    version robust to this type of error.\nTypeError\n    When the length of 1D `weights` is not the same as the shape of `a`\n    along axis.",
        "see_also": "mean\n\nma.average : average for masked arrays -- useful if your data contains\n             \"missing\" values\nnumpy.result_type : Returns the type that results from applying the\n                    numpy type promotion rules to the arguments.",
        "notes": "",
        "examples": ">>> data = np.arange(1, 5)\n>>> data\narray([1, 2, 3, 4])\n>>> np.average(data)\n2.5\n>>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))\n4.0\n\n>>> data = np.arange(6).reshape((3, 2))\n>>> data\narray([[0, 1],\n       [2, 3],\n       [4, 5]])\n>>> np.average(data, axis=1, weights=[1./4, 3./4])\narray([0.75, 2.75, 4.75])\n>>> np.average(data, weights=[1./4, 3./4])\nTraceback (most recent call last):\n    ...\nTypeError: Axis must be specified when shapes of a and weights differ.\n\n>>> a = np.ones(5, dtype=np.float128)\n>>> w = np.ones(5, dtype=np.complex64)\n>>> avg = np.average(a, weights=w)\n>>> print(avg.dtype)\ncomplex256\n\nWith ``keepdims=True``, the following result has shape (3, 1).\n\n>>> np.average(data, axis=1, keepdims=True)\narray([[0.5],\n       [2.5],\n       [4.5]])"
      }
    },
    {
      "name": "bartlett",
      "signature": "bartlett(M)",
      "docstring": {
        "description": "Return the Bartlett window.\n\nThe Bartlett window is very similar to a triangular window, except\nthat the end points are at zero.  It is often used in signal\nprocessing for tapering a signal, without generating too much\nripple in the frequency domain.",
        "parameters": {
          "M": {
            "type": "int",
            "description": "Number of points in the output window. If zero or less, an\n    empty array is returned."
          }
        },
        "returns": "out : array\n    The triangular window, with the maximum value normalized to one\n    (the value one appears only if the number of samples is odd), with\n    the first and last samples equal to zero.",
        "raises": "",
        "see_also": "blackman, hamming, hanning, kaiser",
        "notes": "The Bartlett window is defined as\n\n.. math:: w(n) = \\frac{2}{M-1} \\left(\n          \\frac{M-1}{2} - \\left|n - \\frac{M-1}{2}\\right|\n          \\right)\n\nMost references to the Bartlett window come from the signal processing\nliterature, where it is used as one of many windowing functions for\nsmoothing values.  Note that convolution with this window produces linear\ninterpolation.  It is also known as an apodization (which means \"removing\nthe foot\", i.e. smoothing discontinuities at the beginning and end of the\nsampled signal) or tapering function. The Fourier transform of the\nBartlett window is the product of two sinc functions. Note the excellent\ndiscussion in Kanasewich [2]_.\n\nReferences\n----------\n.. [1] M.S. Bartlett, \"Periodogram Analysis and Continuous Spectra\",\n       Biometrika 37, 1-16, 1950.\n.. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\",\n       The University of Alberta Press, 1975, pp. 109-110.\n.. [3] A.V. Oppenheim and R.W. Schafer, \"Discrete-Time Signal\n       Processing\", Prentice-Hall, 1999, pp. 468-471.\n.. [4] Wikipedia, \"Window function\",\n       https://en.wikipedia.org/wiki/Window_function\n.. [5] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,\n       \"Numerical Recipes\", Cambridge University Press, 1986, page 429.",
        "examples": ">>> import matplotlib.pyplot as plt\n>>> np.bartlett(12)\narray([ 0.        ,  0.18181818,  0.36363636,  0.54545455,  0.72727273, # may vary\n        0.90909091,  0.90909091,  0.72727273,  0.54545455,  0.36363636,\n        0.18181818,  0.        ])\n\nPlot the window and its frequency response (requires SciPy and matplotlib):\n\n>>> from numpy.fft import fft, fftshift\n>>> window = np.bartlett(51)\n>>> plt.plot(window)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Bartlett window\")\nText(0.5, 1.0, 'Bartlett window')\n>>> plt.ylabel(\"Amplitude\")\nText(0, 0.5, 'Amplitude')\n>>> plt.xlabel(\"Sample\")\nText(0.5, 0, 'Sample')\n>>> plt.show()\n\n>>> plt.figure()\n<Figure size 640x480 with 0 Axes>\n>>> A = fft(window, 2048) / 25.5\n>>> mag = np.abs(fftshift(A))\n>>> freq = np.linspace(-0.5, 0.5, len(A))\n>>> with np.errstate(divide='ignore', invalid='ignore'):\n...     response = 20 * np.log10(mag)\n...\n>>> response = np.clip(response, -100, 100)\n>>> plt.plot(freq, response)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Frequency response of Bartlett window\")\nText(0.5, 1.0, 'Frequency response of Bartlett window')\n>>> plt.ylabel(\"Magnitude [dB]\")\nText(0, 0.5, 'Magnitude [dB]')\n>>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\nText(0.5, 0, 'Normalized frequency [cycles per sample]')\n>>> _ = plt.axis('tight')\n>>> plt.show()"
      }
    },
    {
      "name": "bincount",
      "signature": "bincount(...)",
      "docstring": {
        "description": "bincount(x, /, weights=None, minlength=0)\n\nCount number of occurrences of each value in array of non-negative ints.\n\nThe number of bins (of size 1) is one larger than the largest value in\n`x`. If `minlength` is specified, there will be at least this number\nof bins in the output array (though it will be longer if necessary,\ndepending on the contents of `x`).\nEach bin gives the number of occurrences of its index value in `x`.\nIf `weights` is specified the input array is weighted by it, i.e. if a\nvalue ``n`` is found at position ``i``, ``out[n] += weight[i]`` instead\nof ``out[n] += 1``.",
        "parameters": {
          "x": {
            "type": "array_like, 1 dimension, nonnegative ints",
            "description": "Input array."
          },
          "weights": {
            "type": "array_like, optional",
            "description": "Weights, array of the same shape as `x`."
          },
          "minlength": {
            "type": "int, optional",
            "description": "A minimum number of bins for the output array.\n\n    .. versionadded:: 1.6.0"
          }
        },
        "returns": "out : ndarray of ints\n    The result of binning the input array.\n    The length of `out` is equal to ``np.amax(x)+1``.",
        "raises": "ValueError\n    If the input is not 1-dimensional, or contains elements with negative\n    values, or if `minlength` is negative.\nTypeError\n    If the type of the input is float or complex.",
        "see_also": "histogram, digitize, unique",
        "notes": "",
        "examples": ">>> np.bincount(np.arange(5))\narray([1, 1, 1, 1, 1])\n>>> np.bincount(np.array([0, 1, 1, 3, 2, 1, 7]))\narray([1, 3, 1, 1, 0, 0, 0, 1])\n\n>>> x = np.array([0, 1, 1, 3, 2, 1, 7, 23])\n>>> np.bincount(x).size == np.amax(x)+1\nTrue\n\nThe input array needs to be of integer dtype, otherwise a\nTypeError is raised:\n\n>>> np.bincount(np.arange(5, dtype=float))\nTraceback (most recent call last):\n  ...\nTypeError: Cannot cast array data from dtype('float64') to dtype('int64')\naccording to the rule 'safe'\n\nA possible use of ``bincount`` is to perform sums over\nvariable-size chunks of an array, using the ``weights`` keyword.\n\n>>> w = np.array([0.3, 0.5, 0.2, 0.7, 1., -0.6]) # weights\n>>> x = np.array([0, 1, 1, 2, 2, 2])\n>>> np.bincount(x,  weights=w)\narray([ 0.3,  0.7,  1.1])"
      }
    },
    {
      "name": "blackman",
      "signature": "blackman(M)",
      "docstring": {
        "description": "Return the Blackman window.\n\nThe Blackman window is a taper formed by using the first three\nterms of a summation of cosines. It was designed to have close to the\nminimal leakage possible.  It is close to optimal, only slightly worse\nthan a Kaiser window.",
        "parameters": {
          "M": {
            "type": "int",
            "description": "Number of points in the output window. If zero or less, an empty\n    array is returned."
          }
        },
        "returns": "out : ndarray\n    The window, with the maximum value normalized to one (the value one\n    appears only if the number of samples is odd).",
        "raises": "",
        "see_also": "bartlett, hamming, hanning, kaiser",
        "notes": "The Blackman window is defined as\n\n.. math::  w(n) = 0.42 - 0.5 \\cos(2\\pi n/M) + 0.08 \\cos(4\\pi n/M)\n\nMost references to the Blackman window come from the signal processing\nliterature, where it is used as one of many windowing functions for\nsmoothing values.  It is also known as an apodization (which means\n\"removing the foot\", i.e. smoothing discontinuities at the beginning\nand end of the sampled signal) or tapering function. It is known as a\n\"near optimal\" tapering function, almost as good (by some measures)\nas the kaiser window.\n\nReferences\n----------\nBlackman, R.B. and Tukey, J.W., (1958) The measurement of power spectra,\nDover Publications, New York.\n\nOppenheim, A.V., and R.W. Schafer. Discrete-Time Signal Processing.\nUpper Saddle River, NJ: Prentice-Hall, 1999, pp. 468-471.",
        "examples": ">>> import matplotlib.pyplot as plt\n>>> np.blackman(12)\narray([-1.38777878e-17,   3.26064346e-02,   1.59903635e-01, # may vary\n        4.14397981e-01,   7.36045180e-01,   9.67046769e-01,\n        9.67046769e-01,   7.36045180e-01,   4.14397981e-01,\n        1.59903635e-01,   3.26064346e-02,  -1.38777878e-17])\n\nPlot the window and the frequency response:\n\n>>> from numpy.fft import fft, fftshift\n>>> window = np.blackman(51)\n>>> plt.plot(window)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Blackman window\")\nText(0.5, 1.0, 'Blackman window')\n>>> plt.ylabel(\"Amplitude\")\nText(0, 0.5, 'Amplitude')\n>>> plt.xlabel(\"Sample\")\nText(0.5, 0, 'Sample')\n>>> plt.show()\n\n>>> plt.figure()\n<Figure size 640x480 with 0 Axes>\n>>> A = fft(window, 2048) / 25.5\n>>> mag = np.abs(fftshift(A))\n>>> freq = np.linspace(-0.5, 0.5, len(A))\n>>> with np.errstate(divide='ignore', invalid='ignore'):\n...     response = 20 * np.log10(mag)\n...\n>>> response = np.clip(response, -100, 100)\n>>> plt.plot(freq, response)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Frequency response of Blackman window\")\nText(0.5, 1.0, 'Frequency response of Blackman window')\n>>> plt.ylabel(\"Magnitude [dB]\")\nText(0, 0.5, 'Magnitude [dB]')\n>>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\nText(0.5, 0, 'Normalized frequency [cycles per sample]')\n>>> _ = plt.axis('tight')\n>>> plt.show()"
      }
    },
    {
      "name": "broadcast_arrays",
      "signature": "broadcast_arrays(*args, subok=False)",
      "docstring": {
        "description": "Broadcast any number of arrays against each other.",
        "parameters": {
          "`*args`": {
            "type": "array_likes",
            "description": "The arrays to broadcast."
          },
          "subok": {
            "type": "bool, optional",
            "description": "If True, then sub-classes will be passed-through, otherwise\n    the returned arrays will be forced to be a base-class array (default)."
          }
        },
        "returns": "broadcasted : list of arrays\n    These arrays are views on the original arrays.  They are typically\n    not contiguous.  Furthermore, more than one element of a\n    broadcasted array may refer to a single memory location. If you need\n    to write to the arrays, make copies first. While you can set the\n    ``writable`` flag True, writing to a single output value may end up\n    changing more than one location in the output array.\n\n    .. deprecated:: 1.17\n        The output is currently marked so that if written to, a deprecation\n        warning will be emitted. A future version will set the\n        ``writable`` flag False so writing to it will raise an error.",
        "raises": "",
        "see_also": "broadcast\nbroadcast_to\nbroadcast_shapes",
        "notes": "",
        "examples": ">>> x = np.array([[1,2,3]])\n>>> y = np.array([[4],[5]])\n>>> np.broadcast_arrays(x, y)\n[array([[1, 2, 3],\n       [1, 2, 3]]), array([[4, 4, 4],\n       [5, 5, 5]])]\n\nHere is a useful idiom for getting contiguous copies instead of\nnon-contiguous views.\n\n>>> [np.array(a) for a in np.broadcast_arrays(x, y)]\n[array([[1, 2, 3],\n       [1, 2, 3]]), array([[4, 4, 4],\n       [5, 5, 5]])]"
      }
    },
    {
      "name": "broadcast_shapes",
      "signature": "broadcast_shapes(*args)",
      "docstring": {
        "description": "Broadcast the input shapes into a single shape.\n\n:ref:`Learn more about broadcasting here <basics.broadcasting>`.\n\n.. versionadded:: 1.20.0",
        "parameters": {
          "`*args`": {
            "type": "tuples of ints, or ints",
            "description": "The shapes to be broadcast against each other."
          }
        },
        "returns": "tuple\n    Broadcasted shape.",
        "raises": "ValueError\n    If the shapes are not compatible and cannot be broadcast according\n    to NumPy's broadcasting rules.",
        "see_also": "broadcast\nbroadcast_arrays\nbroadcast_to",
        "notes": "",
        "examples": ">>> np.broadcast_shapes((1, 2), (3, 1), (3, 2))\n(3, 2)\n\n>>> np.broadcast_shapes((6, 7), (5, 6, 1), (7,), (5, 1, 7))\n(5, 6, 7)"
      }
    },
    {
      "name": "broadcast_to",
      "signature": "broadcast_to(array, shape, subok=False)",
      "docstring": {
        "description": "Broadcast an array to a new shape.",
        "parameters": {
          "array": {
            "type": "array_like",
            "description": "The array to broadcast."
          },
          "shape": {
            "type": "tuple or int",
            "description": "The shape of the desired array. A single integer ``i`` is interpreted\n    as ``(i,)``."
          },
          "subok": {
            "type": "bool, optional",
            "description": "If True, then sub-classes will be passed-through, otherwise\n    the returned array will be forced to be a base-class array (default)."
          }
        },
        "returns": "broadcast : array\n    A readonly view on the original array with the given shape. It is\n    typically not contiguous. Furthermore, more than one element of a\n    broadcasted array may refer to a single memory location.",
        "raises": "ValueError\n    If the array is not compatible with the new shape according to NumPy's\n    broadcasting rules.",
        "see_also": "broadcast\nbroadcast_arrays\nbroadcast_shapes",
        "notes": ".. versionadded:: 1.10.0",
        "examples": ">>> x = np.array([1, 2, 3])\n>>> np.broadcast_to(x, (3, 3))\narray([[1, 2, 3],\n       [1, 2, 3],\n       [1, 2, 3]])"
      }
    },
    {
      "name": "byte_bounds",
      "signature": "byte_bounds(a)",
      "docstring": {
        "description": "Returns pointers to the end-points of an array.",
        "parameters": {
          "a": {
            "type": "ndarray",
            "description": "Input array. It must conform to the Python-side of the array\n    interface."
          }
        },
        "returns": "(low, high) : tuple of 2 integers\n    The first integer is the first byte of the array, the second\n    integer is just past the last byte of the array.  If `a` is not\n    contiguous it will not use every byte between the (`low`, `high`)\n    values.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ">>> I = np.eye(2, dtype='f'); I.dtype\ndtype('float32')\n>>> low, high = np.byte_bounds(I)\n>>> high - low == I.size*I.itemsize\nTrue\n>>> I = np.eye(2); I.dtype\ndtype('float64')\n>>> low, high = np.byte_bounds(I)\n>>> high - low == I.size*I.itemsize\nTrue"
      }
    },
    {
      "name": "column_stack",
      "signature": "column_stack(tup)",
      "docstring": {
        "description": "Stack 1-D arrays as columns into a 2-D array.\n\nTake a sequence of 1-D arrays and stack them as columns\nto make a single 2-D array. 2-D arrays are stacked as-is,\njust like with `hstack`.  1-D arrays are turned into 2-D columns\nfirst.",
        "parameters": {
          "tup": {
            "type": "sequence of 1-D or 2-D arrays.",
            "description": "Arrays to stack. All of them must have the same first dimension."
          }
        },
        "returns": "stacked : 2-D array\n    The array formed by stacking the given arrays.",
        "raises": "",
        "see_also": "stack, hstack, vstack, concatenate",
        "notes": "",
        "examples": ">>> a = np.array((1,2,3))\n>>> b = np.array((2,3,4))\n>>> np.column_stack((a,b))\narray([[1, 2],\n       [2, 3],\n       [3, 4]])"
      }
    },
    {
      "name": "common_type",
      "signature": "common_type(*arrays)",
      "docstring": {
        "description": "Return a scalar type which is common to the input arrays.\n\nThe return type will always be an inexact (i.e. floating point) scalar\ntype, even if all the arrays are integer arrays. If one of the inputs is\nan integer array, the minimum precision type that is returned is a\n64-bit floating point dtype.\n\nAll input arrays except int64 and uint64 can be safely cast to the\nreturned dtype without loss of information.",
        "parameters": {},
        "returns": "out : data type code\n    Data type code.",
        "raises": "",
        "see_also": "dtype, mintypecode",
        "notes": "",
        "examples": ">>> np.common_type(np.arange(2, dtype=np.float32))\n<class 'numpy.float32'>\n>>> np.common_type(np.arange(2, dtype=np.float32), np.arange(2))\n<class 'numpy.float64'>\n>>> np.common_type(np.arange(4), np.array([45, 6.j]), np.array([45.0]))\n<class 'numpy.complex128'>"
      }
    },
    {
      "name": "copy",
      "signature": "copy(a, order='K', subok=False)",
      "docstring": {
        "description": "Return an array copy of the given object.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input data."
          },
          "order": {
            "type": "{'C', 'F', 'A', 'K'}, optional",
            "description": "Controls the memory layout of the copy. 'C' means C-order,\n    'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,\n    'C' otherwise. 'K' means match the layout of `a` as closely\n    as possible. (Note that this function and :meth:`ndarray.copy` are very\n    similar, but have different default values for their order=\n    arguments.)"
          },
          "subok": {
            "type": "bool, optional",
            "description": "If True, then sub-classes will be passed-through, otherwise the\n    returned array will be forced to be a base-class array (defaults to False).\n\n    .. versionadded:: 1.19.0"
          }
        },
        "returns": "arr : ndarray\n    Array interpretation of `a`.",
        "raises": "",
        "see_also": "ndarray.copy : Preferred method for creating an array copy",
        "notes": "This is equivalent to:\n\n>>> np.array(a, copy=True)  #doctest: +SKIP",
        "examples": "Create an array x, with a reference y and a copy z:\n\n>>> x = np.array([1, 2, 3])\n>>> y = x\n>>> z = np.copy(x)\n\nNote that, when we modify x, y changes, but not z:\n\n>>> x[0] = 10\n>>> x[0] == y[0]\nTrue\n>>> x[0] == z[0]\nFalse\n\nNote that, np.copy clears previously set WRITEABLE=False flag.\n\n>>> a = np.array([1, 2, 3])\n>>> a.flags[\"WRITEABLE\"] = False\n>>> b = np.copy(a)\n>>> b.flags[\"WRITEABLE\"]\nTrue\n>>> b[0] = 3\n>>> b\narray([3, 2, 3])\n\nNote that np.copy is a shallow copy and will not copy object\nelements within arrays. This is mainly important for arrays\ncontaining Python objects. The new array will contain the\nsame object which may lead to surprises if that object can\nbe modified (is mutable):\n\n>>> a = np.array([1, 'm', [2, 3, 4]], dtype=object)\n>>> b = np.copy(a)\n>>> b[2][0] = 10\n>>> a\narray([1, 'm', list([10, 3, 4])], dtype=object)\n\nTo ensure all elements within an ``object`` array are copied,\nuse `copy.deepcopy`:\n\n>>> import copy\n>>> a = np.array([1, 'm', [2, 3, 4]], dtype=object)\n>>> c = copy.deepcopy(a)\n>>> c[2][0] = 10\n>>> c\narray([1, 'm', list([10, 3, 4])], dtype=object)\n>>> a\narray([1, 'm', list([2, 3, 4])], dtype=object)"
      }
    },
    {
      "name": "corrcoef",
      "signature": "corrcoef(x, y=None, rowvar=True, bias=<no value>, ddof=<no value>, *, dtype=None)",
      "docstring": {
        "description": "Return Pearson product-moment correlation coefficients.\n\nPlease refer to the documentation for `cov` for more detail.  The\nrelationship between the correlation coefficient matrix, `R`, and the\ncovariance matrix, `C`, is\n\n.. math:: R_{ij} = \\frac{ C_{ij} } { \\sqrt{ C_{ii} C_{jj} } }\n\nThe values of `R` are between -1 and 1, inclusive.",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "A 1-D or 2-D array containing multiple variables and observations.\n    Each row of `x` represents a variable, and each column a single\n    observation of all those variables. Also see `rowvar` below."
          },
          "y": {
            "type": "array_like, optional",
            "description": "An additional set of variables and observations. `y` has the same\n    shape as `x`."
          },
          "rowvar": {
            "type": "bool, optional",
            "description": "If `rowvar` is True (default), then each row represents a\n    variable, with observations in the columns. Otherwise, the relationship\n    is transposed: each column represents a variable, while the rows\n    contain observations."
          },
          "bias": {
            "type": "_NoValue, optional",
            "description": "Has no effect, do not use.\n\n    .. deprecated:: 1.10.0"
          },
          "ddof": {
            "type": "_NoValue, optional",
            "description": "Has no effect, do not use.\n\n    .. deprecated:: 1.10.0"
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "Data-type of the result. By default, the return data-type will have\n    at least `numpy.float64` precision.\n\n    .. versionadded:: 1.20"
          }
        },
        "returns": "R : ndarray\n    The correlation coefficient matrix of the variables.",
        "raises": "",
        "see_also": "cov : Covariance matrix",
        "notes": "Due to floating point rounding the resulting array may not be Hermitian,\nthe diagonal elements may not be 1, and the elements may not satisfy the\ninequality abs(a) <= 1. The real and imaginary parts are clipped to the\ninterval [-1,  1] in an attempt to improve on that situation but is not\nmuch help in the complex case.\n\nThis function accepts but discards arguments `bias` and `ddof`.  This is\nfor backwards compatibility with previous versions of this function.  These\narguments had no effect on the return values of the function and can be\nsafely ignored in this and previous versions of numpy.",
        "examples": "In this example we generate two random arrays, ``xarr`` and ``yarr``, and\ncompute the row-wise and column-wise Pearson correlation coefficients,\n``R``. Since ``rowvar`` is  true by  default, we first find the row-wise\nPearson correlation coefficients between the variables of ``xarr``.\n\n>>> import numpy as np\n>>> rng = np.random.default_rng(seed=42)\n>>> xarr = rng.random((3, 3))\n>>> xarr\narray([[0.77395605, 0.43887844, 0.85859792],\n       [0.69736803, 0.09417735, 0.97562235],\n       [0.7611397 , 0.78606431, 0.12811363]])\n>>> R1 = np.corrcoef(xarr)\n>>> R1\narray([[ 1.        ,  0.99256089, -0.68080986],\n       [ 0.99256089,  1.        , -0.76492172],\n       [-0.68080986, -0.76492172,  1.        ]])\n\nIf we add another set of variables and observations ``yarr``, we can\ncompute the row-wise Pearson correlation coefficients between the\nvariables in ``xarr`` and ``yarr``.\n\n>>> yarr = rng.random((3, 3))\n>>> yarr\narray([[0.45038594, 0.37079802, 0.92676499],\n       [0.64386512, 0.82276161, 0.4434142 ],\n       [0.22723872, 0.55458479, 0.06381726]])\n>>> R2 = np.corrcoef(xarr, yarr)\n>>> R2\narray([[ 1.        ,  0.99256089, -0.68080986,  0.75008178, -0.934284  ,\n        -0.99004057],\n       [ 0.99256089,  1.        , -0.76492172,  0.82502011, -0.97074098,\n        -0.99981569],\n       [-0.68080986, -0.76492172,  1.        , -0.99507202,  0.89721355,\n         0.77714685],\n       [ 0.75008178,  0.82502011, -0.99507202,  1.        , -0.93657855,\n        -0.83571711],\n       [-0.934284  , -0.97074098,  0.89721355, -0.93657855,  1.        ,\n         0.97517215],\n       [-0.99004057, -0.99981569,  0.77714685, -0.83571711,  0.97517215,\n         1.        ]])\n\nFinally if we use the option ``rowvar=False``, the columns are now\nbeing treated as the variables and we will find the column-wise Pearson\ncorrelation coefficients between variables in ``xarr`` and ``yarr``.\n\n>>> R3 = np.corrcoef(xarr, yarr, rowvar=False)\n>>> R3\narray([[ 1.        ,  0.77598074, -0.47458546, -0.75078643, -0.9665554 ,\n         0.22423734],\n       [ 0.77598074,  1.        , -0.92346708, -0.99923895, -0.58826587,\n        -0.44069024],\n       [-0.47458546, -0.92346708,  1.        ,  0.93773029,  0.23297648,\n         0.75137473],\n       [-0.75078643, -0.99923895,  0.93773029,  1.        ,  0.55627469,\n         0.47536961],\n       [-0.9665554 , -0.58826587,  0.23297648,  0.55627469,  1.        ,\n        -0.46666491],\n       [ 0.22423734, -0.44069024,  0.75137473,  0.47536961, -0.46666491,\n         1.        ]])"
      }
    },
    {
      "name": "cov",
      "signature": "cov(m, y=None, rowvar=True, bias=False, ddof=None, fweights=None, aweights=None, *, dtype=None)",
      "docstring": {
        "description": "Estimate a covariance matrix, given data and weights.\n\nCovariance indicates the level to which two variables vary together.\nIf we examine N-dimensional samples, :math:`X = [x_1, x_2, ... x_N]^T`,\nthen the covariance matrix element :math:`C_{ij}` is the covariance of\n:math:`x_i` and :math:`x_j`. The element :math:`C_{ii}` is the variance\nof :math:`x_i`.\n\nSee the notes for an outline of the algorithm.",
        "parameters": {
          "m": {
            "type": "array_like",
            "description": "A 1-D or 2-D array containing multiple variables and observations.\n    Each row of `m` represents a variable, and each column a single\n    observation of all those variables. Also see `rowvar` below."
          },
          "y": {
            "type": "array_like, optional",
            "description": "An additional set of variables and observations. `y` has the same form\n    as that of `m`."
          },
          "rowvar": {
            "type": "bool, optional",
            "description": "If `rowvar` is True (default), then each row represents a\n    variable, with observations in the columns. Otherwise, the relationship\n    is transposed: each column represents a variable, while the rows\n    contain observations."
          },
          "bias": {
            "type": "bool, optional",
            "description": "Default normalization (False) is by ``(N - 1)``, where ``N`` is the\n    number of observations given (unbiased estimate). If `bias` is True,\n    then normalization is by ``N``. These values can be overridden by using\n    the keyword ``ddof`` in numpy versions >= 1.5."
          },
          "ddof": {
            "type": "int, optional",
            "description": "If not ``None`` the default value implied by `bias` is overridden.\n    Note that ``ddof=1`` will return the unbiased estimate, even if both\n    `fweights` and `aweights` are specified, and ``ddof=0`` will return\n    the simple average. See the notes for the details. The default value\n    is ``None``.\n\n    .. versionadded:: 1.5"
          },
          "fweights": {
            "type": "array_like, int, optional",
            "description": "1-D array of integer frequency weights; the number of times each\n    observation vector should be repeated.\n\n    .. versionadded:: 1.10"
          },
          "aweights": {
            "type": "array_like, optional",
            "description": "1-D array of observation vector weights. These relative weights are\n    typically large for observations considered \"important\" and smaller for\n    observations considered less \"important\". If ``ddof=0`` the array of\n    weights can be used to assign probabilities to observation vectors.\n\n    .. versionadded:: 1.10"
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "Data-type of the result. By default, the return data-type will have\n    at least `numpy.float64` precision.\n\n    .. versionadded:: 1.20"
          }
        },
        "returns": "out : ndarray\n    The covariance matrix of the variables.",
        "raises": "",
        "see_also": "corrcoef : Normalized covariance matrix",
        "notes": "Assume that the observations are in the columns of the observation\narray `m` and let ``f = fweights`` and ``a = aweights`` for brevity. The\nsteps to compute the weighted covariance are as follows::\n\n    >>> m = np.arange(10, dtype=np.float64)\n    >>> f = np.arange(10) * 2\n    >>> a = np.arange(10) ** 2.\n    >>> ddof = 1\n    >>> w = f * a\n    >>> v1 = np.sum(w)\n    >>> v2 = np.sum(w * a)\n    >>> m -= np.sum(m * w, axis=None, keepdims=True) / v1\n    >>> cov = np.dot(m * w, m.T) * v1 / (v1**2 - ddof * v2)\n\nNote that when ``a == 1``, the normalization factor\n``v1 / (v1**2 - ddof * v2)`` goes over to ``1 / (np.sum(f) - ddof)``\nas it should.",
        "examples": "Consider two variables, :math:`x_0` and :math:`x_1`, which\ncorrelate perfectly, but in opposite directions:\n\n>>> x = np.array([[0, 2], [1, 1], [2, 0]]).T\n>>> x\narray([[0, 1, 2],\n       [2, 1, 0]])\n\nNote how :math:`x_0` increases while :math:`x_1` decreases. The covariance\nmatrix shows this clearly:\n\n>>> np.cov(x)\narray([[ 1., -1.],\n       [-1.,  1.]])\n\nNote that element :math:`C_{0,1}`, which shows the correlation between\n:math:`x_0` and :math:`x_1`, is negative.\n\nFurther, note how `x` and `y` are combined:\n\n>>> x = [-2.1, -1,  4.3]\n>>> y = [3,  1.1,  0.12]\n>>> X = np.stack((x, y), axis=0)\n>>> np.cov(X)\narray([[11.71      , -4.286     ], # may vary\n       [-4.286     ,  2.144133]])\n>>> np.cov(x, y)\narray([[11.71      , -4.286     ], # may vary\n       [-4.286     ,  2.144133]])\n>>> np.cov(x)\narray(11.71)"
      }
    },
    {
      "name": "delete",
      "signature": "delete(arr, obj, axis=None)",
      "docstring": {
        "description": "Return a new array with sub-arrays along an axis deleted. For a one\ndimensional array, this returns those entries not returned by\n`arr[obj]`.",
        "parameters": {
          "arr": {
            "type": "array_like",
            "description": "Input array."
          },
          "obj": {
            "type": "slice, int or array of ints",
            "description": "Indicate indices of sub-arrays to remove along the specified axis.\n\n    .. versionchanged:: 1.19.0\n        Boolean indices are now treated as a mask of elements to remove,\n        rather than being cast to the integers 0 and 1."
          },
          "axis": {
            "type": "int, optional",
            "description": "The axis along which to delete the subarray defined by `obj`.\n    If `axis` is None, `obj` is applied to the flattened array."
          }
        },
        "returns": "out : ndarray\n    A copy of `arr` with the elements specified by `obj` removed. Note\n    that `delete` does not occur in-place. If `axis` is None, `out` is\n    a flattened array.",
        "raises": "",
        "see_also": "insert : Insert elements into an array.\nappend : Append elements at the end of an array.",
        "notes": "Often it is preferable to use a boolean mask. For example:\n\n>>> arr = np.arange(12) + 1\n>>> mask = np.ones(len(arr), dtype=bool)\n>>> mask[[0,2,4]] = False\n>>> result = arr[mask,...]\n\nIs equivalent to ``np.delete(arr, [0,2,4], axis=0)``, but allows further\nuse of `mask`.",
        "examples": ">>> arr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n>>> arr\narray([[ 1,  2,  3,  4],\n       [ 5,  6,  7,  8],\n       [ 9, 10, 11, 12]])\n>>> np.delete(arr, 1, 0)\narray([[ 1,  2,  3,  4],\n       [ 9, 10, 11, 12]])\n\n>>> np.delete(arr, np.s_[::2], 1)\narray([[ 2,  4],\n       [ 6,  8],\n       [10, 12]])\n>>> np.delete(arr, [1,3,5], None)\narray([ 1,  3,  5,  7,  8,  9, 10, 11, 12])"
      }
    },
    {
      "name": "deprecate",
      "signature": "deprecate(*args, **kwargs)",
      "docstring": {
        "description": "Issues a DeprecationWarning, adds warning to `old_name`'s\ndocstring, rebinds ``old_name.__name__`` and returns the new\nfunction object.\n\nThis function may also be used as a decorator.",
        "parameters": {
          "func": {
            "type": "function",
            "description": "The function to be deprecated."
          },
          "old_name": {
            "type": "str, optional",
            "description": "The name of the function to be deprecated. Default is None, in\n    which case the name of `func` is used."
          },
          "new_name": {
            "type": "str, optional",
            "description": "The new name for the function. Default is None, in which case the\n    deprecation message is that `old_name` is deprecated. If given, the\n    deprecation message is that `old_name` is deprecated and `new_name`\n    should be used instead."
          },
          "message": {
            "type": "str, optional",
            "description": "Additional explanation of the deprecation.  Displayed in the\n    docstring after the warning."
          }
        },
        "returns": "old_func : function\n    The deprecated function.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "Note that ``olduint`` returns a value after printing Deprecation\nWarning:\n\n>>> olduint = np.deprecate(np.uint)\nDeprecationWarning: `uint64` is deprecated! # may vary\n>>> olduint(6)\n6"
      }
    },
    {
      "name": "deprecate_with_doc",
      "signature": "deprecate_with_doc(msg)",
      "docstring": {
        "description": "Deprecates a function and includes the deprecation in its docstring.\n\nThis function is used as a decorator. It returns an object that can be\nused to issue a DeprecationWarning, by passing the to-be decorated\nfunction as argument, this adds warning to the to-be decorated function's\ndocstring and returns the new function object.",
        "parameters": {
          "msg": {
            "type": "str",
            "description": "Additional explanation of the deprecation. Displayed in the\n    docstring after the warning."
          }
        },
        "returns": "obj : object",
        "raises": "",
        "see_also": "deprecate : Decorate a function such that it issues a `DeprecationWarning`",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "diag",
      "signature": "diag(v, k=0)",
      "docstring": {
        "description": "Extract a diagonal or construct a diagonal array.\n\nSee the more detailed documentation for ``numpy.diagonal`` if you use this\nfunction to extract a diagonal and wish to write to the resulting array;\nwhether it returns a copy or a view depends on what version of numpy you\nare using.",
        "parameters": {
          "v": {
            "type": "array_like",
            "description": "If `v` is a 2-D array, return a copy of its `k`-th diagonal.\n    If `v` is a 1-D array, return a 2-D array with `v` on the `k`-th\n    diagonal."
          },
          "k": {
            "type": "int, optional",
            "description": "Diagonal in question. The default is 0. Use `k>0` for diagonals\n    above the main diagonal, and `k<0` for diagonals below the main\n    diagonal."
          }
        },
        "returns": "out : ndarray\n    The extracted diagonal or constructed diagonal array.",
        "raises": "",
        "see_also": "diagonal : Return specified diagonals.\ndiagflat : Create a 2-D array with the flattened input as a diagonal.\ntrace : Sum along diagonals.\ntriu : Upper triangle of an array.\ntril : Lower triangle of an array.",
        "notes": "",
        "examples": ">>> x = np.arange(9).reshape((3,3))\n>>> x\narray([[0, 1, 2],\n       [3, 4, 5],\n       [6, 7, 8]])\n\n>>> np.diag(x)\narray([0, 4, 8])\n>>> np.diag(x, k=1)\narray([1, 5])\n>>> np.diag(x, k=-1)\narray([3, 7])\n\n>>> np.diag(np.diag(x))\narray([[0, 0, 0],\n       [0, 4, 0],\n       [0, 0, 8]])"
      }
    },
    {
      "name": "diag_indices",
      "signature": "diag_indices(n, ndim=2)",
      "docstring": {
        "description": "Return the indices to access the main diagonal of an array.\n\nThis returns a tuple of indices that can be used to access the main\ndiagonal of an array `a` with ``a.ndim >= 2`` dimensions and shape\n(n, n, ..., n). For ``a.ndim = 2`` this is the usual diagonal, for\n``a.ndim > 2`` this is the set of indices to access ``a[i, i, ..., i]``\nfor ``i = [0..n-1]``.",
        "parameters": {
          "n": {
            "type": "int",
            "description": "The size, along each dimension, of the arrays for which the returned\n  indices can be used."
          },
          "ndim": {
            "type": "int, optional",
            "description": "The number of dimensions."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "diag_indices_from",
        "notes": ".. versionadded:: 1.4.0",
        "examples": "Create a set of indices to access the diagonal of a (4, 4) array:\n\n>>> di = np.diag_indices(4)\n>>> di\n(array([0, 1, 2, 3]), array([0, 1, 2, 3]))\n>>> a = np.arange(16).reshape(4, 4)\n>>> a\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11],\n       [12, 13, 14, 15]])\n>>> a[di] = 100\n>>> a\narray([[100,   1,   2,   3],\n       [  4, 100,   6,   7],\n       [  8,   9, 100,  11],\n       [ 12,  13,  14, 100]])\n\nNow, we create indices to manipulate a 3-D array:\n\n>>> d3 = np.diag_indices(2, 3)\n>>> d3\n(array([0, 1]), array([0, 1]), array([0, 1]))\n\nAnd use it to set the diagonal of an array of zeros to 1:\n\n>>> a = np.zeros((2, 2, 2), dtype=int)\n>>> a[d3] = 1\n>>> a\narray([[[1, 0],\n        [0, 0]],\n       [[0, 0],\n        [0, 1]]])"
      }
    },
    {
      "name": "diag_indices_from",
      "signature": "diag_indices_from(arr)",
      "docstring": {
        "description": "Return the indices to access the main diagonal of an n-dimensional array.\n\nSee `diag_indices` for full details.",
        "parameters": {
          "arr": {
            "type": "array, at least 2-D",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "diag_indices",
        "notes": ".. versionadded:: 1.4.0",
        "examples": "Create a 4 by 4 array.\n\n>>> a = np.arange(16).reshape(4, 4)\n>>> a\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11],\n       [12, 13, 14, 15]])\n\nGet the indices of the diagonal elements.\n\n>>> di = np.diag_indices_from(a)\n>>> di\n(array([0, 1, 2, 3]), array([0, 1, 2, 3]))\n\n>>> a[di]\narray([ 0,  5, 10, 15])\n\nThis is simply syntactic sugar for diag_indices.\n\n>>> np.diag_indices(a.shape[0])\n(array([0, 1, 2, 3]), array([0, 1, 2, 3]))"
      }
    },
    {
      "name": "diagflat",
      "signature": "diagflat(v, k=0)",
      "docstring": {
        "description": "Create a two-dimensional array with the flattened input as a diagonal.",
        "parameters": {
          "v": {
            "type": "array_like",
            "description": "Input data, which is flattened and set as the `k`-th\n    diagonal of the output."
          },
          "k": {
            "type": "int, optional",
            "description": "Diagonal to set; 0, the default, corresponds to the \"main\" diagonal,\n    a positive (negative) `k` giving the number of the diagonal above\n    (below) the main."
          }
        },
        "returns": "out : ndarray\n    The 2-D output array.",
        "raises": "",
        "see_also": "diag : MATLAB work-alike for 1-D and 2-D arrays.\ndiagonal : Return specified diagonals.\ntrace : Sum along diagonals.",
        "notes": "",
        "examples": ">>> np.diagflat([[1,2], [3,4]])\narray([[1, 0, 0, 0],\n       [0, 2, 0, 0],\n       [0, 0, 3, 0],\n       [0, 0, 0, 4]])\n\n>>> np.diagflat([1,2], 1)\narray([[0, 1, 0],\n       [0, 0, 2],\n       [0, 0, 0]])"
      }
    },
    {
      "name": "diff",
      "signature": "diff(a, n=1, axis=-1, prepend=<no value>, append=<no value>)",
      "docstring": {
        "description": "Calculate the n-th discrete difference along the given axis.\n\nThe first difference is given by ``out[i] = a[i+1] - a[i]`` along\nthe given axis, higher differences are calculated by using `diff`\nrecursively.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array"
          },
          "n": {
            "type": "int, optional",
            "description": "The number of times values are differenced. If zero, the input\n    is returned as-is."
          },
          "axis": {
            "type": "int, optional",
            "description": "The axis along which the difference is taken, default is the\n    last axis.\nprepend, append : array_like, optional\n    Values to prepend or append to `a` along axis prior to\n    performing the difference.  Scalar values are expanded to\n    arrays with length 1 in the direction of axis and the shape\n    of the input array in along all other axes.  Otherwise the\n    dimension and shape must match `a` except along axis.\n\n    .. versionadded:: 1.16.0"
          }
        },
        "returns": "diff : ndarray\n    The n-th differences. The shape of the output is the same as `a`\n    except along `axis` where the dimension is smaller by `n`. The\n    type of the output is the same as the type of the difference\n    between any two elements of `a`. This is the same as the type of\n    `a` in most cases. A notable exception is `datetime64`, which\n    results in a `timedelta64` output array.",
        "raises": "",
        "see_also": "gradient, ediff1d, cumsum",
        "notes": "Type is preserved for boolean arrays, so the result will contain\n`False` when consecutive elements are the same and `True` when they\ndiffer.\n\nFor unsigned integer arrays, the results will also be unsigned. This\nshould not be surprising, as the result is consistent with\ncalculating the difference directly:\n\n>>> u8_arr = np.array([1, 0], dtype=np.uint8)\n>>> np.diff(u8_arr)\narray([255], dtype=uint8)\n>>> u8_arr[1,...] - u8_arr[0,...]\n255\n\nIf this is not desirable, then the array should be cast to a larger\ninteger type first:\n\n>>> i16_arr = u8_arr.astype(np.int16)\n>>> np.diff(i16_arr)\narray([-1], dtype=int16)",
        "examples": ">>> x = np.array([1, 2, 4, 7, 0])\n>>> np.diff(x)\narray([ 1,  2,  3, -7])\n>>> np.diff(x, n=2)\narray([  1,   1, -10])\n\n>>> x = np.array([[1, 3, 6, 10], [0, 5, 6, 8]])\n>>> np.diff(x)\narray([[2, 3, 4],\n       [5, 1, 2]])\n>>> np.diff(x, axis=0)\narray([[-1,  2,  0, -2]])\n\n>>> x = np.arange('1066-10-13', '1066-10-16', dtype=np.datetime64)\n>>> np.diff(x)\narray([1, 1], dtype='timedelta64[D]')"
      }
    },
    {
      "name": "digitize",
      "signature": "digitize(x, bins, right=False)",
      "docstring": {
        "description": "Return the indices of the bins to which each value in input array belongs.\n\n=========  =============  ============================\n`right`    order of bins  returned index `i` satisfies\n=========  =============  ============================\n``False``  increasing     ``bins[i-1] <= x < bins[i]``\n``True``   increasing     ``bins[i-1] < x <= bins[i]``\n``False``  decreasing     ``bins[i-1] > x >= bins[i]``\n``True``   decreasing     ``bins[i-1] >= x > bins[i]``\n=========  =============  ============================\n\nIf values in `x` are beyond the bounds of `bins`, 0 or ``len(bins)`` is\nreturned as appropriate.",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "Input array to be binned. Prior to NumPy 1.10.0, this array had to\n    be 1-dimensional, but can now have any shape."
          },
          "bins": {
            "type": "array_like",
            "description": "Array of bins. It has to be 1-dimensional and monotonic."
          },
          "right": {
            "type": "bool, optional",
            "description": "Indicating whether the intervals include the right or the left bin\n    edge. Default behavior is (right==False) indicating that the interval\n    does not include the right edge. The left bin end is open in this\n    case, i.e., bins[i-1] <= x < bins[i] is the default behavior for\n    monotonically increasing bins."
          }
        },
        "returns": "indices : ndarray of ints\n    Output array of indices, of same shape as `x`.",
        "raises": "ValueError\n    If `bins` is not monotonic.\nTypeError\n    If the type of the input is complex.",
        "see_also": "bincount, histogram, unique, searchsorted",
        "notes": "If values in `x` are such that they fall outside the bin range,\nattempting to index `bins` with the indices that `digitize` returns\nwill result in an IndexError.\n\n.. versionadded:: 1.10.0\n\n`np.digitize` is  implemented in terms of `np.searchsorted`. This means\nthat a binary search is used to bin the values, which scales much better\nfor larger number of bins than the previous linear search. It also removes\nthe requirement for the input array to be 1-dimensional.\n\nFor monotonically _increasing_ `bins`, the following are equivalent::\n\n    np.digitize(x, bins, right=True)\n    np.searchsorted(bins, x, side='left')\n\nNote that as the order of the arguments are reversed, the side must be too.\nThe `searchsorted` call is marginally faster, as it does not do any\nmonotonicity checks. Perhaps more importantly, it supports all dtypes.",
        "examples": ">>> x = np.array([0.2, 6.4, 3.0, 1.6])\n>>> bins = np.array([0.0, 1.0, 2.5, 4.0, 10.0])\n>>> inds = np.digitize(x, bins)\n>>> inds\narray([1, 4, 3, 2])\n>>> for n in range(x.size):\n...   print(bins[inds[n]-1], \"<=\", x[n], \"<\", bins[inds[n]])\n...\n0.0 <= 0.2 < 1.0\n4.0 <= 6.4 < 10.0\n2.5 <= 3.0 < 4.0\n1.0 <= 1.6 < 2.5\n\n>>> x = np.array([1.2, 10.0, 12.4, 15.5, 20.])\n>>> bins = np.array([0, 5, 10, 15, 20])\n>>> np.digitize(x,bins,right=True)\narray([1, 2, 3, 4, 4])\n>>> np.digitize(x,bins,right=False)\narray([1, 3, 3, 4, 5])"
      }
    },
    {
      "name": "disp",
      "signature": "disp(mesg, device=None, linefeed=True)",
      "docstring": {
        "description": "Display a message on a device.",
        "parameters": {
          "mesg": {
            "type": "str",
            "description": "Message to display."
          },
          "device": {
            "type": "object",
            "description": "Device to write message. If None, defaults to ``sys.stdout`` which is\n    very similar to ``print``. `device` needs to have ``write()`` and\n    ``flush()`` methods."
          },
          "linefeed": {
            "type": "bool, optional",
            "description": "Option whether to print a line feed or not. Defaults to True."
          }
        },
        "returns": "",
        "raises": "AttributeError\n    If `device` does not have a ``write()`` or ``flush()`` method.",
        "see_also": "",
        "notes": "",
        "examples": "Besides ``sys.stdout``, a file-like object can also be used as it has\nboth required methods:\n\n>>> from io import StringIO\n>>> buf = StringIO()\n>>> np.disp(u'\"Display\" in a file', device=buf)\n>>> buf.getvalue()\n'\"Display\" in a file\\n'"
      }
    },
    {
      "name": "dsplit",
      "signature": "dsplit(ary, indices_or_sections)",
      "docstring": {
        "description": "Split array into multiple sub-arrays along the 3rd axis (depth).\n\nPlease refer to the `split` documentation.  `dsplit` is equivalent\nto `split` with ``axis=2``, the array is always split along the third\naxis provided the array dimension is greater than or equal to 3.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "split : Split an array into multiple sub-arrays of equal size.",
        "notes": "",
        "examples": ">>> x = np.arange(16.0).reshape(2, 2, 4)\n>>> x\narray([[[ 0.,   1.,   2.,   3.],\n        [ 4.,   5.,   6.,   7.]],\n       [[ 8.,   9.,  10.,  11.],\n        [12.,  13.,  14.,  15.]]])\n>>> np.dsplit(x, 2)\n[array([[[ 0.,  1.],\n        [ 4.,  5.]],\n       [[ 8.,  9.],\n        [12., 13.]]]), array([[[ 2.,  3.],\n        [ 6.,  7.]],\n       [[10., 11.],\n        [14., 15.]]])]\n>>> np.dsplit(x, np.array([3, 6]))\n[array([[[ 0.,   1.,   2.],\n        [ 4.,   5.,   6.]],\n       [[ 8.,   9.,  10.],\n        [12.,  13.,  14.]]]),\n array([[[ 3.],\n        [ 7.]],\n       [[11.],\n        [15.]]]),\narray([], shape=(2, 2, 0), dtype=float64)]"
      }
    },
    {
      "name": "dstack",
      "signature": "dstack(tup)",
      "docstring": {
        "description": "Stack arrays in sequence depth wise (along third axis).\n\nThis is equivalent to concatenation along the third axis after 2-D arrays\nof shape `(M,N)` have been reshaped to `(M,N,1)` and 1-D arrays of shape\n`(N,)` have been reshaped to `(1,N,1)`. Rebuilds arrays divided by\n`dsplit`.\n\nThis function makes most sense for arrays with up to 3 dimensions. For\ninstance, for pixel-data with a height (first axis), width (second axis),\nand r/g/b channels (third axis). The functions `concatenate`, `stack` and\n`block` provide more general stacking and concatenation operations.",
        "parameters": {
          "tup": {
            "type": "sequence of arrays",
            "description": "The arrays must have the same shape along all but the third axis.\n    1-D or 2-D arrays must have the same shape."
          }
        },
        "returns": "stacked : ndarray\n    The array formed by stacking the given arrays, will be at least 3-D.",
        "raises": "",
        "see_also": "concatenate : Join a sequence of arrays along an existing axis.\nstack : Join a sequence of arrays along a new axis.\nblock : Assemble an nd-array from nested lists of blocks.\nvstack : Stack arrays in sequence vertically (row wise).\nhstack : Stack arrays in sequence horizontally (column wise).\ncolumn_stack : Stack 1-D arrays as columns into a 2-D array.\ndsplit : Split array along third axis.",
        "notes": "",
        "examples": ">>> a = np.array((1,2,3))\n>>> b = np.array((2,3,4))\n>>> np.dstack((a,b))\narray([[[1, 2],\n        [2, 3],\n        [3, 4]]])\n\n>>> a = np.array([[1],[2],[3]])\n>>> b = np.array([[2],[3],[4]])\n>>> np.dstack((a,b))\narray([[[1, 2]],\n       [[2, 3]],\n       [[3, 4]]])"
      }
    },
    {
      "name": "ediff1d",
      "signature": "ediff1d(ary, to_end=None, to_begin=None)",
      "docstring": {
        "description": "The differences between consecutive elements of an array.",
        "parameters": {
          "ary": {
            "type": "array_like",
            "description": "If necessary, will be flattened before the differences are taken."
          },
          "to_end": {
            "type": "array_like, optional",
            "description": "Number(s) to append at the end of the returned differences."
          },
          "to_begin": {
            "type": "array_like, optional",
            "description": "Number(s) to prepend at the beginning of the returned differences."
          }
        },
        "returns": "ediff1d : ndarray\n    The differences. Loosely, this is ``ary.flat[1:] - ary.flat[:-1]``.",
        "raises": "",
        "see_also": "diff, gradient",
        "notes": "When applied to masked arrays, this function drops the mask information\nif the `to_begin` and/or `to_end` parameters are used.",
        "examples": ">>> x = np.array([1, 2, 4, 7, 0])\n>>> np.ediff1d(x)\narray([ 1,  2,  3, -7])\n\n>>> np.ediff1d(x, to_begin=-99, to_end=np.array([88, 99]))\narray([-99,   1,   2, ...,  -7,  88,  99])\n\nThe returned array is always 1D.\n\n>>> y = [[1, 2, 4], [1, 6, 24]]\n>>> np.ediff1d(y)\narray([ 1,  2, -3,  5, 18])"
      }
    },
    {
      "name": "expand_dims",
      "signature": "expand_dims(a, axis)",
      "docstring": {
        "description": "Expand the shape of an array.\n\nInsert a new axis that will appear at the `axis` position in the expanded\narray shape.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array."
          },
          "axis": {
            "type": "int or tuple of ints",
            "description": "Position in the expanded axes where the new axis (or axes) is placed.\n\n    .. deprecated:: 1.13.0\n        Passing an axis where ``axis > a.ndim`` will be treated as\n        ``axis == a.ndim``, and passing ``axis < -a.ndim - 1`` will\n        be treated as ``axis == 0``. This behavior is deprecated.\n\n    .. versionchanged:: 1.18.0\n        A tuple of axes is now supported.  Out of range axes as\n        described above are now forbidden and raise an `AxisError`."
          }
        },
        "returns": "result : ndarray\n    View of `a` with the number of dimensions increased.",
        "raises": "",
        "see_also": "squeeze : The inverse operation, removing singleton dimensions\nreshape : Insert, remove, and combine dimensions, and resize existing ones\ndoc.indexing, atleast_1d, atleast_2d, atleast_3d",
        "notes": "",
        "examples": ">>> x = np.array([1, 2])\n>>> x.shape\n(2,)\n\nThe following is equivalent to ``x[np.newaxis, :]`` or ``x[np.newaxis]``:\n\n>>> y = np.expand_dims(x, axis=0)\n>>> y\narray([[1, 2]])\n>>> y.shape\n(1, 2)\n\nThe following is equivalent to ``x[:, np.newaxis]``:\n\n>>> y = np.expand_dims(x, axis=1)\n>>> y\narray([[1],\n       [2]])\n>>> y.shape\n(2, 1)\n\n``axis`` may also be a tuple:\n\n>>> y = np.expand_dims(x, axis=(0, 1))\n>>> y\narray([[[1, 2]]])\n\n>>> y = np.expand_dims(x, axis=(2, 0))\n>>> y\narray([[[1],\n        [2]]])\n\nNote that some examples may use ``None`` instead of ``np.newaxis``.  These\nare the same objects:\n\n>>> np.newaxis is None\nTrue"
      }
    },
    {
      "name": "extract",
      "signature": "extract(condition, arr)",
      "docstring": {
        "description": "Return the elements of an array that satisfy some condition.\n\nThis is equivalent to ``np.compress(ravel(condition), ravel(arr))``.  If\n`condition` is boolean ``np.extract`` is equivalent to ``arr[condition]``.\n\nNote that `place` does the exact opposite of `extract`.",
        "parameters": {
          "condition": {
            "type": "array_like",
            "description": "An array whose nonzero or True entries indicate the elements of `arr`\n    to extract."
          },
          "arr": {
            "type": "array_like",
            "description": "Input array of the same size as `condition`."
          }
        },
        "returns": "extract : ndarray\n    Rank 1 array of values from `arr` where `condition` is True.",
        "raises": "",
        "see_also": "take, put, copyto, compress, place",
        "notes": "",
        "examples": ">>> arr = np.arange(12).reshape((3, 4))\n>>> arr\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11]])\n>>> condition = np.mod(arr, 3)==0\n>>> condition\narray([[ True, False, False,  True],\n       [False, False,  True, False],\n       [False,  True, False, False]])\n>>> np.extract(condition, arr)\narray([0, 3, 6, 9])\n\n\nIf `condition` is boolean:\n\n>>> arr[condition]\narray([0, 3, 6, 9])"
      }
    },
    {
      "name": "eye",
      "signature": "eye(N, M=None, k=0, dtype=<class 'float'>, order='C', *, like=None)",
      "docstring": {
        "description": "Return a 2-D array with ones on the diagonal and zeros elsewhere.",
        "parameters": {
          "N": {
            "type": "int",
            "description": "Number of rows in the output."
          },
          "M": {
            "type": "int, optional",
            "description": "Number of columns in the output. If None, defaults to `N`."
          },
          "k": {
            "type": "int, optional",
            "description": "Index of the diagonal: 0 (the default) refers to the main diagonal,\n  a positive value refers to an upper diagonal, and a negative value\n  to a lower diagonal."
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "Data-type of the returned array."
          },
          "order": {
            "type": "{'C', 'F'}, optional",
            "description": "Whether the output should be stored in row-major (C-style) or\n    column-major (Fortran-style) order in memory.\n\n    .. versionadded:: 1.14.0"
          },
          "like": {
            "type": "array_like, optional",
            "description": "Reference object to allow the creation of arrays which are not\n    NumPy arrays. If an array-like passed in as ``like`` supports\n    the ``__array_function__`` protocol, the result will be defined\n    by it. In this case, it ensures the creation of an array object\n    compatible with that passed in via this argument.\n\n    .. versionadded:: 1.20.0"
          }
        },
        "returns": "I : ndarray of shape (N,M)\n  An array where all elements are equal to zero, except for the `k`-th\n  diagonal, whose values are equal to one.",
        "raises": "",
        "see_also": "identity : (almost) equivalent function\ndiag : diagonal 2-D array from a 1-D array specified by the user.",
        "notes": "",
        "examples": ">>> np.eye(2, dtype=int)\narray([[1, 0],\n       [0, 1]])\n>>> np.eye(3, k=1)\narray([[0.,  1.,  0.],\n       [0.,  0.,  1.],\n       [0.,  0.,  0.]])"
      }
    },
    {
      "name": "fill_diagonal",
      "signature": "fill_diagonal(a, val, wrap=False)",
      "docstring": {
        "description": "Fill the main diagonal of the given array of any dimensionality.\n\nFor an array `a` with ``a.ndim >= 2``, the diagonal is the list of\nlocations with indices ``a[i, ..., i]`` all identical. This function\nmodifies the input array in-place, it does not return a value.",
        "parameters": {
          "a": {
            "type": "array, at least 2-D.",
            "description": "Array whose diagonal is to be filled, it gets modified in-place."
          },
          "val": {
            "type": "scalar or array_like",
            "description": "Value(s) to write on the diagonal. If `val` is scalar, the value is\n  written along the diagonal. If array-like, the flattened `val` is\n  written along the diagonal, repeating if necessary to fill all\n  diagonal entries."
          },
          "wrap": {
            "type": "bool",
            "description": "For tall matrices in NumPy version up to 1.6.2, the\n  diagonal \"wrapped\" after N columns. You can have this behavior\n  with this option. This affects only tall matrices.\n\nSee also\n--------\ndiag_indices, diag_indices_from"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": ".. versionadded:: 1.4.0\n\nThis functionality can be obtained via `diag_indices`, but internally\nthis version uses a much faster implementation that never constructs the\nindices and uses simple slicing.",
        "examples": ">>> a = np.zeros((3, 3), int)\n>>> np.fill_diagonal(a, 5)\n>>> a\narray([[5, 0, 0],\n       [0, 5, 0],\n       [0, 0, 5]])\n\nThe same function can operate on a 4-D array:\n\n>>> a = np.zeros((3, 3, 3, 3), int)\n>>> np.fill_diagonal(a, 4)\n\nWe only show a few blocks for clarity:\n\n>>> a[0, 0]\narray([[4, 0, 0],\n       [0, 0, 0],\n       [0, 0, 0]])\n>>> a[1, 1]\narray([[0, 0, 0],\n       [0, 4, 0],\n       [0, 0, 0]])\n>>> a[2, 2]\narray([[0, 0, 0],\n       [0, 0, 0],\n       [0, 0, 4]])\n\nThe wrap option affects only tall matrices:\n\n>>> # tall matrices no wrap\n>>> a = np.zeros((5, 3), int)\n>>> np.fill_diagonal(a, 4)\n>>> a\narray([[4, 0, 0],\n       [0, 4, 0],\n       [0, 0, 4],\n       [0, 0, 0],\n       [0, 0, 0]])\n\n>>> # tall matrices wrap\n>>> a = np.zeros((5, 3), int)\n>>> np.fill_diagonal(a, 4, wrap=True)\n>>> a\narray([[4, 0, 0],\n       [0, 4, 0],\n       [0, 0, 4],\n       [0, 0, 0],\n       [4, 0, 0]])\n\n>>> # wide matrices\n>>> a = np.zeros((3, 5), int)\n>>> np.fill_diagonal(a, 4, wrap=True)\n>>> a\narray([[4, 0, 0, 0, 0],\n       [0, 4, 0, 0, 0],\n       [0, 0, 4, 0, 0]])\n\nThe anti-diagonal can be filled by reversing the order of elements\nusing either `numpy.flipud` or `numpy.fliplr`.\n\n>>> a = np.zeros((3, 3), int);\n>>> np.fill_diagonal(np.fliplr(a), [1,2,3])  # Horizontal flip\n>>> a\narray([[0, 0, 1],\n       [0, 2, 0],\n       [3, 0, 0]])\n>>> np.fill_diagonal(np.flipud(a), [1,2,3])  # Vertical flip\n>>> a\narray([[0, 0, 3],\n       [0, 2, 0],\n       [1, 0, 0]])\n\nNote that the order in which the diagonal is filled varies depending\non the flip function."
      }
    },
    {
      "name": "fix",
      "signature": "fix(x, out=None)",
      "docstring": {
        "description": "Round to nearest integer towards zero.\n\nRound an array of floats element-wise to nearest integer towards zero.\nThe rounded values are returned as floats.",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "An array of floats to be rounded"
          },
          "out": {
            "type": "ndarray, optional",
            "description": "A location into which the result is stored. If provided, it must have\n    a shape that the input broadcasts to. If not provided or None, a\n    freshly-allocated array is returned."
          }
        },
        "returns": "out : ndarray of floats\n    A float array with the same dimensions as the input.\n    If second argument is not supplied then a float array is returned\n    with the rounded values.\n\n    If a second argument is supplied the result is stored there.\n    The return value `out` is then a reference to that array.",
        "raises": "",
        "see_also": "rint, trunc, floor, ceil\naround : Round to given number of decimals",
        "notes": "",
        "examples": ">>> np.fix(3.14)\n3.0\n>>> np.fix(3)\n3.0\n>>> np.fix([2.1, 2.9, -2.1, -2.9])\narray([ 2.,  2., -2., -2.])"
      }
    },
    {
      "name": "flip",
      "signature": "flip(m, axis=None)",
      "docstring": {
        "description": "Reverse the order of elements in an array along the given axis.\n\nThe shape of the array is preserved, but the elements are reordered.\n\n.. versionadded:: 1.12.0",
        "parameters": {
          "m": {
            "type": "array_like",
            "description": "Input array."
          },
          "axis": {
            "type": "None or int or tuple of ints, optional",
            "description": "Axis or axes along which to flip over. The default,\n     axis=None, will flip over all of the axes of the input array.\n     If axis is negative it counts from the last to the first axis.\n\n     If axis is a tuple of ints, flipping is performed on all of the axes\n     specified in the tuple.\n\n     .. versionchanged:: 1.15.0\n        None and tuples of axes are supported"
          }
        },
        "returns": "out : array_like\n    A view of `m` with the entries of axis reversed.  Since a view is\n    returned, this operation is done in constant time.",
        "raises": "",
        "see_also": "flipud : Flip an array vertically (axis=0).\nfliplr : Flip an array horizontally (axis=1).",
        "notes": "flip(m, 0) is equivalent to flipud(m).\n\nflip(m, 1) is equivalent to fliplr(m).\n\nflip(m, n) corresponds to ``m[...,::-1,...]`` with ``::-1`` at position n.\n\nflip(m) corresponds to ``m[::-1,::-1,...,::-1]`` with ``::-1`` at all\npositions.\n\nflip(m, (0, 1)) corresponds to ``m[::-1,::-1,...]`` with ``::-1`` at\nposition 0 and position 1.",
        "examples": ">>> A = np.arange(8).reshape((2,2,2))\n>>> A\narray([[[0, 1],\n        [2, 3]],\n       [[4, 5],\n        [6, 7]]])\n>>> np.flip(A, 0)\narray([[[4, 5],\n        [6, 7]],\n       [[0, 1],\n        [2, 3]]])\n>>> np.flip(A, 1)\narray([[[2, 3],\n        [0, 1]],\n       [[6, 7],\n        [4, 5]]])\n>>> np.flip(A)\narray([[[7, 6],\n        [5, 4]],\n       [[3, 2],\n        [1, 0]]])\n>>> np.flip(A, (0, 2))\narray([[[5, 4],\n        [7, 6]],\n       [[1, 0],\n        [3, 2]]])\n>>> A = np.random.randn(3,4,5)\n>>> np.all(np.flip(A,2) == A[:,:,::-1,...])\nTrue"
      }
    },
    {
      "name": "fliplr",
      "signature": "fliplr(m)",
      "docstring": {
        "description": "Reverse the order of elements along axis 1 (left/right).\n\nFor a 2-D array, this flips the entries in each row in the left/right\ndirection. Columns are preserved, but appear in a different order than\nbefore.",
        "parameters": {
          "m": {
            "type": "array_like",
            "description": "Input array, must be at least 2-D."
          }
        },
        "returns": "f : ndarray\n    A view of `m` with the columns reversed.  Since a view\n    is returned, this operation is :math:`\\mathcal O(1)`.",
        "raises": "",
        "see_also": "flipud : Flip array in the up/down direction.\nflip : Flip array in one or more dimensions.\nrot90 : Rotate array counterclockwise.",
        "notes": "Equivalent to ``m[:,::-1]`` or ``np.flip(m, axis=1)``.\nRequires the array to be at least 2-D.",
        "examples": ">>> A = np.diag([1.,2.,3.])\n>>> A\narray([[1.,  0.,  0.],\n       [0.,  2.,  0.],\n       [0.,  0.,  3.]])\n>>> np.fliplr(A)\narray([[0.,  0.,  1.],\n       [0.,  2.,  0.],\n       [3.,  0.,  0.]])\n\n>>> A = np.random.randn(2,3,5)\n>>> np.all(np.fliplr(A) == A[:,::-1,...])\nTrue"
      }
    },
    {
      "name": "flipud",
      "signature": "flipud(m)",
      "docstring": {
        "description": "Reverse the order of elements along axis 0 (up/down).\n\nFor a 2-D array, this flips the entries in each column in the up/down\ndirection. Rows are preserved, but appear in a different order than before.",
        "parameters": {
          "m": {
            "type": "array_like",
            "description": "Input array."
          }
        },
        "returns": "out : array_like\n    A view of `m` with the rows reversed.  Since a view is\n    returned, this operation is :math:`\\mathcal O(1)`.",
        "raises": "",
        "see_also": "fliplr : Flip array in the left/right direction.\nflip : Flip array in one or more dimensions.\nrot90 : Rotate array counterclockwise.",
        "notes": "Equivalent to ``m[::-1, ...]`` or ``np.flip(m, axis=0)``.\nRequires the array to be at least 1-D.",
        "examples": ">>> A = np.diag([1.0, 2, 3])\n>>> A\narray([[1.,  0.,  0.],\n       [0.,  2.,  0.],\n       [0.,  0.,  3.]])\n>>> np.flipud(A)\narray([[0.,  0.,  3.],\n       [0.,  2.,  0.],\n       [1.,  0.,  0.]])\n\n>>> A = np.random.randn(2,3,5)\n>>> np.all(np.flipud(A) == A[::-1,...])\nTrue\n\n>>> np.flipud([1,2])\narray([2, 1])"
      }
    },
    {
      "name": "fromregex",
      "signature": "fromregex(file, regexp, dtype, encoding=None)",
      "docstring": {
        "description": "Construct an array from a text file, using regular expression parsing.\n\nThe returned array is always a structured array, and is constructed from\nall matches of the regular expression in the file. Groups in the regular\nexpression are converted to fields of the structured array.",
        "parameters": {
          "file": {
            "type": "path or file",
            "description": "Filename or file object to read.\n\n    .. versionchanged:: 1.22.0\n        Now accepts `os.PathLike` implementations."
          },
          "regexp": {
            "type": "str or regexp",
            "description": "Regular expression used to parse the file.\n    Groups in the regular expression correspond to fields in the dtype."
          },
          "dtype": {
            "type": "dtype or list of dtypes",
            "description": "Dtype for the structured array; must be a structured datatype."
          },
          "encoding": {
            "type": "str, optional",
            "description": "Encoding used to decode the inputfile. Does not apply to input streams.\n\n    .. versionadded:: 1.14.0"
          }
        },
        "returns": "output : ndarray\n    The output array, containing the part of the content of `file` that\n    was matched by `regexp`. `output` is always a structured array.",
        "raises": "TypeError\n    When `dtype` is not a valid dtype for a structured array.",
        "see_also": "fromstring, loadtxt",
        "notes": "Dtypes for structured arrays can be specified in several forms, but all\nforms specify at least the data type and field name. For details see\n`basics.rec`.",
        "examples": ">>> from io import StringIO\n>>> text = StringIO(\"1312 foo\\n1534  bar\\n444   qux\")\n\n>>> regexp = r\"(\\d+)\\s+(...)\"  # match [digits, whitespace, anything]\n>>> output = np.fromregex(text, regexp,\n...                       [('num', np.int64), ('key', 'S3')])\n>>> output\narray([(1312, b'foo'), (1534, b'bar'), ( 444, b'qux')],\n      dtype=[('num', '<i8'), ('key', 'S3')])\n>>> output['num']\narray([1312, 1534,  444])"
      }
    },
    {
      "name": "genfromtxt",
      "signature": "genfromtxt(fname, dtype=<class 'float'>, comments='#', delimiter=None, skip_header=0, skip_footer=0, converters=None, missing_values=None, filling_values=None, usecols=None, names=None, excludelist=None, deletechars=\" !#$%&'()*+,-./:;<=>?@[\\\\]^{|}~\", replace_space='_', autostrip=False, case_sensitive=True, defaultfmt='f%i', unpack=None, usemask=False, loose=True, invalid_raise=True, max_rows=None, encoding='bytes', *, ndmin=0, like=None)",
      "docstring": {
        "description": "Load data from a text file, with missing values handled as specified.\n\nEach line past the first `skip_header` lines is split at the `delimiter`\ncharacter, and characters following the `comments` character are discarded.",
        "parameters": {
          "fname": {
            "type": "file, str, pathlib.Path, list of str, generator",
            "description": "File, filename, list, or generator to read.  If the filename\n    extension is ``.gz`` or ``.bz2``, the file is first decompressed. Note\n    that generators must return bytes or strings. The strings\n    in a list or produced by a generator are treated as lines."
          },
          "dtype": {
            "type": "dtype, optional",
            "description": "Data type of the resulting array.\n    If None, the dtypes will be determined by the contents of each\n    column, individually."
          },
          "comments": {
            "type": "str, optional",
            "description": "The character used to indicate the start of a comment.\n    All the characters occurring on a line after a comment are discarded."
          },
          "delimiter": {
            "type": "str, int, or sequence, optional",
            "description": "The string used to separate values.  By default, any consecutive\n    whitespaces act as delimiter.  An integer or sequence of integers\n    can also be provided as width(s) of each field."
          },
          "skiprows": {
            "type": "int, optional",
            "description": "`skiprows` was removed in numpy 1.10. Please use `skip_header` instead."
          },
          "skip_header": {
            "type": "int, optional",
            "description": "The number of lines to skip at the beginning of the file."
          },
          "skip_footer": {
            "type": "int, optional",
            "description": "The number of lines to skip at the end of the file."
          },
          "converters": {
            "type": "variable, optional",
            "description": "The set of functions that convert the data of a column to a value.\n    The converters can also be used to provide a default value\n    for missing data: ``converters = {3: lambda s: float(s or 0)}``."
          },
          "missing": {
            "type": "variable, optional",
            "description": "`missing` was removed in numpy 1.10. Please use `missing_values`\n    instead."
          },
          "missing_values": {
            "type": "variable, optional",
            "description": "The set of strings corresponding to missing data."
          },
          "filling_values": {
            "type": "variable, optional",
            "description": "The set of values to be used as default when the data are missing."
          },
          "usecols": {
            "type": "sequence, optional",
            "description": "Which columns to read, with 0 being the first.  For example,\n    ``usecols = (1, 4, 5)`` will extract the 2nd, 5th and 6th columns."
          },
          "names": {
            "type": "{None, True, str, sequence}, optional",
            "description": "If `names` is True, the field names are read from the first line after\n    the first `skip_header` lines. This line can optionally be preceded\n    by a comment delimiter. If `names` is a sequence or a single-string of\n    comma-separated names, the names will be used to define the field names\n    in a structured dtype. If `names` is None, the names of the dtype\n    fields will be used, if any."
          },
          "excludelist": {
            "type": "sequence, optional",
            "description": "A list of names to exclude. This list is appended to the default list\n    ['return','file','print']. Excluded names are appended with an\n    underscore: for example, `file` would become `file_`."
          },
          "deletechars": {
            "type": "str, optional",
            "description": "A string combining invalid characters that must be deleted from the\n    names."
          },
          "defaultfmt": {
            "type": "str, optional",
            "description": "A format used to define default field names, such as \"f%i\" or \"f_%02i\"."
          },
          "autostrip": {
            "type": "bool, optional",
            "description": "Whether to automatically strip white spaces from the variables."
          },
          "replace_space": {
            "type": "char, optional",
            "description": "Character(s) used in replacement of white spaces in the variable\n    names. By default, use a '_'."
          },
          "case_sensitive": {
            "type": "{True, False, 'upper', 'lower'}, optional",
            "description": "If True, field names are case sensitive.\n    If False or 'upper', field names are converted to upper case.\n    If 'lower', field names are converted to lower case."
          },
          "unpack": {
            "type": "bool, optional",
            "description": "If True, the returned array is transposed, so that arguments may be\n    unpacked using ``x, y, z = genfromtxt(...)``.  When used with a\n    structured data-type, arrays are returned for each field.\n    Default is False."
          },
          "usemask": {
            "type": "bool, optional",
            "description": "If True, return a masked array.\n    If False, return a regular array."
          },
          "loose": {
            "type": "bool, optional",
            "description": "If True, do not raise errors for invalid values."
          },
          "invalid_raise": {
            "type": "bool, optional",
            "description": "If True, an exception is raised if an inconsistency is detected in the\n    number of columns.\n    If False, a warning is emitted and the offending lines are skipped."
          },
          "max_rows": {
            "type": "int,  optional",
            "description": "The maximum number of rows to read. Must not be used with skip_footer\n    at the same time.  If given, the value must be at least 1. Default is\n    to read the entire file.\n\n    .. versionadded:: 1.10.0"
          },
          "encoding": {
            "type": "str, optional",
            "description": "Encoding used to decode the inputfile. Does not apply when `fname` is\n    a file object.  The special value 'bytes' enables backward compatibility\n    workarounds that ensure that you receive byte arrays when possible\n    and passes latin1 encoded strings to converters. Override this value to\n    receive unicode arrays and pass strings as input to converters.  If set\n    to None the system default is used. The default value is 'bytes'.\n\n    .. versionadded:: 1.14.0"
          },
          "ndmin": {
            "type": "int, optional",
            "description": "Same parameter as `loadtxt`\n\n    .. versionadded:: 1.23.0"
          },
          "like": {
            "type": "array_like, optional",
            "description": "Reference object to allow the creation of arrays which are not\n    NumPy arrays. If an array-like passed in as ``like`` supports\n    the ``__array_function__`` protocol, the result will be defined\n    by it. In this case, it ensures the creation of an array object\n    compatible with that passed in via this argument.\n\n    .. versionadded:: 1.20.0"
          }
        },
        "returns": "out : ndarray\n    Data read from the text file. If `usemask` is True, this is a\n    masked array.",
        "raises": "",
        "see_also": "numpy.loadtxt : equivalent function when no data is missing.",
        "notes": "* When spaces are used as delimiters, or when no delimiter has been given\n  as input, there should not be any missing data between two fields.\n* When the variables are named (either by a flexible dtype or with `names`),\n  there must not be any header in the file (else a ValueError\n  exception is raised).\n* Individual values are not stripped of spaces by default.\n  When using a custom converter, make sure the function does remove spaces.\n\nReferences\n----------\n.. [1] NumPy User Guide, section `I/O with NumPy\n       <https://docs.scipy.org/doc/numpy/user/basics.io.genfromtxt.html>`_.",
        "examples": ">>> from io import StringIO\n>>> import numpy as np\n\nComma delimited file with mixed dtype\n\n>>> s = StringIO(u\"1,1.3,abcde\")\n>>> data = np.genfromtxt(s, dtype=[('myint','i8'),('myfloat','f8'),\n... ('mystring','S5')], delimiter=\",\")\n>>> data\narray((1, 1.3, b'abcde'),\n      dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])\n\nUsing dtype = None\n\n>>> _ = s.seek(0) # needed for StringIO example only\n>>> data = np.genfromtxt(s, dtype=None,\n... names = ['myint','myfloat','mystring'], delimiter=\",\")\n>>> data\narray((1, 1.3, b'abcde'),\n      dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])\n\nSpecifying dtype and names\n\n>>> _ = s.seek(0)\n>>> data = np.genfromtxt(s, dtype=\"i8,f8,S5\",\n... names=['myint','myfloat','mystring'], delimiter=\",\")\n>>> data\narray((1, 1.3, b'abcde'),\n      dtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])\n\nAn example with fixed-width columns\n\n>>> s = StringIO(u\"11.3abcde\")\n>>> data = np.genfromtxt(s, dtype=None, names=['intvar','fltvar','strvar'],\n...     delimiter=[1,3,5])\n>>> data\narray((1, 1.3, b'abcde'),\n      dtype=[('intvar', '<i8'), ('fltvar', '<f8'), ('strvar', 'S5')])\n\nAn example to show comments\n\n>>> f = StringIO('''\n... text,# of chars\n... hello world,11\n... numpy,5''')\n>>> np.genfromtxt(f, dtype='S12,S12', delimiter=',')\narray([(b'text', b''), (b'hello world', b'11'), (b'numpy', b'5')],\n  dtype=[('f0', 'S12'), ('f1', 'S12')])"
      }
    },
    {
      "name": "get_array_wrap",
      "signature": "get_array_wrap(*args)",
      "docstring": {
        "description": "Find the wrapper for the array with the highest priority.\n\nIn case of ties, leftmost wins. If no wrapper is found, return None",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "get_include",
      "signature": "get_include()",
      "docstring": {
        "description": "Return the directory that contains the NumPy \\*.h header files.\n\nExtension modules that need to compile against NumPy should use this\nfunction to locate the appropriate include directory.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "When using ``distutils``, for example in ``setup.py``::\n\n    import numpy as np\n    ...\n    Extension('extension_name', ...\n            include_dirs=[np.get_include()])\n    ...",
        "examples": ""
      }
    },
    {
      "name": "gradient",
      "signature": "gradient(f, *varargs, axis=None, edge_order=1)",
      "docstring": {
        "description": "Return the gradient of an N-dimensional array.\n\nThe gradient is computed using second order accurate central differences\nin the interior points and either first or second order accurate one-sides\n(forward or backwards) differences at the boundaries.\nThe returned gradient hence has the same shape as the input array.",
        "parameters": {
          "f": {
            "type": "array_like",
            "description": "An N-dimensional array containing samples of a scalar function."
          },
          "varargs": {
            "type": "list of scalar or array, optional",
            "description": "Spacing between f values. Default unitary spacing for all dimensions.\n    Spacing can be specified using:\n\n    1. single scalar to specify a sample distance for all dimensions.\n    2. N scalars to specify a constant sample distance for each dimension.\n       i.e. `dx`, `dy`, `dz`, ...\n    3. N arrays to specify the coordinates of the values along each\n       dimension of F. The length of the array must match the size of\n       the corresponding dimension\n    4. Any combination of N scalars/arrays with the meaning of 2. and 3.\n\n    If `axis` is given, the number of varargs must equal the number of axes.\n    Default: 1."
          },
          "edge_order": {
            "type": "{1, 2}, optional",
            "description": "Gradient is calculated using N-th order accurate differences\n    at the boundaries. Default: 1.\n\n    .. versionadded:: 1.9.1"
          },
          "axis": {
            "type": "None or int or tuple of ints, optional",
            "description": "Gradient is calculated only along the given axis or axes\n    The default (axis = None) is to calculate the gradient for all the axes\n    of the input array. axis may be negative, in which case it counts from\n    the last to the first axis.\n\n    .. versionadded:: 1.11.0"
          }
        },
        "returns": "gradient : ndarray or list of ndarray\n    A list of ndarrays (or a single ndarray if there is only one dimension)\n    corresponding to the derivatives of f with respect to each dimension.\n    Each derivative has the same shape as f.",
        "raises": "",
        "see_also": "",
        "notes": "Assuming that :math:`f\\in C^{3}` (i.e., :math:`f` has at least 3 continuous\nderivatives) and let :math:`h_{*}` be a non-homogeneous stepsize, we\nminimize the \"consistency error\" :math:`\\eta_{i}` between the true gradient\nand its estimate from a linear combination of the neighboring grid-points:\n\n.. math::\n\n    \\eta_{i} = f_{i}^{\\left(1\\right)} -\n                \\left[ \\alpha f\\left(x_{i}\\right) +\n                        \\beta f\\left(x_{i} + h_{d}\\right) +\n                        \\gamma f\\left(x_{i}-h_{s}\\right)\n                \\right]\n\nBy substituting :math:`f(x_{i} + h_{d})` and :math:`f(x_{i} - h_{s})`\nwith their Taylor series expansion, this translates into solving\nthe following the linear system:\n\n.. math::\n\n    \\left\\{\n        \\begin{array}{r}\n            \\alpha+\\beta+\\gamma=0 \\\\\n            \\beta h_{d}-\\gamma h_{s}=1 \\\\\n            \\beta h_{d}^{2}+\\gamma h_{s}^{2}=0\n        \\end{array}\n    \\right.\n\nThe resulting approximation of :math:`f_{i}^{(1)}` is the following:\n\n.. math::\n\n    \\hat f_{i}^{(1)} =\n        \\frac{\n            h_{s}^{2}f\\left(x_{i} + h_{d}\\right)\n            + \\left(h_{d}^{2} - h_{s}^{2}\\right)f\\left(x_{i}\\right)\n            - h_{d}^{2}f\\left(x_{i}-h_{s}\\right)}\n            { h_{s}h_{d}\\left(h_{d} + h_{s}\\right)}\n        + \\mathcal{O}\\left(\\frac{h_{d}h_{s}^{2}\n                            + h_{s}h_{d}^{2}}{h_{d}\n                            + h_{s}}\\right)\n\nIt is worth noting that if :math:`h_{s}=h_{d}`\n(i.e., data are evenly spaced)\nwe find the standard second order approximation:\n\n.. math::\n\n    \\hat f_{i}^{(1)}=\n        \\frac{f\\left(x_{i+1}\\right) - f\\left(x_{i-1}\\right)}{2h}\n        + \\mathcal{O}\\left(h^{2}\\right)\n\nWith a similar procedure the forward/backward approximations used for\nboundaries can be derived.\n\nReferences\n----------\n.. [1]  Quarteroni A., Sacco R., Saleri F. (2007) Numerical Mathematics\n        (Texts in Applied Mathematics). New York: Springer.\n.. [2]  Durran D. R. (1999) Numerical Methods for Wave Equations\n        in Geophysical Fluid Dynamics. New York: Springer.\n.. [3]  Fornberg B. (1988) Generation of Finite Difference Formulas on\n        Arbitrarily Spaced Grids,\n        Mathematics of Computation 51, no. 184 : 699-706.\n        `PDF <http://www.ams.org/journals/mcom/1988-51-184/\n        S0025-5718-1988-0935077-0/S0025-5718-1988-0935077-0.pdf>`_.",
        "examples": ">>> f = np.array([1, 2, 4, 7, 11, 16], dtype=float)\n>>> np.gradient(f)\narray([1. , 1.5, 2.5, 3.5, 4.5, 5. ])\n>>> np.gradient(f, 2)\narray([0.5 ,  0.75,  1.25,  1.75,  2.25,  2.5 ])\n\nSpacing can be also specified with an array that represents the coordinates\nof the values F along the dimensions.\nFor instance a uniform spacing:\n\n>>> x = np.arange(f.size)\n>>> np.gradient(f, x)\narray([1. ,  1.5,  2.5,  3.5,  4.5,  5. ])\n\nOr a non uniform one:\n\n>>> x = np.array([0., 1., 1.5, 3.5, 4., 6.], dtype=float)\n>>> np.gradient(f, x)\narray([1. ,  3. ,  3.5,  6.7,  6.9,  2.5])\n\nFor two dimensional arrays, the return will be two arrays ordered by\naxis. In this example the first array stands for the gradient in\nrows and the second one in columns direction:\n\n>>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float))\n[array([[ 2.,  2., -1.],\n       [ 2.,  2., -1.]]), array([[1. , 2.5, 4. ],\n       [1. , 1. , 1. ]])]\n\nIn this example the spacing is also specified:\nuniform for axis=0 and non uniform for axis=1\n\n>>> dx = 2.\n>>> y = [1., 1.5, 3.5]\n>>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float), dx, y)\n[array([[ 1. ,  1. , -0.5],\n       [ 1. ,  1. , -0.5]]), array([[2. , 2. , 2. ],\n       [2. , 1.7, 0.5]])]\n\nIt is possible to specify how boundaries are treated using `edge_order`\n\n>>> x = np.array([0, 1, 2, 3, 4])\n>>> f = x**2\n>>> np.gradient(f, edge_order=1)\narray([1.,  2.,  4.,  6.,  7.])\n>>> np.gradient(f, edge_order=2)\narray([0., 2., 4., 6., 8.])\n\nThe `axis` keyword can be used to specify a subset of axes of which the\ngradient is calculated\n\n>>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float), axis=0)\narray([[ 2.,  2., -1.],\n       [ 2.,  2., -1.]])"
      }
    },
    {
      "name": "hamming",
      "signature": "hamming(M)",
      "docstring": {
        "description": "Return the Hamming window.\n\nThe Hamming window is a taper formed by using a weighted cosine.",
        "parameters": {
          "M": {
            "type": "int",
            "description": "Number of points in the output window. If zero or less, an\n    empty array is returned."
          }
        },
        "returns": "out : ndarray\n    The window, with the maximum value normalized to one (the value\n    one appears only if the number of samples is odd).",
        "raises": "",
        "see_also": "bartlett, blackman, hanning, kaiser",
        "notes": "The Hamming window is defined as\n\n.. math::  w(n) = 0.54 - 0.46\\cos\\left(\\frac{2\\pi{n}}{M-1}\\right)\n           \\qquad 0 \\leq n \\leq M-1\n\nThe Hamming was named for R. W. Hamming, an associate of J. W. Tukey\nand is described in Blackman and Tukey. It was recommended for\nsmoothing the truncated autocovariance function in the time domain.\nMost references to the Hamming window come from the signal processing\nliterature, where it is used as one of many windowing functions for\nsmoothing values.  It is also known as an apodization (which means\n\"removing the foot\", i.e. smoothing discontinuities at the beginning\nand end of the sampled signal) or tapering function.\n\nReferences\n----------\n.. [1] Blackman, R.B. and Tukey, J.W., (1958) The measurement of power\n       spectra, Dover Publications, New York.\n.. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\", The\n       University of Alberta Press, 1975, pp. 109-110.\n.. [3] Wikipedia, \"Window function\",\n       https://en.wikipedia.org/wiki/Window_function\n.. [4] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,\n       \"Numerical Recipes\", Cambridge University Press, 1986, page 425.",
        "examples": ">>> np.hamming(12)\narray([ 0.08      ,  0.15302337,  0.34890909,  0.60546483,  0.84123594, # may vary\n        0.98136677,  0.98136677,  0.84123594,  0.60546483,  0.34890909,\n        0.15302337,  0.08      ])\n\nPlot the window and the frequency response:\n\n>>> import matplotlib.pyplot as plt\n>>> from numpy.fft import fft, fftshift\n>>> window = np.hamming(51)\n>>> plt.plot(window)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Hamming window\")\nText(0.5, 1.0, 'Hamming window')\n>>> plt.ylabel(\"Amplitude\")\nText(0, 0.5, 'Amplitude')\n>>> plt.xlabel(\"Sample\")\nText(0.5, 0, 'Sample')\n>>> plt.show()\n\n>>> plt.figure()\n<Figure size 640x480 with 0 Axes>\n>>> A = fft(window, 2048) / 25.5\n>>> mag = np.abs(fftshift(A))\n>>> freq = np.linspace(-0.5, 0.5, len(A))\n>>> response = 20 * np.log10(mag)\n>>> response = np.clip(response, -100, 100)\n>>> plt.plot(freq, response)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Frequency response of Hamming window\")\nText(0.5, 1.0, 'Frequency response of Hamming window')\n>>> plt.ylabel(\"Magnitude [dB]\")\nText(0, 0.5, 'Magnitude [dB]')\n>>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\nText(0.5, 0, 'Normalized frequency [cycles per sample]')\n>>> plt.axis('tight')\n...\n>>> plt.show()"
      }
    },
    {
      "name": "hanning",
      "signature": "hanning(M)",
      "docstring": {
        "description": "Return the Hanning window.\n\nThe Hanning window is a taper formed by using a weighted cosine.",
        "parameters": {
          "M": {
            "type": "int",
            "description": "Number of points in the output window. If zero or less, an\n    empty array is returned."
          }
        },
        "returns": "out : ndarray, shape(M,)\n    The window, with the maximum value normalized to one (the value\n    one appears only if `M` is odd).",
        "raises": "",
        "see_also": "bartlett, blackman, hamming, kaiser",
        "notes": "The Hanning window is defined as\n\n.. math::  w(n) = 0.5 - 0.5\\cos\\left(\\frac{2\\pi{n}}{M-1}\\right)\n           \\qquad 0 \\leq n \\leq M-1\n\nThe Hanning was named for Julius von Hann, an Austrian meteorologist.\nIt is also known as the Cosine Bell. Some authors prefer that it be\ncalled a Hann window, to help avoid confusion with the very similar\nHamming window.\n\nMost references to the Hanning window come from the signal processing\nliterature, where it is used as one of many windowing functions for\nsmoothing values.  It is also known as an apodization (which means\n\"removing the foot\", i.e. smoothing discontinuities at the beginning\nand end of the sampled signal) or tapering function.\n\nReferences\n----------\n.. [1] Blackman, R.B. and Tukey, J.W., (1958) The measurement of power\n       spectra, Dover Publications, New York.\n.. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\",\n       The University of Alberta Press, 1975, pp. 106-108.\n.. [3] Wikipedia, \"Window function\",\n       https://en.wikipedia.org/wiki/Window_function\n.. [4] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,\n       \"Numerical Recipes\", Cambridge University Press, 1986, page 425.",
        "examples": ">>> np.hanning(12)\narray([0.        , 0.07937323, 0.29229249, 0.57115742, 0.82743037,\n       0.97974649, 0.97974649, 0.82743037, 0.57115742, 0.29229249,\n       0.07937323, 0.        ])\n\nPlot the window and its frequency response:\n\n>>> import matplotlib.pyplot as plt\n>>> from numpy.fft import fft, fftshift\n>>> window = np.hanning(51)\n>>> plt.plot(window)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Hann window\")\nText(0.5, 1.0, 'Hann window')\n>>> plt.ylabel(\"Amplitude\")\nText(0, 0.5, 'Amplitude')\n>>> plt.xlabel(\"Sample\")\nText(0.5, 0, 'Sample')\n>>> plt.show()\n\n>>> plt.figure()\n<Figure size 640x480 with 0 Axes>\n>>> A = fft(window, 2048) / 25.5\n>>> mag = np.abs(fftshift(A))\n>>> freq = np.linspace(-0.5, 0.5, len(A))\n>>> with np.errstate(divide='ignore', invalid='ignore'):\n...     response = 20 * np.log10(mag)\n...\n>>> response = np.clip(response, -100, 100)\n>>> plt.plot(freq, response)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Frequency response of the Hann window\")\nText(0.5, 1.0, 'Frequency response of the Hann window')\n>>> plt.ylabel(\"Magnitude [dB]\")\nText(0, 0.5, 'Magnitude [dB]')\n>>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\nText(0.5, 0, 'Normalized frequency [cycles per sample]')\n>>> plt.axis('tight')\n...\n>>> plt.show()"
      }
    },
    {
      "name": "histogram",
      "signature": "histogram(a, bins=10, range=None, density=None, weights=None)",
      "docstring": {
        "description": "Compute the histogram of a dataset.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input data. The histogram is computed over the flattened array."
          },
          "bins": {
            "type": "int or sequence of scalars or str, optional",
            "description": "If `bins` is an int, it defines the number of equal-width\n    bins in the given range (10, by default). If `bins` is a\n    sequence, it defines a monotonically increasing array of bin edges,\n    including the rightmost edge, allowing for non-uniform bin widths.\n\n    .. versionadded:: 1.11.0\n\n    If `bins` is a string, it defines the method used to calculate the\n    optimal bin width, as defined by `histogram_bin_edges`."
          },
          "range": {
            "type": "(float, float), optional",
            "description": "The lower and upper range of the bins.  If not provided, range\n    is simply ``(a.min(), a.max())``.  Values outside the range are\n    ignored. The first element of the range must be less than or\n    equal to the second. `range` affects the automatic bin\n    computation as well. While bin width is computed to be optimal\n    based on the actual data within `range`, the bin count will fill\n    the entire range including portions containing no data."
          },
          "weights": {
            "type": "array_like, optional",
            "description": "An array of weights, of the same shape as `a`.  Each value in\n    `a` only contributes its associated weight towards the bin count\n    (instead of 1). If `density` is True, the weights are\n    normalized, so that the integral of the density over the range\n    remains 1."
          },
          "density": {
            "type": "bool, optional",
            "description": "If ``False``, the result will contain the number of samples in\n    each bin. If ``True``, the result is the value of the\n    probability *density* function at the bin, normalized such that\n    the *integral* over the range is 1. Note that the sum of the\n    histogram values will not be equal to 1 unless bins of unity\n    width are chosen; it is not a probability *mass* function."
          }
        },
        "returns": "hist : array\n    The values of the histogram. See `density` and `weights` for a\n    description of the possible semantics.\nbin_edges : array of dtype float\n    Return the bin edges ``(length(hist)+1)``.",
        "raises": "",
        "see_also": "histogramdd, bincount, searchsorted, digitize, histogram_bin_edges",
        "notes": "All but the last (righthand-most) bin is half-open.  In other words,\nif `bins` is::\n\n  [1, 2, 3, 4]\n\nthen the first bin is ``[1, 2)`` (including 1, but excluding 2) and\nthe second ``[2, 3)``.  The last bin, however, is ``[3, 4]``, which\n*includes* 4.",
        "examples": ">>> np.histogram([1, 2, 1], bins=[0, 1, 2, 3])\n(array([0, 2, 1]), array([0, 1, 2, 3]))\n>>> np.histogram(np.arange(4), bins=np.arange(5), density=True)\n(array([0.25, 0.25, 0.25, 0.25]), array([0, 1, 2, 3, 4]))\n>>> np.histogram([[1, 2, 1], [1, 0, 1]], bins=[0,1,2,3])\n(array([1, 4, 1]), array([0, 1, 2, 3]))\n\n>>> a = np.arange(5)\n>>> hist, bin_edges = np.histogram(a, density=True)\n>>> hist\narray([0.5, 0. , 0.5, 0. , 0. , 0.5, 0. , 0.5, 0. , 0.5])\n>>> hist.sum()\n2.4999999999999996\n>>> np.sum(hist * np.diff(bin_edges))\n1.0\n\n.. versionadded:: 1.11.0\n\nAutomated Bin Selection Methods example, using 2 peak random data\nwith 2000 points:\n\n>>> import matplotlib.pyplot as plt\n>>> rng = np.random.RandomState(10)  # deterministic random data\n>>> a = np.hstack((rng.normal(size=1000),\n...                rng.normal(loc=5, scale=2, size=1000)))\n>>> _ = plt.hist(a, bins='auto')  # arguments are passed to np.histogram\n>>> plt.title(\"Histogram with 'auto' bins\")\nText(0.5, 1.0, \"Histogram with 'auto' bins\")\n>>> plt.show()"
      }
    },
    {
      "name": "histogram2d",
      "signature": "histogram2d(x, y, bins=10, range=None, density=None, weights=None)",
      "docstring": {
        "description": "Compute the bi-dimensional histogram of two data samples.",
        "parameters": {
          "x": {
            "type": "array_like, shape (N,)",
            "description": "An array containing the x coordinates of the points to be\n    histogrammed."
          },
          "y": {
            "type": "array_like, shape (N,)",
            "description": "An array containing the y coordinates of the points to be\n    histogrammed."
          },
          "bins": {
            "type": "int or array_like or [int, int] or [array, array], optional",
            "description": "The bin specification:\n\n      * If int, the number of bins for the two dimensions (nx=ny=bins).\n      * If array_like, the bin edges for the two dimensions\n        (x_edges=y_edges=bins).\n      * If [int, int], the number of bins in each dimension\n        (nx, ny = bins).\n      * If [array, array], the bin edges in each dimension\n        (x_edges, y_edges = bins).\n      * A combination [int, array] or [array, int], where int\n        is the number of bins and array is the bin edges."
          },
          "range": {
            "type": "array_like, shape(2,2), optional",
            "description": "The leftmost and rightmost edges of the bins along each dimension\n    (if not specified explicitly in the `bins` parameters):\n    ``[[xmin, xmax], [ymin, ymax]]``. All values outside of this range\n    will be considered outliers and not tallied in the histogram."
          },
          "density": {
            "type": "bool, optional",
            "description": "If False, the default, returns the number of samples in each bin.\n    If True, returns the probability *density* function at the bin,\n    ``bin_count / sample_count / bin_area``."
          },
          "weights": {
            "type": "array_like, shape(N,), optional",
            "description": "An array of values ``w_i`` weighing each sample ``(x_i, y_i)``.\n    Weights are normalized to 1 if `density` is True. If `density` is\n    False, the values of the returned histogram are equal to the sum of\n    the weights belonging to the samples falling into each bin."
          }
        },
        "returns": "H : ndarray, shape(nx, ny)\n    The bi-dimensional histogram of samples `x` and `y`. Values in `x`\n    are histogrammed along the first dimension and values in `y` are\n    histogrammed along the second dimension.\nxedges : ndarray, shape(nx+1,)\n    The bin edges along the first dimension.\nyedges : ndarray, shape(ny+1,)\n    The bin edges along the second dimension.",
        "raises": "",
        "see_also": "histogram : 1D histogram\nhistogramdd : Multidimensional histogram",
        "notes": "When `density` is True, then the returned histogram is the sample\ndensity, defined such that the sum over bins of the product\n``bin_value * bin_area`` is 1.\n\nPlease note that the histogram does not follow the Cartesian convention\nwhere `x` values are on the abscissa and `y` values on the ordinate\naxis.  Rather, `x` is histogrammed along the first dimension of the\narray (vertical), and `y` along the second dimension of the array\n(horizontal).  This ensures compatibility with `histogramdd`.",
        "examples": ">>> from matplotlib.image import NonUniformImage\n>>> import matplotlib.pyplot as plt\n\nConstruct a 2-D histogram with variable bin width. First define the bin\nedges:\n\n>>> xedges = [0, 1, 3, 5]\n>>> yedges = [0, 2, 3, 4, 6]\n\nNext we create a histogram H with random bin content:\n\n>>> x = np.random.normal(2, 1, 100)\n>>> y = np.random.normal(1, 1, 100)\n>>> H, xedges, yedges = np.histogram2d(x, y, bins=(xedges, yedges))\n>>> # Histogram does not follow Cartesian convention (see Notes),\n>>> # therefore transpose H for visualization purposes.\n>>> H = H.T\n\n:func:`imshow <matplotlib.pyplot.imshow>` can only display square bins:\n\n>>> fig = plt.figure(figsize=(7, 3))\n>>> ax = fig.add_subplot(131, title='imshow: square bins')\n>>> plt.imshow(H, interpolation='nearest', origin='lower',\n...         extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])\n<matplotlib.image.AxesImage object at 0x...>\n\n:func:`pcolormesh <matplotlib.pyplot.pcolormesh>` can display actual edges:\n\n>>> ax = fig.add_subplot(132, title='pcolormesh: actual edges',\n...         aspect='equal')\n>>> X, Y = np.meshgrid(xedges, yedges)\n>>> ax.pcolormesh(X, Y, H)\n<matplotlib.collections.QuadMesh object at 0x...>\n\n:class:`NonUniformImage <matplotlib.image.NonUniformImage>` can be used to\ndisplay actual bin edges with interpolation:\n\n>>> ax = fig.add_subplot(133, title='NonUniformImage: interpolated',\n...         aspect='equal', xlim=xedges[[0, -1]], ylim=yedges[[0, -1]])\n>>> im = NonUniformImage(ax, interpolation='bilinear')\n>>> xcenters = (xedges[:-1] + xedges[1:]) / 2\n>>> ycenters = (yedges[:-1] + yedges[1:]) / 2\n>>> im.set_data(xcenters, ycenters, H)\n>>> ax.add_image(im)\n>>> plt.show()\n\nIt is also possible to construct a 2-D histogram without specifying bin\nedges:\n\n>>> # Generate non-symmetric test data\n>>> n = 10000\n>>> x = np.linspace(1, 100, n)\n>>> y = 2*np.log(x) + np.random.rand(n) - 0.5\n>>> # Compute 2d histogram. Note the order of x/y and xedges/yedges\n>>> H, yedges, xedges = np.histogram2d(y, x, bins=20)\n\nNow we can plot the histogram using\n:func:`pcolormesh <matplotlib.pyplot.pcolormesh>`, and a\n:func:`hexbin <matplotlib.pyplot.hexbin>` for comparison.\n\n>>> # Plot histogram using pcolormesh\n>>> fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n>>> ax1.pcolormesh(xedges, yedges, H, cmap='rainbow')\n>>> ax1.plot(x, 2*np.log(x), 'k-')\n>>> ax1.set_xlim(x.min(), x.max())\n>>> ax1.set_ylim(y.min(), y.max())\n>>> ax1.set_xlabel('x')\n>>> ax1.set_ylabel('y')\n>>> ax1.set_title('histogram2d')\n>>> ax1.grid()\n\n>>> # Create hexbin plot for comparison\n>>> ax2.hexbin(x, y, gridsize=20, cmap='rainbow')\n>>> ax2.plot(x, 2*np.log(x), 'k-')\n>>> ax2.set_title('hexbin')\n>>> ax2.set_xlim(x.min(), x.max())\n>>> ax2.set_xlabel('x')\n>>> ax2.grid()\n\n>>> plt.show()"
      }
    },
    {
      "name": "histogram_bin_edges",
      "signature": "histogram_bin_edges(a, bins=10, range=None, weights=None)",
      "docstring": {
        "description": "Function to calculate only the edges of the bins used by the `histogram`\nfunction.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input data. The histogram is computed over the flattened array."
          },
          "bins": {
            "type": "int or sequence of scalars or str, optional",
            "description": "If `bins` is an int, it defines the number of equal-width\n    bins in the given range (10, by default). If `bins` is a\n    sequence, it defines the bin edges, including the rightmost\n    edge, allowing for non-uniform bin widths.\n\n    If `bins` is a string from the list below, `histogram_bin_edges` will use\n    the method chosen to calculate the optimal bin width and\n    consequently the number of bins (see `Notes` for more detail on\n    the estimators) from the data that falls within the requested\n    range. While the bin width will be optimal for the actual data\n    in the range, the number of bins will be computed to fill the\n    entire range, including the empty portions. For visualisation,\n    using the 'auto' option is suggested. Weighted data is not\n    supported for automated bin size selection.\n\n    'auto'\n        Maximum of the 'sturges' and 'fd' estimators. Provides good\n        all around performance.\n\n    'fd' (Freedman Diaconis Estimator)\n        Robust (resilient to outliers) estimator that takes into\n        account data variability and data size.\n\n    'doane'\n        An improved version of Sturges' estimator that works better\n        with non-normal datasets.\n\n    'scott'\n        Less robust estimator that takes into account data variability\n        and data size.\n\n    'stone'\n        Estimator based on leave-one-out cross-validation estimate of\n        the integrated squared error. Can be regarded as a generalization\n        of Scott's rule.\n\n    'rice'\n        Estimator does not take variability into account, only data\n        size. Commonly overestimates number of bins required.\n\n    'sturges'\n        R's default method, only accounts for data size. Only\n        optimal for gaussian data and underestimates number of bins\n        for large non-gaussian datasets.\n\n    'sqrt'\n        Square root (of data size) estimator, used by Excel and\n        other programs for its speed and simplicity."
          },
          "range": {
            "type": "(float, float), optional",
            "description": "The lower and upper range of the bins.  If not provided, range\n    is simply ``(a.min(), a.max())``.  Values outside the range are\n    ignored. The first element of the range must be less than or\n    equal to the second. `range` affects the automatic bin\n    computation as well. While bin width is computed to be optimal\n    based on the actual data within `range`, the bin count will fill\n    the entire range including portions containing no data."
          },
          "weights": {
            "type": "array_like, optional",
            "description": "An array of weights, of the same shape as `a`.  Each value in\n    `a` only contributes its associated weight towards the bin count\n    (instead of 1). This is currently not used by any of the bin estimators,\n    but may be in the future."
          }
        },
        "returns": "bin_edges : array of dtype float\n    The edges to pass into `histogram`",
        "raises": "",
        "see_also": "histogram",
        "notes": "The methods to estimate the optimal number of bins are well founded\nin literature, and are inspired by the choices R provides for\nhistogram visualisation. Note that having the number of bins\nproportional to :math:`n^{1/3}` is asymptotically optimal, which is\nwhy it appears in most estimators. These are simply plug-in methods\nthat give good starting points for number of bins. In the equations\nbelow, :math:`h` is the binwidth and :math:`n_h` is the number of\nbins. All estimators that compute bin counts are recast to bin width\nusing the `ptp` of the data. The final bin count is obtained from\n``np.round(np.ceil(range / h))``. The final bin width is often less\nthan what is returned by the estimators below.\n\n'auto' (maximum of the 'sturges' and 'fd' estimators)\n    A compromise to get a good value. For small datasets the Sturges\n    value will usually be chosen, while larger datasets will usually\n    default to FD.  Avoids the overly conservative behaviour of FD\n    and Sturges for small and large datasets respectively.\n    Switchover point is usually :math:`a.size \\approx 1000`.\n\n'fd' (Freedman Diaconis Estimator)\n    .. math:: h = 2 \\frac{IQR}{n^{1/3}}\n\n    The binwidth is proportional to the interquartile range (IQR)\n    and inversely proportional to cube root of a.size. Can be too\n    conservative for small datasets, but is quite good for large\n    datasets. The IQR is very robust to outliers.\n\n'scott'\n    .. math:: h = \\sigma \\sqrt[3]{\\frac{24 \\sqrt{\\pi}}{n}}\n\n    The binwidth is proportional to the standard deviation of the\n    data and inversely proportional to cube root of ``x.size``. Can\n    be too conservative for small datasets, but is quite good for\n    large datasets. The standard deviation is not very robust to\n    outliers. Values are very similar to the Freedman-Diaconis\n    estimator in the absence of outliers.\n\n'rice'\n    .. math:: n_h = 2n^{1/3}\n\n    The number of bins is only proportional to cube root of\n    ``a.size``. It tends to overestimate the number of bins and it\n    does not take into account data variability.\n\n'sturges'\n    .. math:: n_h = \\log _{2}(n) + 1\n\n    The number of bins is the base 2 log of ``a.size``.  This\n    estimator assumes normality of data and is too conservative for\n    larger, non-normal datasets. This is the default method in R's\n    ``hist`` method.\n\n'doane'\n    .. math:: n_h = 1 + \\log_{2}(n) +\n                    \\log_{2}\\left(1 + \\frac{|g_1|}{\\sigma_{g_1}}\\right)\n\n        g_1 = mean\\left[\\left(\\frac{x - \\mu}{\\sigma}\\right)^3\\right]\n\n        \\sigma_{g_1} = \\sqrt{\\frac{6(n - 2)}{(n + 1)(n + 3)}}\n\n    An improved version of Sturges' formula that produces better\n    estimates for non-normal datasets. This estimator attempts to\n    account for the skew of the data.\n\n'sqrt'\n    .. math:: n_h = \\sqrt n\n\n    The simplest and fastest estimator. Only takes into account the\n    data size.",
        "examples": ">>> arr = np.array([0, 0, 0, 1, 2, 3, 3, 4, 5])\n>>> np.histogram_bin_edges(arr, bins='auto', range=(0, 1))\narray([0.  , 0.25, 0.5 , 0.75, 1.  ])\n>>> np.histogram_bin_edges(arr, bins=2)\narray([0. , 2.5, 5. ])\n\nFor consistency with histogram, an array of pre-computed bins is\npassed through unmodified:\n\n>>> np.histogram_bin_edges(arr, [1, 2])\narray([1, 2])\n\nThis function allows one set of bins to be computed, and reused across\nmultiple histograms:\n\n>>> shared_bins = np.histogram_bin_edges(arr, bins='auto')\n>>> shared_bins\narray([0., 1., 2., 3., 4., 5.])\n\n>>> group_id = np.array([0, 1, 1, 0, 1, 1, 0, 1, 1])\n>>> hist_0, _ = np.histogram(arr[group_id == 0], bins=shared_bins)\n>>> hist_1, _ = np.histogram(arr[group_id == 1], bins=shared_bins)\n\n>>> hist_0; hist_1\narray([1, 1, 0, 1, 0])\narray([2, 0, 1, 1, 2])\n\nWhich gives more easily comparable results than using separate bins for\neach histogram:\n\n>>> hist_0, bins_0 = np.histogram(arr[group_id == 0], bins='auto')\n>>> hist_1, bins_1 = np.histogram(arr[group_id == 1], bins='auto')\n>>> hist_0; hist_1\narray([1, 1, 1])\narray([2, 1, 1, 2])\n>>> bins_0; bins_1\narray([0., 1., 2., 3.])\narray([0.  , 1.25, 2.5 , 3.75, 5.  ])"
      }
    },
    {
      "name": "histogramdd",
      "signature": "histogramdd(sample, bins=10, range=None, density=None, weights=None)",
      "docstring": {
        "description": "Compute the multidimensional histogram of some data.",
        "parameters": {
          "sample": {
            "type": "(N, D) array, or (N, D) array_like",
            "description": "The data to be histogrammed.\n\n    Note the unusual interpretation of sample when an array_like:\n\n    * When an array, each row is a coordinate in a D-dimensional space -\n      such as ``histogramdd(np.array([p1, p2, p3]))``.\n    * When an array_like, each element is the list of values for single\n      coordinate - such as ``histogramdd((X, Y, Z))``.\n\n    The first form should be preferred."
          },
          "bins": {
            "type": "sequence or int, optional",
            "description": "The bin specification:\n\n    * A sequence of arrays describing the monotonically increasing bin\n      edges along each dimension.\n    * The number of bins for each dimension (nx, ny, ... =bins)\n    * The number of bins for all dimensions (nx=ny=...=bins)."
          },
          "range": {
            "type": "sequence, optional",
            "description": "A sequence of length D, each an optional (lower, upper) tuple giving\n    the outer bin edges to be used if the edges are not given explicitly in\n    `bins`.\n    An entry of None in the sequence results in the minimum and maximum\n    values being used for the corresponding dimension.\n    The default, None, is equivalent to passing a tuple of D None values."
          },
          "density": {
            "type": "bool, optional",
            "description": "If False, the default, returns the number of samples in each bin.\n    If True, returns the probability *density* function at the bin,\n    ``bin_count / sample_count / bin_volume``."
          },
          "weights": {
            "type": "(N,) array_like, optional",
            "description": "An array of values `w_i` weighing each sample `(x_i, y_i, z_i, ...)`.\n    Weights are normalized to 1 if density is True. If density is False,\n    the values of the returned histogram are equal to the sum of the\n    weights belonging to the samples falling into each bin."
          }
        },
        "returns": "H : ndarray\n    The multidimensional histogram of sample x. See density and weights\n    for the different possible semantics.\nedges : list\n    A list of D arrays describing the bin edges for each dimension.",
        "raises": "",
        "see_also": "histogram: 1-D histogram\nhistogram2d: 2-D histogram",
        "notes": "",
        "examples": ">>> r = np.random.randn(100,3)\n>>> H, edges = np.histogramdd(r, bins = (5, 8, 4))\n>>> H.shape, edges[0].size, edges[1].size, edges[2].size\n((5, 8, 4), 6, 9, 5)"
      }
    },
    {
      "name": "hsplit",
      "signature": "hsplit(ary, indices_or_sections)",
      "docstring": {
        "description": "Split an array into multiple sub-arrays horizontally (column-wise).\n\nPlease refer to the `split` documentation.  `hsplit` is equivalent\nto `split` with ``axis=1``, the array is always split along the second\naxis except for 1-D arrays, where it is split at ``axis=0``.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "split : Split an array into multiple sub-arrays of equal size.",
        "notes": "",
        "examples": ">>> x = np.arange(16.0).reshape(4, 4)\n>>> x\narray([[ 0.,   1.,   2.,   3.],\n       [ 4.,   5.,   6.,   7.],\n       [ 8.,   9.,  10.,  11.],\n       [12.,  13.,  14.,  15.]])\n>>> np.hsplit(x, 2)\n[array([[  0.,   1.],\n       [  4.,   5.],\n       [  8.,   9.],\n       [12.,  13.]]),\n array([[  2.,   3.],\n       [  6.,   7.],\n       [10.,  11.],\n       [14.,  15.]])]\n>>> np.hsplit(x, np.array([3, 6]))\n[array([[ 0.,   1.,   2.],\n       [ 4.,   5.,   6.],\n       [ 8.,   9.,  10.],\n       [12.,  13.,  14.]]),\n array([[ 3.],\n       [ 7.],\n       [11.],\n       [15.]]),\n array([], shape=(4, 0), dtype=float64)]\n\nWith a higher dimensional array the split is still along the second axis.\n\n>>> x = np.arange(8.0).reshape(2, 2, 2)\n>>> x\narray([[[0.,  1.],\n        [2.,  3.]],\n       [[4.,  5.],\n        [6.,  7.]]])\n>>> np.hsplit(x, 2)\n[array([[[0.,  1.]],\n       [[4.,  5.]]]),\n array([[[2.,  3.]],\n       [[6.,  7.]]])]\n\nWith a 1-D array, the split is along axis 0.\n\n>>> x = np.array([0, 1, 2, 3, 4, 5])\n>>> np.hsplit(x, 2)\n[array([0, 1, 2]), array([3, 4, 5])]"
      }
    },
    {
      "name": "i0",
      "signature": "i0(x)",
      "docstring": {
        "description": "Modified Bessel function of the first kind, order 0.\n\nUsually denoted :math:`I_0`.",
        "parameters": {
          "x": {
            "type": "array_like of float",
            "description": "Argument of the Bessel function."
          }
        },
        "returns": "out : ndarray, shape = x.shape, dtype = float\n    The modified Bessel function evaluated at each of the elements of `x`.",
        "raises": "",
        "see_also": "scipy.special.i0, scipy.special.iv, scipy.special.ive",
        "notes": "The scipy implementation is recommended over this function: it is a\nproper ufunc written in C, and more than an order of magnitude faster.\n\nWe use the algorithm published by Clenshaw [1]_ and referenced by\nAbramowitz and Stegun [2]_, for which the function domain is\npartitioned into the two intervals [0,8] and (8,inf), and Chebyshev\npolynomial expansions are employed in each interval. Relative error on\nthe domain [0,30] using IEEE arithmetic is documented [3]_ as having a\npeak of 5.8e-16 with an rms of 1.4e-16 (n = 30000).\n\nReferences\n----------\n.. [1] C. W. Clenshaw, \"Chebyshev series for mathematical functions\", in\n       *National Physical Laboratory Mathematical Tables*, vol. 5, London:\n       Her Majesty's Stationery Office, 1962.\n.. [2] M. Abramowitz and I. A. Stegun, *Handbook of Mathematical\n       Functions*, 10th printing, New York: Dover, 1964, pp. 379.\n       https://personal.math.ubc.ca/~cbm/aands/page_379.htm\n.. [3] https://metacpan.org/pod/distribution/Math-Cephes/lib/Math/Cephes.pod#i0:-Modified-Bessel-function-of-order-zero",
        "examples": ">>> np.i0(0.)\narray(1.0)\n>>> np.i0([0, 1, 2, 3])\narray([1.        , 1.26606588, 2.2795853 , 4.88079259])"
      }
    },
    {
      "name": "imag",
      "signature": "imag(val)",
      "docstring": {
        "description": "Return the imaginary part of the complex argument.",
        "parameters": {
          "val": {
            "type": "array_like",
            "description": "Input array."
          }
        },
        "returns": "out : ndarray or scalar\n    The imaginary component of the complex argument. If `val` is real,\n    the type of `val` is used for the output.  If `val` has complex\n    elements, the returned type is float.",
        "raises": "",
        "see_also": "real, angle, real_if_close",
        "notes": "",
        "examples": ">>> a = np.array([1+2j, 3+4j, 5+6j])\n>>> a.imag\narray([2.,  4.,  6.])\n>>> a.imag = np.array([8, 10, 12])\n>>> a\narray([1. +8.j,  3.+10.j,  5.+12.j])\n>>> np.imag(1 + 1j)\n1.0"
      }
    },
    {
      "name": "in1d",
      "signature": "in1d(ar1, ar2, assume_unique=False, invert=False, *, kind=None)",
      "docstring": {
        "description": "Test whether each element of a 1-D array is also present in a second array.\n\nReturns a boolean array the same length as `ar1` that is True\nwhere an element of `ar1` is in `ar2` and False otherwise.\n\nWe recommend using :func:`isin` instead of `in1d` for new code.",
        "parameters": {
          "ar1": {
            "type": "(M,) array_like",
            "description": "Input array."
          },
          "ar2": {
            "type": "array_like",
            "description": "The values against which to test each value of `ar1`."
          },
          "assume_unique": {
            "type": "bool, optional",
            "description": "If True, the input arrays are both assumed to be unique, which\n    can speed up the calculation.  Default is False."
          },
          "invert": {
            "type": "bool, optional",
            "description": "If True, the values in the returned array are inverted (that is,\n    False where an element of `ar1` is in `ar2` and True otherwise).\n    Default is False. ``np.in1d(a, b, invert=True)`` is equivalent\n    to (but is faster than) ``np.invert(in1d(a, b))``."
          },
          "kind": {
            "type": "{None, 'sort', 'table'}, optional",
            "description": "The algorithm to use. This will not affect the final result,\n    but will affect the speed and memory use. The default, None,\n    will select automatically based on memory considerations.\n\n    * If 'sort', will use a mergesort-based approach. This will have\n      a memory usage of roughly 6 times the sum of the sizes of\n      `ar1` and `ar2`, not accounting for size of dtypes.\n    * If 'table', will use a lookup table approach similar\n      to a counting sort. This is only available for boolean and\n      integer arrays. This will have a memory usage of the\n      size of `ar1` plus the max-min value of `ar2`. `assume_unique`\n      has no effect when the 'table' option is used.\n    * If None, will automatically choose 'table' if\n      the required memory allocation is less than or equal to\n      6 times the sum of the sizes of `ar1` and `ar2`,\n      otherwise will use 'sort'. This is done to not use\n      a large amount of memory by default, even though\n      'table' may be faster in most cases. If 'table' is chosen,\n      `assume_unique` will have no effect.\n\n    .. versionadded:: 1.8.0"
          }
        },
        "returns": "in1d : (M,) ndarray, bool\n    The values `ar1[in1d]` are in `ar2`.",
        "raises": "",
        "see_also": "isin                  : Version of this function that preserves the\n                        shape of ar1.\nnumpy.lib.arraysetops : Module with a number of other functions for\n                        performing set operations on arrays.",
        "notes": "`in1d` can be considered as an element-wise function version of the\npython keyword `in`, for 1-D sequences. ``in1d(a, b)`` is roughly\nequivalent to ``np.array([item in b for item in a])``.\nHowever, this idea fails if `ar2` is a set, or similar (non-sequence)\ncontainer:  As ``ar2`` is converted to an array, in those cases\n``asarray(ar2)`` is an object array rather than the expected array of\ncontained values.\n\nUsing ``kind='table'`` tends to be faster than `kind='sort'` if the\nfollowing relationship is true:\n``log10(len(ar2)) > (log10(max(ar2)-min(ar2)) - 2.27) / 0.927``,\nbut may use greater memory. The default value for `kind` will\nbe automatically selected based only on memory usage, so one may\nmanually set ``kind='table'`` if memory constraints can be relaxed.\n\n.. versionadded:: 1.4.0",
        "examples": ">>> test = np.array([0, 1, 2, 5, 0])\n>>> states = [0, 2]\n>>> mask = np.in1d(test, states)\n>>> mask\narray([ True, False,  True, False,  True])\n>>> test[mask]\narray([0, 2, 0])\n>>> mask = np.in1d(test, states, invert=True)\n>>> mask\narray([False,  True, False,  True, False])\n>>> test[mask]\narray([1, 5])"
      }
    },
    {
      "name": "info",
      "signature": "info(object=None, maxwidth=76, output=None, toplevel='numpy')",
      "docstring": {
        "description": "Get help information for an array, function, class, or module.",
        "parameters": {
          "object": {
            "type": "object or str, optional",
            "description": "Input object or name to get information about. If `object` is\n    an `ndarray` instance, information about the array is printed.\n    If `object` is a numpy object, its docstring is given. If it is\n    a string, available modules are searched for matching objects.\n    If None, information about `info` itself is returned."
          },
          "maxwidth": {
            "type": "int, optional",
            "description": "Printing width."
          },
          "output": {
            "type": "file like object, optional",
            "description": "File like object that the output is written to, default is\n    ``None``, in which case ``sys.stdout`` will be used.\n    The object has to be opened in 'w' or 'a' mode."
          },
          "toplevel": {
            "type": "str, optional",
            "description": "Start search at this level."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "source, lookfor",
        "notes": "When used interactively with an object, ``np.info(obj)`` is equivalent\nto ``help(obj)`` on the Python prompt or ``obj?`` on the IPython\nprompt.",
        "examples": ">>> np.info(np.polyval) # doctest: +SKIP\n   polyval(p, x)\n     Evaluate the polynomial p at x.\n     ...\n\nWhen using a string for `object` it is possible to get multiple results.\n\n>>> np.info('fft') # doctest: +SKIP\n     *** Found in numpy ***\nCore FFT routines\n...\n     *** Found in numpy.fft ***\n fft(a, n=None, axis=-1)\n...\n     *** Repeat reference found in numpy.fft.fftpack ***\n     *** Total of 3 references found. ***\n\nWhen the argument is an array, information about the array is printed.\n\n>>> a = np.array([[1 + 2j, 3, -4], [-5j, 6, 0]], dtype=np.complex64)\n>>> np.info(a)\nclass:  ndarray\nshape:  (2, 3)\nstrides:  (24, 8)\nitemsize:  8\naligned:  True\ncontiguous:  True\nfortran:  False\ndata pointer: 0x562b6e0d2860  # may vary\nbyteorder:  little\nbyteswap:  False\ntype: complex64"
      }
    },
    {
      "name": "insert",
      "signature": "insert(arr, obj, values, axis=None)",
      "docstring": {
        "description": "Insert values along the given axis before the given indices.",
        "parameters": {
          "arr": {
            "type": "array_like",
            "description": "Input array."
          },
          "obj": {
            "type": "int, slice or sequence of ints",
            "description": "Object that defines the index or indices before which `values` is\n    inserted.\n\n    .. versionadded:: 1.8.0\n\n    Support for multiple insertions when `obj` is a single scalar or a\n    sequence with one element (similar to calling insert multiple\n    times)."
          },
          "values": {
            "type": "array_like",
            "description": "Values to insert into `arr`. If the type of `values` is different\n    from that of `arr`, `values` is converted to the type of `arr`.\n    `values` should be shaped so that ``arr[...,obj,...] = values``\n    is legal."
          },
          "axis": {
            "type": "int, optional",
            "description": "Axis along which to insert `values`.  If `axis` is None then `arr`\n    is flattened first."
          }
        },
        "returns": "out : ndarray\n    A copy of `arr` with `values` inserted.  Note that `insert`\n    does not occur in-place: a new array is returned. If\n    `axis` is None, `out` is a flattened array.",
        "raises": "",
        "see_also": "append : Append elements at the end of an array.\nconcatenate : Join a sequence of arrays along an existing axis.\ndelete : Delete elements from an array.",
        "notes": "Note that for higher dimensional inserts ``obj=0`` behaves very different\nfrom ``obj=[0]`` just like ``arr[:,0,:] = values`` is different from\n``arr[:,[0],:] = values``.",
        "examples": ">>> a = np.array([[1, 1], [2, 2], [3, 3]])\n>>> a\narray([[1, 1],\n       [2, 2],\n       [3, 3]])\n>>> np.insert(a, 1, 5)\narray([1, 5, 1, ..., 2, 3, 3])\n>>> np.insert(a, 1, 5, axis=1)\narray([[1, 5, 1],\n       [2, 5, 2],\n       [3, 5, 3]])\n\nDifference between sequence and scalars:\n\n>>> np.insert(a, [1], [[1],[2],[3]], axis=1)\narray([[1, 1, 1],\n       [2, 2, 2],\n       [3, 3, 3]])\n>>> np.array_equal(np.insert(a, 1, [1, 2, 3], axis=1),\n...                np.insert(a, [1], [[1],[2],[3]], axis=1))\nTrue\n\n>>> b = a.flatten()\n>>> b\narray([1, 1, 2, 2, 3, 3])\n>>> np.insert(b, [2, 2], [5, 6])\narray([1, 1, 5, ..., 2, 3, 3])\n\n>>> np.insert(b, slice(2, 4), [5, 6])\narray([1, 1, 5, ..., 2, 3, 3])\n\n>>> np.insert(b, [2, 2], [7.13, False]) # type casting\narray([1, 1, 7, ..., 2, 3, 3])\n\n>>> x = np.arange(8).reshape(2, 4)\n>>> idx = (1, 3)\n>>> np.insert(x, idx, 999, axis=1)\narray([[  0, 999,   1,   2, 999,   3],\n       [  4, 999,   5,   6, 999,   7]])"
      }
    },
    {
      "name": "interp",
      "signature": "interp(x, xp, fp, left=None, right=None, period=None)",
      "docstring": {
        "description": "One-dimensional linear interpolation for monotonically increasing sample points.\n\nReturns the one-dimensional piecewise linear interpolant to a function\nwith given discrete data points (`xp`, `fp`), evaluated at `x`.",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "The x-coordinates at which to evaluate the interpolated values."
          },
          "xp": {
            "type": "1-D sequence of floats",
            "description": "The x-coordinates of the data points, must be increasing if argument\n    `period` is not specified. Otherwise, `xp` is internally sorted after\n    normalizing the periodic boundaries with ``xp = xp % period``."
          },
          "fp": {
            "type": "1-D sequence of float or complex",
            "description": "The y-coordinates of the data points, same length as `xp`."
          },
          "left": {
            "type": "optional float or complex corresponding to fp",
            "description": "Value to return for `x < xp[0]`, default is `fp[0]`."
          },
          "right": {
            "type": "optional float or complex corresponding to fp",
            "description": "Value to return for `x > xp[-1]`, default is `fp[-1]`."
          },
          "period": {
            "type": "None or float, optional",
            "description": "A period for the x-coordinates. This parameter allows the proper\n    interpolation of angular x-coordinates. Parameters `left` and `right`\n    are ignored if `period` is specified.\n\n    .. versionadded:: 1.10.0"
          }
        },
        "returns": "y : float or complex (corresponding to fp) or ndarray\n    The interpolated values, same shape as `x`.",
        "raises": "ValueError\n    If `xp` and `fp` have different length\n    If `xp` or `fp` are not 1-D sequences\n    If `period == 0`",
        "see_also": "scipy.interpolate\n\nWarnings\n--------\nThe x-coordinate sequence is expected to be increasing, but this is not\nexplicitly enforced.  However, if the sequence `xp` is non-increasing,\ninterpolation results are meaningless.\n\nNote that, since NaN is unsortable, `xp` also cannot contain NaNs.\n\nA simple check for `xp` being strictly increasing is::\n\n    np.all(np.diff(xp) > 0)",
        "notes": "",
        "examples": ">>> xp = [1, 2, 3]\n>>> fp = [3, 2, 0]\n>>> np.interp(2.5, xp, fp)\n1.0\n>>> np.interp([0, 1, 1.5, 2.72, 3.14], xp, fp)\narray([3.  , 3.  , 2.5 , 0.56, 0.  ])\n>>> UNDEF = -99.0\n>>> np.interp(3.14, xp, fp, right=UNDEF)\n-99.0\n\nPlot an interpolant to the sine function:\n\n>>> x = np.linspace(0, 2*np.pi, 10)\n>>> y = np.sin(x)\n>>> xvals = np.linspace(0, 2*np.pi, 50)\n>>> yinterp = np.interp(xvals, x, y)\n>>> import matplotlib.pyplot as plt\n>>> plt.plot(x, y, 'o')\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.plot(xvals, yinterp, '-x')\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.show()\n\nInterpolation with periodic x-coordinates:\n\n>>> x = [-180, -170, -185, 185, -10, -5, 0, 365]\n>>> xp = [190, -190, 350, -350]\n>>> fp = [5, 10, 3, 4]\n>>> np.interp(x, xp, fp, period=360)\narray([7.5 , 5.  , 8.75, 6.25, 3.  , 3.25, 3.5 , 3.75])\n\nComplex interpolation:\n\n>>> x = [1.5, 4.0]\n>>> xp = [2,3,5]\n>>> fp = [1.0j, 0, 2+3j]\n>>> np.interp(x, xp, fp)\narray([0.+1.j , 1.+1.5j])"
      }
    },
    {
      "name": "intersect1d",
      "signature": "intersect1d(ar1, ar2, assume_unique=False, return_indices=False)",
      "docstring": {
        "description": "Find the intersection of two arrays.\n\nReturn the sorted, unique values that are in both of the input arrays.",
        "parameters": {
          "assume_unique": {
            "type": "bool",
            "description": "If True, the input arrays are both assumed to be unique, which\n    can speed up the calculation.  If True but ``ar1`` or ``ar2`` are not\n    unique, incorrect results and out-of-bounds indices could result.\n    Default is False."
          },
          "return_indices": {
            "type": "bool",
            "description": "If True, the indices which correspond to the intersection of the two\n    arrays are returned. The first instance of a value is used if there are\n    multiple. Default is False.\n\n    .. versionadded:: 1.15.0"
          }
        },
        "returns": "intersect1d : ndarray\n    Sorted 1D array of common and unique elements.\ncomm1 : ndarray\n    The indices of the first occurrences of the common values in `ar1`.\n    Only provided if `return_indices` is True.\ncomm2 : ndarray\n    The indices of the first occurrences of the common values in `ar2`.\n    Only provided if `return_indices` is True.",
        "raises": "",
        "see_also": "numpy.lib.arraysetops : Module with a number of other functions for\n                        performing set operations on arrays.",
        "notes": "",
        "examples": ">>> np.intersect1d([1, 3, 4, 3], [3, 1, 2, 1])\narray([1, 3])\n\nTo intersect more than two arrays, use functools.reduce:\n\n>>> from functools import reduce\n>>> reduce(np.intersect1d, ([1, 3, 4, 3], [3, 1, 2, 1], [6, 3, 4, 2]))\narray([3])\n\nTo return the indices of the values common to the input arrays\nalong with the intersected values:\n\n>>> x = np.array([1, 1, 2, 3, 4])\n>>> y = np.array([2, 1, 4, 6])\n>>> xy, x_ind, y_ind = np.intersect1d(x, y, return_indices=True)\n>>> x_ind, y_ind\n(array([0, 2, 4]), array([1, 0, 2]))\n>>> xy, x[x_ind], y[y_ind]\n(array([1, 2, 4]), array([1, 2, 4]), array([1, 2, 4]))"
      }
    },
    {
      "name": "iscomplex",
      "signature": "iscomplex(x)",
      "docstring": {
        "description": "Returns a bool array, where True if input element is complex.\n\nWhat is tested is whether the input has a non-zero imaginary part, not if\nthe input type is complex.",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "Input array."
          }
        },
        "returns": "out : ndarray of bools\n    Output array.",
        "raises": "",
        "see_also": "isreal\niscomplexobj : Return True if x is a complex type or an array of complex\n               numbers.",
        "notes": "",
        "examples": ">>> np.iscomplex([1+1j, 1+0j, 4.5, 3, 2, 2j])\narray([ True, False, False, False, False,  True])"
      }
    },
    {
      "name": "iscomplexobj",
      "signature": "iscomplexobj(x)",
      "docstring": {
        "description": "Check for a complex type or an array of complex numbers.\n\nThe type of the input is checked, not the value. Even if the input\nhas an imaginary part equal to zero, `iscomplexobj` evaluates to True.",
        "parameters": {
          "x": {
            "type": "any",
            "description": "The input can be of any type and shape."
          }
        },
        "returns": "iscomplexobj : bool\n    The return value, True if `x` is of a complex type or has at least\n    one complex element.",
        "raises": "",
        "see_also": "isrealobj, iscomplex",
        "notes": "",
        "examples": ">>> np.iscomplexobj(1)\nFalse\n>>> np.iscomplexobj(1+0j)\nTrue\n>>> np.iscomplexobj([3, 1+0j, True])\nTrue"
      }
    },
    {
      "name": "isin",
      "signature": "isin(element, test_elements, assume_unique=False, invert=False, *, kind=None)",
      "docstring": {
        "description": "Calculates ``element in test_elements``, broadcasting over `element` only.\nReturns a boolean array of the same shape as `element` that is True\nwhere an element of `element` is in `test_elements` and False otherwise.",
        "parameters": {
          "element": {
            "type": "array_like",
            "description": "Input array."
          },
          "test_elements": {
            "type": "array_like",
            "description": "The values against which to test each value of `element`.\n    This argument is flattened if it is an array or array_like.\n    See notes for behavior with non-array-like parameters."
          },
          "assume_unique": {
            "type": "bool, optional",
            "description": "If True, the input arrays are both assumed to be unique, which\n    can speed up the calculation.  Default is False."
          },
          "invert": {
            "type": "bool, optional",
            "description": "If True, the values in the returned array are inverted, as if\n    calculating `element not in test_elements`. Default is False.\n    ``np.isin(a, b, invert=True)`` is equivalent to (but faster\n    than) ``np.invert(np.isin(a, b))``."
          },
          "kind": {
            "type": "{None, 'sort', 'table'}, optional",
            "description": "The algorithm to use. This will not affect the final result,\n    but will affect the speed and memory use. The default, None,\n    will select automatically based on memory considerations.\n\n    * If 'sort', will use a mergesort-based approach. This will have\n      a memory usage of roughly 6 times the sum of the sizes of\n      `ar1` and `ar2`, not accounting for size of dtypes.\n    * If 'table', will use a lookup table approach similar\n      to a counting sort. This is only available for boolean and\n      integer arrays. This will have a memory usage of the\n      size of `ar1` plus the max-min value of `ar2`. `assume_unique`\n      has no effect when the 'table' option is used.\n    * If None, will automatically choose 'table' if\n      the required memory allocation is less than or equal to\n      6 times the sum of the sizes of `ar1` and `ar2`,\n      otherwise will use 'sort'. This is done to not use\n      a large amount of memory by default, even though\n      'table' may be faster in most cases. If 'table' is chosen,\n      `assume_unique` will have no effect."
          }
        },
        "returns": "isin : ndarray, bool\n    Has the same shape as `element`. The values `element[isin]`\n    are in `test_elements`.",
        "raises": "",
        "see_also": "in1d                  : Flattened version of this function.\nnumpy.lib.arraysetops : Module with a number of other functions for\n                        performing set operations on arrays.",
        "notes": "`isin` is an element-wise function version of the python keyword `in`.\n``isin(a, b)`` is roughly equivalent to\n``np.array([item in b for item in a])`` if `a` and `b` are 1-D sequences.\n\n`element` and `test_elements` are converted to arrays if they are not\nalready. If `test_elements` is a set (or other non-sequence collection)\nit will be converted to an object array with one element, rather than an\narray of the values contained in `test_elements`. This is a consequence\nof the `array` constructor's way of handling non-sequence collections.\nConverting the set to a list usually gives the desired behavior.\n\nUsing ``kind='table'`` tends to be faster than `kind='sort'` if the\nfollowing relationship is true:\n``log10(len(ar2)) > (log10(max(ar2)-min(ar2)) - 2.27) / 0.927``,\nbut may use greater memory. The default value for `kind` will\nbe automatically selected based only on memory usage, so one may\nmanually set ``kind='table'`` if memory constraints can be relaxed.\n\n.. versionadded:: 1.13.0",
        "examples": ">>> element = 2*np.arange(4).reshape((2, 2))\n>>> element\narray([[0, 2],\n       [4, 6]])\n>>> test_elements = [1, 2, 4, 8]\n>>> mask = np.isin(element, test_elements)\n>>> mask\narray([[False,  True],\n       [ True, False]])\n>>> element[mask]\narray([2, 4])\n\nThe indices of the matched values can be obtained with `nonzero`:\n\n>>> np.nonzero(mask)\n(array([0, 1]), array([1, 0]))\n\nThe test can also be inverted:\n\n>>> mask = np.isin(element, test_elements, invert=True)\n>>> mask\narray([[ True, False],\n       [False,  True]])\n>>> element[mask]\narray([0, 6])\n\nBecause of how `array` handles sets, the following does not\nwork as expected:\n\n>>> test_set = {1, 2, 4, 8}\n>>> np.isin(element, test_set)\narray([[False, False],\n       [False, False]])\n\nCasting the set to a list gives the expected result:\n\n>>> np.isin(element, list(test_set))\narray([[False,  True],\n       [ True, False]])"
      }
    },
    {
      "name": "isneginf",
      "signature": "isneginf(x, out=None)",
      "docstring": {
        "description": "Test element-wise for negative infinity, return result as bool array.",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "The input array."
          },
          "out": {
            "type": "array_like, optional",
            "description": "A location into which the result is stored. If provided, it must have a\n    shape that the input broadcasts to. If not provided or None, a\n    freshly-allocated boolean array is returned."
          }
        },
        "returns": "out : ndarray\n    A boolean array with the same dimensions as the input.\n    If second argument is not supplied then a numpy boolean array is\n    returned with values True where the corresponding element of the\n    input is negative infinity and values False where the element of\n    the input is not negative infinity.\n\n    If a second argument is supplied the result is stored there. If the\n    type of that array is a numeric type the result is represented as\n    zeros and ones, if the type is boolean then as False and True. The\n    return value `out` is then a reference to that array.",
        "raises": "",
        "see_also": "isinf, isposinf, isnan, isfinite",
        "notes": "NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic\n(IEEE 754).\n\nErrors result if the second argument is also supplied when x is a scalar\ninput, if first and second arguments have different shapes, or if the\nfirst argument has complex values.",
        "examples": ">>> np.isneginf(np.NINF)\nTrue\n>>> np.isneginf(np.inf)\nFalse\n>>> np.isneginf(np.PINF)\nFalse\n>>> np.isneginf([-np.inf, 0., np.inf])\narray([ True, False, False])\n\n>>> x = np.array([-np.inf, 0., np.inf])\n>>> y = np.array([2, 2, 2])\n>>> np.isneginf(x, y)\narray([1, 0, 0])\n>>> y\narray([1, 0, 0])"
      }
    },
    {
      "name": "isposinf",
      "signature": "isposinf(x, out=None)",
      "docstring": {
        "description": "Test element-wise for positive infinity, return result as bool array.",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "The input array."
          },
          "out": {
            "type": "array_like, optional",
            "description": "A location into which the result is stored. If provided, it must have a\n    shape that the input broadcasts to. If not provided or None, a\n    freshly-allocated boolean array is returned."
          }
        },
        "returns": "out : ndarray\n    A boolean array with the same dimensions as the input.\n    If second argument is not supplied then a boolean array is returned\n    with values True where the corresponding element of the input is\n    positive infinity and values False where the element of the input is\n    not positive infinity.\n\n    If a second argument is supplied the result is stored there. If the\n    type of that array is a numeric type the result is represented as zeros\n    and ones, if the type is boolean then as False and True.\n    The return value `out` is then a reference to that array.",
        "raises": "",
        "see_also": "isinf, isneginf, isfinite, isnan",
        "notes": "NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic\n(IEEE 754).\n\nErrors result if the second argument is also supplied when x is a scalar\ninput, if first and second arguments have different shapes, or if the\nfirst argument has complex values",
        "examples": ">>> np.isposinf(np.PINF)\nTrue\n>>> np.isposinf(np.inf)\nTrue\n>>> np.isposinf(np.NINF)\nFalse\n>>> np.isposinf([-np.inf, 0., np.inf])\narray([False, False,  True])\n\n>>> x = np.array([-np.inf, 0., np.inf])\n>>> y = np.array([2, 2, 2])\n>>> np.isposinf(x, y)\narray([0, 0, 1])\n>>> y\narray([0, 0, 1])"
      }
    },
    {
      "name": "isreal",
      "signature": "isreal(x)",
      "docstring": {
        "description": "Returns a bool array, where True if input element is real.\n\nIf element has complex type with zero complex part, the return value\nfor that element is True.",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "Input array."
          }
        },
        "returns": "out : ndarray, bool\n    Boolean array of same shape as `x`.",
        "raises": "",
        "see_also": "iscomplex\nisrealobj : Return True if x is not a complex type.",
        "notes": "`isreal` may behave unexpectedly for string or object arrays (see examples)",
        "examples": ">>> a = np.array([1+1j, 1+0j, 4.5, 3, 2, 2j], dtype=complex)\n>>> np.isreal(a)\narray([False,  True,  True,  True,  True, False])\n\nThe function does not work on string arrays.\n\n>>> a = np.array([2j, \"a\"], dtype=\"U\")\n>>> np.isreal(a)  # Warns about non-elementwise comparison\nFalse\n\nReturns True for all elements in input array of ``dtype=object`` even if\nany of the elements is complex.\n\n>>> a = np.array([1, \"2\", 3+4j], dtype=object)\n>>> np.isreal(a)\narray([ True,  True,  True])\n\nisreal should not be used with object arrays\n\n>>> a = np.array([1+2j, 2+1j], dtype=object)\n>>> np.isreal(a)\narray([ True,  True])"
      }
    },
    {
      "name": "isrealobj",
      "signature": "isrealobj(x)",
      "docstring": {
        "description": "Return True if x is a not complex type or an array of complex numbers.\n\nThe type of the input is checked, not the value. So even if the input\nhas an imaginary part equal to zero, `isrealobj` evaluates to False\nif the data type is complex.",
        "parameters": {
          "x": {
            "type": "any",
            "description": "The input can be of any type and shape."
          }
        },
        "returns": "y : bool\n    The return value, False if `x` is of a complex type.",
        "raises": "",
        "see_also": "iscomplexobj, isreal",
        "notes": "The function is only meant for arrays with numerical values but it\naccepts all other objects. Since it assumes array input, the return\nvalue of other objects may be True.\n\n>>> np.isrealobj('A string')\nTrue\n>>> np.isrealobj(False)\nTrue\n>>> np.isrealobj(None)\nTrue",
        "examples": ">>> np.isrealobj(1)\nTrue\n>>> np.isrealobj(1+0j)\nFalse\n>>> np.isrealobj([3, 1+0j, True])\nFalse"
      }
    },
    {
      "name": "issubclass_",
      "signature": "issubclass_(arg1, arg2)",
      "docstring": {
        "description": "Determine if a class is a subclass of a second class.\n\n`issubclass_` is equivalent to the Python built-in ``issubclass``,\nexcept that it returns False instead of raising a TypeError if one\nof the arguments is not a class.",
        "parameters": {
          "arg1": {
            "type": "class",
            "description": "Input class. True is returned if `arg1` is a subclass of `arg2`."
          },
          "arg2": {
            "type": "class or tuple of classes.",
            "description": "Input class. If a tuple of classes, True is returned if `arg1` is a\n    subclass of any of the tuple elements."
          }
        },
        "returns": "out : bool\n    Whether `arg1` is a subclass of `arg2` or not.",
        "raises": "",
        "see_also": "issubsctype, issubdtype, issctype",
        "notes": "",
        "examples": ">>> np.issubclass_(np.int32, int)\nFalse\n>>> np.issubclass_(np.int32, float)\nFalse\n>>> np.issubclass_(np.float64, float)\nTrue"
      }
    },
    {
      "name": "issubdtype",
      "signature": "issubdtype(arg1, arg2)",
      "docstring": {
        "description": "Returns True if first argument is a typecode lower/equal in type hierarchy.\n\nThis is like the builtin :func:`issubclass`, but for `dtype`\\ s.",
        "parameters": {},
        "returns": "out : bool",
        "raises": "",
        "see_also": ":ref:`arrays.scalars` : Overview of the numpy type hierarchy.\nissubsctype, issubclass_",
        "notes": "",
        "examples": "`issubdtype` can be used to check the type of arrays:\n\n>>> ints = np.array([1, 2, 3], dtype=np.int32)\n>>> np.issubdtype(ints.dtype, np.integer)\nTrue\n>>> np.issubdtype(ints.dtype, np.floating)\nFalse\n\n>>> floats = np.array([1, 2, 3], dtype=np.float32)\n>>> np.issubdtype(floats.dtype, np.integer)\nFalse\n>>> np.issubdtype(floats.dtype, np.floating)\nTrue\n\nSimilar types of different sizes are not subdtypes of each other:\n\n>>> np.issubdtype(np.float64, np.float32)\nFalse\n>>> np.issubdtype(np.float32, np.float64)\nFalse\n\nbut both are subtypes of `floating`:\n\n>>> np.issubdtype(np.float64, np.floating)\nTrue\n>>> np.issubdtype(np.float32, np.floating)\nTrue\n\nFor convenience, dtype-like objects are allowed too:\n\n>>> np.issubdtype('S1', np.string_)\nTrue\n>>> np.issubdtype('i4', np.signedinteger)\nTrue"
      }
    },
    {
      "name": "issubsctype",
      "signature": "issubsctype(arg1, arg2)",
      "docstring": {
        "description": "Determine if the first argument is a subclass of the second argument.",
        "parameters": {},
        "returns": "out : bool\n    The result.",
        "raises": "",
        "see_also": "issctype, issubdtype, obj2sctype",
        "notes": "",
        "examples": ">>> np.issubsctype('S8', str)\nFalse\n>>> np.issubsctype(np.array([1]), int)\nTrue\n>>> np.issubsctype(np.array([1]), float)\nFalse"
      }
    },
    {
      "name": "iterable",
      "signature": "iterable(y)",
      "docstring": {
        "description": "Check whether or not an object can be iterated over.",
        "parameters": {
          "y": {
            "type": "object",
            "description": "Input object."
          }
        },
        "returns": "b : bool\n  Return ``True`` if the object has an iterator method or is a\n  sequence and ``False`` otherwise.",
        "raises": "",
        "see_also": "",
        "notes": "In most cases, the results of ``np.iterable(obj)`` are consistent with\n``isinstance(obj, collections.abc.Iterable)``. One notable exception is\nthe treatment of 0-dimensional arrays::\n\n    >>> from collections.abc import Iterable\n    >>> a = np.array(1.0)  # 0-dimensional numpy array\n    >>> isinstance(a, Iterable)\n    True\n    >>> np.iterable(a)\n    False",
        "examples": ">>> np.iterable([1, 2, 3])\nTrue\n>>> np.iterable(2)\nFalse"
      }
    },
    {
      "name": "ix_",
      "signature": "ix_(*args)",
      "docstring": {
        "description": "Construct an open mesh from multiple sequences.\n\nThis function takes N 1-D sequences and returns N outputs with N\ndimensions each, such that the shape is 1 in all but one dimension\nand the dimension with the non-unit shape value cycles through all\nN dimensions.\n\nUsing `ix_` one can quickly construct index arrays that will index\nthe cross product. ``a[np.ix_([1,3],[2,5])]`` returns the array\n``[[a[1,2] a[1,5]], [a[3,2] a[3,5]]]``.",
        "parameters": {
          "args": {
            "type": "1-D sequences",
            "description": "Each sequence should be of integer or boolean type.\n    Boolean sequences will be interpreted as boolean masks for the\n    corresponding dimension (equivalent to passing in\n    ``np.nonzero(boolean_sequence)``)."
          }
        },
        "returns": "out : tuple of ndarrays\n    N arrays with N dimensions each, with N the number of input\n    sequences. Together these arrays form an open mesh.",
        "raises": "",
        "see_also": "ogrid, mgrid, meshgrid",
        "notes": "",
        "examples": ">>> a = np.arange(10).reshape(2, 5)\n>>> a\narray([[0, 1, 2, 3, 4],\n       [5, 6, 7, 8, 9]])\n>>> ixgrid = np.ix_([0, 1], [2, 4])\n>>> ixgrid\n(array([[0],\n       [1]]), array([[2, 4]]))\n>>> ixgrid[0].shape, ixgrid[1].shape\n((2, 1), (1, 2))\n>>> a[ixgrid]\narray([[2, 4],\n       [7, 9]])\n\n>>> ixgrid = np.ix_([True, True], [2, 4])\n>>> a[ixgrid]\narray([[2, 4],\n       [7, 9]])\n>>> ixgrid = np.ix_([True, True], [False, False, True, False, True])\n>>> a[ixgrid]\narray([[2, 4],\n       [7, 9]])"
      }
    },
    {
      "name": "kaiser",
      "signature": "kaiser(M, beta)",
      "docstring": {
        "description": "Return the Kaiser window.\n\nThe Kaiser window is a taper formed by using a Bessel function.",
        "parameters": {
          "M": {
            "type": "int",
            "description": "Number of points in the output window. If zero or less, an\n    empty array is returned."
          },
          "beta": {
            "type": "float",
            "description": "Shape parameter for window."
          }
        },
        "returns": "out : array\n    The window, with the maximum value normalized to one (the value\n    one appears only if the number of samples is odd).",
        "raises": "",
        "see_also": "bartlett, blackman, hamming, hanning",
        "notes": "The Kaiser window is defined as\n\n.. math::  w(n) = I_0\\left( \\beta \\sqrt{1-\\frac{4n^2}{(M-1)^2}}\n           \\right)/I_0(\\beta)\n\nwith\n\n.. math:: \\quad -\\frac{M-1}{2} \\leq n \\leq \\frac{M-1}{2},\n\nwhere :math:`I_0` is the modified zeroth-order Bessel function.\n\nThe Kaiser was named for Jim Kaiser, who discovered a simple\napproximation to the DPSS window based on Bessel functions.  The Kaiser\nwindow is a very good approximation to the Digital Prolate Spheroidal\nSequence, or Slepian window, which is the transform which maximizes the\nenergy in the main lobe of the window relative to total energy.\n\nThe Kaiser can approximate many other windows by varying the beta\nparameter.\n\n====  =======================\nbeta  Window shape\n====  =======================\n0     Rectangular\n5     Similar to a Hamming\n6     Similar to a Hanning\n8.6   Similar to a Blackman\n====  =======================\n\nA beta value of 14 is probably a good starting point. Note that as beta\ngets large, the window narrows, and so the number of samples needs to be\nlarge enough to sample the increasingly narrow spike, otherwise NaNs will\nget returned.\n\nMost references to the Kaiser window come from the signal processing\nliterature, where it is used as one of many windowing functions for\nsmoothing values.  It is also known as an apodization (which means\n\"removing the foot\", i.e. smoothing discontinuities at the beginning\nand end of the sampled signal) or tapering function.\n\nReferences\n----------\n.. [1] J. F. Kaiser, \"Digital Filters\" - Ch 7 in \"Systems analysis by\n       digital computer\", Editors: F.F. Kuo and J.F. Kaiser, p 218-285.\n       John Wiley and Sons, New York, (1966).\n.. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\", The\n       University of Alberta Press, 1975, pp. 177-178.\n.. [3] Wikipedia, \"Window function\",\n       https://en.wikipedia.org/wiki/Window_function",
        "examples": ">>> import matplotlib.pyplot as plt\n>>> np.kaiser(12, 14)\n array([7.72686684e-06, 3.46009194e-03, 4.65200189e-02, # may vary\n        2.29737120e-01, 5.99885316e-01, 9.45674898e-01,\n        9.45674898e-01, 5.99885316e-01, 2.29737120e-01,\n        4.65200189e-02, 3.46009194e-03, 7.72686684e-06])\n\n\nPlot the window and the frequency response:\n\n>>> from numpy.fft import fft, fftshift\n>>> window = np.kaiser(51, 14)\n>>> plt.plot(window)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Kaiser window\")\nText(0.5, 1.0, 'Kaiser window')\n>>> plt.ylabel(\"Amplitude\")\nText(0, 0.5, 'Amplitude')\n>>> plt.xlabel(\"Sample\")\nText(0.5, 0, 'Sample')\n>>> plt.show()\n\n>>> plt.figure()\n<Figure size 640x480 with 0 Axes>\n>>> A = fft(window, 2048) / 25.5\n>>> mag = np.abs(fftshift(A))\n>>> freq = np.linspace(-0.5, 0.5, len(A))\n>>> response = 20 * np.log10(mag)\n>>> response = np.clip(response, -100, 100)\n>>> plt.plot(freq, response)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Frequency response of Kaiser window\")\nText(0.5, 1.0, 'Frequency response of Kaiser window')\n>>> plt.ylabel(\"Magnitude [dB]\")\nText(0, 0.5, 'Magnitude [dB]')\n>>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\nText(0.5, 0, 'Normalized frequency [cycles per sample]')\n>>> plt.axis('tight')\n(-0.5, 0.5, -100.0, ...) # may vary\n>>> plt.show()"
      }
    },
    {
      "name": "kron",
      "signature": "kron(a, b)",
      "docstring": {
        "description": "Kronecker product of two arrays.\n\nComputes the Kronecker product, a composite array made of blocks of the\nsecond array scaled by the first.",
        "parameters": {},
        "returns": "out : ndarray",
        "raises": "",
        "see_also": "outer : The outer product",
        "notes": "The function assumes that the number of dimensions of `a` and `b`\nare the same, if necessary prepending the smallest with ones.\nIf ``a.shape = (r0,r1,..,rN)`` and ``b.shape = (s0,s1,...,sN)``,\nthe Kronecker product has shape ``(r0*s0, r1*s1, ..., rN*SN)``.\nThe elements are products of elements from `a` and `b`, organized\nexplicitly by::\n\n    kron(a,b)[k0,k1,...,kN] = a[i0,i1,...,iN] * b[j0,j1,...,jN]\n\nwhere::\n\n    kt = it * st + jt,  t = 0,...,N\n\nIn the common 2-D case (N=1), the block structure can be visualized::\n\n    [[ a[0,0]*b,   a[0,1]*b,  ... , a[0,-1]*b  ],\n     [  ...                              ...   ],\n     [ a[-1,0]*b,  a[-1,1]*b, ... , a[-1,-1]*b ]]",
        "examples": ">>> np.kron([1,10,100], [5,6,7])\narray([  5,   6,   7, ..., 500, 600, 700])\n>>> np.kron([5,6,7], [1,10,100])\narray([  5,  50, 500, ...,   7,  70, 700])\n\n>>> np.kron(np.eye(2), np.ones((2,2)))\narray([[1.,  1.,  0.,  0.],\n       [1.,  1.,  0.,  0.],\n       [0.,  0.,  1.,  1.],\n       [0.,  0.,  1.,  1.]])\n\n>>> a = np.arange(100).reshape((2,5,2,5))\n>>> b = np.arange(24).reshape((2,3,4))\n>>> c = np.kron(a,b)\n>>> c.shape\n(2, 10, 6, 20)\n>>> I = (1,3,0,2)\n>>> J = (0,2,1)\n>>> J1 = (0,) + J             # extend to ndim=4\n>>> S1 = (1,) + b.shape\n>>> K = tuple(np.array(I) * np.array(S1) + np.array(J1))\n>>> c[K] == a[I]*b[J]\nTrue"
      }
    },
    {
      "name": "load",
      "signature": "load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII', *, max_header_size=10000)",
      "docstring": {
        "description": "Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.\n\n.. warning:: Loading files that contain object arrays uses the ``pickle``\n             module, which is not secure against erroneous or maliciously\n             constructed data. Consider passing ``allow_pickle=False`` to\n             load data that is known not to contain object arrays for the\n             safer handling of untrusted sources.",
        "parameters": {
          "file": {
            "type": "file-like object, string, or pathlib.Path",
            "description": "The file to read. File-like objects must support the\n    ``seek()`` and ``read()`` methods and must always\n    be opened in binary mode.  Pickled files require that the\n    file-like object support the ``readline()`` method as well."
          },
          "mmap_mode": {
            "type": "{None, 'r+', 'r', 'w+', 'c'}, optional",
            "description": "If not None, then memory-map the file, using the given mode (see\n    `numpy.memmap` for a detailed description of the modes).  A\n    memory-mapped array is kept on disk. However, it can be accessed\n    and sliced like any ndarray.  Memory mapping is especially useful\n    for accessing small fragments of large files without reading the\n    entire file into memory."
          },
          "allow_pickle": {
            "type": "bool, optional",
            "description": "Allow loading pickled object arrays stored in npy files. Reasons for\n    disallowing pickles include security, as loading pickled data can\n    execute arbitrary code. If pickles are disallowed, loading object\n    arrays will fail. Default: False\n\n    .. versionchanged:: 1.16.3\n        Made default False in response to CVE-2019-6446."
          },
          "fix_imports": {
            "type": "bool, optional",
            "description": "Only useful when loading Python 2 generated pickled files on Python 3,\n    which includes npy/npz files containing object arrays. If `fix_imports`\n    is True, pickle will try to map the old Python 2 names to the new names\n    used in Python 3."
          },
          "encoding": {
            "type": "str, optional",
            "description": "What encoding to use when reading Python 2 strings. Only useful when\n    loading Python 2 generated pickled files in Python 3, which includes\n    npy/npz files containing object arrays. Values other than 'latin1',\n    'ASCII', and 'bytes' are not allowed, as they can corrupt numerical\n    data. Default: 'ASCII'"
          },
          "max_header_size": {
            "type": "int, optional",
            "description": "Maximum allowed size of the header.  Large headers may not be safe\n    to load securely and thus require explicitly passing a larger value.\n    See :py:func:`ast.literal_eval()` for details.\n    This option is ignored when `allow_pickle` is passed.  In that case\n    the file is by definition trusted and the limit is unnecessary."
          }
        },
        "returns": "result : array, tuple, dict, etc.\n    Data stored in the file. For ``.npz`` files, the returned instance\n    of NpzFile class must be closed to avoid leaking file descriptors.",
        "raises": "OSError\n    If the input file does not exist or cannot be read.\nUnpicklingError\n    If ``allow_pickle=True``, but the file cannot be loaded as a pickle.\nValueError\n    The file contains an object array, but ``allow_pickle=False`` given.\nEOFError\n    When calling ``np.load`` multiple times on the same file handle,\n    if all data has already been read",
        "see_also": "save, savez, savez_compressed, loadtxt\nmemmap : Create a memory-map to an array stored in a file on disk.\nlib.format.open_memmap : Create or load a memory-mapped ``.npy`` file.",
        "notes": "- If the file contains pickle data, then whatever object is stored\n  in the pickle is returned.\n- If the file is a ``.npy`` file, then a single array is returned.\n- If the file is a ``.npz`` file, then a dictionary-like object is\n  returned, containing ``{filename: array}`` key-value pairs, one for\n  each file in the archive.\n- If the file is a ``.npz`` file, the returned value supports the\n  context manager protocol in a similar fashion to the open function::\n\n    with load('foo.npz') as data:\n        a = data['a']\n\n  The underlying file descriptor is closed when exiting the 'with'\n  block.",
        "examples": "Store data to disk, and load it again:\n\n>>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))\n>>> np.load('/tmp/123.npy')\narray([[1, 2, 3],\n       [4, 5, 6]])\n\nStore compressed data to disk, and load it again:\n\n>>> a=np.array([[1, 2, 3], [4, 5, 6]])\n>>> b=np.array([1, 2])\n>>> np.savez('/tmp/123.npz', a=a, b=b)\n>>> data = np.load('/tmp/123.npz')\n>>> data['a']\narray([[1, 2, 3],\n       [4, 5, 6]])\n>>> data['b']\narray([1, 2])\n>>> data.close()\n\nMem-map the stored array, and then access the second row\ndirectly from disk:\n\n>>> X = np.load('/tmp/123.npy', mmap_mode='r')\n>>> X[1, :]\nmemmap([4, 5, 6])"
      }
    },
    {
      "name": "loadtxt",
      "signature": "loadtxt(fname, dtype=<class 'float'>, comments='#', delimiter=None, converters=None, skiprows=0, usecols=None, unpack=False, ndmin=0, encoding='bytes', max_rows=None, *, quotechar=None, like=None)",
      "docstring": {
        "description": "Load data from a text file.",
        "parameters": {
          "fname": {
            "type": "file, str, pathlib.Path, list of str, generator",
            "description": "File, filename, list, or generator to read.  If the filename\n    extension is ``.gz`` or ``.bz2``, the file is first decompressed. Note\n    that generators must return bytes or strings. The strings\n    in a list or produced by a generator are treated as lines."
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "Data-type of the resulting array; default: float.  If this is a\n    structured data-type, the resulting array will be 1-dimensional, and\n    each row will be interpreted as an element of the array.  In this\n    case, the number of columns used must match the number of fields in\n    the data-type."
          },
          "comments": {
            "type": "str or sequence of str or None, optional",
            "description": "The characters or list of characters used to indicate the start of a\n    comment. None implies no comments. For backwards compatibility, byte\n    strings will be decoded as 'latin1'. The default is '#'."
          },
          "delimiter": {
            "type": "str, optional",
            "description": "The character used to separate the values. For backwards compatibility,\n    byte strings will be decoded as 'latin1'. The default is whitespace.\n\n    .. versionchanged:: 1.23.0\n       Only single character delimiters are supported. Newline characters\n       cannot be used as the delimiter."
          },
          "converters": {
            "type": "dict or callable, optional",
            "description": "Converter functions to customize value parsing. If `converters` is\n    callable, the function is applied to all columns, else it must be a\n    dict that maps column number to a parser function.\n    See examples for further details.\n    Default: None.\n\n    .. versionchanged:: 1.23.0\n       The ability to pass a single callable to be applied to all columns\n       was added."
          },
          "skiprows": {
            "type": "int, optional",
            "description": "Skip the first `skiprows` lines, including comments; default: 0."
          },
          "usecols": {
            "type": "int or sequence, optional",
            "description": "Which columns to read, with 0 being the first. For example,\n    ``usecols = (1,4,5)`` will extract the 2nd, 5th and 6th columns.\n    The default, None, results in all columns being read.\n\n    .. versionchanged:: 1.11.0\n        When a single column has to be read it is possible to use\n        an integer instead of a tuple. E.g ``usecols = 3`` reads the\n        fourth column the same way as ``usecols = (3,)`` would."
          },
          "unpack": {
            "type": "bool, optional",
            "description": "If True, the returned array is transposed, so that arguments may be\n    unpacked using ``x, y, z = loadtxt(...)``.  When used with a\n    structured data-type, arrays are returned for each field.\n    Default is False."
          },
          "ndmin": {
            "type": "int, optional",
            "description": "The returned array will have at least `ndmin` dimensions.\n    Otherwise mono-dimensional axes will be squeezed.\n    Legal values: 0 (default), 1 or 2.\n\n    .. versionadded:: 1.6.0"
          },
          "encoding": {
            "type": "str, optional",
            "description": "Encoding used to decode the inputfile. Does not apply to input streams.\n    The special value 'bytes' enables backward compatibility workarounds\n    that ensures you receive byte arrays as results if possible and passes\n    'latin1' encoded strings to converters. Override this value to receive\n    unicode arrays and pass strings as input to converters.  If set to None\n    the system default is used. The default value is 'bytes'.\n\n    .. versionadded:: 1.14.0"
          },
          "max_rows": {
            "type": "int, optional",
            "description": "Read `max_rows` rows of content after `skiprows` lines. The default is\n    to read all the rows. Note that empty rows containing no data such as\n    empty lines and comment lines are not counted towards `max_rows`,\n    while such lines are counted in `skiprows`.\n\n    .. versionadded:: 1.16.0\n\n    .. versionchanged:: 1.23.0\n        Lines containing no data, including comment lines (e.g., lines\n        starting with '#' or as specified via `comments`) are not counted\n        towards `max_rows`."
          },
          "quotechar": {
            "type": "unicode character or None, optional",
            "description": "The character used to denote the start and end of a quoted item.\n    Occurrences of the delimiter or comment characters are ignored within\n    a quoted item. The default value is ``quotechar=None``, which means\n    quoting support is disabled.\n\n    If two consecutive instances of `quotechar` are found within a quoted\n    field, the first is treated as an escape character. See examples.\n\n    .. versionadded:: 1.23.0"
          },
          "like": {
            "type": "array_like, optional",
            "description": "Reference object to allow the creation of arrays which are not\n    NumPy arrays. If an array-like passed in as ``like`` supports\n    the ``__array_function__`` protocol, the result will be defined\n    by it. In this case, it ensures the creation of an array object\n    compatible with that passed in via this argument.\n\n    .. versionadded:: 1.20.0"
          }
        },
        "returns": "out : ndarray\n    Data read from the text file.",
        "raises": "",
        "see_also": "load, fromstring, fromregex\ngenfromtxt : Load data with missing values handled as specified.\nscipy.io.loadmat : reads MATLAB data files",
        "notes": "This function aims to be a fast reader for simply formatted files.  The\n`genfromtxt` function provides more sophisticated handling of, e.g.,\nlines with missing values.\n\nEach row in the input text file must have the same number of values to be\nable to read all values. If all rows do not have same number of values, a\nsubset of up to n columns (where n is the least number of values present\nin all rows) can be read by specifying the columns via `usecols`.\n\n.. versionadded:: 1.10.0\n\nThe strings produced by the Python float.hex method can be used as\ninput for floats.",
        "examples": ">>> from io import StringIO   # StringIO behaves like a file object\n>>> c = StringIO(\"0 1\\n2 3\")\n>>> np.loadtxt(c)\narray([[0., 1.],\n       [2., 3.]])\n\n>>> d = StringIO(\"M 21 72\\nF 35 58\")\n>>> np.loadtxt(d, dtype={'names': ('gender', 'age', 'weight'),\n...                      'formats': ('S1', 'i4', 'f4')})\narray([(b'M', 21, 72.), (b'F', 35, 58.)],\n      dtype=[('gender', 'S1'), ('age', '<i4'), ('weight', '<f4')])\n\n>>> c = StringIO(\"1,0,2\\n3,0,4\")\n>>> x, y = np.loadtxt(c, delimiter=',', usecols=(0, 2), unpack=True)\n>>> x\narray([1., 3.])\n>>> y\narray([2., 4.])\n\nThe `converters` argument is used to specify functions to preprocess the\ntext prior to parsing. `converters` can be a dictionary that maps\npreprocessing functions to each column:\n\n>>> s = StringIO(\"1.618, 2.296\\n3.141, 4.669\\n\")\n>>> conv = {\n...     0: lambda x: np.floor(float(x)),  # conversion fn for column 0\n...     1: lambda x: np.ceil(float(x)),  # conversion fn for column 1\n... }\n>>> np.loadtxt(s, delimiter=\",\", converters=conv)\narray([[1., 3.],\n       [3., 5.]])\n\n`converters` can be a callable instead of a dictionary, in which case it\nis applied to all columns:\n\n>>> s = StringIO(\"0xDE 0xAD\\n0xC0 0xDE\")\n>>> import functools\n>>> conv = functools.partial(int, base=16)\n>>> np.loadtxt(s, converters=conv)\narray([[222., 173.],\n       [192., 222.]])\n\nThis example shows how `converters` can be used to convert a field\nwith a trailing minus sign into a negative number.\n\n>>> s = StringIO('10.01 31.25-\\n19.22 64.31\\n17.57- 63.94')\n>>> def conv(fld):\n...     return -float(fld[:-1]) if fld.endswith(b'-') else float(fld)\n...\n>>> np.loadtxt(s, converters=conv)\narray([[ 10.01, -31.25],\n       [ 19.22,  64.31],\n       [-17.57,  63.94]])\n\nUsing a callable as the converter can be particularly useful for handling\nvalues with different formatting, e.g. floats with underscores:\n\n>>> s = StringIO(\"1 2.7 100_000\")\n>>> np.loadtxt(s, converters=float)\narray([1.e+00, 2.7e+00, 1.e+05])\n\nThis idea can be extended to automatically handle values specified in\nmany different formats:\n\n>>> def conv(val):\n...     try:\n...         return float(val)\n...     except ValueError:\n...         return float.fromhex(val)\n>>> s = StringIO(\"1, 2.5, 3_000, 0b4, 0x1.4000000000000p+2\")\n>>> np.loadtxt(s, delimiter=\",\", converters=conv, encoding=None)\narray([1.0e+00, 2.5e+00, 3.0e+03, 1.8e+02, 5.0e+00])\n\nNote that with the default ``encoding=\"bytes\"``, the inputs to the\nconverter function are latin-1 encoded byte strings. To deactivate the\nimplicit encoding prior to conversion, use ``encoding=None``\n\n>>> s = StringIO('10.01 31.25-\\n19.22 64.31\\n17.57- 63.94')\n>>> conv = lambda x: -float(x[:-1]) if x.endswith('-') else float(x)\n>>> np.loadtxt(s, converters=conv, encoding=None)\narray([[ 10.01, -31.25],\n       [ 19.22,  64.31],\n       [-17.57,  63.94]])\n\nSupport for quoted fields is enabled with the `quotechar` parameter.\nComment and delimiter characters are ignored when they appear within a\nquoted item delineated by `quotechar`:\n\n>>> s = StringIO('\"alpha, #42\", 10.0\\n\"beta, #64\", 2.0\\n')\n>>> dtype = np.dtype([(\"label\", \"U12\"), (\"value\", float)])\n>>> np.loadtxt(s, dtype=dtype, delimiter=\",\", quotechar='\"')\narray([('alpha, #42', 10.), ('beta, #64',  2.)],\n      dtype=[('label', '<U12'), ('value', '<f8')])\n\nQuoted fields can be separated by multiple whitespace characters:\n\n>>> s = StringIO('\"alpha, #42\"       10.0\\n\"beta, #64\" 2.0\\n')\n>>> dtype = np.dtype([(\"label\", \"U12\"), (\"value\", float)])\n>>> np.loadtxt(s, dtype=dtype, delimiter=None, quotechar='\"')\narray([('alpha, #42', 10.), ('beta, #64',  2.)],\n      dtype=[('label', '<U12'), ('value', '<f8')])\n\nTwo consecutive quote characters within a quoted field are treated as a\nsingle escaped character:\n\n>>> s = StringIO('\"Hello, my name is \"\"Monty\"\"!\"')\n>>> np.loadtxt(s, dtype=\"U\", delimiter=\",\", quotechar='\"')\narray('Hello, my name is \"Monty\"!', dtype='<U26')\n\nRead subset of columns when all rows do not contain equal number of values:\n\n>>> d = StringIO(\"1 2\\n2 4\\n3 9 12\\n4 16 20\")\n>>> np.loadtxt(d, usecols=(0, 1))\narray([[ 1.,  2.],\n       [ 2.,  4.],\n       [ 3.,  9.],\n       [ 4., 16.]])"
      }
    },
    {
      "name": "lookfor",
      "signature": "lookfor(what, module=None, import_modules=True, regenerate=False, output=None)",
      "docstring": {
        "description": "Do a keyword search on docstrings.\n\nA list of objects that matched the search is displayed,\nsorted by relevance. All given keywords need to be found in the\ndocstring for it to be returned as a result, but the order does\nnot matter.",
        "parameters": {
          "what": {
            "type": "str",
            "description": "String containing words to look for."
          },
          "module": {
            "type": "str or list, optional",
            "description": "Name of module(s) whose docstrings to go through."
          },
          "import_modules": {
            "type": "bool, optional",
            "description": "Whether to import sub-modules in packages. Default is True."
          },
          "regenerate": {
            "type": "bool, optional",
            "description": "Whether to re-generate the docstring cache. Default is False."
          },
          "output": {
            "type": "file-like, optional",
            "description": "File-like object to write the output to. If omitted, use a pager."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "source, info",
        "notes": "Relevance is determined only roughly, by checking if the keywords occur\nin the function name, at the start of a docstring, etc.",
        "examples": ">>> np.lookfor('binary representation') # doctest: +SKIP\nSearch results for 'binary representation'\n------------------------------------------\nnumpy.binary_repr\n    Return the binary representation of the input number as a string.\nnumpy.core.setup_common.long_double_representation\n    Given a binary dump as given by GNU od -b, look for long double\nnumpy.base_repr\n    Return a string representation of a number in the given base system.\n..."
      }
    },
    {
      "name": "mask_indices",
      "signature": "mask_indices(n, mask_func, k=0)",
      "docstring": {
        "description": "Return the indices to access (n, n) arrays, given a masking function.\n\nAssume `mask_func` is a function that, for a square array a of size\n``(n, n)`` with a possible offset argument `k`, when called as\n``mask_func(a, k)`` returns a new array with zeros in certain locations\n(functions like `triu` or `tril` do precisely this). Then this function\nreturns the indices where the non-zero values would be located.",
        "parameters": {
          "n": {
            "type": "int",
            "description": "The returned indices will be valid to access arrays of shape (n, n)."
          },
          "mask_func": {
            "type": "callable",
            "description": "A function whose call signature is similar to that of `triu`, `tril`.\n    That is, ``mask_func(x, k)`` returns a boolean array, shaped like `x`.\n    `k` is an optional argument to the function."
          },
          "k": {
            "type": "scalar",
            "description": "An optional argument which is passed through to `mask_func`. Functions\n    like `triu`, `tril` take a second argument that is interpreted as an\n    offset."
          }
        },
        "returns": "indices : tuple of arrays.\n    The `n` arrays of indices corresponding to the locations where\n    ``mask_func(np.ones((n, n)), k)`` is True.",
        "raises": "",
        "see_also": "triu, tril, triu_indices, tril_indices",
        "notes": ".. versionadded:: 1.4.0",
        "examples": "These are the indices that would allow you to access the upper triangular\npart of any 3x3 array:\n\n>>> iu = np.mask_indices(3, np.triu)\n\nFor example, if `a` is a 3x3 array:\n\n>>> a = np.arange(9).reshape(3, 3)\n>>> a\narray([[0, 1, 2],\n       [3, 4, 5],\n       [6, 7, 8]])\n>>> a[iu]\narray([0, 1, 2, 4, 5, 8])\n\nAn offset can be passed also to the masking function.  This gets us the\nindices starting on the first diagonal right of the main one:\n\n>>> iu1 = np.mask_indices(3, np.triu, 1)\n\nwith which we now extract only three elements:\n\n>>> a[iu1]\narray([1, 2, 5])"
      }
    },
    {
      "name": "median",
      "signature": "median(a, axis=None, out=None, overwrite_input=False, keepdims=False)",
      "docstring": {
        "description": "Compute the median along the specified axis.\n\nReturns the median of the array elements.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array or object that can be converted to an array."
          },
          "axis": {
            "type": "{int, sequence of int, None}, optional",
            "description": "Axis or axes along which the medians are computed. The default\n    is to compute the median along a flattened version of the array.\n    A sequence of axes is supported since version 1.9.0."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must\n    have the same shape and buffer length as the expected output,\n    but the type (of the output) will be cast if necessary."
          },
          "overwrite_input": {
            "type": "bool, optional",
            "description": "If True, then allow use of memory of input array `a` for\n   calculations. The input array will be modified by the call to\n   `median`. This will save memory when you do not need to preserve\n   the contents of the input array. Treat the input as undefined,\n   but it will probably be fully or partially sorted. Default is\n   False. If `overwrite_input` is ``True`` and `a` is not already an\n   `ndarray`, an error will be raised."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\n    in the result as dimensions with size one. With this option,\n    the result will broadcast correctly against the original `arr`.\n\n    .. versionadded:: 1.9.0"
          }
        },
        "returns": "median : ndarray\n    A new array holding the result. If the input contains integers\n    or floats smaller than ``float64``, then the output data-type is\n    ``np.float64``.  Otherwise, the data-type of the output is the\n    same as that of the input. If `out` is specified, that array is\n    returned instead.",
        "raises": "",
        "see_also": "mean, percentile",
        "notes": "Given a vector ``V`` of length ``N``, the median of ``V`` is the\nmiddle value of a sorted copy of ``V``, ``V_sorted`` - i\ne., ``V_sorted[(N-1)/2]``, when ``N`` is odd, and the average of the\ntwo middle values of ``V_sorted`` when ``N`` is even.",
        "examples": ">>> a = np.array([[10, 7, 4], [3, 2, 1]])\n>>> a\narray([[10,  7,  4],\n       [ 3,  2,  1]])\n>>> np.median(a)\n3.5\n>>> np.median(a, axis=0)\narray([6.5, 4.5, 2.5])\n>>> np.median(a, axis=1)\narray([7.,  2.])\n>>> m = np.median(a, axis=0)\n>>> out = np.zeros_like(m)\n>>> np.median(a, axis=0, out=m)\narray([6.5,  4.5,  2.5])\n>>> m\narray([6.5,  4.5,  2.5])\n>>> b = a.copy()\n>>> np.median(b, axis=1, overwrite_input=True)\narray([7.,  2.])\n>>> assert not np.all(a==b)\n>>> b = a.copy()\n>>> np.median(b, axis=None, overwrite_input=True)\n3.5\n>>> assert not np.all(a==b)"
      }
    },
    {
      "name": "meshgrid",
      "signature": "meshgrid(*xi, copy=True, sparse=False, indexing='xy')",
      "docstring": {
        "description": "Return a list of coordinate matrices from coordinate vectors.\n\nMake N-D coordinate arrays for vectorized evaluations of\nN-D scalar/vector fields over N-D grids, given\none-dimensional coordinate arrays x1, x2,..., xn.\n\n.. versionchanged:: 1.9\n   1-D and 0-D cases are allowed.",
        "parameters": {
          "indexing": {
            "type": "{'xy', 'ij'}, optional",
            "description": "Cartesian ('xy', default) or matrix ('ij') indexing of output.\n    See Notes for more details.\n\n    .. versionadded:: 1.7.0"
          },
          "sparse": {
            "type": "bool, optional",
            "description": "If True the shape of the returned coordinate array for dimension *i*\n    is reduced from ``(N1, ..., Ni, ... Nn)`` to\n    ``(1, ..., 1, Ni, 1, ..., 1)``.  These sparse coordinate grids are\n    intended to be use with :ref:`basics.broadcasting`.  When all\n    coordinates are used in an expression, broadcasting still leads to a\n    fully-dimensonal result array.\n\n    Default is False.\n\n    .. versionadded:: 1.7.0"
          },
          "copy": {
            "type": "bool, optional",
            "description": "If False, a view into the original arrays are returned in order to\n    conserve memory.  Default is True.  Please note that\n    ``sparse=False, copy=False`` will likely return non-contiguous\n    arrays.  Furthermore, more than one element of a broadcast array\n    may refer to a single memory location.  If you need to write to the\n    arrays, make copies first.\n\n    .. versionadded:: 1.7.0"
          }
        },
        "returns": "X1, X2,..., XN : list of ndarrays\n    For vectors `x1`, `x2`,..., `xn` with lengths ``Ni=len(xi)``,\n    returns ``(N1, N2, N3,..., Nn)`` shaped arrays if indexing='ij'\n    or ``(N2, N1, N3,..., Nn)`` shaped arrays if indexing='xy'\n    with the elements of `xi` repeated to fill the matrix along\n    the first dimension for `x1`, the second for `x2` and so on.",
        "raises": "",
        "see_also": "mgrid : Construct a multi-dimensional \"meshgrid\" using indexing notation.\nogrid : Construct an open multi-dimensional \"meshgrid\" using indexing\n        notation.\nhow-to-index",
        "notes": "This function supports both indexing conventions through the indexing\nkeyword argument.  Giving the string 'ij' returns a meshgrid with\nmatrix indexing, while 'xy' returns a meshgrid with Cartesian indexing.\nIn the 2-D case with inputs of length M and N, the outputs are of shape\n(N, M) for 'xy' indexing and (M, N) for 'ij' indexing.  In the 3-D case\nwith inputs of length M, N and P, outputs are of shape (N, M, P) for\n'xy' indexing and (M, N, P) for 'ij' indexing.  The difference is\nillustrated by the following code snippet::\n\n    xv, yv = np.meshgrid(x, y, indexing='ij')\n    for i in range(nx):\n        for j in range(ny):\n            # treat xv[i,j], yv[i,j]\n\n    xv, yv = np.meshgrid(x, y, indexing='xy')\n    for i in range(nx):\n        for j in range(ny):\n            # treat xv[j,i], yv[j,i]\n\nIn the 1-D and 0-D case, the indexing and sparse keywords have no effect.",
        "examples": ">>> nx, ny = (3, 2)\n>>> x = np.linspace(0, 1, nx)\n>>> y = np.linspace(0, 1, ny)\n>>> xv, yv = np.meshgrid(x, y)\n>>> xv\narray([[0. , 0.5, 1. ],\n       [0. , 0.5, 1. ]])\n>>> yv\narray([[0.,  0.,  0.],\n       [1.,  1.,  1.]])\n\nThe result of `meshgrid` is a coordinate grid:\n\n>>> import matplotlib.pyplot as plt\n>>> plt.plot(xv, yv, marker='o', color='k', linestyle='none')\n>>> plt.show()\n\nYou can create sparse output arrays to save memory and computation time.\n\n>>> xv, yv = np.meshgrid(x, y, sparse=True)\n>>> xv\narray([[0. ,  0.5,  1. ]])\n>>> yv\narray([[0.],\n       [1.]])\n\n`meshgrid` is very useful to evaluate functions on a grid. If the\nfunction depends on all coordinates, both dense and sparse outputs can be\nused.\n\n>>> x = np.linspace(-5, 5, 101)\n>>> y = np.linspace(-5, 5, 101)\n>>> # full coordinate arrays\n>>> xx, yy = np.meshgrid(x, y)\n>>> zz = np.sqrt(xx**2 + yy**2)\n>>> xx.shape, yy.shape, zz.shape\n((101, 101), (101, 101), (101, 101))\n>>> # sparse coordinate arrays\n>>> xs, ys = np.meshgrid(x, y, sparse=True)\n>>> zs = np.sqrt(xs**2 + ys**2)\n>>> xs.shape, ys.shape, zs.shape\n((1, 101), (101, 1), (101, 101))\n>>> np.array_equal(zz, zs)\nTrue\n\n>>> h = plt.contourf(x, y, zs)\n>>> plt.axis('scaled')\n>>> plt.colorbar()\n>>> plt.show()"
      }
    },
    {
      "name": "mintypecode",
      "signature": "mintypecode(typechars, typeset='GDFgdf', default='d')",
      "docstring": {
        "description": "Return the character for the minimum-size type to which given types can\nbe safely cast.\n\nThe returned type character must represent the smallest size dtype such\nthat an array of the returned type can handle the data from an array of\nall types in `typechars` (or if `typechars` is an array, then its\ndtype.char).",
        "parameters": {
          "typechars": {
            "type": "list of str or array_like",
            "description": "If a list of strings, each string should represent a dtype.\n    If array_like, the character representation of the array dtype is used."
          },
          "typeset": {
            "type": "str or list of str, optional",
            "description": "The set of characters that the returned character is chosen from.\n    The default set is 'GDFgdf'."
          },
          "default": {
            "type": "str, optional",
            "description": "The default character, this is returned if none of the characters in\n    `typechars` matches a character in `typeset`."
          }
        },
        "returns": "typechar : str\n    The character representing the minimum-size type that was found.",
        "raises": "",
        "see_also": "dtype, sctype2char, maximum_sctype",
        "notes": "",
        "examples": ">>> np.mintypecode(['d', 'f', 'S'])\n'd'\n>>> x = np.array([1.1, 2-3.j])\n>>> np.mintypecode(x)\n'D'\n\n>>> np.mintypecode('abceh', default='G')\n'G'"
      }
    },
    {
      "name": "msort",
      "signature": "msort(a)",
      "docstring": {
        "description": "Return a copy of an array sorted along the first axis.\n\n.. deprecated:: 1.24\n\n   msort is deprecated, use ``np.sort(a, axis=0)`` instead.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Array to be sorted."
          }
        },
        "returns": "sorted_array : ndarray\n    Array of the same type and shape as `a`.",
        "raises": "",
        "see_also": "sort",
        "notes": "``np.msort(a)`` is equivalent to  ``np.sort(a, axis=0)``.",
        "examples": ">>> a = np.array([[1, 4], [3, 1]])\n>>> np.msort(a)  # sort along the first axis\narray([[1, 1],\n       [3, 4]])"
      }
    },
    {
      "name": "nan_to_num",
      "signature": "nan_to_num(x, copy=True, nan=0.0, posinf=None, neginf=None)",
      "docstring": {
        "description": "Replace NaN with zero and infinity with large finite numbers (default\nbehaviour) or with the numbers defined by the user using the `nan`,\n`posinf` and/or `neginf` keywords.\n\nIf `x` is inexact, NaN is replaced by zero or by the user defined value in\n`nan` keyword, infinity is replaced by the largest finite floating point\nvalues representable by ``x.dtype`` or by the user defined value in\n`posinf` keyword and -infinity is replaced by the most negative finite\nfloating point values representable by ``x.dtype`` or by the user defined\nvalue in `neginf` keyword.\n\nFor complex dtypes, the above is applied to each of the real and\nimaginary components of `x` separately.\n\nIf `x` is not inexact, then no replacements are made.",
        "parameters": {
          "x": {
            "type": "scalar or array_like",
            "description": "Input data."
          },
          "copy": {
            "type": "bool, optional",
            "description": "Whether to create a copy of `x` (True) or to replace values\n    in-place (False). The in-place operation only occurs if\n    casting to an array does not require a copy.\n    Default is True.\n\n    .. versionadded:: 1.13"
          },
          "nan": {
            "type": "int, float, optional",
            "description": "Value to be used to fill NaN values. If no value is passed\n    then NaN values will be replaced with 0.0.\n\n    .. versionadded:: 1.17"
          },
          "posinf": {
            "type": "int, float, optional",
            "description": "Value to be used to fill positive infinity values. If no value is\n    passed then positive infinity values will be replaced with a very\n    large number.\n\n    .. versionadded:: 1.17"
          },
          "neginf": {
            "type": "int, float, optional",
            "description": "Value to be used to fill negative infinity values. If no value is\n    passed then negative infinity values will be replaced with a very\n    small (or negative) number.\n\n    .. versionadded:: 1.17"
          }
        },
        "returns": "out : ndarray\n    `x`, with the non-finite values replaced. If `copy` is False, this may\n    be `x` itself.",
        "raises": "",
        "see_also": "isinf : Shows which elements are positive or negative infinity.\nisneginf : Shows which elements are negative infinity.\nisposinf : Shows which elements are positive infinity.\nisnan : Shows which elements are Not a Number (NaN).\nisfinite : Shows which elements are finite (not NaN, not infinity)",
        "notes": "NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic\n(IEEE 754). This means that Not a Number is not equivalent to infinity.",
        "examples": ">>> np.nan_to_num(np.inf)\n1.7976931348623157e+308\n>>> np.nan_to_num(-np.inf)\n-1.7976931348623157e+308\n>>> np.nan_to_num(np.nan)\n0.0\n>>> x = np.array([np.inf, -np.inf, np.nan, -128, 128])\n>>> np.nan_to_num(x)\narray([ 1.79769313e+308, -1.79769313e+308,  0.00000000e+000, # may vary\n       -1.28000000e+002,  1.28000000e+002])\n>>> np.nan_to_num(x, nan=-9999, posinf=33333333, neginf=33333333)\narray([ 3.3333333e+07,  3.3333333e+07, -9.9990000e+03,\n       -1.2800000e+02,  1.2800000e+02])\n>>> y = np.array([complex(np.inf, np.nan), np.nan, complex(np.nan, np.inf)])\narray([  1.79769313e+308,  -1.79769313e+308,   0.00000000e+000, # may vary\n     -1.28000000e+002,   1.28000000e+002])\n>>> np.nan_to_num(y)\narray([  1.79769313e+308 +0.00000000e+000j, # may vary\n         0.00000000e+000 +0.00000000e+000j,\n         0.00000000e+000 +1.79769313e+308j])\n>>> np.nan_to_num(y, nan=111111, posinf=222222)\narray([222222.+111111.j, 111111.     +0.j, 111111.+222222.j])"
      }
    },
    {
      "name": "nanargmax",
      "signature": "nanargmax(a, axis=None, out=None, *, keepdims=<no value>)",
      "docstring": {
        "description": "Return the indices of the maximum values in the specified axis ignoring\nNaNs. For all-NaN slices ``ValueError`` is raised. Warning: the\nresults cannot be trusted if a slice contains only NaNs and -Infs.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input data."
          },
          "axis": {
            "type": "int, optional",
            "description": "Axis along which to operate.  By default flattened input is used."
          },
          "out": {
            "type": "array, optional",
            "description": "If provided, the result will be inserted into this array. It should\n    be of the appropriate shape and dtype.\n\n    .. versionadded:: 1.22.0"
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\n    in the result as dimensions with size one. With this option,\n    the result will broadcast correctly against the array.\n\n    .. versionadded:: 1.22.0"
          }
        },
        "returns": "index_array : ndarray\n    An array of indices or a single index value.",
        "raises": "",
        "see_also": "argmax, nanargmin",
        "notes": "",
        "examples": ">>> a = np.array([[np.nan, 4], [2, 3]])\n>>> np.argmax(a)\n0\n>>> np.nanargmax(a)\n1\n>>> np.nanargmax(a, axis=0)\narray([1, 0])\n>>> np.nanargmax(a, axis=1)\narray([1, 1])"
      }
    },
    {
      "name": "nanargmin",
      "signature": "nanargmin(a, axis=None, out=None, *, keepdims=<no value>)",
      "docstring": {
        "description": "Return the indices of the minimum values in the specified axis ignoring\nNaNs. For all-NaN slices ``ValueError`` is raised. Warning: the results\ncannot be trusted if a slice contains only NaNs and Infs.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input data."
          },
          "axis": {
            "type": "int, optional",
            "description": "Axis along which to operate.  By default flattened input is used."
          },
          "out": {
            "type": "array, optional",
            "description": "If provided, the result will be inserted into this array. It should\n    be of the appropriate shape and dtype.\n\n    .. versionadded:: 1.22.0"
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\n    in the result as dimensions with size one. With this option,\n    the result will broadcast correctly against the array.\n\n    .. versionadded:: 1.22.0"
          }
        },
        "returns": "index_array : ndarray\n    An array of indices or a single index value.",
        "raises": "",
        "see_also": "argmin, nanargmax",
        "notes": "",
        "examples": ">>> a = np.array([[np.nan, 4], [2, 3]])\n>>> np.argmin(a)\n0\n>>> np.nanargmin(a)\n2\n>>> np.nanargmin(a, axis=0)\narray([1, 1])\n>>> np.nanargmin(a, axis=1)\narray([1, 0])"
      }
    },
    {
      "name": "nancumprod",
      "signature": "nancumprod(a, axis=None, dtype=None, out=None)",
      "docstring": {
        "description": "Return the cumulative product of array elements over a given axis treating Not a\nNumbers (NaNs) as one.  The cumulative product does not change when NaNs are\nencountered and leading NaNs are replaced by ones.\n\nOnes are returned for slices that are all-NaN or empty.\n\n.. versionadded:: 1.12.0",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array."
          },
          "axis": {
            "type": "int, optional",
            "description": "Axis along which the cumulative product is computed.  By default\n    the input is flattened."
          },
          "dtype": {
            "type": "dtype, optional",
            "description": "Type of the returned array, as well as of the accumulator in which\n    the elements are multiplied.  If *dtype* is not specified, it\n    defaults to the dtype of `a`, unless `a` has an integer dtype with\n    a precision less than that of the default platform integer.  In\n    that case, the default platform integer is used instead."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must\n    have the same shape and buffer length as the expected output\n    but the type of the resulting values will be cast if necessary."
          }
        },
        "returns": "nancumprod : ndarray\n    A new array holding the result is returned unless `out` is\n    specified, in which case it is returned.",
        "raises": "",
        "see_also": "numpy.cumprod : Cumulative product across array propagating NaNs.\nisnan : Show which elements are NaN.",
        "notes": "",
        "examples": ">>> np.nancumprod(1)\narray([1])\n>>> np.nancumprod([1])\narray([1])\n>>> np.nancumprod([1, np.nan])\narray([1.,  1.])\n>>> a = np.array([[1, 2], [3, np.nan]])\n>>> np.nancumprod(a)\narray([1.,  2.,  6.,  6.])\n>>> np.nancumprod(a, axis=0)\narray([[1.,  2.],\n       [3.,  2.]])\n>>> np.nancumprod(a, axis=1)\narray([[1.,  2.],\n       [3.,  3.]])"
      }
    },
    {
      "name": "nancumsum",
      "signature": "nancumsum(a, axis=None, dtype=None, out=None)",
      "docstring": {
        "description": "Return the cumulative sum of array elements over a given axis treating Not a\nNumbers (NaNs) as zero.  The cumulative sum does not change when NaNs are\nencountered and leading NaNs are replaced by zeros.\n\nZeros are returned for slices that are all-NaN or empty.\n\n.. versionadded:: 1.12.0",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array."
          },
          "axis": {
            "type": "int, optional",
            "description": "Axis along which the cumulative sum is computed. The default\n    (None) is to compute the cumsum over the flattened array."
          },
          "dtype": {
            "type": "dtype, optional",
            "description": "Type of the returned array and of the accumulator in which the\n    elements are summed.  If `dtype` is not specified, it defaults\n    to the dtype of `a`, unless `a` has an integer dtype with a\n    precision less than that of the default platform integer.  In\n    that case, the default platform integer is used."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must\n    have the same shape and buffer length as the expected output\n    but the type will be cast if necessary. See :ref:`ufuncs-output-type` for\n    more details."
          }
        },
        "returns": "nancumsum : ndarray.\n    A new array holding the result is returned unless `out` is\n    specified, in which it is returned. The result has the same\n    size as `a`, and the same shape as `a` if `axis` is not None\n    or `a` is a 1-d array.",
        "raises": "",
        "see_also": "numpy.cumsum : Cumulative sum across array propagating NaNs.\nisnan : Show which elements are NaN.",
        "notes": "",
        "examples": ">>> np.nancumsum(1)\narray([1])\n>>> np.nancumsum([1])\narray([1])\n>>> np.nancumsum([1, np.nan])\narray([1.,  1.])\n>>> a = np.array([[1, 2], [3, np.nan]])\n>>> np.nancumsum(a)\narray([1.,  3.,  6.,  6.])\n>>> np.nancumsum(a, axis=0)\narray([[1.,  2.],\n       [4.,  2.]])\n>>> np.nancumsum(a, axis=1)\narray([[1.,  3.],\n       [3.,  3.]])"
      }
    },
    {
      "name": "nanmax",
      "signature": "nanmax(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)",
      "docstring": {
        "description": "Return the maximum of an array or maximum along an axis, ignoring any\nNaNs.  When all-NaN slices are encountered a ``RuntimeWarning`` is\nraised and NaN is returned for that slice.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Array containing numbers whose maximum is desired. If `a` is not an\n    array, a conversion is attempted."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the maximum is computed. The default is to compute\n    the maximum of the flattened array."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternate output array in which to place the result.  The default\n    is ``None``; if provided, it must have the same shape as the\n    expected output, but the type will be cast if necessary. See\n    :ref:`ufuncs-output-type` for more details.\n\n    .. versionadded:: 1.8.0"
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\n    in the result as dimensions with size one. With this option,\n    the result will broadcast correctly against the original `a`.\n\n    If the value is anything but the default, then\n    `keepdims` will be passed through to the `max` method\n    of sub-classes of `ndarray`.  If the sub-classes methods\n    does not implement `keepdims` any exceptions will be raised.\n\n    .. versionadded:: 1.8.0"
          },
          "initial": {
            "type": "scalar, optional",
            "description": "The minimum value of an output element. Must be present to allow\n    computation on empty slice. See `~numpy.ufunc.reduce` for details.\n\n    .. versionadded:: 1.22.0"
          },
          "where": {
            "type": "array_like of bool, optional",
            "description": "Elements to compare for the maximum. See `~numpy.ufunc.reduce`\n    for details.\n\n    .. versionadded:: 1.22.0"
          }
        },
        "returns": "nanmax : ndarray\n    An array with the same shape as `a`, with the specified axis removed.\n    If `a` is a 0-d array, or if axis is None, an ndarray scalar is\n    returned.  The same dtype as `a` is returned.",
        "raises": "",
        "see_also": "nanmin :\n    The minimum value of an array along a given axis, ignoring any NaNs.\namax :\n    The maximum value of an array along a given axis, propagating any NaNs.\nfmax :\n    Element-wise maximum of two arrays, ignoring any NaNs.\nmaximum :\n    Element-wise maximum of two arrays, propagating any NaNs.\nisnan :\n    Shows which elements are Not a Number (NaN).\nisfinite:\n    Shows which elements are neither NaN nor infinity.\n\namin, fmin, minimum",
        "notes": "NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic\n(IEEE 754). This means that Not a Number is not equivalent to infinity.\nPositive infinity is treated as a very large number and negative\ninfinity is treated as a very small (i.e. negative) number.\n\nIf the input has a integer type the function is equivalent to np.max.",
        "examples": ">>> a = np.array([[1, 2], [3, np.nan]])\n>>> np.nanmax(a)\n3.0\n>>> np.nanmax(a, axis=0)\narray([3.,  2.])\n>>> np.nanmax(a, axis=1)\narray([2.,  3.])\n\nWhen positive infinity and negative infinity are present:\n\n>>> np.nanmax([1, 2, np.nan, np.NINF])\n2.0\n>>> np.nanmax([1, 2, np.nan, np.inf])\ninf"
      }
    },
    {
      "name": "nanmean",
      "signature": "nanmean(a, axis=None, dtype=None, out=None, keepdims=<no value>, *, where=<no value>)",
      "docstring": {
        "description": "Compute the arithmetic mean along the specified axis, ignoring NaNs.\n\nReturns the average of the array elements.  The average is taken over\nthe flattened array by default, otherwise over the specified axis.\n`float64` intermediate and return values are used for integer inputs.\n\nFor all-NaN slices, NaN is returned and a `RuntimeWarning` is raised.\n\n.. versionadded:: 1.8.0",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Array containing numbers whose mean is desired. If `a` is not an\n    array, a conversion is attempted."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the means are computed. The default is to compute\n    the mean of the flattened array."
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "Type to use in computing the mean.  For integer inputs, the default\n    is `float64`; for inexact inputs, it is the same as the input\n    dtype."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternate output array in which to place the result.  The default\n    is ``None``; if provided, it must have the same shape as the\n    expected output, but the type will be cast if necessary. See\n    :ref:`ufuncs-output-type` for more details."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\n    in the result as dimensions with size one. With this option,\n    the result will broadcast correctly against the original `a`.\n\n    If the value is anything but the default, then\n    `keepdims` will be passed through to the `mean` or `sum` methods\n    of sub-classes of `ndarray`.  If the sub-classes methods\n    does not implement `keepdims` any exceptions will be raised."
          },
          "where": {
            "type": "array_like of bool, optional",
            "description": "Elements to include in the mean. See `~numpy.ufunc.reduce` for details.\n\n    .. versionadded:: 1.22.0"
          }
        },
        "returns": "m : ndarray, see dtype parameter above\n    If `out=None`, returns a new array containing the mean values,\n    otherwise a reference to the output array is returned. Nan is\n    returned for slices that contain only NaNs.",
        "raises": "",
        "see_also": "average : Weighted average\nmean : Arithmetic mean taken while not ignoring NaNs\nvar, nanvar",
        "notes": "The arithmetic mean is the sum of the non-NaN elements along the axis\ndivided by the number of non-NaN elements.\n\nNote that for floating-point input, the mean is computed using the same\nprecision the input has.  Depending on the input data, this can cause\nthe results to be inaccurate, especially for `float32`.  Specifying a\nhigher-precision accumulator using the `dtype` keyword can alleviate\nthis issue.",
        "examples": ">>> a = np.array([[1, np.nan], [3, 4]])\n>>> np.nanmean(a)\n2.6666666666666665\n>>> np.nanmean(a, axis=0)\narray([2.,  4.])\n>>> np.nanmean(a, axis=1)\narray([1.,  3.5]) # may vary"
      }
    },
    {
      "name": "nanmedian",
      "signature": "nanmedian(a, axis=None, out=None, overwrite_input=False, keepdims=<no value>)",
      "docstring": {
        "description": "Compute the median along the specified axis, while ignoring NaNs.\n\nReturns the median of the array elements.\n\n.. versionadded:: 1.9.0",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array or object that can be converted to an array."
          },
          "axis": {
            "type": "{int, sequence of int, None}, optional",
            "description": "Axis or axes along which the medians are computed. The default\n    is to compute the median along a flattened version of the array.\n    A sequence of axes is supported since version 1.9.0."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must\n    have the same shape and buffer length as the expected output,\n    but the type (of the output) will be cast if necessary."
          },
          "overwrite_input": {
            "type": "bool, optional",
            "description": "If True, then allow use of memory of input array `a` for\n   calculations. The input array will be modified by the call to\n   `median`. This will save memory when you do not need to preserve\n   the contents of the input array. Treat the input as undefined,\n   but it will probably be fully or partially sorted. Default is\n   False. If `overwrite_input` is ``True`` and `a` is not already an\n   `ndarray`, an error will be raised."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\n    in the result as dimensions with size one. With this option,\n    the result will broadcast correctly against the original `a`.\n\n    If this is anything but the default value it will be passed\n    through (in the special case of an empty array) to the\n    `mean` function of the underlying array.  If the array is\n    a sub-class and `mean` does not have the kwarg `keepdims` this\n    will raise a RuntimeError."
          }
        },
        "returns": "median : ndarray\n    A new array holding the result. If the input contains integers\n    or floats smaller than ``float64``, then the output data-type is\n    ``np.float64``.  Otherwise, the data-type of the output is the\n    same as that of the input. If `out` is specified, that array is\n    returned instead.",
        "raises": "",
        "see_also": "mean, median, percentile",
        "notes": "Given a vector ``V`` of length ``N``, the median of ``V`` is the\nmiddle value of a sorted copy of ``V``, ``V_sorted`` - i.e.,\n``V_sorted[(N-1)/2]``, when ``N`` is odd and the average of the two\nmiddle values of ``V_sorted`` when ``N`` is even.",
        "examples": ">>> a = np.array([[10.0, 7, 4], [3, 2, 1]])\n>>> a[0, 1] = np.nan\n>>> a\narray([[10., nan,  4.],\n       [ 3.,  2.,  1.]])\n>>> np.median(a)\nnan\n>>> np.nanmedian(a)\n3.0\n>>> np.nanmedian(a, axis=0)\narray([6.5, 2. , 2.5])\n>>> np.median(a, axis=1)\narray([nan,  2.])\n>>> b = a.copy()\n>>> np.nanmedian(b, axis=1, overwrite_input=True)\narray([7.,  2.])\n>>> assert not np.all(a==b)\n>>> b = a.copy()\n>>> np.nanmedian(b, axis=None, overwrite_input=True)\n3.0\n>>> assert not np.all(a==b)"
      }
    },
    {
      "name": "nanmin",
      "signature": "nanmin(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)",
      "docstring": {
        "description": "Return minimum of an array or minimum along an axis, ignoring any NaNs.\nWhen all-NaN slices are encountered a ``RuntimeWarning`` is raised and\nNan is returned for that slice.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Array containing numbers whose minimum is desired. If `a` is not an\n    array, a conversion is attempted."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the minimum is computed. The default is to compute\n    the minimum of the flattened array."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternate output array in which to place the result.  The default\n    is ``None``; if provided, it must have the same shape as the\n    expected output, but the type will be cast if necessary. See\n    :ref:`ufuncs-output-type` for more details.\n\n    .. versionadded:: 1.8.0"
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\n    in the result as dimensions with size one. With this option,\n    the result will broadcast correctly against the original `a`.\n\n    If the value is anything but the default, then\n    `keepdims` will be passed through to the `min` method\n    of sub-classes of `ndarray`.  If the sub-classes methods\n    does not implement `keepdims` any exceptions will be raised.\n\n    .. versionadded:: 1.8.0"
          },
          "initial": {
            "type": "scalar, optional",
            "description": "The maximum value of an output element. Must be present to allow\n    computation on empty slice. See `~numpy.ufunc.reduce` for details.\n\n    .. versionadded:: 1.22.0"
          },
          "where": {
            "type": "array_like of bool, optional",
            "description": "Elements to compare for the minimum. See `~numpy.ufunc.reduce`\n    for details.\n\n    .. versionadded:: 1.22.0"
          }
        },
        "returns": "nanmin : ndarray\n    An array with the same shape as `a`, with the specified axis\n    removed.  If `a` is a 0-d array, or if axis is None, an ndarray\n    scalar is returned.  The same dtype as `a` is returned.",
        "raises": "",
        "see_also": "nanmax :\n    The maximum value of an array along a given axis, ignoring any NaNs.\namin :\n    The minimum value of an array along a given axis, propagating any NaNs.\nfmin :\n    Element-wise minimum of two arrays, ignoring any NaNs.\nminimum :\n    Element-wise minimum of two arrays, propagating any NaNs.\nisnan :\n    Shows which elements are Not a Number (NaN).\nisfinite:\n    Shows which elements are neither NaN nor infinity.\n\namax, fmax, maximum",
        "notes": "NumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic\n(IEEE 754). This means that Not a Number is not equivalent to infinity.\nPositive infinity is treated as a very large number and negative\ninfinity is treated as a very small (i.e. negative) number.\n\nIf the input has a integer type the function is equivalent to np.min.",
        "examples": ">>> a = np.array([[1, 2], [3, np.nan]])\n>>> np.nanmin(a)\n1.0\n>>> np.nanmin(a, axis=0)\narray([1.,  2.])\n>>> np.nanmin(a, axis=1)\narray([1.,  3.])\n\nWhen positive infinity and negative infinity are present:\n\n>>> np.nanmin([1, 2, np.nan, np.inf])\n1.0\n>>> np.nanmin([1, 2, np.nan, np.NINF])\n-inf"
      }
    },
    {
      "name": "nanpercentile",
      "signature": "nanpercentile(a, q, axis=None, out=None, overwrite_input=False, method='linear', keepdims=<no value>, *, interpolation=None)",
      "docstring": {
        "description": "Compute the qth percentile of the data along the specified axis,\nwhile ignoring nan values.\n\nReturns the qth percentile(s) of the array elements.\n\n.. versionadded:: 1.9.0",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array or object that can be converted to an array, containing\n    nan values to be ignored."
          },
          "q": {
            "type": "array_like of float",
            "description": "Percentile or sequence of percentiles to compute, which must be\n    between 0 and 100 inclusive."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the percentiles are computed. The default\n    is to compute the percentile(s) along a flattened version of the\n    array."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must have\n    the same shape and buffer length as the expected output, but the\n    type (of the output) will be cast if necessary."
          },
          "overwrite_input": {
            "type": "bool, optional",
            "description": "If True, then allow the input array `a` to be modified by\n    intermediate calculations, to save memory. In this case, the\n    contents of the input `a` after this function completes is\n    undefined."
          },
          "method": {
            "type": "str, optional",
            "description": "This parameter specifies the method to use for estimating the\n    percentile.  There are many different methods, some unique to NumPy.\n    See the notes for explanation.  The options sorted by their R type\n    as summarized in the H&F paper [1]_ are:\n\n    1. 'inverted_cdf'\n    2. 'averaged_inverted_cdf'\n    3. 'closest_observation'\n    4. 'interpolated_inverted_cdf'\n    5. 'hazen'\n    6. 'weibull'\n    7. 'linear'  (default)\n    8. 'median_unbiased'\n    9. 'normal_unbiased'\n\n    The first three methods are discontinuous.  NumPy further defines the\n    following discontinuous variations of the default 'linear' (7.) option:\n\n    * 'lower'\n    * 'higher',\n    * 'midpoint'\n    * 'nearest'\n\n    .. versionchanged:: 1.22.0\n        This argument was previously called \"interpolation\" and only\n        offered the \"linear\" default and last four options."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left in\n    the result as dimensions with size one. With this option, the\n    result will broadcast correctly against the original array `a`.\n\n    If this is anything but the default value it will be passed\n    through (in the special case of an empty array) to the\n    `mean` function of the underlying array.  If the array is\n    a sub-class and `mean` does not have the kwarg `keepdims` this\n    will raise a RuntimeError."
          },
          "interpolation": {
            "type": "str, optional",
            "description": "Deprecated name for the method keyword argument.\n\n    .. deprecated:: 1.22.0"
          }
        },
        "returns": "percentile : scalar or ndarray\n    If `q` is a single percentile and `axis=None`, then the result\n    is a scalar. If multiple percentiles are given, first axis of\n    the result corresponds to the percentiles. The other axes are\n    the axes that remain after the reduction of `a`. If the input\n    contains integers or floats smaller than ``float64``, the output\n    data-type is ``float64``. Otherwise, the output data-type is the\n    same as that of the input. If `out` is specified, that array is\n    returned instead.",
        "raises": "",
        "see_also": "nanmean\nnanmedian : equivalent to ``nanpercentile(..., 50)``\npercentile, median, mean\nnanquantile : equivalent to nanpercentile, except q in range [0, 1].",
        "notes": "For more information please see `numpy.percentile`",
        "examples": ">>> a = np.array([[10., 7., 4.], [3., 2., 1.]])\n>>> a[0][1] = np.nan\n>>> a\narray([[10.,  nan,   4.],\n      [ 3.,   2.,   1.]])\n>>> np.percentile(a, 50)\nnan\n>>> np.nanpercentile(a, 50)\n3.0\n>>> np.nanpercentile(a, 50, axis=0)\narray([6.5, 2. , 2.5])\n>>> np.nanpercentile(a, 50, axis=1, keepdims=True)\narray([[7.],\n       [2.]])\n>>> m = np.nanpercentile(a, 50, axis=0)\n>>> out = np.zeros_like(m)\n>>> np.nanpercentile(a, 50, axis=0, out=out)\narray([6.5, 2. , 2.5])\n>>> m\narray([6.5,  2. ,  2.5])\n\n>>> b = a.copy()\n>>> np.nanpercentile(b, 50, axis=1, overwrite_input=True)\narray([7., 2.])\n>>> assert not np.all(a==b)\n\nReferences\n----------\n.. [1] R. J. Hyndman and Y. Fan,\n   \"Sample quantiles in statistical packages,\"\n   The American Statistician, 50(4), pp. 361-365, 1996"
      }
    },
    {
      "name": "nanprod",
      "signature": "nanprod(a, axis=None, dtype=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)",
      "docstring": {
        "description": "Return the product of array elements over a given axis treating Not a\nNumbers (NaNs) as ones.\n\nOne is returned for slices that are all-NaN or empty.\n\n.. versionadded:: 1.10.0",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Array containing numbers whose product is desired. If `a` is not an\n    array, a conversion is attempted."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the product is computed. The default is to compute\n    the product of the flattened array."
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "The type of the returned array and of the accumulator in which the\n    elements are summed.  By default, the dtype of `a` is used.  An\n    exception is when `a` has an integer type with less precision than\n    the platform (u)intp. In that case, the default will be either\n    (u)int32 or (u)int64 depending on whether the platform is 32 or 64\n    bits. For inexact inputs, dtype must be inexact."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternate output array in which to place the result.  The default\n    is ``None``. If provided, it must have the same shape as the\n    expected output, but the type will be cast if necessary. See\n    :ref:`ufuncs-output-type` for more details. The casting of NaN to integer\n    can yield unexpected results."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If True, the axes which are reduced are left in the result as\n    dimensions with size one. With this option, the result will\n    broadcast correctly against the original `arr`."
          },
          "initial": {
            "type": "scalar, optional",
            "description": "The starting value for this product. See `~numpy.ufunc.reduce`\n    for details.\n\n    .. versionadded:: 1.22.0"
          },
          "where": {
            "type": "array_like of bool, optional",
            "description": "Elements to include in the product. See `~numpy.ufunc.reduce`\n    for details.\n\n    .. versionadded:: 1.22.0"
          }
        },
        "returns": "nanprod : ndarray\n    A new array holding the result is returned unless `out` is\n    specified, in which case it is returned.",
        "raises": "",
        "see_also": "numpy.prod : Product across array propagating NaNs.\nisnan : Show which elements are NaN.",
        "notes": "",
        "examples": ">>> np.nanprod(1)\n1\n>>> np.nanprod([1])\n1\n>>> np.nanprod([1, np.nan])\n1.0\n>>> a = np.array([[1, 2], [3, np.nan]])\n>>> np.nanprod(a)\n6.0\n>>> np.nanprod(a, axis=0)\narray([3., 2.])"
      }
    },
    {
      "name": "nanquantile",
      "signature": "nanquantile(a, q, axis=None, out=None, overwrite_input=False, method='linear', keepdims=<no value>, *, interpolation=None)",
      "docstring": {
        "description": "Compute the qth quantile of the data along the specified axis,\nwhile ignoring nan values.\nReturns the qth quantile(s) of the array elements.\n\n.. versionadded:: 1.15.0",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array or object that can be converted to an array, containing\n    nan values to be ignored"
          },
          "q": {
            "type": "array_like of float",
            "description": "Probability or sequence of probabilities for the quantiles to compute.\n    Values must be between 0 and 1 inclusive."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the quantiles are computed. The\n    default is to compute the quantile(s) along a flattened\n    version of the array."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must\n    have the same shape and buffer length as the expected output,\n    but the type (of the output) will be cast if necessary."
          },
          "overwrite_input": {
            "type": "bool, optional",
            "description": "If True, then allow the input array `a` to be modified by intermediate\n    calculations, to save memory. In this case, the contents of the input\n    `a` after this function completes is undefined."
          },
          "method": {
            "type": "str, optional",
            "description": "This parameter specifies the method to use for estimating the\n    quantile.  There are many different methods, some unique to NumPy.\n    See the notes for explanation.  The options sorted by their R type\n    as summarized in the H&F paper [1]_ are:\n\n    1. 'inverted_cdf'\n    2. 'averaged_inverted_cdf'\n    3. 'closest_observation'\n    4. 'interpolated_inverted_cdf'\n    5. 'hazen'\n    6. 'weibull'\n    7. 'linear'  (default)\n    8. 'median_unbiased'\n    9. 'normal_unbiased'\n\n    The first three methods are discontinuous.  NumPy further defines the\n    following discontinuous variations of the default 'linear' (7.) option:\n\n    * 'lower'\n    * 'higher',\n    * 'midpoint'\n    * 'nearest'\n\n    .. versionchanged:: 1.22.0\n        This argument was previously called \"interpolation\" and only\n        offered the \"linear\" default and last four options."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left in\n    the result as dimensions with size one. With this option, the\n    result will broadcast correctly against the original array `a`.\n\n    If this is anything but the default value it will be passed\n    through (in the special case of an empty array) to the\n    `mean` function of the underlying array.  If the array is\n    a sub-class and `mean` does not have the kwarg `keepdims` this\n    will raise a RuntimeError."
          },
          "interpolation": {
            "type": "str, optional",
            "description": "Deprecated name for the method keyword argument.\n\n    .. deprecated:: 1.22.0"
          }
        },
        "returns": "quantile : scalar or ndarray\n    If `q` is a single probability and `axis=None`, then the result\n    is a scalar. If multiple probability levels are given, first axis of\n    the result corresponds to the quantiles. The other axes are\n    the axes that remain after the reduction of `a`. If the input\n    contains integers or floats smaller than ``float64``, the output\n    data-type is ``float64``. Otherwise, the output data-type is the\n    same as that of the input. If `out` is specified, that array is\n    returned instead.",
        "raises": "",
        "see_also": "quantile\nnanmean, nanmedian\nnanmedian : equivalent to ``nanquantile(..., 0.5)``\nnanpercentile : same as nanquantile, but with q in the range [0, 100].",
        "notes": "For more information please see `numpy.quantile`",
        "examples": ">>> a = np.array([[10., 7., 4.], [3., 2., 1.]])\n>>> a[0][1] = np.nan\n>>> a\narray([[10.,  nan,   4.],\n      [ 3.,   2.,   1.]])\n>>> np.quantile(a, 0.5)\nnan\n>>> np.nanquantile(a, 0.5)\n3.0\n>>> np.nanquantile(a, 0.5, axis=0)\narray([6.5, 2. , 2.5])\n>>> np.nanquantile(a, 0.5, axis=1, keepdims=True)\narray([[7.],\n       [2.]])\n>>> m = np.nanquantile(a, 0.5, axis=0)\n>>> out = np.zeros_like(m)\n>>> np.nanquantile(a, 0.5, axis=0, out=out)\narray([6.5, 2. , 2.5])\n>>> m\narray([6.5,  2. ,  2.5])\n>>> b = a.copy()\n>>> np.nanquantile(b, 0.5, axis=1, overwrite_input=True)\narray([7., 2.])\n>>> assert not np.all(a==b)\n\nReferences\n----------\n.. [1] R. J. Hyndman and Y. Fan,\n   \"Sample quantiles in statistical packages,\"\n   The American Statistician, 50(4), pp. 361-365, 1996"
      }
    },
    {
      "name": "nanstd",
      "signature": "nanstd(a, axis=None, dtype=None, out=None, ddof=0, keepdims=<no value>, *, where=<no value>)",
      "docstring": {
        "description": "Compute the standard deviation along the specified axis, while\nignoring NaNs.\n\nReturns the standard deviation, a measure of the spread of a\ndistribution, of the non-NaN array elements. The standard deviation is\ncomputed for the flattened array by default, otherwise over the\nspecified axis.\n\nFor all-NaN slices or slices with zero degrees of freedom, NaN is\nreturned and a `RuntimeWarning` is raised.\n\n.. versionadded:: 1.8.0",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Calculate the standard deviation of the non-NaN values."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the standard deviation is computed. The default is\n    to compute the standard deviation of the flattened array."
          },
          "dtype": {
            "type": "dtype, optional",
            "description": "Type to use in computing the standard deviation. For arrays of\n    integer type the default is float64, for arrays of float types it\n    is the same as the array type."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must have\n    the same shape as the expected output but the type (of the\n    calculated values) will be cast if necessary."
          },
          "ddof": {
            "type": "int, optional",
            "description": "Means Delta Degrees of Freedom.  The divisor used in calculations\n    is ``N - ddof``, where ``N`` represents the number of non-NaN\n    elements.  By default `ddof` is zero."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\n    in the result as dimensions with size one. With this option,\n    the result will broadcast correctly against the original `a`.\n\n    If this value is anything but the default it is passed through\n    as-is to the relevant functions of the sub-classes.  If these\n    functions do not have a `keepdims` kwarg, a RuntimeError will\n    be raised."
          },
          "where": {
            "type": "array_like of bool, optional",
            "description": "Elements to include in the standard deviation.\n    See `~numpy.ufunc.reduce` for details.\n\n    .. versionadded:: 1.22.0"
          }
        },
        "returns": "standard_deviation : ndarray, see dtype parameter above.\n    If `out` is None, return a new array containing the standard\n    deviation, otherwise return a reference to the output array. If\n    ddof is >= the number of non-NaN elements in a slice or the slice\n    contains only NaNs, then the result for that slice is NaN.",
        "raises": "",
        "see_also": "var, mean, std\nnanvar, nanmean\n:ref:`ufuncs-output-type`",
        "notes": "The standard deviation is the square root of the average of the squared\ndeviations from the mean: ``std = sqrt(mean(abs(x - x.mean())**2))``.\n\nThe average squared deviation is normally calculated as\n``x.sum() / N``, where ``N = len(x)``.  If, however, `ddof` is\nspecified, the divisor ``N - ddof`` is used instead. In standard\nstatistical practice, ``ddof=1`` provides an unbiased estimator of the\nvariance of the infinite population. ``ddof=0`` provides a maximum\nlikelihood estimate of the variance for normally distributed variables.\nThe standard deviation computed in this function is the square root of\nthe estimated variance, so even with ``ddof=1``, it will not be an\nunbiased estimate of the standard deviation per se.\n\nNote that, for complex numbers, `std` takes the absolute value before\nsquaring, so that the result is always real and nonnegative.\n\nFor floating-point input, the *std* is computed using the same\nprecision the input has. Depending on the input data, this can cause\nthe results to be inaccurate, especially for float32 (see example\nbelow).  Specifying a higher-accuracy accumulator using the `dtype`\nkeyword can alleviate this issue.",
        "examples": ">>> a = np.array([[1, np.nan], [3, 4]])\n>>> np.nanstd(a)\n1.247219128924647\n>>> np.nanstd(a, axis=0)\narray([1., 0.])\n>>> np.nanstd(a, axis=1)\narray([0.,  0.5]) # may vary"
      }
    },
    {
      "name": "nansum",
      "signature": "nansum(a, axis=None, dtype=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)",
      "docstring": {
        "description": "Return the sum of array elements over a given axis treating Not a\nNumbers (NaNs) as zero.\n\nIn NumPy versions <= 1.9.0 Nan is returned for slices that are all-NaN or\nempty. In later versions zero is returned.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Array containing numbers whose sum is desired. If `a` is not an\n    array, a conversion is attempted."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the sum is computed. The default is to compute the\n    sum of the flattened array."
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "The type of the returned array and of the accumulator in which the\n    elements are summed.  By default, the dtype of `a` is used.  An\n    exception is when `a` has an integer type with less precision than\n    the platform (u)intp. In that case, the default will be either\n    (u)int32 or (u)int64 depending on whether the platform is 32 or 64\n    bits. For inexact inputs, dtype must be inexact.\n\n    .. versionadded:: 1.8.0"
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternate output array in which to place the result.  The default\n    is ``None``. If provided, it must have the same shape as the\n    expected output, but the type will be cast if necessary.  See\n    :ref:`ufuncs-output-type` for more details. The casting of NaN to integer\n    can yield unexpected results.\n\n    .. versionadded:: 1.8.0"
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\n    in the result as dimensions with size one. With this option,\n    the result will broadcast correctly against the original `a`.\n\n\n    If the value is anything but the default, then\n    `keepdims` will be passed through to the `mean` or `sum` methods\n    of sub-classes of `ndarray`.  If the sub-classes methods\n    does not implement `keepdims` any exceptions will be raised.\n\n    .. versionadded:: 1.8.0"
          },
          "initial": {
            "type": "scalar, optional",
            "description": "Starting value for the sum. See `~numpy.ufunc.reduce` for details.\n\n    .. versionadded:: 1.22.0"
          },
          "where": {
            "type": "array_like of bool, optional",
            "description": "Elements to include in the sum. See `~numpy.ufunc.reduce` for details.\n\n    .. versionadded:: 1.22.0"
          }
        },
        "returns": "nansum : ndarray.\n    A new array holding the result is returned unless `out` is\n    specified, in which it is returned. The result has the same\n    size as `a`, and the same shape as `a` if `axis` is not None\n    or `a` is a 1-d array.",
        "raises": "",
        "see_also": "numpy.sum : Sum across array propagating NaNs.\nisnan : Show which elements are NaN.\nisfinite : Show which elements are not NaN or +/-inf.",
        "notes": "If both positive and negative infinity are present, the sum will be Not\nA Number (NaN).",
        "examples": ">>> np.nansum(1)\n1\n>>> np.nansum([1])\n1\n>>> np.nansum([1, np.nan])\n1.0\n>>> a = np.array([[1, 1], [1, np.nan]])\n>>> np.nansum(a)\n3.0\n>>> np.nansum(a, axis=0)\narray([2.,  1.])\n>>> np.nansum([1, np.nan, np.inf])\ninf\n>>> np.nansum([1, np.nan, np.NINF])\n-inf\n>>> from numpy.testing import suppress_warnings\n>>> with suppress_warnings() as sup:\n...     sup.filter(RuntimeWarning)\n...     np.nansum([1, np.nan, np.inf, -np.inf]) # both +/- infinity present\nnan"
      }
    },
    {
      "name": "nanvar",
      "signature": "nanvar(a, axis=None, dtype=None, out=None, ddof=0, keepdims=<no value>, *, where=<no value>)",
      "docstring": {
        "description": "Compute the variance along the specified axis, while ignoring NaNs.\n\nReturns the variance of the array elements, a measure of the spread of\na distribution.  The variance is computed for the flattened array by\ndefault, otherwise over the specified axis.\n\nFor all-NaN slices or slices with zero degrees of freedom, NaN is\nreturned and a `RuntimeWarning` is raised.\n\n.. versionadded:: 1.8.0",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Array containing numbers whose variance is desired.  If `a` is not an\n    array, a conversion is attempted."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the variance is computed.  The default is to compute\n    the variance of the flattened array."
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "Type to use in computing the variance.  For arrays of integer type\n    the default is `float64`; for arrays of float types it is the same as\n    the array type."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternate output array in which to place the result.  It must have\n    the same shape as the expected output, but the type is cast if\n    necessary."
          },
          "ddof": {
            "type": "int, optional",
            "description": "\"Delta Degrees of Freedom\": the divisor used in the calculation is\n    ``N - ddof``, where ``N`` represents the number of non-NaN\n    elements. By default `ddof` is zero."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\n    in the result as dimensions with size one. With this option,\n    the result will broadcast correctly against the original `a`."
          },
          "where": {
            "type": "array_like of bool, optional",
            "description": "Elements to include in the variance. See `~numpy.ufunc.reduce` for\n    details.\n\n    .. versionadded:: 1.22.0"
          }
        },
        "returns": "variance : ndarray, see dtype parameter above\n    If `out` is None, return a new array containing the variance,\n    otherwise return a reference to the output array. If ddof is >= the\n    number of non-NaN elements in a slice or the slice contains only\n    NaNs, then the result for that slice is NaN.",
        "raises": "",
        "see_also": "std : Standard deviation\nmean : Average\nvar : Variance while not ignoring NaNs\nnanstd, nanmean\n:ref:`ufuncs-output-type`",
        "notes": "The variance is the average of the squared deviations from the mean,\ni.e.,  ``var = mean(abs(x - x.mean())**2)``.\n\nThe mean is normally calculated as ``x.sum() / N``, where ``N = len(x)``.\nIf, however, `ddof` is specified, the divisor ``N - ddof`` is used\ninstead.  In standard statistical practice, ``ddof=1`` provides an\nunbiased estimator of the variance of a hypothetical infinite\npopulation.  ``ddof=0`` provides a maximum likelihood estimate of the\nvariance for normally distributed variables.\n\nNote that for complex numbers, the absolute value is taken before\nsquaring, so that the result is always real and nonnegative.\n\nFor floating-point input, the variance is computed using the same\nprecision the input has.  Depending on the input data, this can cause\nthe results to be inaccurate, especially for `float32` (see example\nbelow).  Specifying a higher-accuracy accumulator using the ``dtype``\nkeyword can alleviate this issue.\n\nFor this function to work on sub-classes of ndarray, they must define\n`sum` with the kwarg `keepdims`",
        "examples": ">>> a = np.array([[1, np.nan], [3, 4]])\n>>> np.nanvar(a)\n1.5555555555555554\n>>> np.nanvar(a, axis=0)\narray([1.,  0.])\n>>> np.nanvar(a, axis=1)\narray([0.,  0.25])  # may vary"
      }
    },
    {
      "name": "ndenumerate",
      "signature": "ndenumerate(arr)",
      "docstring": {
        "description": "Multidimensional index iterator.\n\nReturn an iterator yielding pairs of array coordinates and values.",
        "parameters": {
          "arr": {
            "type": "ndarray",
            "description": "Input array."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "ndindex, flatiter",
        "notes": "",
        "examples": ">>> a = np.array([[1, 2], [3, 4]])\n>>> for index, x in np.ndenumerate(a):\n...     print(index, x)\n(0, 0) 1\n(0, 1) 2\n(1, 0) 3\n(1, 1) 4"
      }
    },
    {
      "name": "ndindex",
      "signature": "ndindex(*shape)",
      "docstring": {
        "description": "An N-dimensional iterator object to index arrays.\n\nGiven the shape of an array, an `ndindex` instance iterates over\nthe N-dimensional index of the array. At each iteration a tuple\nof indices is returned, the last dimension is iterated over first.",
        "parameters": {
          "shape": {
            "type": "ints, or a single tuple of ints",
            "description": "The size of each dimension of the array can be passed as\n    individual parameters or as the elements of a tuple."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "ndenumerate, flatiter",
        "notes": "",
        "examples": "Dimensions as individual arguments\n\n>>> for index in np.ndindex(3, 2, 1):\n...     print(index)\n(0, 0, 0)\n(0, 1, 0)\n(1, 0, 0)\n(1, 1, 0)\n(2, 0, 0)\n(2, 1, 0)\n\nSame dimensions - but in a tuple ``(3, 2, 1)``\n\n>>> for index in np.ndindex((3, 2, 1)):\n...     print(index)\n(0, 0, 0)\n(0, 1, 0)\n(1, 0, 0)\n(1, 1, 0)\n(2, 0, 0)\n(2, 1, 0)"
      }
    },
    {
      "name": "packbits",
      "signature": "packbits(...)",
      "docstring": {
        "description": "packbits(a, /, axis=None, bitorder='big')\n\nPacks the elements of a binary-valued array into bits in a uint8 array.\n\nThe result is padded to full bytes by inserting zero bits at the end.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "An array of integers or booleans whose elements should be packed to\n    bits."
          },
          "axis": {
            "type": "int, optional",
            "description": "The dimension over which bit-packing is done.\n    ``None`` implies packing the flattened array."
          },
          "bitorder": {
            "type": "{'big', 'little'}, optional",
            "description": "The order of the input bits. 'big' will mimic bin(val),\n    ``[0, 0, 0, 0, 0, 0, 1, 1] => 3 = 0b00000011``, 'little' will\n    reverse the order so ``[1, 1, 0, 0, 0, 0, 0, 0] => 3``.\n    Defaults to 'big'.\n\n    .. versionadded:: 1.17.0"
          }
        },
        "returns": "packed : ndarray\n    Array of type uint8 whose elements represent bits corresponding to the\n    logical (0 or nonzero) value of the input elements. The shape of\n    `packed` has the same number of dimensions as the input (unless `axis`\n    is None, in which case the output is 1-D).",
        "raises": "",
        "see_also": "unpackbits: Unpacks elements of a uint8 array into a binary-valued output\n            array.",
        "notes": "",
        "examples": ">>> a = np.array([[[1,0,1],\n...                [0,1,0]],\n...               [[1,1,0],\n...                [0,0,1]]])\n>>> b = np.packbits(a, axis=-1)\n>>> b\narray([[[160],\n        [ 64]],\n       [[192],\n        [ 32]]], dtype=uint8)\n\nNote that in binary 160 = 1010 0000, 64 = 0100 0000, 192 = 1100 0000,\nand 32 = 0010 0000."
      }
    },
    {
      "name": "pad",
      "signature": "pad(array, pad_width, mode='constant', **kwargs)",
      "docstring": {
        "description": "Pad an array.",
        "parameters": {
          "array": {
            "type": "array_like of rank N",
            "description": "The array to pad."
          },
          "pad_width": {
            "type": "{sequence, array_like, int}",
            "description": "Number of values padded to the edges of each axis.\n    ``((before_1, after_1), ... (before_N, after_N))`` unique pad widths\n    for each axis.\n    ``(before, after)`` or ``((before, after),)`` yields same before\n    and after pad for each axis.\n    ``(pad,)`` or ``int`` is a shortcut for before = after = pad width\n    for all axes."
          },
          "mode": {
            "type": "str or function, optional",
            "description": "One of the following string values or a user supplied function.\n\n    'constant' (default)\n        Pads with a constant value.\n    'edge'\n        Pads with the edge values of array.\n    'linear_ramp'\n        Pads with the linear ramp between end_value and the\n        array edge value.\n    'maximum'\n        Pads with the maximum value of all or part of the\n        vector along each axis.\n    'mean'\n        Pads with the mean value of all or part of the\n        vector along each axis.\n    'median'\n        Pads with the median value of all or part of the\n        vector along each axis.\n    'minimum'\n        Pads with the minimum value of all or part of the\n        vector along each axis.\n    'reflect'\n        Pads with the reflection of the vector mirrored on\n        the first and last values of the vector along each\n        axis.\n    'symmetric'\n        Pads with the reflection of the vector mirrored\n        along the edge of the array.\n    'wrap'\n        Pads with the wrap of the vector along the axis.\n        The first values are used to pad the end and the\n        end values are used to pad the beginning.\n    'empty'\n        Pads with undefined values.\n\n        .. versionadded:: 1.17\n\n    <function>\n        Padding function, see Notes."
          },
          "stat_length": {
            "type": "sequence or int, optional",
            "description": "Used in 'maximum', 'mean', 'median', and 'minimum'.  Number of\n    values at edge of each axis used to calculate the statistic value.\n\n    ``((before_1, after_1), ... (before_N, after_N))`` unique statistic\n    lengths for each axis.\n\n    ``(before, after)`` or ``((before, after),)`` yields same before\n    and after statistic lengths for each axis.\n\n    ``(stat_length,)`` or ``int`` is a shortcut for\n    ``before = after = statistic`` length for all axes.\n\n    Default is ``None``, to use the entire axis."
          },
          "constant_values": {
            "type": "sequence or scalar, optional",
            "description": "Used in 'constant'.  The values to set the padded values for each\n    axis.\n\n    ``((before_1, after_1), ... (before_N, after_N))`` unique pad constants\n    for each axis.\n\n    ``(before, after)`` or ``((before, after),)`` yields same before\n    and after constants for each axis.\n\n    ``(constant,)`` or ``constant`` is a shortcut for\n    ``before = after = constant`` for all axes.\n\n    Default is 0."
          },
          "end_values": {
            "type": "sequence or scalar, optional",
            "description": "Used in 'linear_ramp'.  The values used for the ending value of the\n    linear_ramp and that will form the edge of the padded array.\n\n    ``((before_1, after_1), ... (before_N, after_N))`` unique end values\n    for each axis.\n\n    ``(before, after)`` or ``((before, after),)`` yields same before\n    and after end values for each axis.\n\n    ``(constant,)`` or ``constant`` is a shortcut for\n    ``before = after = constant`` for all axes.\n\n    Default is 0."
          },
          "reflect_type": {
            "type": "{'even', 'odd'}, optional",
            "description": "Used in 'reflect', and 'symmetric'.  The 'even' style is the\n    default with an unaltered reflection around the edge value.  For\n    the 'odd' style, the extended part of the array is created by\n    subtracting the reflected values from two times the edge value."
          }
        },
        "returns": "pad : ndarray\n    Padded array of rank equal to `array` with shape increased\n    according to `pad_width`.",
        "raises": "",
        "see_also": "",
        "notes": ".. versionadded:: 1.7.0\n\nFor an array with rank greater than 1, some of the padding of later\naxes is calculated from padding of previous axes.  This is easiest to\nthink about with a rank 2 array where the corners of the padded array\nare calculated by using padded values from the first axis.\n\nThe padding function, if used, should modify a rank 1 array in-place. It\nhas the following signature::\n\n    padding_func(vector, iaxis_pad_width, iaxis, kwargs)\n\nwhere\n\n    vector : ndarray\n        A rank 1 array already padded with zeros.  Padded values are\n        vector[:iaxis_pad_width[0]] and vector[-iaxis_pad_width[1]:].\n    iaxis_pad_width : tuple\n        A 2-tuple of ints, iaxis_pad_width[0] represents the number of\n        values padded at the beginning of vector where\n        iaxis_pad_width[1] represents the number of values padded at\n        the end of vector.\n    iaxis : int\n        The axis currently being calculated.\n    kwargs : dict\n        Any keyword arguments the function requires.",
        "examples": ">>> a = [1, 2, 3, 4, 5]\n>>> np.pad(a, (2, 3), 'constant', constant_values=(4, 6))\narray([4, 4, 1, ..., 6, 6, 6])\n\n>>> np.pad(a, (2, 3), 'edge')\narray([1, 1, 1, ..., 5, 5, 5])\n\n>>> np.pad(a, (2, 3), 'linear_ramp', end_values=(5, -4))\narray([ 5,  3,  1,  2,  3,  4,  5,  2, -1, -4])\n\n>>> np.pad(a, (2,), 'maximum')\narray([5, 5, 1, 2, 3, 4, 5, 5, 5])\n\n>>> np.pad(a, (2,), 'mean')\narray([3, 3, 1, 2, 3, 4, 5, 3, 3])\n\n>>> np.pad(a, (2,), 'median')\narray([3, 3, 1, 2, 3, 4, 5, 3, 3])\n\n>>> a = [[1, 2], [3, 4]]\n>>> np.pad(a, ((3, 2), (2, 3)), 'minimum')\narray([[1, 1, 1, 2, 1, 1, 1],\n       [1, 1, 1, 2, 1, 1, 1],\n       [1, 1, 1, 2, 1, 1, 1],\n       [1, 1, 1, 2, 1, 1, 1],\n       [3, 3, 3, 4, 3, 3, 3],\n       [1, 1, 1, 2, 1, 1, 1],\n       [1, 1, 1, 2, 1, 1, 1]])\n\n>>> a = [1, 2, 3, 4, 5]\n>>> np.pad(a, (2, 3), 'reflect')\narray([3, 2, 1, 2, 3, 4, 5, 4, 3, 2])\n\n>>> np.pad(a, (2, 3), 'reflect', reflect_type='odd')\narray([-1,  0,  1,  2,  3,  4,  5,  6,  7,  8])\n\n>>> np.pad(a, (2, 3), 'symmetric')\narray([2, 1, 1, 2, 3, 4, 5, 5, 4, 3])\n\n>>> np.pad(a, (2, 3), 'symmetric', reflect_type='odd')\narray([0, 1, 1, 2, 3, 4, 5, 5, 6, 7])\n\n>>> np.pad(a, (2, 3), 'wrap')\narray([4, 5, 1, 2, 3, 4, 5, 1, 2, 3])\n\n>>> def pad_with(vector, pad_width, iaxis, kwargs):\n...     pad_value = kwargs.get('padder', 10)\n...     vector[:pad_width[0]] = pad_value\n...     vector[-pad_width[1]:] = pad_value\n>>> a = np.arange(6)\n>>> a = a.reshape((2, 3))\n>>> np.pad(a, 2, pad_with)\narray([[10, 10, 10, 10, 10, 10, 10],\n       [10, 10, 10, 10, 10, 10, 10],\n       [10, 10,  0,  1,  2, 10, 10],\n       [10, 10,  3,  4,  5, 10, 10],\n       [10, 10, 10, 10, 10, 10, 10],\n       [10, 10, 10, 10, 10, 10, 10]])\n>>> np.pad(a, 2, pad_with, padder=100)\narray([[100, 100, 100, 100, 100, 100, 100],\n       [100, 100, 100, 100, 100, 100, 100],\n       [100, 100,   0,   1,   2, 100, 100],\n       [100, 100,   3,   4,   5, 100, 100],\n       [100, 100, 100, 100, 100, 100, 100],\n       [100, 100, 100, 100, 100, 100, 100]])"
      }
    },
    {
      "name": "percentile",
      "signature": "percentile(a, q, axis=None, out=None, overwrite_input=False, method='linear', keepdims=False, *, interpolation=None)",
      "docstring": {
        "description": "Compute the q-th percentile of the data along the specified axis.\n\nReturns the q-th percentile(s) of the array elements.",
        "parameters": {
          "a": {
            "type": "array_like of real numbers",
            "description": "Input array or object that can be converted to an array."
          },
          "q": {
            "type": "array_like of float",
            "description": "Percentage or sequence of percentages for the percentiles to compute.\n    Values must be between 0 and 100 inclusive."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the percentiles are computed. The\n    default is to compute the percentile(s) along a flattened\n    version of the array.\n\n    .. versionchanged:: 1.9.0\n        A tuple of axes is supported"
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must\n    have the same shape and buffer length as the expected output,\n    but the type (of the output) will be cast if necessary."
          },
          "overwrite_input": {
            "type": "bool, optional",
            "description": "If True, then allow the input array `a` to be modified by intermediate\n    calculations, to save memory. In this case, the contents of the input\n    `a` after this function completes is undefined."
          },
          "method": {
            "type": "str, optional",
            "description": "This parameter specifies the method to use for estimating the\n    percentile.  There are many different methods, some unique to NumPy.\n    See the notes for explanation.  The options sorted by their R type\n    as summarized in the H&F paper [1]_ are:\n\n    1. 'inverted_cdf'\n    2. 'averaged_inverted_cdf'\n    3. 'closest_observation'\n    4. 'interpolated_inverted_cdf'\n    5. 'hazen'\n    6. 'weibull'\n    7. 'linear'  (default)\n    8. 'median_unbiased'\n    9. 'normal_unbiased'\n\n    The first three methods are discontinuous.  NumPy further defines the\n    following discontinuous variations of the default 'linear' (7.) option:\n\n    * 'lower'\n    * 'higher',\n    * 'midpoint'\n    * 'nearest'\n\n    .. versionchanged:: 1.22.0\n        This argument was previously called \"interpolation\" and only\n        offered the \"linear\" default and last four options."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left in\n    the result as dimensions with size one. With this option, the\n    result will broadcast correctly against the original array `a`.\n\n    .. versionadded:: 1.9.0"
          },
          "interpolation": {
            "type": "str, optional",
            "description": "Deprecated name for the method keyword argument.\n\n    .. deprecated:: 1.22.0"
          }
        },
        "returns": "percentile : scalar or ndarray\n    If `q` is a single percentile and `axis=None`, then the result\n    is a scalar. If multiple percentiles are given, first axis of\n    the result corresponds to the percentiles. The other axes are\n    the axes that remain after the reduction of `a`. If the input\n    contains integers or floats smaller than ``float64``, the output\n    data-type is ``float64``. Otherwise, the output data-type is the\n    same as that of the input. If `out` is specified, that array is\n    returned instead.",
        "raises": "",
        "see_also": "mean\nmedian : equivalent to ``percentile(..., 50)``\nnanpercentile\nquantile : equivalent to percentile, except q in the range [0, 1].",
        "notes": "Given a vector ``V`` of length ``n``, the q-th percentile of ``V`` is\nthe value ``q/100`` of the way from the minimum to the maximum in a\nsorted copy of ``V``. The values and distances of the two nearest\nneighbors as well as the `method` parameter will determine the\npercentile if the normalized ranking does not match the location of\n``q`` exactly. This function is the same as the median if ``q=50``, the\nsame as the minimum if ``q=0`` and the same as the maximum if\n``q=100``.\n\nThe optional `method` parameter specifies the method to use when the\ndesired percentile lies between two indexes ``i`` and ``j = i + 1``.\nIn that case, we first determine ``i + g``, a virtual index that lies\nbetween ``i`` and ``j``, where  ``i`` is the floor and ``g`` is the\nfractional part of the index. The final result is, then, an interpolation\nof ``a[i]`` and ``a[j]`` based on ``g``. During the computation of ``g``,\n``i`` and ``j`` are modified using correction constants ``alpha`` and\n``beta`` whose choices depend on the ``method`` used. Finally, note that\nsince Python uses 0-based indexing, the code subtracts another 1 from the\nindex internally.\n\nThe following formula determines the virtual index ``i + g``, the location\nof the percentile in the sorted sample:\n\n.. math::\n    i + g = (q / 100) * ( n - alpha - beta + 1 ) + alpha\n\nThe different methods then work as follows\n\ninverted_cdf:\n    method 1 of H&F [1]_.\n    This method gives discontinuous results:\n\n    * if g > 0 ; then take j\n    * if g = 0 ; then take i\n\naveraged_inverted_cdf:\n    method 2 of H&F [1]_.\n    This method give discontinuous results:\n\n    * if g > 0 ; then take j\n    * if g = 0 ; then average between bounds\n\nclosest_observation:\n    method 3 of H&F [1]_.\n    This method give discontinuous results:\n\n    * if g > 0 ; then take j\n    * if g = 0 and index is odd ; then take j\n    * if g = 0 and index is even ; then take i\n\ninterpolated_inverted_cdf:\n    method 4 of H&F [1]_.\n    This method give continuous results using:\n\n    * alpha = 0\n    * beta = 1\n\nhazen:\n    method 5 of H&F [1]_.\n    This method give continuous results using:\n\n    * alpha = 1/2\n    * beta = 1/2\n\nweibull:\n    method 6 of H&F [1]_.\n    This method give continuous results using:\n\n    * alpha = 0\n    * beta = 0\n\nlinear:\n    method 7 of H&F [1]_.\n    This method give continuous results using:\n\n    * alpha = 1\n    * beta = 1\n\nmedian_unbiased:\n    method 8 of H&F [1]_.\n    This method is probably the best method if the sample\n    distribution function is unknown (see reference).\n    This method give continuous results using:\n\n    * alpha = 1/3\n    * beta = 1/3\n\nnormal_unbiased:\n    method 9 of H&F [1]_.\n    This method is probably the best method if the sample\n    distribution function is known to be normal.\n    This method give continuous results using:\n\n    * alpha = 3/8\n    * beta = 3/8\n\nlower:\n    NumPy method kept for backwards compatibility.\n    Takes ``i`` as the interpolation point.\n\nhigher:\n    NumPy method kept for backwards compatibility.\n    Takes ``j`` as the interpolation point.\n\nnearest:\n    NumPy method kept for backwards compatibility.\n    Takes ``i`` or ``j``, whichever is nearest.\n\nmidpoint:\n    NumPy method kept for backwards compatibility.\n    Uses ``(i + j) / 2``.",
        "examples": ">>> a = np.array([[10, 7, 4], [3, 2, 1]])\n>>> a\narray([[10,  7,  4],\n       [ 3,  2,  1]])\n>>> np.percentile(a, 50)\n3.5\n>>> np.percentile(a, 50, axis=0)\narray([6.5, 4.5, 2.5])\n>>> np.percentile(a, 50, axis=1)\narray([7.,  2.])\n>>> np.percentile(a, 50, axis=1, keepdims=True)\narray([[7.],\n       [2.]])\n\n>>> m = np.percentile(a, 50, axis=0)\n>>> out = np.zeros_like(m)\n>>> np.percentile(a, 50, axis=0, out=out)\narray([6.5, 4.5, 2.5])\n>>> m\narray([6.5, 4.5, 2.5])\n\n>>> b = a.copy()\n>>> np.percentile(b, 50, axis=1, overwrite_input=True)\narray([7.,  2.])\n>>> assert not np.all(a == b)\n\nThe different methods can be visualized graphically:\n\n.. plot::\n\n    import matplotlib.pyplot as plt\n\n    a = np.arange(4)\n    p = np.linspace(0, 100, 6001)\n    ax = plt.gca()\n    lines = [\n        ('linear', '-', 'C0'),\n        ('inverted_cdf', ':', 'C1'),\n        # Almost the same as `inverted_cdf`:\n        ('averaged_inverted_cdf', '-.', 'C1'),\n        ('closest_observation', ':', 'C2'),\n        ('interpolated_inverted_cdf', '--', 'C1'),\n        ('hazen', '--', 'C3'),\n        ('weibull', '-.', 'C4'),\n        ('median_unbiased', '--', 'C5'),\n        ('normal_unbiased', '-.', 'C6'),\n        ]\n    for method, style, color in lines:\n        ax.plot(\n            p, np.percentile(a, p, method=method),\n            label=method, linestyle=style, color=color)\n    ax.set(\n        title='Percentiles for different methods and data: ' + str(a),\n        xlabel='Percentile',\n        ylabel='Estimated percentile value',\n        yticks=a)\n    ax.legend(bbox_to_anchor=(1.03, 1))\n    plt.tight_layout()\n    plt.show()\n\nReferences\n----------\n.. [1] R. J. Hyndman and Y. Fan,\n   \"Sample quantiles in statistical packages,\"\n   The American Statistician, 50(4), pp. 361-365, 1996"
      }
    },
    {
      "name": "piecewise",
      "signature": "piecewise(x, condlist, funclist, *args, **kw)",
      "docstring": {
        "description": "Evaluate a piecewise-defined function.\n\nGiven a set of conditions and corresponding functions, evaluate each\nfunction on the input data wherever its condition is true.",
        "parameters": {
          "x": {
            "type": "ndarray or scalar",
            "description": "The input domain."
          },
          "condlist": {
            "type": "list of bool arrays or bool scalars",
            "description": "Each boolean array corresponds to a function in `funclist`.  Wherever\n    `condlist[i]` is True, `funclist[i](x)` is used as the output value.\n\n    Each boolean array in `condlist` selects a piece of `x`,\n    and should therefore be of the same shape as `x`.\n\n    The length of `condlist` must correspond to that of `funclist`.\n    If one extra function is given, i.e. if\n    ``len(funclist) == len(condlist) + 1``, then that extra function\n    is the default value, used wherever all conditions are false."
          },
          "funclist": {
            "type": "list of callables, f(x,*args,**kw), or scalars",
            "description": "Each function is evaluated over `x` wherever its corresponding\n    condition is True.  It should take a 1d array as input and give an 1d\n    array or a scalar value as output.  If, instead of a callable,\n    a scalar is provided then a constant function (``lambda x: scalar``) is\n    assumed."
          },
          "args": {
            "type": "tuple, optional",
            "description": "Any further arguments given to `piecewise` are passed to the functions\n    upon execution, i.e., if called ``piecewise(..., ..., 1, 'a')``, then\n    each function is called as ``f(x, 1, 'a')``."
          },
          "kw": {
            "type": "dict, optional",
            "description": "Keyword arguments used in calling `piecewise` are passed to the\n    functions upon execution, i.e., if called\n    ``piecewise(..., ..., alpha=1)``, then each function is called as\n    ``f(x, alpha=1)``."
          }
        },
        "returns": "out : ndarray\n    The output is the same shape and type as x and is found by\n    calling the functions in `funclist` on the appropriate portions of `x`,\n    as defined by the boolean arrays in `condlist`.  Portions not covered\n    by any condition have a default value of 0.",
        "raises": "",
        "see_also": "choose, select, where",
        "notes": "This is similar to choose or select, except that functions are\nevaluated on elements of `x` that satisfy the corresponding condition from\n`condlist`.\n\nThe result is::\n\n        |--\n        |funclist[0](x[condlist[0]])\n  out = |funclist[1](x[condlist[1]])\n        |...\n        |funclist[n2](x[condlist[n2]])\n        |--",
        "examples": "Define the sigma function, which is -1 for ``x < 0`` and +1 for ``x >= 0``.\n\n>>> x = np.linspace(-2.5, 2.5, 6)\n>>> np.piecewise(x, [x < 0, x >= 0], [-1, 1])\narray([-1., -1., -1.,  1.,  1.,  1.])\n\nDefine the absolute value, which is ``-x`` for ``x <0`` and ``x`` for\n``x >= 0``.\n\n>>> np.piecewise(x, [x < 0, x >= 0], [lambda x: -x, lambda x: x])\narray([2.5,  1.5,  0.5,  0.5,  1.5,  2.5])\n\nApply the same function to a scalar value.\n\n>>> y = -2\n>>> np.piecewise(y, [y < 0, y >= 0], [lambda x: -x, lambda x: x])\narray(2)"
      }
    },
    {
      "name": "place",
      "signature": "place(arr, mask, vals)",
      "docstring": {
        "description": "Change elements of an array based on conditional and input values.\n\nSimilar to ``np.copyto(arr, vals, where=mask)``, the difference is that\n`place` uses the first N elements of `vals`, where N is the number of\nTrue values in `mask`, while `copyto` uses the elements where `mask`\nis True.\n\nNote that `extract` does the exact opposite of `place`.",
        "parameters": {
          "arr": {
            "type": "ndarray",
            "description": "Array to put data into."
          },
          "mask": {
            "type": "array_like",
            "description": "Boolean mask array. Must have the same size as `a`."
          },
          "vals": {
            "type": "1-D sequence",
            "description": "Values to put into `a`. Only the first N elements are used, where\n    N is the number of True values in `mask`. If `vals` is smaller\n    than N, it will be repeated, and if elements of `a` are to be masked,\n    this sequence must be non-empty."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "copyto, put, take, extract",
        "notes": "",
        "examples": ">>> arr = np.arange(6).reshape(2, 3)\n>>> np.place(arr, arr>2, [44, 55])\n>>> arr\narray([[ 0,  1,  2],\n       [44, 55, 44]])"
      }
    },
    {
      "name": "poly",
      "signature": "poly(seq_of_zeros)",
      "docstring": {
        "description": "Find the coefficients of a polynomial with the given sequence of roots.\n\n.. note::\n   This forms part of the old polynomial API. Since version 1.4, the\n   new polynomial API defined in `numpy.polynomial` is preferred.\n   A summary of the differences can be found in the\n   :doc:`transition guide </reference/routines.polynomials>`.\n\nReturns the coefficients of the polynomial whose leading coefficient\nis one for the given sequence of zeros (multiple roots must be included\nin the sequence as many times as their multiplicity; see Examples).\nA square matrix (or array, which will be treated as a matrix) can also\nbe given, in which case the coefficients of the characteristic polynomial\nof the matrix are returned.",
        "parameters": {
          "seq_of_zeros": {
            "type": "array_like, shape (N,) or (N, N)",
            "description": "A sequence of polynomial roots, or a square array or matrix object."
          }
        },
        "returns": "c : ndarray\n    1D array of polynomial coefficients from highest to lowest degree:\n\n    ``c[0] * x**(N) + c[1] * x**(N-1) + ... + c[N-1] * x + c[N]``\n    where c[0] always equals 1.",
        "raises": "ValueError\n    If input is the wrong shape (the input must be a 1-D or square\n    2-D array).",
        "see_also": "polyval : Compute polynomial values.\nroots : Return the roots of a polynomial.\npolyfit : Least squares polynomial fit.\npoly1d : A one-dimensional polynomial class.",
        "notes": "Specifying the roots of a polynomial still leaves one degree of\nfreedom, typically represented by an undetermined leading\ncoefficient. [1]_ In the case of this function, that coefficient -\nthe first one in the returned array - is always taken as one. (If\nfor some reason you have one other point, the only automatic way\npresently to leverage that information is to use ``polyfit``.)\n\nThe characteristic polynomial, :math:`p_a(t)`, of an `n`-by-`n`\nmatrix **A** is given by\n\n    :math:`p_a(t) = \\mathrm{det}(t\\, \\mathbf{I} - \\mathbf{A})`,\n\nwhere **I** is the `n`-by-`n` identity matrix. [2]_\n\nReferences\n----------\n.. [1] M. Sullivan and M. Sullivan, III, \"Algebra and Trigonometry,\n   Enhanced With Graphing Utilities,\" Prentice-Hall, pg. 318, 1996.\n\n.. [2] G. Strang, \"Linear Algebra and Its Applications, 2nd Edition,\"\n   Academic Press, pg. 182, 1980.",
        "examples": "Given a sequence of a polynomial's zeros:\n\n>>> np.poly((0, 0, 0)) # Multiple root example\narray([1., 0., 0., 0.])\n\nThe line above represents z**3 + 0*z**2 + 0*z + 0.\n\n>>> np.poly((-1./2, 0, 1./2))\narray([ 1.  ,  0.  , -0.25,  0.  ])\n\nThe line above represents z**3 - z/4\n\n>>> np.poly((np.random.random(1)[0], 0, np.random.random(1)[0]))\narray([ 1.        , -0.77086955,  0.08618131,  0.        ]) # random\n\nGiven a square array object:\n\n>>> P = np.array([[0, 1./3], [-1./2, 0]])\n>>> np.poly(P)\narray([1.        , 0.        , 0.16666667])\n\nNote how in all cases the leading coefficient is always 1."
      }
    },
    {
      "name": "poly1d",
      "signature": "poly1d(c_or_r, r=False, variable=None)",
      "docstring": {
        "description": "A one-dimensional polynomial class.\n\n.. note::\n   This forms part of the old polynomial API. Since version 1.4, the\n   new polynomial API defined in `numpy.polynomial` is preferred.\n   A summary of the differences can be found in the\n   :doc:`transition guide </reference/routines.polynomials>`.\n\nA convenience class, used to encapsulate \"natural\" operations on\npolynomials so that said operations may take on their customary\nform in code (see Examples).",
        "parameters": {
          "c_or_r": {
            "type": "array_like",
            "description": "The polynomial's coefficients, in decreasing powers, or if\n    the value of the second parameter is True, the polynomial's\n    roots (values where the polynomial evaluates to 0).  For example,\n    ``poly1d([1, 2, 3])`` returns an object that represents\n    :math:`x^2 + 2x + 3`, whereas ``poly1d([1, 2, 3], True)`` returns\n    one that represents :math:`(x-1)(x-2)(x-3) = x^3 - 6x^2 + 11x -6`."
          },
          "r": {
            "type": "bool, optional",
            "description": "If True, `c_or_r` specifies the polynomial's roots; the default\n    is False."
          },
          "variable": {
            "type": "str, optional",
            "description": "Changes the variable used when printing `p` from `x` to `variable`\n    (see Examples)."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "Construct the polynomial :math:`x^2 + 2x + 3`:\n\n>>> p = np.poly1d([1, 2, 3])\n>>> print(np.poly1d(p))\n   2\n1 x + 2 x + 3\n\nEvaluate the polynomial at :math:`x = 0.5`:\n\n>>> p(0.5)\n4.25\n\nFind the roots:\n\n>>> p.r\narray([-1.+1.41421356j, -1.-1.41421356j])\n>>> p(p.r)\narray([ -4.44089210e-16+0.j,  -4.44089210e-16+0.j]) # may vary\n\nThese numbers in the previous line represent (0, 0) to machine precision\n\nShow the coefficients:\n\n>>> p.c\narray([1, 2, 3])\n\nDisplay the order (the leading zero-coefficients are removed):\n\n>>> p.order\n2\n\nShow the coefficient of the k-th power in the polynomial\n(which is equivalent to ``p.c[-(i+1)]``):\n\n>>> p[1]\n2\n\nPolynomials can be added, subtracted, multiplied, and divided\n(returns quotient and remainder):\n\n>>> p * p\npoly1d([ 1,  4, 10, 12,  9])\n\n>>> (p**3 + 4) / p\n(poly1d([ 1.,  4., 10., 12.,  9.]), poly1d([4.]))\n\n``asarray(p)`` gives the coefficient array, so polynomials can be\nused in all functions that accept arrays:\n\n>>> p**2 # square of polynomial\npoly1d([ 1,  4, 10, 12,  9])\n\n>>> np.square(p) # square of individual coefficients\narray([1, 4, 9])\n\nThe variable used in the string representation of `p` can be modified,\nusing the `variable` parameter:\n\n>>> p = np.poly1d([1,2,3], variable='z')\n>>> print(p)\n   2\n1 z + 2 z + 3\n\nConstruct a polynomial from its roots:\n\n>>> np.poly1d([1, 2], True)\npoly1d([ 1., -3.,  2.])\n\nThis is the same polynomial as obtained by:\n\n>>> np.poly1d([1, -1]) * np.poly1d([1, -2])\npoly1d([ 1, -3,  2])"
      }
    },
    {
      "name": "polyadd",
      "signature": "polyadd(a1, a2)",
      "docstring": {
        "description": "Find the sum of two polynomials.\n\n.. note::\n   This forms part of the old polynomial API. Since version 1.4, the\n   new polynomial API defined in `numpy.polynomial` is preferred.\n   A summary of the differences can be found in the\n   :doc:`transition guide </reference/routines.polynomials>`.\n\nReturns the polynomial resulting from the sum of two input polynomials.\nEach input must be either a poly1d object or a 1D sequence of polynomial\ncoefficients, from highest to lowest degree.",
        "parameters": {},
        "returns": "out : ndarray or poly1d object\n    The sum of the inputs. If either input is a poly1d object, then the\n    output is also a poly1d object. Otherwise, it is a 1D array of\n    polynomial coefficients from highest to lowest degree.",
        "raises": "",
        "see_also": "poly1d : A one-dimensional polynomial class.\npoly, polyadd, polyder, polydiv, polyfit, polyint, polysub, polyval",
        "notes": "",
        "examples": ">>> np.polyadd([1, 2], [9, 5, 4])\narray([9, 6, 6])\n\nUsing poly1d objects:\n\n>>> p1 = np.poly1d([1, 2])\n>>> p2 = np.poly1d([9, 5, 4])\n>>> print(p1)\n1 x + 2\n>>> print(p2)\n   2\n9 x + 5 x + 4\n>>> print(np.polyadd(p1, p2))\n   2\n9 x + 6 x + 6"
      }
    },
    {
      "name": "polyder",
      "signature": "polyder(p, m=1)",
      "docstring": {
        "description": "Return the derivative of the specified order of a polynomial.\n\n.. note::\n   This forms part of the old polynomial API. Since version 1.4, the\n   new polynomial API defined in `numpy.polynomial` is preferred.\n   A summary of the differences can be found in the\n   :doc:`transition guide </reference/routines.polynomials>`.",
        "parameters": {
          "p": {
            "type": "poly1d or sequence",
            "description": "Polynomial to differentiate.\n    A sequence is interpreted as polynomial coefficients, see `poly1d`."
          },
          "m": {
            "type": "int, optional",
            "description": "Order of differentiation (default: 1)"
          }
        },
        "returns": "der : poly1d\n    A new polynomial representing the derivative.",
        "raises": "",
        "see_also": "polyint : Anti-derivative of a polynomial.\npoly1d : Class for one-dimensional polynomials.",
        "notes": "",
        "examples": "The derivative of the polynomial :math:`x^3 + x^2 + x^1 + 1` is:\n\n>>> p = np.poly1d([1,1,1,1])\n>>> p2 = np.polyder(p)\n>>> p2\npoly1d([3, 2, 1])\n\nwhich evaluates to:\n\n>>> p2(2.)\n17.0\n\nWe can verify this, approximating the derivative with\n``(f(x + h) - f(x))/h``:\n\n>>> (p(2. + 0.001) - p(2.)) / 0.001\n17.007000999997857\n\nThe fourth-order derivative of a 3rd-order polynomial is zero:\n\n>>> np.polyder(p, 2)\npoly1d([6, 2])\n>>> np.polyder(p, 3)\npoly1d([6])\n>>> np.polyder(p, 4)\npoly1d([0])"
      }
    },
    {
      "name": "polydiv",
      "signature": "polydiv(u, v)",
      "docstring": {
        "description": "Returns the quotient and remainder of polynomial division.\n\n.. note::\n   This forms part of the old polynomial API. Since version 1.4, the\n   new polynomial API defined in `numpy.polynomial` is preferred.\n   A summary of the differences can be found in the\n   :doc:`transition guide </reference/routines.polynomials>`.\n\nThe input arrays are the coefficients (including any coefficients\nequal to zero) of the \"numerator\" (dividend) and \"denominator\"\n(divisor) polynomials, respectively.",
        "parameters": {
          "u": {
            "type": "array_like or poly1d",
            "description": "Dividend polynomial's coefficients."
          },
          "v": {
            "type": "array_like or poly1d",
            "description": "Divisor polynomial's coefficients."
          }
        },
        "returns": "q : ndarray\n    Coefficients, including those equal to zero, of the quotient.\nr : ndarray\n    Coefficients, including those equal to zero, of the remainder.",
        "raises": "",
        "see_also": "poly, polyadd, polyder, polydiv, polyfit, polyint, polymul, polysub\npolyval",
        "notes": "Both `u` and `v` must be 0-d or 1-d (ndim = 0 or 1), but `u.ndim` need\nnot equal `v.ndim`. In other words, all four possible combinations -\n``u.ndim = v.ndim = 0``, ``u.ndim = v.ndim = 1``,\n``u.ndim = 1, v.ndim = 0``, and ``u.ndim = 0, v.ndim = 1`` - work.",
        "examples": ".. math:: \\frac{3x^2 + 5x + 2}{2x + 1} = 1.5x + 1.75, remainder 0.25\n\n>>> x = np.array([3.0, 5.0, 2.0])\n>>> y = np.array([2.0, 1.0])\n>>> np.polydiv(x, y)\n(array([1.5 , 1.75]), array([0.25]))"
      }
    },
    {
      "name": "polyfit",
      "signature": "polyfit(x, y, deg, rcond=None, full=False, w=None, cov=False)",
      "docstring": {
        "description": "Least squares polynomial fit.\n\n.. note::\n   This forms part of the old polynomial API. Since version 1.4, the\n   new polynomial API defined in `numpy.polynomial` is preferred.\n   A summary of the differences can be found in the\n   :doc:`transition guide </reference/routines.polynomials>`.\n\nFit a polynomial ``p(x) = p[0] * x**deg + ... + p[deg]`` of degree `deg`\nto points `(x, y)`. Returns a vector of coefficients `p` that minimises\nthe squared error in the order `deg`, `deg-1`, ... `0`.\n\nThe `Polynomial.fit <numpy.polynomial.polynomial.Polynomial.fit>` class\nmethod is recommended for new code as it is more stable numerically. See\nthe documentation of the method for more information.",
        "parameters": {
          "x": {
            "type": "array_like, shape (M,)",
            "description": "x-coordinates of the M sample points ``(x[i], y[i])``."
          },
          "y": {
            "type": "array_like, shape (M,) or (M, K)",
            "description": "y-coordinates of the sample points. Several data sets of sample\n    points sharing the same x-coordinates can be fitted at once by\n    passing in a 2D-array that contains one dataset per column."
          },
          "deg": {
            "type": "int",
            "description": "Degree of the fitting polynomial"
          },
          "rcond": {
            "type": "float, optional",
            "description": "Relative condition number of the fit. Singular values smaller than\n    this relative to the largest singular value will be ignored. The\n    default value is len(x)*eps, where eps is the relative precision of\n    the float type, about 2e-16 in most cases."
          },
          "full": {
            "type": "bool, optional",
            "description": "Switch determining nature of return value. When it is False (the\n    default) just the coefficients are returned, when True diagnostic\n    information from the singular value decomposition is also returned."
          },
          "w": {
            "type": "array_like, shape (M,), optional",
            "description": "Weights. If not None, the weight ``w[i]`` applies to the unsquared\n    residual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally the weights are\n    chosen so that the errors of the products ``w[i]*y[i]`` all have the\n    same variance.  When using inverse-variance weighting, use\n    ``w[i] = 1/sigma(y[i])``.  The default value is None."
          },
          "cov": {
            "type": "bool or str, optional",
            "description": "If given and not `False`, return not just the estimate but also its\n    covariance matrix. By default, the covariance are scaled by\n    chi2/dof, where dof = M - (deg + 1), i.e., the weights are presumed\n    to be unreliable except in a relative sense and everything is scaled\n    such that the reduced chi2 is unity. This scaling is omitted if\n    ``cov='unscaled'``, as is relevant for the case that the weights are\n    w = 1/sigma, with sigma known to be a reliable estimate of the\n    uncertainty."
          }
        },
        "returns": "p : ndarray, shape (deg + 1,) or (deg + 1, K)\n    Polynomial coefficients, highest power first.  If `y` was 2-D, the\n    coefficients for `k`-th data set are in ``p[:,k]``.\n\nresiduals, rank, singular_values, rcond\n    These values are only returned if ``full == True``\n\n    - residuals -- sum of squared residuals of the least squares fit\n    - rank -- the effective rank of the scaled Vandermonde\n       coefficient matrix\n    - singular_values -- singular values of the scaled Vandermonde\n       coefficient matrix\n    - rcond -- value of `rcond`.\n\n    For more details, see `numpy.linalg.lstsq`.\n\nV : ndarray, shape (M,M) or (M,M,K)\n    Present only if ``full == False`` and ``cov == True``.  The covariance\n    matrix of the polynomial coefficient estimates.  The diagonal of\n    this matrix are the variance estimates for each coefficient.  If y\n    is a 2-D array, then the covariance matrix for the `k`-th data set\n    are in ``V[:,:,k]``\n\n\nWarns\n-----\nRankWarning\n    The rank of the coefficient matrix in the least-squares fit is\n    deficient. The warning is only raised if ``full == False``.\n\n    The warnings can be turned off by\n\n    >>> import warnings\n    >>> warnings.simplefilter('ignore', np.RankWarning)",
        "raises": "",
        "see_also": "polyval : Compute polynomial values.\nlinalg.lstsq : Computes a least-squares fit.\nscipy.interpolate.UnivariateSpline : Computes spline fits.",
        "notes": "The solution minimizes the squared error\n\n.. math::\n    E = \\sum_{j=0}^k |p(x_j) - y_j|^2\n\nin the equations::\n\n    x[0]**n * p[0] + ... + x[0] * p[n-1] + p[n] = y[0]\n    x[1]**n * p[0] + ... + x[1] * p[n-1] + p[n] = y[1]\n    ...\n    x[k]**n * p[0] + ... + x[k] * p[n-1] + p[n] = y[k]\n\nThe coefficient matrix of the coefficients `p` is a Vandermonde matrix.\n\n`polyfit` issues a `RankWarning` when the least-squares fit is badly\nconditioned. This implies that the best fit is not well-defined due\nto numerical error. The results may be improved by lowering the polynomial\ndegree or by replacing `x` by `x` - `x`.mean(). The `rcond` parameter\ncan also be set to a value smaller than its default, but the resulting\nfit may be spurious: including contributions from the small singular\nvalues can add numerical noise to the result.\n\nNote that fitting polynomial coefficients is inherently badly conditioned\nwhen the degree of the polynomial is large or the interval of sample points\nis badly centered. The quality of the fit should always be checked in these\ncases. When polynomial fits are not satisfactory, splines may be a good\nalternative.\n\nReferences\n----------\n.. [1] Wikipedia, \"Curve fitting\",\n       https://en.wikipedia.org/wiki/Curve_fitting\n.. [2] Wikipedia, \"Polynomial interpolation\",\n       https://en.wikipedia.org/wiki/Polynomial_interpolation",
        "examples": ">>> import warnings\n>>> x = np.array([0.0, 1.0, 2.0, 3.0,  4.0,  5.0])\n>>> y = np.array([0.0, 0.8, 0.9, 0.1, -0.8, -1.0])\n>>> z = np.polyfit(x, y, 3)\n>>> z\narray([ 0.08703704, -0.81349206,  1.69312169, -0.03968254]) # may vary\n\nIt is convenient to use `poly1d` objects for dealing with polynomials:\n\n>>> p = np.poly1d(z)\n>>> p(0.5)\n0.6143849206349179 # may vary\n>>> p(3.5)\n-0.34732142857143039 # may vary\n>>> p(10)\n22.579365079365115 # may vary\n\nHigh-order polynomials may oscillate wildly:\n\n>>> with warnings.catch_warnings():\n...     warnings.simplefilter('ignore', np.RankWarning)\n...     p30 = np.poly1d(np.polyfit(x, y, 30))\n...\n>>> p30(4)\n-0.80000000000000204 # may vary\n>>> p30(5)\n-0.99999999999999445 # may vary\n>>> p30(4.5)\n-0.10547061179440398 # may vary\n\nIllustration:\n\n>>> import matplotlib.pyplot as plt\n>>> xp = np.linspace(-2, 6, 100)\n>>> _ = plt.plot(x, y, '.', xp, p(xp), '-', xp, p30(xp), '--')\n>>> plt.ylim(-2,2)\n(-2, 2)\n>>> plt.show()"
      }
    },
    {
      "name": "polyint",
      "signature": "polyint(p, m=1, k=None)",
      "docstring": {
        "description": "Return an antiderivative (indefinite integral) of a polynomial.\n\n.. note::\n   This forms part of the old polynomial API. Since version 1.4, the\n   new polynomial API defined in `numpy.polynomial` is preferred.\n   A summary of the differences can be found in the\n   :doc:`transition guide </reference/routines.polynomials>`.\n\nThe returned order `m` antiderivative `P` of polynomial `p` satisfies\n:math:`\\frac{d^m}{dx^m}P(x) = p(x)` and is defined up to `m - 1`\nintegration constants `k`. The constants determine the low-order\npolynomial part\n\n.. math:: \\frac{k_{m-1}}{0!} x^0 + \\ldots + \\frac{k_0}{(m-1)!}x^{m-1}\n\nof `P` so that :math:`P^{(j)}(0) = k_{m-j-1}`.",
        "parameters": {
          "p": {
            "type": "array_like or poly1d",
            "description": "Polynomial to integrate.\n    A sequence is interpreted as polynomial coefficients, see `poly1d`."
          },
          "m": {
            "type": "int, optional",
            "description": "Order of the antiderivative. (Default: 1)"
          },
          "k": {
            "type": "list of `m` scalars or scalar, optional",
            "description": "Integration constants. They are given in the order of integration:\n    those corresponding to highest-order terms come first.\n\n    If ``None`` (default), all constants are assumed to be zero.\n    If `m = 1`, a single scalar can be given instead of a list."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "polyder : derivative of a polynomial\npoly1d.integ : equivalent method",
        "notes": "",
        "examples": "The defining property of the antiderivative:\n\n>>> p = np.poly1d([1,1,1])\n>>> P = np.polyint(p)\n>>> P\n poly1d([ 0.33333333,  0.5       ,  1.        ,  0.        ]) # may vary\n>>> np.polyder(P) == p\nTrue\n\nThe integration constants default to zero, but can be specified:\n\n>>> P = np.polyint(p, 3)\n>>> P(0)\n0.0\n>>> np.polyder(P)(0)\n0.0\n>>> np.polyder(P, 2)(0)\n0.0\n>>> P = np.polyint(p, 3, k=[6,5,3])\n>>> P\npoly1d([ 0.01666667,  0.04166667,  0.16666667,  3. ,  5. ,  3. ]) # may vary\n\nNote that 3 = 6 / 2!, and that the constants are given in the order of\nintegrations. Constant of the highest-order polynomial term comes first:\n\n>>> np.polyder(P, 2)(0)\n6.0\n>>> np.polyder(P, 1)(0)\n5.0\n>>> P(0)\n3.0"
      }
    },
    {
      "name": "polymul",
      "signature": "polymul(a1, a2)",
      "docstring": {
        "description": "Find the product of two polynomials.\n\n.. note::\n   This forms part of the old polynomial API. Since version 1.4, the\n   new polynomial API defined in `numpy.polynomial` is preferred.\n   A summary of the differences can be found in the\n   :doc:`transition guide </reference/routines.polynomials>`.\n\nFinds the polynomial resulting from the multiplication of the two input\npolynomials. Each input must be either a poly1d object or a 1D sequence\nof polynomial coefficients, from highest to lowest degree.",
        "parameters": {},
        "returns": "out : ndarray or poly1d object\n    The polynomial resulting from the multiplication of the inputs. If\n    either inputs is a poly1d object, then the output is also a poly1d\n    object. Otherwise, it is a 1D array of polynomial coefficients from\n    highest to lowest degree.",
        "raises": "",
        "see_also": "poly1d : A one-dimensional polynomial class.\npoly, polyadd, polyder, polydiv, polyfit, polyint, polysub, polyval\nconvolve : Array convolution. Same output as polymul, but has parameter\n           for overlap mode.",
        "notes": "",
        "examples": ">>> np.polymul([1, 2, 3], [9, 5, 1])\narray([ 9, 23, 38, 17,  3])\n\nUsing poly1d objects:\n\n>>> p1 = np.poly1d([1, 2, 3])\n>>> p2 = np.poly1d([9, 5, 1])\n>>> print(p1)\n   2\n1 x + 2 x + 3\n>>> print(p2)\n   2\n9 x + 5 x + 1\n>>> print(np.polymul(p1, p2))\n   4      3      2\n9 x + 23 x + 38 x + 17 x + 3"
      }
    },
    {
      "name": "polysub",
      "signature": "polysub(a1, a2)",
      "docstring": {
        "description": "Difference (subtraction) of two polynomials.\n\n.. note::\n   This forms part of the old polynomial API. Since version 1.4, the\n   new polynomial API defined in `numpy.polynomial` is preferred.\n   A summary of the differences can be found in the\n   :doc:`transition guide </reference/routines.polynomials>`.\n\nGiven two polynomials `a1` and `a2`, returns ``a1 - a2``.\n`a1` and `a2` can be either array_like sequences of the polynomials'\ncoefficients (including coefficients equal to zero), or `poly1d` objects.",
        "parameters": {},
        "returns": "out : ndarray or poly1d\n    Array or `poly1d` object of the difference polynomial's coefficients.",
        "raises": "",
        "see_also": "polyval, polydiv, polymul, polyadd",
        "notes": "",
        "examples": ".. math:: (2 x^2 + 10 x - 2) - (3 x^2 + 10 x -4) = (-x^2 + 2)\n\n>>> np.polysub([2, 10, -2], [3, 10, -4])\narray([-1,  0,  2])"
      }
    },
    {
      "name": "polyval",
      "signature": "polyval(p, x)",
      "docstring": {
        "description": "Evaluate a polynomial at specific values.\n\n.. note::\n   This forms part of the old polynomial API. Since version 1.4, the\n   new polynomial API defined in `numpy.polynomial` is preferred.\n   A summary of the differences can be found in the\n   :doc:`transition guide </reference/routines.polynomials>`.\n\nIf `p` is of length N, this function returns the value:\n\n    ``p[0]*x**(N-1) + p[1]*x**(N-2) + ... + p[N-2]*x + p[N-1]``\n\nIf `x` is a sequence, then ``p(x)`` is returned for each element of ``x``.\nIf `x` is another polynomial then the composite polynomial ``p(x(t))``\nis returned.",
        "parameters": {
          "p": {
            "type": "array_like or poly1d object",
            "description": "1D array of polynomial coefficients (including coefficients equal\n   to zero) from highest degree to the constant term, or an\n   instance of poly1d."
          },
          "x": {
            "type": "array_like or poly1d object",
            "description": "A number, an array of numbers, or an instance of poly1d, at\n   which to evaluate `p`."
          }
        },
        "returns": "values : ndarray or poly1d\n   If `x` is a poly1d instance, the result is the composition of the two\n   polynomials, i.e., `x` is \"substituted\" in `p` and the simplified\n   result is returned. In addition, the type of `x` - array_like or\n   poly1d - governs the type of the output: `x` array_like => `values`\n   array_like, `x` a poly1d object => `values` is also.",
        "raises": "",
        "see_also": "poly1d: A polynomial class.",
        "notes": "Horner's scheme [1]_ is used to evaluate the polynomial. Even so,\nfor polynomials of high degree the values may be inaccurate due to\nrounding errors. Use carefully.\n\nIf `x` is a subtype of `ndarray` the return value will be of the same type.\n\nReferences\n----------\n.. [1] I. N. Bronshtein, K. A. Semendyayev, and K. A. Hirsch (Eng.\n   trans. Ed.), *Handbook of Mathematics*, New York, Van Nostrand\n   Reinhold Co., 1985, pg. 720.",
        "examples": ">>> np.polyval([3,0,1], 5)  # 3 * 5**2 + 0 * 5**1 + 1\n76\n>>> np.polyval([3,0,1], np.poly1d(5))\npoly1d([76])\n>>> np.polyval(np.poly1d([3,0,1]), 5)\n76\n>>> np.polyval(np.poly1d([3,0,1]), np.poly1d(5))\npoly1d([76])"
      }
    },
    {
      "name": "put_along_axis",
      "signature": "put_along_axis(arr, indices, values, axis)",
      "docstring": {
        "description": "Put values into the destination array by matching 1d index and data slices.\n\nThis iterates over matching 1d slices oriented along the specified axis in\nthe index and data arrays, and uses the former to place values into the\nlatter. These slices can be different lengths.\n\nFunctions returning an index along an axis, like `argsort` and\n`argpartition`, produce suitable indices for this function.\n\n.. versionadded:: 1.15.0",
        "parameters": {
          "arr": {
            "type": "ndarray (Ni..., M, Nk...)",
            "description": "Destination array."
          },
          "indices": {
            "type": "ndarray (Ni..., J, Nk...)",
            "description": "Indices to change along each 1d slice of `arr`. This must match the\n    dimension of arr, but dimensions in Ni and Nj may be 1 to broadcast\n    against `arr`."
          },
          "values": {
            "type": "array_like (Ni..., J, Nk...)",
            "description": "values to insert at those indices. Its shape and dimension are\n    broadcast to match that of `indices`."
          },
          "axis": {
            "type": "int",
            "description": "The axis to take 1d slices along. If axis is None, the destination\n    array is treated as if a flattened 1d view had been created of it."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "take_along_axis :\n    Take values from the input array by matching 1d index and data slices",
        "notes": "This is equivalent to (but faster than) the following use of `ndindex` and\n`s_`, which sets each of ``ii`` and ``kk`` to a tuple of indices::\n\n    Ni, M, Nk = a.shape[:axis], a.shape[axis], a.shape[axis+1:]\n    J = indices.shape[axis]  # Need not equal M\n\n    for ii in ndindex(Ni):\n        for kk in ndindex(Nk):\n            a_1d       = a      [ii + s_[:,] + kk]\n            indices_1d = indices[ii + s_[:,] + kk]\n            values_1d  = values [ii + s_[:,] + kk]\n            for j in range(J):\n                a_1d[indices_1d[j]] = values_1d[j]\n\nEquivalently, eliminating the inner loop, the last two lines would be::\n\n            a_1d[indices_1d] = values_1d",
        "examples": "For this sample array\n\n>>> a = np.array([[10, 30, 20], [60, 40, 50]])\n\nWe can replace the maximum values with:\n\n>>> ai = np.argmax(a, axis=1, keepdims=True)\n>>> ai\narray([[1],\n       [0]])\n>>> np.put_along_axis(a, ai, 99, axis=1)\n>>> a\narray([[10, 99, 20],\n       [99, 40, 50]])"
      }
    },
    {
      "name": "quantile",
      "signature": "quantile(a, q, axis=None, out=None, overwrite_input=False, method='linear', keepdims=False, *, interpolation=None)",
      "docstring": {
        "description": "Compute the q-th quantile of the data along the specified axis.\n\n.. versionadded:: 1.15.0",
        "parameters": {
          "a": {
            "type": "array_like of real numbers",
            "description": "Input array or object that can be converted to an array."
          },
          "q": {
            "type": "array_like of float",
            "description": "Probability or sequence of probabilities for the quantiles to compute.\n    Values must be between 0 and 1 inclusive."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the quantiles are computed. The default is\n    to compute the quantile(s) along a flattened version of the array."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must have\n    the same shape and buffer length as the expected output, but the\n    type (of the output) will be cast if necessary."
          },
          "overwrite_input": {
            "type": "bool, optional",
            "description": "If True, then allow the input array `a` to be modified by\n    intermediate calculations, to save memory. In this case, the\n    contents of the input `a` after this function completes is\n    undefined."
          },
          "method": {
            "type": "str, optional",
            "description": "This parameter specifies the method to use for estimating the\n    quantile.  There are many different methods, some unique to NumPy.\n    See the notes for explanation.  The options sorted by their R type\n    as summarized in the H&F paper [1]_ are:\n\n    1. 'inverted_cdf'\n    2. 'averaged_inverted_cdf'\n    3. 'closest_observation'\n    4. 'interpolated_inverted_cdf'\n    5. 'hazen'\n    6. 'weibull'\n    7. 'linear'  (default)\n    8. 'median_unbiased'\n    9. 'normal_unbiased'\n\n    The first three methods are discontinuous.  NumPy further defines the\n    following discontinuous variations of the default 'linear' (7.) option:\n\n    * 'lower'\n    * 'higher',\n    * 'midpoint'\n    * 'nearest'\n\n    .. versionchanged:: 1.22.0\n        This argument was previously called \"interpolation\" and only\n        offered the \"linear\" default and last four options."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left in\n    the result as dimensions with size one. With this option, the\n    result will broadcast correctly against the original array `a`."
          },
          "interpolation": {
            "type": "str, optional",
            "description": "Deprecated name for the method keyword argument.\n\n    .. deprecated:: 1.22.0"
          }
        },
        "returns": "quantile : scalar or ndarray\n    If `q` is a single probability and `axis=None`, then the result\n    is a scalar. If multiple probabilies levels are given, first axis of\n    the result corresponds to the quantiles. The other axes are\n    the axes that remain after the reduction of `a`. If the input\n    contains integers or floats smaller than ``float64``, the output\n    data-type is ``float64``. Otherwise, the output data-type is the\n    same as that of the input. If `out` is specified, that array is\n    returned instead.",
        "raises": "",
        "see_also": "mean\npercentile : equivalent to quantile, but with q in the range [0, 100].\nmedian : equivalent to ``quantile(..., 0.5)``\nnanquantile",
        "notes": "Given a vector ``V`` of length ``n``, the q-th quantile of ``V`` is\nthe value ``q`` of the way from the minimum to the maximum in a\nsorted copy of ``V``. The values and distances of the two nearest\nneighbors as well as the `method` parameter will determine the\nquantile if the normalized ranking does not match the location of\n``q`` exactly. This function is the same as the median if ``q=0.5``, the\nsame as the minimum if ``q=0.0`` and the same as the maximum if\n``q=1.0``.\n\nThe optional `method` parameter specifies the method to use when the\ndesired quantile lies between two indexes ``i`` and ``j = i + 1``.\nIn that case, we first determine ``i + g``, a virtual index that lies\nbetween ``i`` and ``j``, where  ``i`` is the floor and ``g`` is the\nfractional part of the index. The final result is, then, an interpolation\nof ``a[i]`` and ``a[j]`` based on ``g``. During the computation of ``g``,\n``i`` and ``j`` are modified using correction constants ``alpha`` and\n``beta`` whose choices depend on the ``method`` used. Finally, note that\nsince Python uses 0-based indexing, the code subtracts another 1 from the\nindex internally.\n\nThe following formula determines the virtual index ``i + g``, the location\nof the quantile in the sorted sample:\n\n.. math::\n    i + g = q * ( n - alpha - beta + 1 ) + alpha\n\nThe different methods then work as follows\n\ninverted_cdf:\n    method 1 of H&F [1]_.\n    This method gives discontinuous results:\n\n    * if g > 0 ; then take j\n    * if g = 0 ; then take i\n\naveraged_inverted_cdf:\n    method 2 of H&F [1]_.\n    This method gives discontinuous results:\n\n    * if g > 0 ; then take j\n    * if g = 0 ; then average between bounds\n\nclosest_observation:\n    method 3 of H&F [1]_.\n    This method gives discontinuous results:\n\n    * if g > 0 ; then take j\n    * if g = 0 and index is odd ; then take j\n    * if g = 0 and index is even ; then take i\n\ninterpolated_inverted_cdf:\n    method 4 of H&F [1]_.\n    This method gives continuous results using:\n\n    * alpha = 0\n    * beta = 1\n\nhazen:\n    method 5 of H&F [1]_.\n    This method gives continuous results using:\n\n    * alpha = 1/2\n    * beta = 1/2\n\nweibull:\n    method 6 of H&F [1]_.\n    This method gives continuous results using:\n\n    * alpha = 0\n    * beta = 0\n\nlinear:\n    method 7 of H&F [1]_.\n    This method gives continuous results using:\n\n    * alpha = 1\n    * beta = 1\n\nmedian_unbiased:\n    method 8 of H&F [1]_.\n    This method is probably the best method if the sample\n    distribution function is unknown (see reference).\n    This method gives continuous results using:\n\n    * alpha = 1/3\n    * beta = 1/3\n\nnormal_unbiased:\n    method 9 of H&F [1]_.\n    This method is probably the best method if the sample\n    distribution function is known to be normal.\n    This method gives continuous results using:\n\n    * alpha = 3/8\n    * beta = 3/8\n\nlower:\n    NumPy method kept for backwards compatibility.\n    Takes ``i`` as the interpolation point.\n\nhigher:\n    NumPy method kept for backwards compatibility.\n    Takes ``j`` as the interpolation point.\n\nnearest:\n    NumPy method kept for backwards compatibility.\n    Takes ``i`` or ``j``, whichever is nearest.\n\nmidpoint:\n    NumPy method kept for backwards compatibility.\n    Uses ``(i + j) / 2``.",
        "examples": ">>> a = np.array([[10, 7, 4], [3, 2, 1]])\n>>> a\narray([[10,  7,  4],\n       [ 3,  2,  1]])\n>>> np.quantile(a, 0.5)\n3.5\n>>> np.quantile(a, 0.5, axis=0)\narray([6.5, 4.5, 2.5])\n>>> np.quantile(a, 0.5, axis=1)\narray([7.,  2.])\n>>> np.quantile(a, 0.5, axis=1, keepdims=True)\narray([[7.],\n       [2.]])\n>>> m = np.quantile(a, 0.5, axis=0)\n>>> out = np.zeros_like(m)\n>>> np.quantile(a, 0.5, axis=0, out=out)\narray([6.5, 4.5, 2.5])\n>>> m\narray([6.5, 4.5, 2.5])\n>>> b = a.copy()\n>>> np.quantile(b, 0.5, axis=1, overwrite_input=True)\narray([7.,  2.])\n>>> assert not np.all(a == b)\n\nSee also `numpy.percentile` for a visualization of most methods.\n\nReferences\n----------\n.. [1] R. J. Hyndman and Y. Fan,\n   \"Sample quantiles in statistical packages,\"\n   The American Statistician, 50(4), pp. 361-365, 1996"
      }
    },
    {
      "name": "ravel_multi_index",
      "signature": "ravel_multi_index(...)",
      "docstring": {
        "description": "ravel_multi_index(multi_index, dims, mode='raise', order='C')\n\nConverts a tuple of index arrays into an array of flat\nindices, applying boundary modes to the multi-index.",
        "parameters": {
          "multi_index": {
            "type": "tuple of array_like",
            "description": "A tuple of integer arrays, one array for each dimension."
          },
          "dims": {
            "type": "tuple of ints",
            "description": "The shape of array into which the indices from ``multi_index`` apply."
          },
          "mode": {
            "type": "{'raise', 'wrap', 'clip'}, optional",
            "description": "Specifies how out-of-bounds indices are handled.  Can specify\n    either one mode or a tuple of modes, one mode per index.\n\n    * 'raise' -- raise an error (default)\n    * 'wrap' -- wrap around\n    * 'clip' -- clip to the range\n\n    In 'clip' mode, a negative index which would normally\n    wrap will clip to 0 instead."
          },
          "order": {
            "type": "{'C', 'F'}, optional",
            "description": "Determines whether the multi-index should be viewed as\n    indexing in row-major (C-style) or column-major\n    (Fortran-style) order."
          }
        },
        "returns": "raveled_indices : ndarray\n    An array of indices into the flattened version of an array\n    of dimensions ``dims``.",
        "raises": "",
        "see_also": "unravel_index",
        "notes": ".. versionadded:: 1.6.0",
        "examples": ">>> arr = np.array([[3,6,6],[4,5,1]])\n>>> np.ravel_multi_index(arr, (7,6))\narray([22, 41, 37])\n>>> np.ravel_multi_index(arr, (7,6), order='F')\narray([31, 41, 13])\n>>> np.ravel_multi_index(arr, (4,6), mode='clip')\narray([22, 23, 19])\n>>> np.ravel_multi_index(arr, (4,4), mode=('clip','wrap'))\narray([12, 13, 13])\n\n>>> np.ravel_multi_index((3,1,4,1), (6,7,8,9))\n1621"
      }
    },
    {
      "name": "real",
      "signature": "real(val)",
      "docstring": {
        "description": "Return the real part of the complex argument.",
        "parameters": {
          "val": {
            "type": "array_like",
            "description": "Input array."
          }
        },
        "returns": "out : ndarray or scalar\n    The real component of the complex argument. If `val` is real, the type\n    of `val` is used for the output.  If `val` has complex elements, the\n    returned type is float.",
        "raises": "",
        "see_also": "real_if_close, imag, angle",
        "notes": "",
        "examples": ">>> a = np.array([1+2j, 3+4j, 5+6j])\n>>> a.real\narray([1.,  3.,  5.])\n>>> a.real = 9\n>>> a\narray([9.+2.j,  9.+4.j,  9.+6.j])\n>>> a.real = np.array([9, 8, 7])\n>>> a\narray([9.+2.j,  8.+4.j,  7.+6.j])\n>>> np.real(1 + 1j)\n1.0"
      }
    },
    {
      "name": "real_if_close",
      "signature": "real_if_close(a, tol=100)",
      "docstring": {
        "description": "If input is complex with all imaginary parts close to zero, return\nreal parts.\n\n\"Close to zero\" is defined as `tol` * (machine epsilon of the type for\n`a`).",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array."
          },
          "tol": {
            "type": "float",
            "description": "Tolerance in machine epsilons for the complex part of the elements\n    in the array. If the tolerance is <=1, then the absolute tolerance\n    is used."
          }
        },
        "returns": "out : ndarray\n    If `a` is real, the type of `a` is used for the output.  If `a`\n    has complex elements, the returned type is float.",
        "raises": "",
        "see_also": "real, imag, angle",
        "notes": "Machine epsilon varies from machine to machine and between data types\nbut Python floats on most platforms have a machine epsilon equal to\n2.2204460492503131e-16.  You can use 'np.finfo(float).eps' to print\nout the machine epsilon for floats.",
        "examples": ">>> np.finfo(float).eps\n2.2204460492503131e-16 # may vary\n\n>>> np.real_if_close([2.1 + 4e-14j, 5.2 + 3e-15j], tol=1000)\narray([2.1, 5.2])\n>>> np.real_if_close([2.1 + 4e-13j, 5.2 + 3e-15j], tol=1000)\narray([2.1+4.e-13j, 5.2 + 3e-15j])"
      }
    },
    {
      "name": "recfromcsv",
      "signature": "recfromcsv(fname, **kwargs)",
      "docstring": {
        "description": "Load ASCII data stored in a comma-separated file.\n\nThe returned array is a record array (if ``usemask=False``, see\n`recarray`) or a masked record array (if ``usemask=True``,\nsee `ma.mrecords.MaskedRecords`).",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "numpy.genfromtxt : generic function to load ASCII data.",
        "notes": "By default, `dtype` is None, which means that the data-type of the output\narray will be determined from the data.",
        "examples": ""
      }
    },
    {
      "name": "recfromtxt",
      "signature": "recfromtxt(fname, **kwargs)",
      "docstring": {
        "description": "Load ASCII data from a file and return it in a record array.\n\nIf ``usemask=False`` a standard `recarray` is returned,\nif ``usemask=True`` a MaskedRecords array is returned.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "numpy.genfromtxt : generic function",
        "notes": "By default, `dtype` is None, which means that the data-type of the output\narray will be determined from the data.",
        "examples": ""
      }
    },
    {
      "name": "roots",
      "signature": "roots(p)",
      "docstring": {
        "description": "Return the roots of a polynomial with coefficients given in p.\n\n.. note::\n   This forms part of the old polynomial API. Since version 1.4, the\n   new polynomial API defined in `numpy.polynomial` is preferred.\n   A summary of the differences can be found in the\n   :doc:`transition guide </reference/routines.polynomials>`.\n\nThe values in the rank-1 array `p` are coefficients of a polynomial.\nIf the length of `p` is n+1 then the polynomial is described by::\n\n  p[0] * x**n + p[1] * x**(n-1) + ... + p[n-1]*x + p[n]",
        "parameters": {
          "p": {
            "type": "array_like",
            "description": "Rank-1 array of polynomial coefficients."
          }
        },
        "returns": "out : ndarray\n    An array containing the roots of the polynomial.",
        "raises": "ValueError\n    When `p` cannot be converted to a rank-1 array.\n\nSee also\n--------\npoly : Find the coefficients of a polynomial with a given sequence\n       of roots.\npolyval : Compute polynomial values.\npolyfit : Least squares polynomial fit.\npoly1d : A one-dimensional polynomial class.",
        "see_also": "",
        "notes": "The algorithm relies on computing the eigenvalues of the\ncompanion matrix [1]_.\n\nReferences\n----------\n.. [1] R. A. Horn & C. R. Johnson, *Matrix Analysis*.  Cambridge, UK:\n    Cambridge University Press, 1999, pp. 146-7.",
        "examples": ">>> coeff = [3.2, 2, 1]\n>>> np.roots(coeff)\narray([-0.3125+0.46351241j, -0.3125-0.46351241j])"
      }
    },
    {
      "name": "rot90",
      "signature": "rot90(m, k=1, axes=(0, 1))",
      "docstring": {
        "description": "Rotate an array by 90 degrees in the plane specified by axes.\n\nRotation direction is from the first towards the second axis.\nThis means for a 2D array with the default `k` and `axes`, the\nrotation will be counterclockwise.",
        "parameters": {
          "m": {
            "type": "array_like",
            "description": "Array of two or more dimensions."
          },
          "k": {
            "type": "integer",
            "description": "Number of times the array is rotated by 90 degrees."
          },
          "axes": {
            "type": "(2,) array_like",
            "description": "The array is rotated in the plane defined by the axes.\n    Axes must be different.\n\n    .. versionadded:: 1.12.0"
          }
        },
        "returns": "y : ndarray\n    A rotated view of `m`.",
        "raises": "",
        "see_also": "flip : Reverse the order of elements in an array along the given axis.\nfliplr : Flip an array horizontally.\nflipud : Flip an array vertically.",
        "notes": "``rot90(m, k=1, axes=(1,0))``  is the reverse of\n``rot90(m, k=1, axes=(0,1))``\n\n``rot90(m, k=1, axes=(1,0))`` is equivalent to\n``rot90(m, k=-1, axes=(0,1))``",
        "examples": ">>> m = np.array([[1,2],[3,4]], int)\n>>> m\narray([[1, 2],\n       [3, 4]])\n>>> np.rot90(m)\narray([[2, 4],\n       [1, 3]])\n>>> np.rot90(m, 2)\narray([[4, 3],\n       [2, 1]])\n>>> m = np.arange(8).reshape((2,2,2))\n>>> np.rot90(m, 1, (1,2))\narray([[[1, 3],\n        [0, 2]],\n       [[5, 7],\n        [4, 6]]])"
      }
    },
    {
      "name": "row_stack",
      "signature": "vstack(tup, *, dtype=None, casting='same_kind')",
      "docstring": {
        "description": "Stack arrays in sequence vertically (row wise).\n\nThis is equivalent to concatenation along the first axis after 1-D arrays\nof shape `(N,)` have been reshaped to `(1,N)`. Rebuilds arrays divided by\n`vsplit`.\n\nThis function makes most sense for arrays with up to 3 dimensions. For\ninstance, for pixel-data with a height (first axis), width (second axis),\nand r/g/b channels (third axis). The functions `concatenate`, `stack` and\n`block` provide more general stacking and concatenation operations.\n\n``np.row_stack`` is an alias for `vstack`. They are the same function.",
        "parameters": {
          "tup": {
            "type": "sequence of ndarrays",
            "description": "The arrays must have the same shape along all but the first axis.\n    1-D arrays must have the same length."
          },
          "dtype": {
            "type": "str or dtype",
            "description": "If provided, the destination array will have this dtype. Cannot be\n    provided together with `out`.\n\n.. versionadded:: 1.24"
          },
          "casting": {
            "type": "{'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional",
            "description": "Controls what kind of data casting may occur. Defaults to 'same_kind'.\n\n.. versionadded:: 1.24"
          }
        },
        "returns": "stacked : ndarray\n    The array formed by stacking the given arrays, will be at least 2-D.",
        "raises": "",
        "see_also": "concatenate : Join a sequence of arrays along an existing axis.\nstack : Join a sequence of arrays along a new axis.\nblock : Assemble an nd-array from nested lists of blocks.\nhstack : Stack arrays in sequence horizontally (column wise).\ndstack : Stack arrays in sequence depth wise (along third axis).\ncolumn_stack : Stack 1-D arrays as columns into a 2-D array.\nvsplit : Split an array into multiple sub-arrays vertically (row-wise).",
        "notes": "",
        "examples": ">>> a = np.array([1, 2, 3])\n>>> b = np.array([4, 5, 6])\n>>> np.vstack((a,b))\narray([[1, 2, 3],\n       [4, 5, 6]])\n\n>>> a = np.array([[1], [2], [3]])\n>>> b = np.array([[4], [5], [6]])\n>>> np.vstack((a,b))\narray([[1],\n       [2],\n       [3],\n       [4],\n       [5],\n       [6]])"
      }
    },
    {
      "name": "safe_eval",
      "signature": "safe_eval(source)",
      "docstring": {
        "description": "Protected string evaluation.\n\nEvaluate a string containing a Python literal expression without\nallowing the execution of arbitrary non-literal code.\n\n.. warning::\n\n    This function is identical to :py:meth:`ast.literal_eval` and\n    has the same security implications.  It may not always be safe\n    to evaluate large input strings.",
        "parameters": {
          "source": {
            "type": "str",
            "description": "The string to evaluate."
          }
        },
        "returns": "obj : object\n   The result of evaluating `source`.",
        "raises": "SyntaxError\n    If the code has invalid Python syntax, or if it contains\n    non-literal code.",
        "see_also": "",
        "notes": "",
        "examples": ">>> np.safe_eval('1')\n1\n>>> np.safe_eval('[1, 2, 3]')\n[1, 2, 3]\n>>> np.safe_eval('{\"foo\": (\"bar\", 10.0)}')\n{'foo': ('bar', 10.0)}\n\n>>> np.safe_eval('import os')\nTraceback (most recent call last):\n  ...\nSyntaxError: invalid syntax\n\n>>> np.safe_eval('open(\"/home/user/.ssh/id_dsa\").read()')\nTraceback (most recent call last):\n  ...\nValueError: malformed node or string: <_ast.Call object at 0x...>"
      }
    },
    {
      "name": "save",
      "signature": "save(file, arr, allow_pickle=True, fix_imports=True)",
      "docstring": {
        "description": "Save an array to a binary file in NumPy ``.npy`` format.",
        "parameters": {
          "file": {
            "type": "file, str, or pathlib.Path",
            "description": "File or filename to which the data is saved.  If file is a file-object,\n    then the filename is unchanged.  If file is a string or Path, a ``.npy``\n    extension will be appended to the filename if it does not already\n    have one."
          },
          "arr": {
            "type": "array_like",
            "description": "Array data to be saved."
          },
          "allow_pickle": {
            "type": "bool, optional",
            "description": "Allow saving object arrays using Python pickles. Reasons for disallowing\n    pickles include security (loading pickled data can execute arbitrary\n    code) and portability (pickled objects may not be loadable on different\n    Python installations, for example if the stored objects require libraries\n    that are not available, and not all pickled data is compatible between\n    Python 2 and Python 3).\n    Default: True"
          },
          "fix_imports": {
            "type": "bool, optional",
            "description": "Only useful in forcing objects in object arrays on Python 3 to be\n    pickled in a Python 2 compatible way. If `fix_imports` is True, pickle\n    will try to map the new Python 3 names to the old module names used in\n    Python 2, so that the pickle data stream is readable with Python 2."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "savez : Save several arrays into a ``.npz`` archive\nsavetxt, load",
        "notes": "For a description of the ``.npy`` format, see :py:mod:`numpy.lib.format`.\n\nAny data saved to the file is appended to the end of the file.",
        "examples": ">>> from tempfile import TemporaryFile\n>>> outfile = TemporaryFile()\n\n>>> x = np.arange(10)\n>>> np.save(outfile, x)\n\n>>> _ = outfile.seek(0) # Only needed here to simulate closing & reopening file\n>>> np.load(outfile)\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\n>>> with open('test.npy', 'wb') as f:\n...     np.save(f, np.array([1, 2]))\n...     np.save(f, np.array([1, 3]))\n>>> with open('test.npy', 'rb') as f:\n...     a = np.load(f)\n...     b = np.load(f)\n>>> print(a, b)\n# [1 2] [1 3]"
      }
    },
    {
      "name": "savetxt",
      "signature": "savetxt(fname, X, fmt='%.18e', delimiter=' ', newline='\\n', header='', footer='', comments='# ', encoding=None)",
      "docstring": {
        "description": "Save an array to a text file.",
        "parameters": {
          "fname": {
            "type": "filename or file handle",
            "description": "If the filename ends in ``.gz``, the file is automatically saved in\n    compressed gzip format.  `loadtxt` understands gzipped files\n    transparently."
          },
          "X": {
            "type": "1D or 2D array_like",
            "description": "Data to be saved to a text file."
          },
          "fmt": {
            "type": "str or sequence of strs, optional",
            "description": "A single format (%10.5f), a sequence of formats, or a\n    multi-format string, e.g. 'Iteration %d -- %10.5f', in which\n    case `delimiter` is ignored. For complex `X`, the legal options\n    for `fmt` are:\n\n    * a single specifier, `fmt='%.4e'`, resulting in numbers formatted\n      like `' (%s+%sj)' % (fmt, fmt)`\n    * a full string specifying every real and imaginary part, e.g.\n      `' %.4e %+.4ej %.4e %+.4ej %.4e %+.4ej'` for 3 columns\n    * a list of specifiers, one per column - in this case, the real\n      and imaginary part must have separate specifiers,\n      e.g. `['%.3e + %.3ej', '(%.15e%+.15ej)']` for 2 columns"
          },
          "delimiter": {
            "type": "str, optional",
            "description": "String or character separating columns."
          },
          "newline": {
            "type": "str, optional",
            "description": "String or character separating lines.\n\n    .. versionadded:: 1.5.0"
          },
          "header": {
            "type": "str, optional",
            "description": "String that will be written at the beginning of the file.\n\n    .. versionadded:: 1.7.0"
          },
          "footer": {
            "type": "str, optional",
            "description": "String that will be written at the end of the file.\n\n    .. versionadded:: 1.7.0"
          },
          "comments": {
            "type": "str, optional",
            "description": "String that will be prepended to the ``header`` and ``footer`` strings,\n    to mark them as comments. Default: '# ',  as expected by e.g.\n    ``numpy.loadtxt``.\n\n    .. versionadded:: 1.7.0"
          },
          "encoding": {
            "type": "{None, str}, optional",
            "description": "Encoding used to encode the outputfile. Does not apply to output\n    streams. If the encoding is something other than 'bytes' or 'latin1'\n    you will not be able to load the file in NumPy versions < 1.14. Default\n    is 'latin1'.\n\n    .. versionadded:: 1.14.0"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "save : Save an array to a binary file in NumPy ``.npy`` format\nsavez : Save several arrays into an uncompressed ``.npz`` archive\nsavez_compressed : Save several arrays into a compressed ``.npz`` archive",
        "notes": "Further explanation of the `fmt` parameter\n(``%[flag]width[.precision]specifier``):\n\nflags:\n    ``-`` : left justify\n\n    ``+`` : Forces to precede result with + or -.\n\n    ``0`` : Left pad the number with zeros instead of space (see width).\n\nwidth:\n    Minimum number of characters to be printed. The value is not truncated\n    if it has more characters.\n\nprecision:\n    - For integer specifiers (eg. ``d,i,o,x``), the minimum number of\n      digits.\n    - For ``e, E`` and ``f`` specifiers, the number of digits to print\n      after the decimal point.\n    - For ``g`` and ``G``, the maximum number of significant digits.\n    - For ``s``, the maximum number of characters.\n\nspecifiers:\n    ``c`` : character\n\n    ``d`` or ``i`` : signed decimal integer\n\n    ``e`` or ``E`` : scientific notation with ``e`` or ``E``.\n\n    ``f`` : decimal floating point\n\n    ``g,G`` : use the shorter of ``e,E`` or ``f``\n\n    ``o`` : signed octal\n\n    ``s`` : string of characters\n\n    ``u`` : unsigned decimal integer\n\n    ``x,X`` : unsigned hexadecimal integer\n\nThis explanation of ``fmt`` is not complete, for an exhaustive\nspecification see [1]_.\n\nReferences\n----------\n.. [1] `Format Specification Mini-Language\n       <https://docs.python.org/library/string.html#format-specification-mini-language>`_,\n       Python Documentation.",
        "examples": ">>> x = y = z = np.arange(0.0,5.0,1.0)\n>>> np.savetxt('test.out', x, delimiter=',')   # X is an array\n>>> np.savetxt('test.out', (x,y,z))   # x,y,z equal sized 1D arrays\n>>> np.savetxt('test.out', x, fmt='%1.4e')   # use exponential notation"
      }
    },
    {
      "name": "savez",
      "signature": "savez(file, *args, **kwds)",
      "docstring": {
        "description": "Save several arrays into a single file in uncompressed ``.npz`` format.\n\nProvide arrays as keyword arguments to store them under the\ncorresponding name in the output file: ``savez(fn, x=x, y=y)``.\n\nIf arrays are specified as positional arguments, i.e., ``savez(fn,\nx, y)``, their names will be `arr_0`, `arr_1`, etc.",
        "parameters": {
          "file": {
            "type": "str or file",
            "description": "Either the filename (string) or an open file (file-like object)\n    where the data will be saved. If file is a string or a Path, the\n    ``.npz`` extension will be appended to the filename if it is not\n    already there."
          },
          "args": {
            "type": "Arguments, optional",
            "description": "Arrays to save to the file. Please use keyword arguments (see\n    `kwds` below) to assign names to arrays.  Arrays specified as\n    args will be named \"arr_0\", \"arr_1\", and so on."
          },
          "kwds": {
            "type": "Keyword arguments, optional",
            "description": "Arrays to save to the file. Each array will be saved to the\n    output file with its corresponding keyword name."
          }
        },
        "returns": "None",
        "raises": "",
        "see_also": "save : Save a single array to a binary file in NumPy format.\nsavetxt : Save an array to a file as plain text.\nsavez_compressed : Save several arrays into a compressed ``.npz`` archive",
        "notes": "The ``.npz`` file format is a zipped archive of files named after the\nvariables they contain.  The archive is not compressed and each file\nin the archive contains one variable in ``.npy`` format. For a\ndescription of the ``.npy`` format, see :py:mod:`numpy.lib.format`.\n\nWhen opening the saved ``.npz`` file with `load` a `NpzFile` object is\nreturned. This is a dictionary-like object which can be queried for\nits list of arrays (with the ``.files`` attribute), and for the arrays\nthemselves.\n\nKeys passed in `kwds` are used as filenames inside the ZIP archive.\nTherefore, keys should be valid filenames; e.g., avoid keys that begin with\n``/`` or contain ``.``.\n\nWhen naming variables with keyword arguments, it is not possible to name a\nvariable ``file``, as this would cause the ``file`` argument to be defined\ntwice in the call to ``savez``.",
        "examples": ">>> from tempfile import TemporaryFile\n>>> outfile = TemporaryFile()\n>>> x = np.arange(10)\n>>> y = np.sin(x)\n\nUsing `savez` with \\*args, the arrays are saved with default names.\n\n>>> np.savez(outfile, x, y)\n>>> _ = outfile.seek(0) # Only needed here to simulate closing & reopening file\n>>> npzfile = np.load(outfile)\n>>> npzfile.files\n['arr_0', 'arr_1']\n>>> npzfile['arr_0']\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\nUsing `savez` with \\**kwds, the arrays are saved with the keyword names.\n\n>>> outfile = TemporaryFile()\n>>> np.savez(outfile, x=x, y=y)\n>>> _ = outfile.seek(0)\n>>> npzfile = np.load(outfile)\n>>> sorted(npzfile.files)\n['x', 'y']\n>>> npzfile['x']\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      }
    },
    {
      "name": "savez_compressed",
      "signature": "savez_compressed(file, *args, **kwds)",
      "docstring": {
        "description": "Save several arrays into a single file in compressed ``.npz`` format.\n\nProvide arrays as keyword arguments to store them under the\ncorresponding name in the output file: ``savez(fn, x=x, y=y)``.\n\nIf arrays are specified as positional arguments, i.e., ``savez(fn,\nx, y)``, their names will be `arr_0`, `arr_1`, etc.",
        "parameters": {
          "file": {
            "type": "str or file",
            "description": "Either the filename (string) or an open file (file-like object)\n    where the data will be saved. If file is a string or a Path, the\n    ``.npz`` extension will be appended to the filename if it is not\n    already there."
          },
          "args": {
            "type": "Arguments, optional",
            "description": "Arrays to save to the file. Please use keyword arguments (see\n    `kwds` below) to assign names to arrays.  Arrays specified as\n    args will be named \"arr_0\", \"arr_1\", and so on."
          },
          "kwds": {
            "type": "Keyword arguments, optional",
            "description": "Arrays to save to the file. Each array will be saved to the\n    output file with its corresponding keyword name."
          }
        },
        "returns": "None",
        "raises": "",
        "see_also": "numpy.save : Save a single array to a binary file in NumPy format.\nnumpy.savetxt : Save an array to a file as plain text.\nnumpy.savez : Save several arrays into an uncompressed ``.npz`` file format\nnumpy.load : Load the files created by savez_compressed.",
        "notes": "The ``.npz`` file format is a zipped archive of files named after the\nvariables they contain.  The archive is compressed with\n``zipfile.ZIP_DEFLATED`` and each file in the archive contains one variable\nin ``.npy`` format. For a description of the ``.npy`` format, see\n:py:mod:`numpy.lib.format`.\n\n\nWhen opening the saved ``.npz`` file with `load` a `NpzFile` object is\nreturned. This is a dictionary-like object which can be queried for\nits list of arrays (with the ``.files`` attribute), and for the arrays\nthemselves.",
        "examples": ">>> test_array = np.random.rand(3, 2)\n>>> test_vector = np.random.rand(4)\n>>> np.savez_compressed('/tmp/123', a=test_array, b=test_vector)\n>>> loaded = np.load('/tmp/123.npz')\n>>> print(np.array_equal(test_array, loaded['a']))\nTrue\n>>> print(np.array_equal(test_vector, loaded['b']))\nTrue"
      }
    },
    {
      "name": "select",
      "signature": "select(condlist, choicelist, default=0)",
      "docstring": {
        "description": "Return an array drawn from elements in choicelist, depending on conditions.",
        "parameters": {
          "condlist": {
            "type": "list of bool ndarrays",
            "description": "The list of conditions which determine from which array in `choicelist`\n    the output elements are taken. When multiple conditions are satisfied,\n    the first one encountered in `condlist` is used."
          },
          "choicelist": {
            "type": "list of ndarrays",
            "description": "The list of arrays from which the output elements are taken. It has\n    to be of the same length as `condlist`."
          },
          "default": {
            "type": "scalar, optional",
            "description": "The element inserted in `output` when all conditions evaluate to False."
          }
        },
        "returns": "output : ndarray\n    The output at position m is the m-th element of the array in\n    `choicelist` where the m-th element of the corresponding array in\n    `condlist` is True.",
        "raises": "",
        "see_also": "where : Return elements from one of two arrays depending on condition.\ntake, choose, compress, diag, diagonal",
        "notes": "",
        "examples": ">>> x = np.arange(6)\n>>> condlist = [x<3, x>3]\n>>> choicelist = [x, x**2]\n>>> np.select(condlist, choicelist, 42)\narray([ 0,  1,  2, 42, 16, 25])\n\n>>> condlist = [x<=4, x>3]\n>>> choicelist = [x, x**2]\n>>> np.select(condlist, choicelist, 55)\narray([ 0,  1,  2,  3,  4, 25])"
      }
    },
    {
      "name": "setdiff1d",
      "signature": "setdiff1d(ar1, ar2, assume_unique=False)",
      "docstring": {
        "description": "Find the set difference of two arrays.\n\nReturn the unique values in `ar1` that are not in `ar2`.",
        "parameters": {
          "ar1": {
            "type": "array_like",
            "description": "Input array."
          },
          "ar2": {
            "type": "array_like",
            "description": "Input comparison array."
          },
          "assume_unique": {
            "type": "bool",
            "description": "If True, the input arrays are both assumed to be unique, which\n    can speed up the calculation.  Default is False."
          }
        },
        "returns": "setdiff1d : ndarray\n    1D array of values in `ar1` that are not in `ar2`. The result\n    is sorted when `assume_unique=False`, but otherwise only sorted\n    if the input is sorted.",
        "raises": "",
        "see_also": "numpy.lib.arraysetops : Module with a number of other functions for\n                        performing set operations on arrays.",
        "notes": "",
        "examples": ">>> a = np.array([1, 2, 3, 2, 4, 1])\n>>> b = np.array([3, 4, 5, 6])\n>>> np.setdiff1d(a, b)\narray([1, 2])"
      }
    },
    {
      "name": "setxor1d",
      "signature": "setxor1d(ar1, ar2, assume_unique=False)",
      "docstring": {
        "description": "Find the set exclusive-or of two arrays.\n\nReturn the sorted, unique values that are in only one (not both) of the\ninput arrays.",
        "parameters": {
          "assume_unique": {
            "type": "bool",
            "description": "If True, the input arrays are both assumed to be unique, which\n    can speed up the calculation.  Default is False."
          }
        },
        "returns": "setxor1d : ndarray\n    Sorted 1D array of unique values that are in only one of the input\n    arrays.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ">>> a = np.array([1, 2, 3, 2, 4])\n>>> b = np.array([2, 3, 5, 7, 5])\n>>> np.setxor1d(a,b)\narray([1, 4, 5, 7])"
      }
    },
    {
      "name": "show_runtime",
      "signature": "show_runtime()",
      "docstring": {
        "description": "Print information about various resources in the system\nincluding available intrinsic support and BLAS/LAPACK library\nin use\n\n.. versionadded:: 1.24.0",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "show_config : Show libraries in the system on which NumPy was built.",
        "notes": "1. Information is derived with the help of `threadpoolctl <https://pypi.org/project/threadpoolctl/>`_\n   library if available.\n2. SIMD related information is derived from ``__cpu_features__``,\n   ``__cpu_baseline__`` and ``__cpu_dispatch__``",
        "examples": ""
      }
    },
    {
      "name": "sinc",
      "signature": "sinc(x)",
      "docstring": {
        "description": "Return the normalized sinc function.\n\nThe sinc function is equal to :math:`\\sin(\\pi x)/(\\pi x)` for any argument\n:math:`x\\ne 0`. ``sinc(0)`` takes the limit value 1, making ``sinc`` not\nonly everywhere continuous but also infinitely differentiable.\n\n.. note::\n\n    Note the normalization factor of ``pi`` used in the definition.\n    This is the most commonly used definition in signal processing.\n    Use ``sinc(x / np.pi)`` to obtain the unnormalized sinc function\n    :math:`\\sin(x)/x` that is more common in mathematics.",
        "parameters": {
          "x": {
            "type": "ndarray",
            "description": "Array (possibly multi-dimensional) of values for which to calculate\n    ``sinc(x)``."
          }
        },
        "returns": "out : ndarray\n    ``sinc(x)``, which has the same shape as the input.",
        "raises": "",
        "see_also": "",
        "notes": "The name sinc is short for \"sine cardinal\" or \"sinus cardinalis\".\n\nThe sinc function is used in various signal processing applications,\nincluding in anti-aliasing, in the construction of a Lanczos resampling\nfilter, and in interpolation.\n\nFor bandlimited interpolation of discrete-time signals, the ideal\ninterpolation kernel is proportional to the sinc function.\n\nReferences\n----------\n.. [1] Weisstein, Eric W. \"Sinc Function.\" From MathWorld--A Wolfram Web\n       Resource. http://mathworld.wolfram.com/SincFunction.html\n.. [2] Wikipedia, \"Sinc function\",\n       https://en.wikipedia.org/wiki/Sinc_function",
        "examples": ">>> import matplotlib.pyplot as plt\n>>> x = np.linspace(-4, 4, 41)\n>>> np.sinc(x)\n array([-3.89804309e-17,  -4.92362781e-02,  -8.40918587e-02, # may vary\n        -8.90384387e-02,  -5.84680802e-02,   3.89804309e-17,\n        6.68206631e-02,   1.16434881e-01,   1.26137788e-01,\n        8.50444803e-02,  -3.89804309e-17,  -1.03943254e-01,\n        -1.89206682e-01,  -2.16236208e-01,  -1.55914881e-01,\n        3.89804309e-17,   2.33872321e-01,   5.04551152e-01,\n        7.56826729e-01,   9.35489284e-01,   1.00000000e+00,\n        9.35489284e-01,   7.56826729e-01,   5.04551152e-01,\n        2.33872321e-01,   3.89804309e-17,  -1.55914881e-01,\n       -2.16236208e-01,  -1.89206682e-01,  -1.03943254e-01,\n       -3.89804309e-17,   8.50444803e-02,   1.26137788e-01,\n        1.16434881e-01,   6.68206631e-02,   3.89804309e-17,\n        -5.84680802e-02,  -8.90384387e-02,  -8.40918587e-02,\n        -4.92362781e-02,  -3.89804309e-17])\n\n>>> plt.plot(x, np.sinc(x))\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Sinc Function\")\nText(0.5, 1.0, 'Sinc Function')\n>>> plt.ylabel(\"Amplitude\")\nText(0, 0.5, 'Amplitude')\n>>> plt.xlabel(\"X\")\nText(0.5, 0, 'X')\n>>> plt.show()"
      }
    },
    {
      "name": "sort_complex",
      "signature": "sort_complex(a)",
      "docstring": {
        "description": "Sort a complex array using the real part first, then the imaginary part.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array"
          }
        },
        "returns": "out : complex ndarray\n    Always returns a sorted complex array.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ">>> np.sort_complex([5, 3, 6, 2, 1])\narray([1.+0.j, 2.+0.j, 3.+0.j, 5.+0.j, 6.+0.j])\n\n>>> np.sort_complex([1 + 2j, 2 - 1j, 3 - 2j, 3 - 3j, 3 + 5j])\narray([1.+2.j,  2.-1.j,  3.-3.j,  3.-2.j,  3.+5.j])"
      }
    },
    {
      "name": "source",
      "signature": "source(object, output=<_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'>)",
      "docstring": {
        "description": "Print or write to a file the source code for a NumPy object.\n\nThe source code is only returned for objects written in Python. Many\nfunctions and classes are defined in C and will therefore not return\nuseful information.",
        "parameters": {
          "object": {
            "type": "numpy object",
            "description": "Input object. This can be any object (function, class, module,\n    ...)."
          },
          "output": {
            "type": "file object, optional",
            "description": "If `output` not supplied then source code is printed to screen\n    (sys.stdout).  File object must be created with either write 'w' or\n    append 'a' modes."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "lookfor, info",
        "notes": "",
        "examples": ">>> np.source(np.interp)                        #doctest: +SKIP\nIn file: /usr/lib/python2.6/dist-packages/numpy/lib/function_base.py\ndef interp(x, xp, fp, left=None, right=None):\n    \"\"\".... (full docstring printed)\"\"\"\n    if isinstance(x, (float, int, number)):\n        return compiled_interp([x], xp, fp, left, right).item()\n    else:\n        return compiled_interp(x, xp, fp, left, right)\n\nThe source code is only returned for objects written in Python.\n\n>>> np.source(np.array)                         #doctest: +SKIP\nNot available for this object."
      }
    },
    {
      "name": "split",
      "signature": "split(ary, indices_or_sections, axis=0)",
      "docstring": {
        "description": "Split an array into multiple sub-arrays as views into `ary`.",
        "parameters": {
          "ary": {
            "type": "ndarray",
            "description": "Array to be divided into sub-arrays."
          },
          "indices_or_sections": {
            "type": "int or 1-D array",
            "description": "If `indices_or_sections` is an integer, N, the array will be divided\n    into N equal arrays along `axis`.  If such a split is not possible,\n    an error is raised.\n\n    If `indices_or_sections` is a 1-D array of sorted integers, the entries\n    indicate where along `axis` the array is split.  For example,\n    ``[2, 3]`` would, for ``axis=0``, result in\n\n      - ary[:2]\n      - ary[2:3]\n      - ary[3:]\n\n    If an index exceeds the dimension of the array along `axis`,\n    an empty sub-array is returned correspondingly."
          },
          "axis": {
            "type": "int, optional",
            "description": "The axis along which to split, default is 0."
          }
        },
        "returns": "sub-arrays : list of ndarrays\n    A list of sub-arrays as views into `ary`.",
        "raises": "ValueError\n    If `indices_or_sections` is given as an integer, but\n    a split does not result in equal division.",
        "see_also": "array_split : Split an array into multiple sub-arrays of equal or\n              near-equal size.  Does not raise an exception if\n              an equal division cannot be made.\nhsplit : Split array into multiple sub-arrays horizontally (column-wise).\nvsplit : Split array into multiple sub-arrays vertically (row wise).\ndsplit : Split array into multiple sub-arrays along the 3rd axis (depth).\nconcatenate : Join a sequence of arrays along an existing axis.\nstack : Join a sequence of arrays along a new axis.\nhstack : Stack arrays in sequence horizontally (column wise).\nvstack : Stack arrays in sequence vertically (row wise).\ndstack : Stack arrays in sequence depth wise (along third dimension).",
        "notes": "",
        "examples": ">>> x = np.arange(9.0)\n>>> np.split(x, 3)\n[array([0.,  1.,  2.]), array([3.,  4.,  5.]), array([6.,  7.,  8.])]\n\n>>> x = np.arange(8.0)\n>>> np.split(x, [3, 5, 6, 10])\n[array([0.,  1.,  2.]),\n array([3.,  4.]),\n array([5.]),\n array([6.,  7.]),\n array([], dtype=float64)]"
      }
    },
    {
      "name": "take_along_axis",
      "signature": "take_along_axis(arr, indices, axis)",
      "docstring": {
        "description": "Take values from the input array by matching 1d index and data slices.\n\nThis iterates over matching 1d slices oriented along the specified axis in\nthe index and data arrays, and uses the former to look up values in the\nlatter. These slices can be different lengths.\n\nFunctions returning an index along an axis, like `argsort` and\n`argpartition`, produce suitable indices for this function.\n\n.. versionadded:: 1.15.0",
        "parameters": {
          "arr": {
            "type": "ndarray (Ni..., M, Nk...)",
            "description": "Source array"
          },
          "indices": {
            "type": "ndarray (Ni..., J, Nk...)",
            "description": "Indices to take along each 1d slice of `arr`. This must match the\n    dimension of arr, but dimensions Ni and Nj only need to broadcast\n    against `arr`."
          },
          "axis": {
            "type": "int",
            "description": "The axis to take 1d slices along. If axis is None, the input array is\n    treated as if it had first been flattened to 1d, for consistency with\n    `sort` and `argsort`."
          }
        },
        "returns": "out: ndarray (Ni..., J, Nk...)\n    The indexed result.",
        "raises": "",
        "see_also": "take : Take along an axis, using the same indices for every 1d slice\nput_along_axis :\n    Put values into the destination array by matching 1d index and data slices",
        "notes": "This is equivalent to (but faster than) the following use of `ndindex` and\n`s_`, which sets each of ``ii`` and ``kk`` to a tuple of indices::\n\n    Ni, M, Nk = a.shape[:axis], a.shape[axis], a.shape[axis+1:]\n    J = indices.shape[axis]  # Need not equal M\n    out = np.empty(Ni + (J,) + Nk)\n\n    for ii in ndindex(Ni):\n        for kk in ndindex(Nk):\n            a_1d       = a      [ii + s_[:,] + kk]\n            indices_1d = indices[ii + s_[:,] + kk]\n            out_1d     = out    [ii + s_[:,] + kk]\n            for j in range(J):\n                out_1d[j] = a_1d[indices_1d[j]]\n\nEquivalently, eliminating the inner loop, the last two lines would be::\n\n            out_1d[:] = a_1d[indices_1d]",
        "examples": "For this sample array\n\n>>> a = np.array([[10, 30, 20], [60, 40, 50]])\n\nWe can sort either by using sort directly, or argsort and this function\n\n>>> np.sort(a, axis=1)\narray([[10, 20, 30],\n       [40, 50, 60]])\n>>> ai = np.argsort(a, axis=1)\n>>> ai\narray([[0, 2, 1],\n       [1, 2, 0]])\n>>> np.take_along_axis(a, ai, axis=1)\narray([[10, 20, 30],\n       [40, 50, 60]])\n\nThe same works for max and min, if you maintain the trivial dimension\nwith ``keepdims``:\n\n>>> np.max(a, axis=1, keepdims=True)\narray([[30],\n       [60]])\n>>> ai = np.argmax(a, axis=1, keepdims=True)\n>>> ai\narray([[1],\n       [0]])\n>>> np.take_along_axis(a, ai, axis=1)\narray([[30],\n       [60]])\n\nIf we want to get the max and min at the same time, we can stack the\nindices first\n\n>>> ai_min = np.argmin(a, axis=1, keepdims=True)\n>>> ai_max = np.argmax(a, axis=1, keepdims=True)\n>>> ai = np.concatenate([ai_min, ai_max], axis=1)\n>>> ai\narray([[0, 1],\n       [1, 0]])\n>>> np.take_along_axis(a, ai, axis=1)\narray([[10, 30],\n       [40, 60]])"
      }
    },
    {
      "name": "test",
      "signature": "test(...)",
      "docstring": {}
    },
    {
      "name": "tile",
      "signature": "tile(A, reps)",
      "docstring": {
        "description": "Construct an array by repeating A the number of times given by reps.\n\nIf `reps` has length ``d``, the result will have dimension of\n``max(d, A.ndim)``.\n\nIf ``A.ndim < d``, `A` is promoted to be d-dimensional by prepending new\naxes. So a shape (3,) array is promoted to (1, 3) for 2-D replication,\nor shape (1, 1, 3) for 3-D replication. If this is not the desired\nbehavior, promote `A` to d-dimensions manually before calling this\nfunction.\n\nIf ``A.ndim > d``, `reps` is promoted to `A`.ndim by pre-pending 1's to it.\nThus for an `A` of shape (2, 3, 4, 5), a `reps` of (2, 2) is treated as\n(1, 1, 2, 2).\n\nNote : Although tile may be used for broadcasting, it is strongly\nrecommended to use numpy's broadcasting operations and functions.",
        "parameters": {
          "A": {
            "type": "array_like",
            "description": "The input array."
          },
          "reps": {
            "type": "array_like",
            "description": "The number of repetitions of `A` along each axis."
          }
        },
        "returns": "c : ndarray\n    The tiled output array.",
        "raises": "",
        "see_also": "repeat : Repeat elements of an array.\nbroadcast_to : Broadcast an array to a new shape",
        "notes": "",
        "examples": ">>> a = np.array([0, 1, 2])\n>>> np.tile(a, 2)\narray([0, 1, 2, 0, 1, 2])\n>>> np.tile(a, (2, 2))\narray([[0, 1, 2, 0, 1, 2],\n       [0, 1, 2, 0, 1, 2]])\n>>> np.tile(a, (2, 1, 2))\narray([[[0, 1, 2, 0, 1, 2]],\n       [[0, 1, 2, 0, 1, 2]]])\n\n>>> b = np.array([[1, 2], [3, 4]])\n>>> np.tile(b, 2)\narray([[1, 2, 1, 2],\n       [3, 4, 3, 4]])\n>>> np.tile(b, (2, 1))\narray([[1, 2],\n       [3, 4],\n       [1, 2],\n       [3, 4]])\n\n>>> c = np.array([1,2,3,4])\n>>> np.tile(c,(4,1))\narray([[1, 2, 3, 4],\n       [1, 2, 3, 4],\n       [1, 2, 3, 4],\n       [1, 2, 3, 4]])"
      }
    },
    {
      "name": "trapz",
      "signature": "trapz(y, x=None, dx=1.0, axis=-1)",
      "docstring": {
        "description": "Integrate along the given axis using the composite trapezoidal rule.\n\nIf `x` is provided, the integration happens in sequence along its\nelements - they are not sorted.\n\nIntegrate `y` (`x`) along each 1d slice on the given axis, compute\n:math:`\\int y(x) dx`.\nWhen `x` is specified, this integrates along the parametric curve,\ncomputing :math:`\\int_t y(t) dt =\n\\int_t y(t) \\left.\\frac{dx}{dt}\\right|_{x=x(t)} dt`.",
        "parameters": {
          "y": {
            "type": "array_like",
            "description": "Input array to integrate."
          },
          "x": {
            "type": "array_like, optional",
            "description": "The sample points corresponding to the `y` values. If `x` is None,\n    the sample points are assumed to be evenly spaced `dx` apart. The\n    default is None."
          },
          "dx": {
            "type": "scalar, optional",
            "description": "The spacing between sample points when `x` is None. The default is 1."
          },
          "axis": {
            "type": "int, optional",
            "description": "The axis along which to integrate."
          }
        },
        "returns": "trapz : float or ndarray\n    Definite integral of `y` = n-dimensional array as approximated along\n    a single axis by the trapezoidal rule. If `y` is a 1-dimensional array,\n    then the result is a float. If `n` is greater than 1, then the result\n    is an `n`-1 dimensional array.",
        "raises": "",
        "see_also": "sum, cumsum",
        "notes": "Image [2]_ illustrates trapezoidal rule -- y-axis locations of points\nwill be taken from `y` array, by default x-axis distances between\npoints will be 1.0, alternatively they can be provided with `x` array\nor with `dx` scalar.  Return value will be equal to combined area under\nthe red lines.\n\n\nReferences\n----------\n.. [1] Wikipedia page: https://en.wikipedia.org/wiki/Trapezoidal_rule\n\n.. [2] Illustration image:\n       https://en.wikipedia.org/wiki/File:Composite_trapezoidal_rule_illustration.png",
        "examples": "Use the trapezoidal rule on evenly spaced points:\n\n>>> np.trapz([1, 2, 3])\n4.0\n\nThe spacing between sample points can be selected by either the\n``x`` or ``dx`` arguments:\n\n>>> np.trapz([1, 2, 3], x=[4, 6, 8])\n8.0\n>>> np.trapz([1, 2, 3], dx=2)\n8.0\n\nUsing a decreasing ``x`` corresponds to integrating in reverse:\n\n>>> np.trapz([1, 2, 3], x=[8, 6, 4])\n-8.0\n\nMore generally ``x`` is used to integrate along a parametric curve. We can\nestimate the integral :math:`\\int_0^1 x^2 = 1/3` using:\n\n>>> x = np.linspace(0, 1, num=50)\n>>> y = x**2\n>>> np.trapz(y, x)\n0.33340274885464394\n\nOr estimate the area of a circle, noting we repeat the sample which closes\nthe curve:\n\n>>> theta = np.linspace(0, 2 * np.pi, num=1000, endpoint=True)\n>>> np.trapz(np.cos(theta), x=np.sin(theta))\n3.141571941375841\n\n``np.trapz`` can be applied along a specified axis to do multiple\ncomputations in one call:\n\n>>> a = np.arange(6).reshape(2, 3)\n>>> a\narray([[0, 1, 2],\n       [3, 4, 5]])\n>>> np.trapz(a, axis=0)\narray([1.5, 2.5, 3.5])\n>>> np.trapz(a, axis=1)\narray([2.,  8.])"
      }
    },
    {
      "name": "tri",
      "signature": "tri(N, M=None, k=0, dtype=<class 'float'>, *, like=None)",
      "docstring": {
        "description": "An array with ones at and below the given diagonal and zeros elsewhere.",
        "parameters": {
          "N": {
            "type": "int",
            "description": "Number of rows in the array."
          },
          "M": {
            "type": "int, optional",
            "description": "Number of columns in the array.\n    By default, `M` is taken equal to `N`."
          },
          "k": {
            "type": "int, optional",
            "description": "The sub-diagonal at and below which the array is filled.\n    `k` = 0 is the main diagonal, while `k` < 0 is below it,\n    and `k` > 0 is above.  The default is 0."
          },
          "dtype": {
            "type": "dtype, optional",
            "description": "Data type of the returned array.  The default is float."
          },
          "like": {
            "type": "array_like, optional",
            "description": "Reference object to allow the creation of arrays which are not\n    NumPy arrays. If an array-like passed in as ``like`` supports\n    the ``__array_function__`` protocol, the result will be defined\n    by it. In this case, it ensures the creation of an array object\n    compatible with that passed in via this argument.\n\n    .. versionadded:: 1.20.0"
          }
        },
        "returns": "tri : ndarray of shape (N, M)\n    Array with its lower triangle filled with ones and zero elsewhere;\n    in other words ``T[i,j] == 1`` for ``j <= i + k``, 0 otherwise.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ">>> np.tri(3, 5, 2, dtype=int)\narray([[1, 1, 1, 0, 0],\n       [1, 1, 1, 1, 0],\n       [1, 1, 1, 1, 1]])\n\n>>> np.tri(3, 5, -1)\narray([[0.,  0.,  0.,  0.,  0.],\n       [1.,  0.,  0.,  0.,  0.],\n       [1.,  1.,  0.,  0.,  0.]])"
      }
    },
    {
      "name": "tril",
      "signature": "tril(m, k=0)",
      "docstring": {
        "description": "Lower triangle of an array.\n\nReturn a copy of an array with elements above the `k`-th diagonal zeroed.\nFor arrays with ``ndim`` exceeding 2, `tril` will apply to the final two\naxes.",
        "parameters": {
          "m": {
            "type": "array_like, shape (..., M, N)",
            "description": "Input array."
          },
          "k": {
            "type": "int, optional",
            "description": "Diagonal above which to zero elements.  `k = 0` (the default) is the\n    main diagonal, `k < 0` is below it and `k > 0` is above."
          }
        },
        "returns": "tril : ndarray, shape (..., M, N)\n    Lower triangle of `m`, of same shape and data-type as `m`.",
        "raises": "",
        "see_also": "triu : same thing, only for the upper triangle",
        "notes": "",
        "examples": ">>> np.tril([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], -1)\narray([[ 0,  0,  0],\n       [ 4,  0,  0],\n       [ 7,  8,  0],\n       [10, 11, 12]])\n\n>>> np.tril(np.arange(3*4*5).reshape(3, 4, 5))\narray([[[ 0,  0,  0,  0,  0],\n        [ 5,  6,  0,  0,  0],\n        [10, 11, 12,  0,  0],\n        [15, 16, 17, 18,  0]],\n       [[20,  0,  0,  0,  0],\n        [25, 26,  0,  0,  0],\n        [30, 31, 32,  0,  0],\n        [35, 36, 37, 38,  0]],\n       [[40,  0,  0,  0,  0],\n        [45, 46,  0,  0,  0],\n        [50, 51, 52,  0,  0],\n        [55, 56, 57, 58,  0]]])"
      }
    },
    {
      "name": "tril_indices",
      "signature": "tril_indices(n, k=0, m=None)",
      "docstring": {
        "description": "Return the indices for the lower-triangle of an (n, m) array.",
        "parameters": {
          "n": {
            "type": "int",
            "description": "The row dimension of the arrays for which the returned\n    indices will be valid."
          },
          "k": {
            "type": "int, optional",
            "description": "Diagonal offset (see `tril` for details)."
          },
          "m": {
            "type": "int, optional",
            "description": ".. versionadded:: 1.9.0\n\n    The column dimension of the arrays for which the returned\n    arrays will be valid.\n    By default `m` is taken equal to `n`."
          }
        },
        "returns": "inds : tuple of arrays\n    The indices for the triangle. The returned tuple contains two arrays,\n    each with the indices along one dimension of the array.\n\nSee also\n--------\ntriu_indices : similar function, for upper-triangular.\nmask_indices : generic function accepting an arbitrary mask function.\ntril, triu",
        "raises": "",
        "see_also": "",
        "notes": ".. versionadded:: 1.4.0",
        "examples": "Compute two different sets of indices to access 4x4 arrays, one for the\nlower triangular part starting at the main diagonal, and one starting two\ndiagonals further right:\n\n>>> il1 = np.tril_indices(4)\n>>> il2 = np.tril_indices(4, 2)\n\nHere is how they can be used with a sample array:\n\n>>> a = np.arange(16).reshape(4, 4)\n>>> a\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11],\n       [12, 13, 14, 15]])\n\nBoth for indexing:\n\n>>> a[il1]\narray([ 0,  4,  5, ..., 13, 14, 15])\n\nAnd for assigning values:\n\n>>> a[il1] = -1\n>>> a\narray([[-1,  1,  2,  3],\n       [-1, -1,  6,  7],\n       [-1, -1, -1, 11],\n       [-1, -1, -1, -1]])\n\nThese cover almost the whole array (two diagonals right of the main one):\n\n>>> a[il2] = -10\n>>> a\narray([[-10, -10, -10,   3],\n       [-10, -10, -10, -10],\n       [-10, -10, -10, -10],\n       [-10, -10, -10, -10]])"
      }
    },
    {
      "name": "tril_indices_from",
      "signature": "tril_indices_from(arr, k=0)",
      "docstring": {
        "description": "Return the indices for the lower-triangle of arr.\n\nSee `tril_indices` for full details.",
        "parameters": {
          "arr": {
            "type": "array_like",
            "description": "The indices will be valid for square arrays whose dimensions are\n    the same as arr."
          },
          "k": {
            "type": "int, optional",
            "description": "Diagonal offset (see `tril` for details)."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "tril_indices, tril, triu_indices_from",
        "notes": ".. versionadded:: 1.4.0",
        "examples": "Create a 4 by 4 array.\n\n>>> a = np.arange(16).reshape(4, 4)\n>>> a\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11],\n       [12, 13, 14, 15]])\n\nPass the array to get the indices of the lower triangular elements.\n\n>>> trili = np.tril_indices_from(a)\n>>> trili\n(array([0, 1, 1, 2, 2, 2, 3, 3, 3, 3]), array([0, 0, 1, 0, 1, 2, 0, 1, 2, 3]))\n\n>>> a[trili]\narray([ 0,  4,  5,  8,  9, 10, 12, 13, 14, 15])\n\nThis is syntactic sugar for tril_indices().\n\n>>> np.tril_indices(a.shape[0])\n(array([0, 1, 1, 2, 2, 2, 3, 3, 3, 3]), array([0, 0, 1, 0, 1, 2, 0, 1, 2, 3]))\n\nUse the `k` parameter to return the indices for the lower triangular array\nup to the k-th diagonal.\n\n>>> trili1 = np.tril_indices_from(a, k=1)\n>>> a[trili1]\narray([ 0,  1,  4,  5,  6,  8,  9, 10, 11, 12, 13, 14, 15])"
      }
    },
    {
      "name": "trim_zeros",
      "signature": "trim_zeros(filt, trim='fb')",
      "docstring": {
        "description": "Trim the leading and/or trailing zeros from a 1-D array or sequence.",
        "parameters": {
          "filt": {
            "type": "1-D array or sequence",
            "description": "Input array."
          },
          "trim": {
            "type": "str, optional",
            "description": "A string with 'f' representing trim from front and 'b' to trim from\n    back. Default is 'fb', trim zeros from both front and back of the\n    array."
          }
        },
        "returns": "trimmed : 1-D array or sequence\n    The result of trimming the input. The input data type is preserved.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ">>> a = np.array((0, 0, 0, 1, 2, 3, 0, 2, 1, 0))\n>>> np.trim_zeros(a)\narray([1, 2, 3, 0, 2, 1])\n\n>>> np.trim_zeros(a, 'b')\narray([0, 0, 0, ..., 0, 2, 1])\n\nThe input data type is preserved, list/tuple in means list/tuple out.\n\n>>> np.trim_zeros([0, 1, 2, 0])\n[1, 2]"
      }
    },
    {
      "name": "triu",
      "signature": "triu(m, k=0)",
      "docstring": {
        "description": "Upper triangle of an array.\n\nReturn a copy of an array with the elements below the `k`-th diagonal\nzeroed. For arrays with ``ndim`` exceeding 2, `triu` will apply to the\nfinal two axes.\n\nPlease refer to the documentation for `tril` for further details.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "tril : lower triangle of an array",
        "notes": "",
        "examples": ">>> np.triu([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], -1)\narray([[ 1,  2,  3],\n       [ 4,  5,  6],\n       [ 0,  8,  9],\n       [ 0,  0, 12]])\n\n>>> np.triu(np.arange(3*4*5).reshape(3, 4, 5))\narray([[[ 0,  1,  2,  3,  4],\n        [ 0,  6,  7,  8,  9],\n        [ 0,  0, 12, 13, 14],\n        [ 0,  0,  0, 18, 19]],\n       [[20, 21, 22, 23, 24],\n        [ 0, 26, 27, 28, 29],\n        [ 0,  0, 32, 33, 34],\n        [ 0,  0,  0, 38, 39]],\n       [[40, 41, 42, 43, 44],\n        [ 0, 46, 47, 48, 49],\n        [ 0,  0, 52, 53, 54],\n        [ 0,  0,  0, 58, 59]]])"
      }
    },
    {
      "name": "triu_indices",
      "signature": "triu_indices(n, k=0, m=None)",
      "docstring": {
        "description": "Return the indices for the upper-triangle of an (n, m) array.",
        "parameters": {
          "n": {
            "type": "int",
            "description": "The size of the arrays for which the returned indices will\n    be valid."
          },
          "k": {
            "type": "int, optional",
            "description": "Diagonal offset (see `triu` for details)."
          },
          "m": {
            "type": "int, optional",
            "description": ".. versionadded:: 1.9.0\n\n    The column dimension of the arrays for which the returned\n    arrays will be valid.\n    By default `m` is taken equal to `n`."
          }
        },
        "returns": "inds : tuple, shape(2) of ndarrays, shape(`n`)\n    The indices for the triangle. The returned tuple contains two arrays,\n    each with the indices along one dimension of the array.  Can be used\n    to slice a ndarray of shape(`n`, `n`).\n\nSee also\n--------\ntril_indices : similar function, for lower-triangular.\nmask_indices : generic function accepting an arbitrary mask function.\ntriu, tril",
        "raises": "",
        "see_also": "",
        "notes": ".. versionadded:: 1.4.0",
        "examples": "Compute two different sets of indices to access 4x4 arrays, one for the\nupper triangular part starting at the main diagonal, and one starting two\ndiagonals further right:\n\n>>> iu1 = np.triu_indices(4)\n>>> iu2 = np.triu_indices(4, 2)\n\nHere is how they can be used with a sample array:\n\n>>> a = np.arange(16).reshape(4, 4)\n>>> a\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11],\n       [12, 13, 14, 15]])\n\nBoth for indexing:\n\n>>> a[iu1]\narray([ 0,  1,  2, ..., 10, 11, 15])\n\nAnd for assigning values:\n\n>>> a[iu1] = -1\n>>> a\narray([[-1, -1, -1, -1],\n       [ 4, -1, -1, -1],\n       [ 8,  9, -1, -1],\n       [12, 13, 14, -1]])\n\nThese cover only a small part of the whole array (two diagonals right\nof the main one):\n\n>>> a[iu2] = -10\n>>> a\narray([[ -1,  -1, -10, -10],\n       [  4,  -1,  -1, -10],\n       [  8,   9,  -1,  -1],\n       [ 12,  13,  14,  -1]])"
      }
    },
    {
      "name": "triu_indices_from",
      "signature": "triu_indices_from(arr, k=0)",
      "docstring": {
        "description": "Return the indices for the upper-triangle of arr.\n\nSee `triu_indices` for full details.",
        "parameters": {
          "arr": {
            "type": "ndarray, shape(N, N)",
            "description": "The indices will be valid for square arrays."
          },
          "k": {
            "type": "int, optional",
            "description": "Diagonal offset (see `triu` for details)."
          }
        },
        "returns": "triu_indices_from : tuple, shape(2) of ndarray, shape(N)\n    Indices for the upper-triangle of `arr`.",
        "raises": "",
        "see_also": "triu_indices, triu, tril_indices_from",
        "notes": ".. versionadded:: 1.4.0",
        "examples": "Create a 4 by 4 array.\n\n>>> a = np.arange(16).reshape(4, 4)\n>>> a\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11],\n       [12, 13, 14, 15]])\n\nPass the array to get the indices of the upper triangular elements.\n\n>>> triui = np.triu_indices_from(a)\n>>> triui\n(array([0, 0, 0, 0, 1, 1, 1, 2, 2, 3]), array([0, 1, 2, 3, 1, 2, 3, 2, 3, 3]))\n\n>>> a[triui]\narray([ 0,  1,  2,  3,  5,  6,  7, 10, 11, 15])\n\nThis is syntactic sugar for triu_indices().\n\n>>> np.triu_indices(a.shape[0])\n(array([0, 0, 0, 0, 1, 1, 1, 2, 2, 3]), array([0, 1, 2, 3, 1, 2, 3, 2, 3, 3]))\n\nUse the `k` parameter to return the indices for the upper triangular array\nfrom the k-th diagonal.\n\n>>> triuim1 = np.triu_indices_from(a, k=1)\n>>> a[triuim1]\narray([ 1,  2,  3,  6,  7, 11])"
      }
    },
    {
      "name": "typename",
      "signature": "typename(char)",
      "docstring": {
        "description": "Return a description for the given data type code.",
        "parameters": {
          "char": {
            "type": "str",
            "description": "Data type code."
          }
        },
        "returns": "out : str\n    Description of the input data type code.",
        "raises": "",
        "see_also": "dtype, typecodes",
        "notes": "",
        "examples": ">>> typechars = ['S1', '?', 'B', 'D', 'G', 'F', 'I', 'H', 'L', 'O', 'Q',\n...              'S', 'U', 'V', 'b', 'd', 'g', 'f', 'i', 'h', 'l', 'q']\n>>> for typechar in typechars:\n...     print(typechar, ' : ', np.typename(typechar))\n...\nS1  :  character\n?  :  bool\nB  :  unsigned char\nD  :  complex double precision\nG  :  complex long double precision\nF  :  complex single precision\nI  :  unsigned integer\nH  :  unsigned short\nL  :  unsigned long integer\nO  :  object\nQ  :  unsigned long long integer\nS  :  string\nU  :  unicode\nV  :  void\nb  :  signed char\nd  :  double precision\ng  :  long precision\nf  :  single precision\ni  :  integer\nh  :  short\nl  :  long integer\nq  :  long long integer"
      }
    },
    {
      "name": "union1d",
      "signature": "union1d(ar1, ar2)",
      "docstring": {
        "description": "Find the union of two arrays.\n\nReturn the unique, sorted array of values that are in either of the two\ninput arrays.",
        "parameters": {},
        "returns": "union1d : ndarray\n    Unique, sorted union of the input arrays.",
        "raises": "",
        "see_also": "numpy.lib.arraysetops : Module with a number of other functions for\n                        performing set operations on arrays.",
        "notes": "",
        "examples": ">>> np.union1d([-1, 0, 1], [-2, 0, 2])\narray([-2, -1,  0,  1,  2])\n\nTo find the union of more than two arrays, use functools.reduce:\n\n>>> from functools import reduce\n>>> reduce(np.union1d, ([1, 3, 4, 3], [3, 1, 2, 1], [6, 3, 4, 2]))\narray([1, 2, 3, 4, 6])"
      }
    },
    {
      "name": "unique",
      "signature": "unique(ar, return_index=False, return_inverse=False, return_counts=False, axis=None, *, equal_nan=True)",
      "docstring": {
        "description": "Find the unique elements of an array.\n\nReturns the sorted unique elements of an array. There are three optional\noutputs in addition to the unique elements:\n\n* the indices of the input array that give the unique values\n* the indices of the unique array that reconstruct the input array\n* the number of times each unique value comes up in the input array",
        "parameters": {
          "ar": {
            "type": "array_like",
            "description": "Input array. Unless `axis` is specified, this will be flattened if it\n    is not already 1-D."
          },
          "return_index": {
            "type": "bool, optional",
            "description": "If True, also return the indices of `ar` (along the specified axis,\n    if provided, or in the flattened array) that result in the unique array."
          },
          "return_inverse": {
            "type": "bool, optional",
            "description": "If True, also return the indices of the unique array (for the specified\n    axis, if provided) that can be used to reconstruct `ar`."
          },
          "return_counts": {
            "type": "bool, optional",
            "description": "If True, also return the number of times each unique item appears\n    in `ar`."
          },
          "axis": {
            "type": "int or None, optional",
            "description": "The axis to operate on. If None, `ar` will be flattened. If an integer,\n    the subarrays indexed by the given axis will be flattened and treated\n    as the elements of a 1-D array with the dimension of the given axis,\n    see the notes for more details.  Object arrays or structured arrays\n    that contain objects are not supported if the `axis` kwarg is used. The\n    default is None.\n\n    .. versionadded:: 1.13.0"
          },
          "equal_nan": {
            "type": "bool, optional",
            "description": "If True, collapses multiple NaN values in the return array into one.\n\n    .. versionadded:: 1.24"
          }
        },
        "returns": "unique : ndarray\n    The sorted unique values.\nunique_indices : ndarray, optional\n    The indices of the first occurrences of the unique values in the\n    original array. Only provided if `return_index` is True.\nunique_inverse : ndarray, optional\n    The indices to reconstruct the original array from the\n    unique array. Only provided if `return_inverse` is True.\nunique_counts : ndarray, optional\n    The number of times each of the unique values comes up in the\n    original array. Only provided if `return_counts` is True.\n\n    .. versionadded:: 1.9.0",
        "raises": "",
        "see_also": "numpy.lib.arraysetops : Module with a number of other functions for\n                        performing set operations on arrays.\nrepeat : Repeat elements of an array.",
        "notes": "When an axis is specified the subarrays indexed by the axis are sorted.\nThis is done by making the specified axis the first dimension of the array\n(move the axis to the first dimension to keep the order of the other axes)\nand then flattening the subarrays in C order. The flattened subarrays are\nthen viewed as a structured type with each element given a label, with the\neffect that we end up with a 1-D array of structured types that can be\ntreated in the same way as any other 1-D array. The result is that the\nflattened subarrays are sorted in lexicographic order starting with the\nfirst element.\n\n.. versionchanged: NumPy 1.21\n    If nan values are in the input array, a single nan is put\n    to the end of the sorted unique values.\n\n    Also for complex arrays all NaN values are considered equivalent\n    (no matter whether the NaN is in the real or imaginary part).\n    As the representant for the returned array the smallest one in the\n    lexicographical order is chosen - see np.sort for how the lexicographical\n    order is defined for complex arrays.",
        "examples": ">>> np.unique([1, 1, 2, 2, 3, 3])\narray([1, 2, 3])\n>>> a = np.array([[1, 1], [2, 3]])\n>>> np.unique(a)\narray([1, 2, 3])\n\nReturn the unique rows of a 2D array\n\n>>> a = np.array([[1, 0, 0], [1, 0, 0], [2, 3, 4]])\n>>> np.unique(a, axis=0)\narray([[1, 0, 0], [2, 3, 4]])\n\nReturn the indices of the original array that give the unique values:\n\n>>> a = np.array(['a', 'b', 'b', 'c', 'a'])\n>>> u, indices = np.unique(a, return_index=True)\n>>> u\narray(['a', 'b', 'c'], dtype='<U1')\n>>> indices\narray([0, 1, 3])\n>>> a[indices]\narray(['a', 'b', 'c'], dtype='<U1')\n\nReconstruct the input array from the unique values and inverse:\n\n>>> a = np.array([1, 2, 6, 4, 2, 3, 2])\n>>> u, indices = np.unique(a, return_inverse=True)\n>>> u\narray([1, 2, 3, 4, 6])\n>>> indices\narray([0, 1, 4, 3, 1, 2, 1])\n>>> u[indices]\narray([1, 2, 6, 4, 2, 3, 2])\n\nReconstruct the input values from the unique values and counts:\n\n>>> a = np.array([1, 2, 6, 4, 2, 3, 2])\n>>> values, counts = np.unique(a, return_counts=True)\n>>> values\narray([1, 2, 3, 4, 6])\n>>> counts\narray([1, 3, 1, 1, 1])\n>>> np.repeat(values, counts)\narray([1, 2, 2, 2, 3, 4, 6])    # original order not preserved"
      }
    },
    {
      "name": "unpackbits",
      "signature": "unpackbits(...)",
      "docstring": {
        "description": "unpackbits(a, /, axis=None, count=None, bitorder='big')\n\nUnpacks elements of a uint8 array into a binary-valued output array.\n\nEach element of `a` represents a bit-field that should be unpacked\ninto a binary-valued output array. The shape of the output array is\neither 1-D (if `axis` is ``None``) or the same shape as the input\narray with unpacking done along the axis specified.",
        "parameters": {
          "a": {
            "type": "ndarray, uint8 type",
            "description": "Input array."
          },
          "axis": {
            "type": "int, optional",
            "description": "The dimension over which bit-unpacking is done.\n    ``None`` implies unpacking the flattened array."
          },
          "count": {
            "type": "int or None, optional",
            "description": "The number of elements to unpack along `axis`, provided as a way\n    of undoing the effect of packing a size that is not a multiple\n    of eight. A non-negative number means to only unpack `count`\n    bits. A negative number means to trim off that many bits from\n    the end. ``None`` means to unpack the entire array (the\n    default). Counts larger than the available number of bits will\n    add zero padding to the output. Negative counts must not\n    exceed the available number of bits.\n\n    .. versionadded:: 1.17.0"
          },
          "bitorder": {
            "type": "{'big', 'little'}, optional",
            "description": "The order of the returned bits. 'big' will mimic bin(val),\n    ``3 = 0b00000011 => [0, 0, 0, 0, 0, 0, 1, 1]``, 'little' will reverse\n    the order to ``[1, 1, 0, 0, 0, 0, 0, 0]``.\n    Defaults to 'big'.\n\n    .. versionadded:: 1.17.0"
          }
        },
        "returns": "unpacked : ndarray, uint8 type\n   The elements are binary-valued (0 or 1).",
        "raises": "",
        "see_also": "packbits : Packs the elements of a binary-valued array into bits in\n           a uint8 array.",
        "notes": "",
        "examples": ">>> a = np.array([[2], [7], [23]], dtype=np.uint8)\n>>> a\narray([[ 2],\n       [ 7],\n       [23]], dtype=uint8)\n>>> b = np.unpackbits(a, axis=1)\n>>> b\narray([[0, 0, 0, 0, 0, 0, 1, 0],\n       [0, 0, 0, 0, 0, 1, 1, 1],\n       [0, 0, 0, 1, 0, 1, 1, 1]], dtype=uint8)\n>>> c = np.unpackbits(a, axis=1, count=-3)\n>>> c\narray([[0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0],\n       [0, 0, 0, 1, 0]], dtype=uint8)\n\n>>> p = np.packbits(b, axis=0)\n>>> np.unpackbits(p, axis=0)\narray([[0, 0, 0, 0, 0, 0, 1, 0],\n       [0, 0, 0, 0, 0, 1, 1, 1],\n       [0, 0, 0, 1, 0, 1, 1, 1],\n       [0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)\n>>> np.array_equal(b, np.unpackbits(p, axis=0, count=b.shape[0]))\nTrue"
      }
    },
    {
      "name": "unravel_index",
      "signature": "unravel_index(...)",
      "docstring": {
        "description": "unravel_index(indices, shape, order='C')\n\nConverts a flat index or array of flat indices into a tuple\nof coordinate arrays.",
        "parameters": {
          "indices": {
            "type": "array_like",
            "description": "An integer array whose elements are indices into the flattened\n    version of an array of dimensions ``shape``. Before version 1.6.0,\n    this function accepted just one index value."
          },
          "shape": {
            "type": "tuple of ints",
            "description": "The shape of the array to use for unraveling ``indices``.\n\n    .. versionchanged:: 1.16.0\n        Renamed from ``dims`` to ``shape``."
          },
          "order": {
            "type": "{'C', 'F'}, optional",
            "description": "Determines whether the indices should be viewed as indexing in\n    row-major (C-style) or column-major (Fortran-style) order.\n\n    .. versionadded:: 1.6.0"
          }
        },
        "returns": "unraveled_coords : tuple of ndarray\n    Each array in the tuple has the same shape as the ``indices``\n    array.",
        "raises": "",
        "see_also": "ravel_multi_index",
        "notes": "",
        "examples": ">>> np.unravel_index([22, 41, 37], (7,6))\n(array([3, 6, 6]), array([4, 5, 1]))\n>>> np.unravel_index([31, 41, 13], (7,6), order='F')\n(array([3, 6, 6]), array([4, 5, 1]))\n\n>>> np.unravel_index(1621, (6,7,8,9))\n(3, 1, 4, 1)"
      }
    },
    {
      "name": "unwrap",
      "signature": "unwrap(p, discont=None, axis=-1, *, period=6.283185307179586)",
      "docstring": {
        "description": "Unwrap by taking the complement of large deltas with respect to the period.\n\nThis unwraps a signal `p` by changing elements which have an absolute\ndifference from their predecessor of more than ``max(discont, period/2)``\nto their `period`-complementary values.\n\nFor the default case where `period` is :math:`2\\pi` and `discont` is\n:math:`\\pi`, this unwraps a radian phase `p` such that adjacent differences\nare never greater than :math:`\\pi` by adding :math:`2k\\pi` for some\ninteger :math:`k`.",
        "parameters": {
          "p": {
            "type": "array_like",
            "description": "Input array."
          },
          "discont": {
            "type": "float, optional",
            "description": "Maximum discontinuity between values, default is ``period/2``.\n    Values below ``period/2`` are treated as if they were ``period/2``.\n    To have an effect different from the default, `discont` should be\n    larger than ``period/2``."
          },
          "axis": {
            "type": "int, optional",
            "description": "Axis along which unwrap will operate, default is the last axis."
          },
          "period": {
            "type": "float, optional",
            "description": "Size of the range over which the input wraps. By default, it is\n    ``2 pi``.\n\n    .. versionadded:: 1.21.0"
          }
        },
        "returns": "out : ndarray\n    Output array.",
        "raises": "",
        "see_also": "rad2deg, deg2rad",
        "notes": "If the discontinuity in `p` is smaller than ``period/2``,\nbut larger than `discont`, no unwrapping is done because taking\nthe complement would only make the discontinuity larger.",
        "examples": ">>> phase = np.linspace(0, np.pi, num=5)\n>>> phase[3:] += np.pi\n>>> phase\narray([ 0.        ,  0.78539816,  1.57079633,  5.49778714,  6.28318531]) # may vary\n>>> np.unwrap(phase)\narray([ 0.        ,  0.78539816,  1.57079633, -0.78539816,  0.        ]) # may vary\n>>> np.unwrap([0, 1, 2, -1, 0], period=4)\narray([0, 1, 2, 3, 4])\n>>> np.unwrap([ 1, 2, 3, 4, 5, 6, 1, 2, 3], period=6)\narray([1, 2, 3, 4, 5, 6, 7, 8, 9])\n>>> np.unwrap([2, 3, 4, 5, 2, 3, 4, 5], period=4)\narray([2, 3, 4, 5, 6, 7, 8, 9])\n>>> phase_deg = np.mod(np.linspace(0 ,720, 19), 360) - 180\n>>> np.unwrap(phase_deg, period=360)\narray([-180., -140., -100.,  -60.,  -20.,   20.,   60.,  100.,  140.,\n        180.,  220.,  260.,  300.,  340.,  380.,  420.,  460.,  500.,\n        540.])"
      }
    },
    {
      "name": "vander",
      "signature": "vander(x, N=None, increasing=False)",
      "docstring": {
        "description": "Generate a Vandermonde matrix.\n\nThe columns of the output matrix are powers of the input vector. The\norder of the powers is determined by the `increasing` boolean argument.\nSpecifically, when `increasing` is False, the `i`-th output column is\nthe input vector raised element-wise to the power of ``N - i - 1``. Such\na matrix with a geometric progression in each row is named for Alexandre-\nTheophile Vandermonde.",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "1-D input array."
          },
          "N": {
            "type": "int, optional",
            "description": "Number of columns in the output.  If `N` is not specified, a square\n    array is returned (``N = len(x)``)."
          },
          "increasing": {
            "type": "bool, optional",
            "description": "Order of the powers of the columns.  If True, the powers increase\n    from left to right, if False (the default) they are reversed.\n\n    .. versionadded:: 1.9.0"
          }
        },
        "returns": "out : ndarray\n    Vandermonde matrix.  If `increasing` is False, the first column is\n    ``x^(N-1)``, the second ``x^(N-2)`` and so forth. If `increasing` is\n    True, the columns are ``x^0, x^1, ..., x^(N-1)``.",
        "raises": "",
        "see_also": "polynomial.polynomial.polyvander",
        "notes": "",
        "examples": ">>> x = np.array([1, 2, 3, 5])\n>>> N = 3\n>>> np.vander(x, N)\narray([[ 1,  1,  1],\n       [ 4,  2,  1],\n       [ 9,  3,  1],\n       [25,  5,  1]])\n\n>>> np.column_stack([x**(N-1-i) for i in range(N)])\narray([[ 1,  1,  1],\n       [ 4,  2,  1],\n       [ 9,  3,  1],\n       [25,  5,  1]])\n\n>>> x = np.array([1, 2, 3, 5])\n>>> np.vander(x)\narray([[  1,   1,   1,   1],\n       [  8,   4,   2,   1],\n       [ 27,   9,   3,   1],\n       [125,  25,   5,   1]])\n>>> np.vander(x, increasing=True)\narray([[  1,   1,   1,   1],\n       [  1,   2,   4,   8],\n       [  1,   3,   9,  27],\n       [  1,   5,  25, 125]])\n\nThe determinant of a square Vandermonde matrix is the product\nof the differences between the values of the input vector:\n\n>>> np.linalg.det(np.vander(x))\n48.000000000000043 # may vary\n>>> (5-3)*(5-2)*(5-1)*(3-2)*(3-1)*(2-1)\n48"
      }
    },
    {
      "name": "vectorize",
      "signature": "vectorize(pyfunc=<no value>, otypes=None, doc=None, excluded=None, cache=False, signature=None)",
      "docstring": {
        "description": "vectorize(pyfunc=np._NoValue, otypes=None, doc=None, excluded=None,\ncache=False, signature=None)\n\nReturns an object that acts like pyfunc, but takes arrays as input.\n\nDefine a vectorized function which takes a nested sequence of objects or\nnumpy arrays as inputs and returns a single numpy array or a tuple of numpy\narrays. The vectorized function evaluates `pyfunc` over successive tuples\nof the input arrays like the python map function, except it uses the\nbroadcasting rules of numpy.\n\nThe data type of the output of `vectorized` is determined by calling\nthe function with the first element of the input.  This can be avoided\nby specifying the `otypes` argument.",
        "parameters": {
          "pyfunc": {
            "type": "callable, optional",
            "description": "A python function or method.\n    Can be omitted to produce a decorator with keyword arguments."
          },
          "otypes": {
            "type": "str or list of dtypes, optional",
            "description": "The output data type. It must be specified as either a string of\n    typecode characters or a list of data type specifiers. There should\n    be one data type specifier for each output."
          },
          "doc": {
            "type": "str, optional",
            "description": "The docstring for the function. If None, the docstring will be the\n    ``pyfunc.__doc__``."
          },
          "excluded": {
            "type": "set, optional",
            "description": "Set of strings or integers representing the positional or keyword\n    arguments for which the function will not be vectorized.  These will be\n    passed directly to `pyfunc` unmodified.\n\n    .. versionadded:: 1.7.0"
          },
          "cache": {
            "type": "bool, optional",
            "description": "If `True`, then cache the first function call that determines the number\n    of outputs if `otypes` is not provided.\n\n    .. versionadded:: 1.7.0"
          },
          "signature": {
            "type": "string, optional",
            "description": "Generalized universal function signature, e.g., ``(m,n),(n)->(m)`` for\n    vectorized matrix-vector multiplication. If provided, ``pyfunc`` will\n    be called with (and expected to return) arrays with shapes given by the\n    size of corresponding core dimensions. By default, ``pyfunc`` is\n    assumed to take scalars as input and output.\n\n    .. versionadded:: 1.12.0"
          }
        },
        "returns": "out : callable\n    A vectorized function if ``pyfunc`` was provided,\n    a decorator otherwise.",
        "raises": "",
        "see_also": "frompyfunc : Takes an arbitrary Python function and returns a ufunc",
        "notes": "The `vectorize` function is provided primarily for convenience, not for\nperformance. The implementation is essentially a for loop.\n\nIf `otypes` is not specified, then a call to the function with the\nfirst argument will be used to determine the number of outputs.  The\nresults of this call will be cached if `cache` is `True` to prevent\ncalling the function twice.  However, to implement the cache, the\noriginal function must be wrapped which will slow down subsequent\ncalls, so only do this if your function is expensive.\n\nThe new keyword argument interface and `excluded` argument support\nfurther degrades performance.\n\nReferences\n----------\n.. [1] :doc:`/reference/c-api/generalized-ufuncs`",
        "examples": ">>> def myfunc(a, b):\n...     \"Return a-b if a>b, otherwise return a+b\"\n...     if a > b:\n...         return a - b\n...     else:\n...         return a + b\n\n>>> vfunc = np.vectorize(myfunc)\n>>> vfunc([1, 2, 3, 4], 2)\narray([3, 4, 1, 2])\n\nThe docstring is taken from the input function to `vectorize` unless it\nis specified:\n\n>>> vfunc.__doc__\n'Return a-b if a>b, otherwise return a+b'\n>>> vfunc = np.vectorize(myfunc, doc='Vectorized `myfunc`')\n>>> vfunc.__doc__\n'Vectorized `myfunc`'\n\nThe output type is determined by evaluating the first element of the input,\nunless it is specified:\n\n>>> out = vfunc([1, 2, 3, 4], 2)\n>>> type(out[0])\n<class 'numpy.int64'>\n>>> vfunc = np.vectorize(myfunc, otypes=[float])\n>>> out = vfunc([1, 2, 3, 4], 2)\n>>> type(out[0])\n<class 'numpy.float64'>\n\nThe `excluded` argument can be used to prevent vectorizing over certain\narguments.  This can be useful for array-like arguments of a fixed length\nsuch as the coefficients for a polynomial as in `polyval`:\n\n>>> def mypolyval(p, x):\n...     _p = list(p)\n...     res = _p.pop(0)\n...     while _p:\n...         res = res*x + _p.pop(0)\n...     return res\n>>> vpolyval = np.vectorize(mypolyval, excluded=['p'])\n>>> vpolyval(p=[1, 2, 3], x=[0, 1])\narray([3, 6])\n\nPositional arguments may also be excluded by specifying their position:\n\n>>> vpolyval.excluded.add(0)\n>>> vpolyval([1, 2, 3], x=[0, 1])\narray([3, 6])\n\nThe `signature` argument allows for vectorizing functions that act on\nnon-scalar arrays of fixed length. For example, you can use it for a\nvectorized calculation of Pearson correlation coefficient and its p-value:\n\n>>> import scipy.stats\n>>> pearsonr = np.vectorize(scipy.stats.pearsonr,\n...                 signature='(n),(n)->(),()')\n>>> pearsonr([[0, 1, 2, 3]], [[1, 2, 3, 4], [4, 3, 2, 1]])\n(array([ 1., -1.]), array([ 0.,  0.]))\n\nOr for a vectorized convolution:\n\n>>> convolve = np.vectorize(np.convolve, signature='(n),(m)->(k)')\n>>> convolve(np.eye(4), [1, 2, 1])\narray([[1., 2., 1., 0., 0., 0.],\n       [0., 1., 2., 1., 0., 0.],\n       [0., 0., 1., 2., 1., 0.],\n       [0., 0., 0., 1., 2., 1.]])\n\nDecorator syntax is supported.  The decorator can be called as\na function to provide keyword arguments.\n>>>@np.vectorize\n...def identity(x):\n...    return x\n...\n>>>identity([0, 1, 2])\narray([0, 1, 2])\n>>>@np.vectorize(otypes=[float])\n...def as_float(x):\n...    return x\n...\n>>>as_float([0, 1, 2])\narray([0., 1., 2.])"
      }
    },
    {
      "name": "vsplit",
      "signature": "vsplit(ary, indices_or_sections)",
      "docstring": {
        "description": "Split an array into multiple sub-arrays vertically (row-wise).\n\nPlease refer to the ``split`` documentation.  ``vsplit`` is equivalent\nto ``split`` with `axis=0` (default), the array is always split along the\nfirst axis regardless of the array dimension.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "split : Split an array into multiple sub-arrays of equal size.",
        "notes": "",
        "examples": ">>> x = np.arange(16.0).reshape(4, 4)\n>>> x\narray([[ 0.,   1.,   2.,   3.],\n       [ 4.,   5.,   6.,   7.],\n       [ 8.,   9.,  10.,  11.],\n       [12.,  13.,  14.,  15.]])\n>>> np.vsplit(x, 2)\n[array([[0., 1., 2., 3.],\n       [4., 5., 6., 7.]]), array([[ 8.,  9., 10., 11.],\n       [12., 13., 14., 15.]])]\n>>> np.vsplit(x, np.array([3, 6]))\n[array([[ 0.,  1.,  2.,  3.],\n       [ 4.,  5.,  6.,  7.],\n       [ 8.,  9., 10., 11.]]), array([[12., 13., 14., 15.]]), array([], shape=(0, 4), dtype=float64)]\n\nWith a higher dimensional array the split is still along the first axis.\n\n>>> x = np.arange(8.0).reshape(2, 2, 2)\n>>> x\narray([[[0.,  1.],\n        [2.,  3.]],\n       [[4.,  5.],\n        [6.,  7.]]])\n>>> np.vsplit(x, 2)\n[array([[[0., 1.],\n        [2., 3.]]]), array([[[4., 5.],\n        [6., 7.]]])]"
      }
    },
    {
      "name": "who",
      "signature": "who(vardict=None)",
      "docstring": {
        "description": "Print the NumPy arrays in the given dictionary.\n\nIf there is no dictionary passed in or `vardict` is None then returns\nNumPy arrays in the globals() dictionary (all NumPy arrays in the\nnamespace).",
        "parameters": {
          "vardict": {
            "type": "dict, optional",
            "description": "A dictionary possibly containing ndarrays.  Default is globals()."
          }
        },
        "returns": "out : None\n    Returns 'None'.",
        "raises": "",
        "see_also": "",
        "notes": "Prints out the name, shape, bytes and type of all of the ndarrays\npresent in `vardict`.",
        "examples": ">>> a = np.arange(10)\n>>> b = np.ones(20)\n>>> np.who()\nName            Shape            Bytes            Type\n===========================================================\na               10               80               int64\nb               20               160              float64\nUpper bound on total bytes  =       240\n\n>>> d = {'x': np.arange(2.0), 'y': np.arange(3.0), 'txt': 'Some str',\n... 'idx':5}\n>>> np.who(d)\nName            Shape            Bytes            Type\n===========================================================\nx               2                16               float64\ny               3                24               float64\nUpper bound on total bytes  =       40"
      }
    }
  ],
  "classes": [
    {
      "name": "Arrayterator",
      "docstring": {
        "description": "Buffered iterator for big arrays.\n\n`Arrayterator` creates a buffered iterator for reading big arrays in small\ncontiguous blocks. The class is useful for objects stored in the\nfile system. It allows iteration over the object *without* reading\neverything in memory; instead, small blocks are read and iterated over.\n\n`Arrayterator` can be used with any object that supports multidimensional\nslices. This includes NumPy arrays, but also variables from\nScientific.IO.NetCDF or pynetcdf for example.",
        "parameters": {
          "var": {
            "type": "array_like",
            "description": "The object to iterate over."
          },
          "buf_size": {
            "type": "int, optional",
            "description": "The buffer size. If `buf_size` is supplied, the maximum amount of\n    data that will be read into memory is `buf_size` elements.\n    Default is None, which will read as many element as possible\n    into memory.\n\nAttributes\n----------\nvar\nbuf_size\nstart\nstop\nstep\nshape\nflat"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "ndenumerate : Multidimensional array iterator.\nflatiter : Flat array iterator.\nmemmap : Create a memory-map to an array stored in a binary file on disk.",
        "notes": "The algorithm works by first finding a \"running dimension\", along which\nthe blocks will be extracted. Given an array of dimensions\n``(d1, d2, ..., dn)``, e.g. if `buf_size` is smaller than ``d1``, the\nfirst dimension will be used. If, on the other hand,\n``d1 < buf_size < d1*d2`` the second dimension will be used, and so on.\nBlocks are extracted along this dimension, and when the last block is\nreturned the process continues from the next dimension, until all\nelements have been read.",
        "examples": ">>> a = np.arange(3 * 4 * 5 * 6).reshape(3, 4, 5, 6)\n>>> a_itor = np.lib.Arrayterator(a, 2)\n>>> a_itor.shape\n(3, 4, 5, 6)\n\nNow we can iterate over ``a_itor``, and it will return arrays of size\ntwo. Since `buf_size` was smaller than any dimension, the first\ndimension will be iterated over first:\n\n>>> for subarr in a_itor:\n...     if not subarr.all():\n...         print(subarr, subarr.shape) # doctest: +SKIP\n>>> # [[[[0 1]]]] (1, 1, 1, 2)"
      },
      "methods": []
    },
    {
      "name": "DataSource",
      "docstring": {
        "description": "DataSource(destpath='.')\n\nA generic data source file (file, http, ftp, ...).\n\nDataSources can be local files or remote files/URLs.  The files may\nalso be compressed or uncompressed. DataSource hides some of the\nlow-level details of downloading the file, allowing you to simply pass\nin a valid file path (or URL) and obtain a file object.",
        "parameters": {
          "destpath": {
            "type": "str or None, optional",
            "description": "Path to the directory where the source file gets downloaded to for\n    use.  If `destpath` is None, a temporary directory will be created.\n    The default path is the current directory."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "URLs require a scheme string (``http://``) to be used, without it they\nwill fail::\n\n    >>> repos = np.DataSource()\n    >>> repos.exists('www.google.com/index.html')\n    False\n    >>> repos.exists('http://www.google.com/index.html')\n    True\n\nTemporary directories are deleted when the DataSource is deleted.",
        "examples": "::\n\n    >>> ds = np.DataSource('/home/guido')\n    >>> urlname = 'http://www.google.com/'\n    >>> gfile = ds.open('http://www.google.com/')\n    >>> ds.abspath(urlname)\n    '/home/guido/www.google.com/index.html'\n\n    >>> ds = np.DataSource(None)  # use with temporary file\n    >>> ds.open('/home/guido/foobar.txt')\n    <open file '/home/guido.foobar.txt', mode 'r' at 0x91d4430>\n    >>> ds.abspath('/home/guido/foobar.txt')\n    '/tmp/.../home/guido/foobar.txt'"
      },
      "methods": [
        {
          "name": "abspath",
          "signature": "abspath(self, path)",
          "docstring": {
            "description": "Return absolute path of file in the DataSource directory.\n\nIf `path` is an URL, then `abspath` will return either the location\nthe file exists locally or the location it would exist when opened\nusing the `open` method.",
            "parameters": {
              "path": {
                "type": "str",
                "description": "Can be a local file or a remote URL."
              }
            },
            "returns": "out : str\n    Complete path, including the `DataSource` destination directory.",
            "raises": "",
            "see_also": "",
            "notes": "The functionality is based on `os.path.abspath`.",
            "examples": ""
          }
        },
        {
          "name": "exists",
          "signature": "exists(self, path)",
          "docstring": {
            "description": "Test if path exists.\n\nTest if `path` exists as (and in this order):\n\n- a local file.\n- a remote URL that has been downloaded and stored locally in the\n  `DataSource` directory.\n- a remote URL that has not been downloaded, but is valid and\n  accessible.",
            "parameters": {
              "path": {
                "type": "str",
                "description": "Can be a local file or a remote URL."
              }
            },
            "returns": "out : bool\n    True if `path` exists.",
            "raises": "",
            "see_also": "",
            "notes": "When `path` is an URL, `exists` will return True if it's either\nstored locally in the `DataSource` directory, or is a valid remote\nURL.  `DataSource` does not discriminate between the two, the file\nis accessible if it exists in either location.",
            "examples": ""
          }
        },
        {
          "name": "open",
          "signature": "open(self, path, mode='r', encoding=None, newline=None)",
          "docstring": {
            "description": "Open and return file-like object.\n\nIf `path` is an URL, it will be downloaded, stored in the\n`DataSource` directory and opened from there.",
            "parameters": {
              "path": {
                "type": "str",
                "description": "Local file path or URL to open."
              },
              "mode": {
                "type": "{'r', 'w', 'a'}, optional",
                "description": "Mode to open `path`.  Mode 'r' for reading, 'w' for writing,\n    'a' to append. Available modes depend on the type of object\n    specified by `path`. Default is 'r'."
              },
              "encoding": {
                "type": "{None, str}, optional",
                "description": "Open text file with given encoding. The default encoding will be\n    what `io.open` uses."
              },
              "newline": {
                "type": "{None, str}, optional",
                "description": "Newline to use when reading text file."
              }
            },
            "returns": "out : file object\n    File object.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "NumpyVersion",
      "docstring": {
        "description": "Parse and compare numpy version strings.\n\nNumPy has the following versioning scheme (numbers given are examples; they\ncan be > 9 in principle):\n\n- Released version: '1.8.0', '1.8.1', etc.\n- Alpha: '1.8.0a1', '1.8.0a2', etc.\n- Beta: '1.8.0b1', '1.8.0b2', etc.\n- Release candidates: '1.8.0rc1', '1.8.0rc2', etc.\n- Development versions: '1.8.0.dev-f1234afa' (git commit hash appended)\n- Development versions after a1: '1.8.0a1.dev-f1234afa',\n                                 '1.8.0b2.dev-f1234afa',\n                                 '1.8.1rc1.dev-f1234afa', etc.\n- Development versions (no git hash available): '1.8.0.dev-Unknown'\n\nComparing needs to be done against a valid version string or other\n`NumpyVersion` instance. Note that all development versions of the same\n(pre-)release compare equal.\n\n.. versionadded:: 1.9.0",
        "parameters": {
          "vstring": {
            "type": "str",
            "description": "NumPy version string (``np.__version__``)."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ">>> from numpy.lib import NumpyVersion\n>>> if NumpyVersion(np.__version__) < '1.7.0':\n...     print('skip')\n>>> # skip\n\n>>> NumpyVersion('1.7')  # raises ValueError, add \".0\"\nTraceback (most recent call last):\n    ...\nValueError: Not a valid numpy version string"
      },
      "methods": []
    },
    {
      "name": "RankWarning",
      "docstring": {
        "description": "Issued by `polyfit` when the Vandermonde matrix is rank deficient.\n\nFor more information, a way to suppress the warning, and an example of\n`RankWarning` being issued, see `polyfit`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "add_note",
          "signature": "add_note(...)",
          "docstring": {
            "description": "Exception.add_note(note) --\nadd a note to the exception",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_traceback",
          "signature": "with_traceback(...)",
          "docstring": {
            "description": "Exception.with_traceback(tb) --\nset self.__traceback__ to tb and return self.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "ndenumerate",
      "docstring": {
        "description": "Multidimensional index iterator.\n\nReturn an iterator yielding pairs of array coordinates and values.",
        "parameters": {
          "arr": {
            "type": "ndarray",
            "description": "Input array."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "ndindex, flatiter",
        "notes": "",
        "examples": ">>> a = np.array([[1, 2], [3, 4]])\n>>> for index, x in np.ndenumerate(a):\n...     print(index, x)\n(0, 0) 1\n(0, 1) 2\n(1, 0) 3\n(1, 1) 4"
      },
      "methods": []
    },
    {
      "name": "ndindex",
      "docstring": {
        "description": "An N-dimensional iterator object to index arrays.\n\nGiven the shape of an array, an `ndindex` instance iterates over\nthe N-dimensional index of the array. At each iteration a tuple\nof indices is returned, the last dimension is iterated over first.",
        "parameters": {
          "shape": {
            "type": "ints, or a single tuple of ints",
            "description": "The size of each dimension of the array can be passed as\n    individual parameters or as the elements of a tuple."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "ndenumerate, flatiter",
        "notes": "",
        "examples": "Dimensions as individual arguments\n\n>>> for index in np.ndindex(3, 2, 1):\n...     print(index)\n(0, 0, 0)\n(0, 1, 0)\n(1, 0, 0)\n(1, 1, 0)\n(2, 0, 0)\n(2, 1, 0)\n\nSame dimensions - but in a tuple ``(3, 2, 1)``\n\n>>> for index in np.ndindex((3, 2, 1)):\n...     print(index)\n(0, 0, 0)\n(0, 1, 0)\n(1, 0, 0)\n(1, 1, 0)\n(2, 0, 0)\n(2, 1, 0)"
      },
      "methods": [
        {
          "name": "ndincr",
          "signature": "ndincr(self)",
          "docstring": {
            "description": "Increment the multi-dimensional index by one.\n\nThis method is for backward compatibility only: do not use.\n\n.. deprecated:: 1.20.0\n    This method has been advised against since numpy 1.8.0, but only\n    started emitting DeprecationWarning as of this version.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "poly1d",
      "docstring": {
        "description": "A one-dimensional polynomial class.\n\n.. note::\n   This forms part of the old polynomial API. Since version 1.4, the\n   new polynomial API defined in `numpy.polynomial` is preferred.\n   A summary of the differences can be found in the\n   :doc:`transition guide </reference/routines.polynomials>`.\n\nA convenience class, used to encapsulate \"natural\" operations on\npolynomials so that said operations may take on their customary\nform in code (see Examples).",
        "parameters": {
          "c_or_r": {
            "type": "array_like",
            "description": "The polynomial's coefficients, in decreasing powers, or if\n    the value of the second parameter is True, the polynomial's\n    roots (values where the polynomial evaluates to 0).  For example,\n    ``poly1d([1, 2, 3])`` returns an object that represents\n    :math:`x^2 + 2x + 3`, whereas ``poly1d([1, 2, 3], True)`` returns\n    one that represents :math:`(x-1)(x-2)(x-3) = x^3 - 6x^2 + 11x -6`."
          },
          "r": {
            "type": "bool, optional",
            "description": "If True, `c_or_r` specifies the polynomial's roots; the default\n    is False."
          },
          "variable": {
            "type": "str, optional",
            "description": "Changes the variable used when printing `p` from `x` to `variable`\n    (see Examples)."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "Construct the polynomial :math:`x^2 + 2x + 3`:\n\n>>> p = np.poly1d([1, 2, 3])\n>>> print(np.poly1d(p))\n   2\n1 x + 2 x + 3\n\nEvaluate the polynomial at :math:`x = 0.5`:\n\n>>> p(0.5)\n4.25\n\nFind the roots:\n\n>>> p.r\narray([-1.+1.41421356j, -1.-1.41421356j])\n>>> p(p.r)\narray([ -4.44089210e-16+0.j,  -4.44089210e-16+0.j]) # may vary\n\nThese numbers in the previous line represent (0, 0) to machine precision\n\nShow the coefficients:\n\n>>> p.c\narray([1, 2, 3])\n\nDisplay the order (the leading zero-coefficients are removed):\n\n>>> p.order\n2\n\nShow the coefficient of the k-th power in the polynomial\n(which is equivalent to ``p.c[-(i+1)]``):\n\n>>> p[1]\n2\n\nPolynomials can be added, subtracted, multiplied, and divided\n(returns quotient and remainder):\n\n>>> p * p\npoly1d([ 1,  4, 10, 12,  9])\n\n>>> (p**3 + 4) / p\n(poly1d([ 1.,  4., 10., 12.,  9.]), poly1d([4.]))\n\n``asarray(p)`` gives the coefficient array, so polynomials can be\nused in all functions that accept arrays:\n\n>>> p**2 # square of polynomial\npoly1d([ 1,  4, 10, 12,  9])\n\n>>> np.square(p) # square of individual coefficients\narray([1, 4, 9])\n\nThe variable used in the string representation of `p` can be modified,\nusing the `variable` parameter:\n\n>>> p = np.poly1d([1,2,3], variable='z')\n>>> print(p)\n   2\n1 z + 2 z + 3\n\nConstruct a polynomial from its roots:\n\n>>> np.poly1d([1, 2], True)\npoly1d([ 1., -3.,  2.])\n\nThis is the same polynomial as obtained by:\n\n>>> np.poly1d([1, -1]) * np.poly1d([1, -2])\npoly1d([ 1, -3,  2])"
      },
      "methods": [
        {
          "name": "deriv",
          "signature": "deriv(self, m=1)",
          "docstring": {
            "description": "Return a derivative of this polynomial.\n\nRefer to `polyder` for full documentation.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "polyder : equivalent function",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "integ",
          "signature": "integ(self, m=1, k=0)",
          "docstring": {
            "description": "Return an antiderivative (indefinite integral) of this polynomial.\n\nRefer to `polyint` for full documentation.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "polyint : equivalent function",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "vectorize",
      "docstring": {
        "description": "vectorize(pyfunc=np._NoValue, otypes=None, doc=None, excluded=None,\ncache=False, signature=None)\n\nReturns an object that acts like pyfunc, but takes arrays as input.\n\nDefine a vectorized function which takes a nested sequence of objects or\nnumpy arrays as inputs and returns a single numpy array or a tuple of numpy\narrays. The vectorized function evaluates `pyfunc` over successive tuples\nof the input arrays like the python map function, except it uses the\nbroadcasting rules of numpy.\n\nThe data type of the output of `vectorized` is determined by calling\nthe function with the first element of the input.  This can be avoided\nby specifying the `otypes` argument.",
        "parameters": {
          "pyfunc": {
            "type": "callable, optional",
            "description": "A python function or method.\n    Can be omitted to produce a decorator with keyword arguments."
          },
          "otypes": {
            "type": "str or list of dtypes, optional",
            "description": "The output data type. It must be specified as either a string of\n    typecode characters or a list of data type specifiers. There should\n    be one data type specifier for each output."
          },
          "doc": {
            "type": "str, optional",
            "description": "The docstring for the function. If None, the docstring will be the\n    ``pyfunc.__doc__``."
          },
          "excluded": {
            "type": "set, optional",
            "description": "Set of strings or integers representing the positional or keyword\n    arguments for which the function will not be vectorized.  These will be\n    passed directly to `pyfunc` unmodified.\n\n    .. versionadded:: 1.7.0"
          },
          "cache": {
            "type": "bool, optional",
            "description": "If `True`, then cache the first function call that determines the number\n    of outputs if `otypes` is not provided.\n\n    .. versionadded:: 1.7.0"
          },
          "signature": {
            "type": "string, optional",
            "description": "Generalized universal function signature, e.g., ``(m,n),(n)->(m)`` for\n    vectorized matrix-vector multiplication. If provided, ``pyfunc`` will\n    be called with (and expected to return) arrays with shapes given by the\n    size of corresponding core dimensions. By default, ``pyfunc`` is\n    assumed to take scalars as input and output.\n\n    .. versionadded:: 1.12.0"
          }
        },
        "returns": "out : callable\n    A vectorized function if ``pyfunc`` was provided,\n    a decorator otherwise.",
        "raises": "",
        "see_also": "frompyfunc : Takes an arbitrary Python function and returns a ufunc",
        "notes": "The `vectorize` function is provided primarily for convenience, not for\nperformance. The implementation is essentially a for loop.\n\nIf `otypes` is not specified, then a call to the function with the\nfirst argument will be used to determine the number of outputs.  The\nresults of this call will be cached if `cache` is `True` to prevent\ncalling the function twice.  However, to implement the cache, the\noriginal function must be wrapped which will slow down subsequent\ncalls, so only do this if your function is expensive.\n\nThe new keyword argument interface and `excluded` argument support\nfurther degrades performance.\n\nReferences\n----------\n.. [1] :doc:`/reference/c-api/generalized-ufuncs`",
        "examples": ">>> def myfunc(a, b):\n...     \"Return a-b if a>b, otherwise return a+b\"\n...     if a > b:\n...         return a - b\n...     else:\n...         return a + b\n\n>>> vfunc = np.vectorize(myfunc)\n>>> vfunc([1, 2, 3, 4], 2)\narray([3, 4, 1, 2])\n\nThe docstring is taken from the input function to `vectorize` unless it\nis specified:\n\n>>> vfunc.__doc__\n'Return a-b if a>b, otherwise return a+b'\n>>> vfunc = np.vectorize(myfunc, doc='Vectorized `myfunc`')\n>>> vfunc.__doc__\n'Vectorized `myfunc`'\n\nThe output type is determined by evaluating the first element of the input,\nunless it is specified:\n\n>>> out = vfunc([1, 2, 3, 4], 2)\n>>> type(out[0])\n<class 'numpy.int64'>\n>>> vfunc = np.vectorize(myfunc, otypes=[float])\n>>> out = vfunc([1, 2, 3, 4], 2)\n>>> type(out[0])\n<class 'numpy.float64'>\n\nThe `excluded` argument can be used to prevent vectorizing over certain\narguments.  This can be useful for array-like arguments of a fixed length\nsuch as the coefficients for a polynomial as in `polyval`:\n\n>>> def mypolyval(p, x):\n...     _p = list(p)\n...     res = _p.pop(0)\n...     while _p:\n...         res = res*x + _p.pop(0)\n...     return res\n>>> vpolyval = np.vectorize(mypolyval, excluded=['p'])\n>>> vpolyval(p=[1, 2, 3], x=[0, 1])\narray([3, 6])\n\nPositional arguments may also be excluded by specifying their position:\n\n>>> vpolyval.excluded.add(0)\n>>> vpolyval([1, 2, 3], x=[0, 1])\narray([3, 6])\n\nThe `signature` argument allows for vectorizing functions that act on\nnon-scalar arrays of fixed length. For example, you can use it for a\nvectorized calculation of Pearson correlation coefficient and its p-value:\n\n>>> import scipy.stats\n>>> pearsonr = np.vectorize(scipy.stats.pearsonr,\n...                 signature='(n),(n)->(),()')\n>>> pearsonr([[0, 1, 2, 3]], [[1, 2, 3, 4], [4, 3, 2, 1]])\n(array([ 1., -1.]), array([ 0.,  0.]))\n\nOr for a vectorized convolution:\n\n>>> convolve = np.vectorize(np.convolve, signature='(n),(m)->(k)')\n>>> convolve(np.eye(4), [1, 2, 1])\narray([[1., 2., 1., 0., 0., 0.],\n       [0., 1., 2., 1., 0., 0.],\n       [0., 0., 1., 2., 1., 0.],\n       [0., 0., 0., 1., 2., 1.]])\n\nDecorator syntax is supported.  The decorator can be called as\na function to provide keyword arguments.\n>>>@np.vectorize\n...def identity(x):\n...    return x\n...\n>>>identity([0, 1, 2])\narray([0, 1, 2])\n>>>@np.vectorize(otypes=[float])\n...def as_float(x):\n...    return x\n...\n>>>as_float([0, 1, 2])\narray([0., 1., 2.])"
      },
      "methods": []
    }
  ],
  "constants": []
}