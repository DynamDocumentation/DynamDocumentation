{
  "description": "**Note:** almost all functions in the ``numpy.lib`` namespace\nare also present in the main ``numpy`` namespace.  Please use the\nfunctions as ``np.<funcname>`` where possible.\n\n``numpy.lib`` is mostly a space for implementing functions that don't\nbelong in core or in another NumPy submodule with a clear purpose\n(e.g. ``random``, ``fft``, ``linalg``, ``ma``).\n\nMost contains basic functions that are used by several submodules and are\nuseful to have in the main name-space.",
  "functions": [
    {
      "name": "add_docstring",
      "signature": "add_docstring(obj, docstring)",
      "documentation": {
        "description": "add_docstring(obj, docstring)\nAdd a docstring to a built-in obj if possible.\nIf the obj already has a docstring raise a RuntimeError\nIf this routine does not know how to add a docstring to the object\nraise a TypeError",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "add_newdoc",
      "signature": "add_newdoc(place, obj, doc, warn_on_python=True)",
      "documentation": {
        "description": "Add documentation to an existing object, typically one defined in C\nThe purpose is to allow easier editing of the docstrings without requiring\na re-compile. This exists primarily for internal use within numpy itself.",
        "parameters": {
          "place": {
            "type": "str",
            "description": "The absolute name of the module to import from"
          },
          "obj": {
            "type": "str",
            "description": "The name of the object to add documentation to, typically a class or\nfunction name"
          },
          "doc": {
            "type": "{str, Tuple[str, str], List[Tuple[str, str]]}",
            "description": "If a string, the documentation to apply to `obj`\nIf a tuple, then the first element is interpreted as an attribute of\n`obj` and the second as the docstring to apply - ``(method, docstring)``\nIf a list, then each element of the list should be a tuple of length\ntwo - ``[(method1, docstring1), (method2, docstring2), ...]``"
          },
          "warn_on_python": {
            "type": "bool",
            "description": "If True, the default, emit `UserWarning` if this is used to attach\ndocumentation to a pure-python object."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "-----\nThis routine never raises an error if the docstring can't be written, but\nwill raise an error if the object being documented does not exist.\nThis routine cannot modify read-only docstrings, as appear\nin new-style classes or built-in functions. Because this\nroutine never raises an error the caller must check manually\nthat the docstrings were changed.\nSince this function grabs the ``char *`` from a c-level str object and puts\nit into the ``tp_doc`` slot of the type of `obj`, it violates a number of\nC-API best-practices, by:\n- modifying a `PyTypeObject` after calling `PyType_Ready`\n- calling `Py_INCREF` on the str and losing the reference, so the str\nwill never be released\nIf possible it should be avoided.",
        "examples": ""
      }
    },
    {
      "name": "add_newdoc_ufunc",
      "signature": "_add_newdoc_ufunc(ufunc, new_docstring)",
      "documentation": {
        "description": "add_ufunc_docstring(ufunc, new_docstring)\nReplace the docstring for a ufunc with new_docstring.\nThis method will only work if the current docstring for\nthe ufunc is NULL. (At the C level, i.e. when ufunc->doc is NULL.)",
        "parameters": {
          "ufunc": {
            "type": "numpy.ufunc",
            "description": "A ufunc whose current doc is NULL."
          },
          "new_docstring": {
            "type": "string",
            "description": "The new docstring for the ufunc."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "-----\nThis method allocates memory for new_docstring on\nthe heap. Technically this creates a mempory leak, since this\nmemory will not be reclaimed until the end of the program\neven if the ufunc itself is removed. However this will only\nbe a problem if the user is repeatedly creating ufuncs with\nno documentation, adding documentation via add_newdoc_ufunc,\nand then throwing away the ufunc.",
        "examples": ""
      }
    },
    {
      "name": "angle",
      "signature": "angle(z, deg=False)",
      "documentation": {
        "description": "Return the angle of the complex argument.",
        "parameters": {
          "z": {
            "type": "array_like",
            "description": "A complex number or sequence of complex numbers."
          },
          "deg": {
            "type": "bool, optional",
            "description": "Return angle in degrees if True, radians if False (default)."
          }
        },
        "returns": "-------\nangle : ndarray or scalar\nThe counterclockwise angle from the positive real axis on the complex\nplane in the range ``(-pi, pi]``, with dtype as numpy.float64.\n.. versionchanged:: 1.16.0\nThis function works on subclasses of ndarray like `ma.array`.",
        "raises": "",
        "see_also": "--------\narctan2\nabsolute",
        "notes": "-----\nAlthough the angle of the complex number 0 is undefined, ``numpy.angle(0)``\nreturns the value 0.",
        "examples": "--------\n>>> np.angle([1.0, 1.0j, 1+1j])               # in radians\narray([ 0.        ,  1.57079633,  0.78539816]) # may vary\n>>> np.angle(1+1j, deg=True)                  # in degrees\n45.0"
      }
    },
    {
      "name": "append",
      "signature": "append(arr, values, axis=None)",
      "documentation": {
        "description": "Append values to the end of an array.",
        "parameters": {
          "arr": {
            "type": "array_like",
            "description": "Values are appended to a copy of this array."
          },
          "values": {
            "type": "array_like",
            "description": "These values are appended to a copy of `arr`.  It must be of the\ncorrect shape (the same shape as `arr`, excluding `axis`).  If\n`axis` is not specified, `values` can be any shape and will be\nflattened before use."
          },
          "axis": {
            "type": "int, optional",
            "description": "The axis along which `values` are appended.  If `axis` is not\ngiven, both `arr` and `values` are flattened before use."
          }
        },
        "returns": "-------\nappend : ndarray\nA copy of `arr` with `values` appended to `axis`.  Note that\n`append` does not occur in-place: a new array is allocated and\nfilled.  If `axis` is None, `out` is a flattened array.",
        "raises": "",
        "see_also": "--------\ninsert : Insert elements into an array.\ndelete : Delete elements from an array.",
        "notes": "",
        "examples": "--------\n>>> np.append([1, 2, 3], [[4, 5, 6], [7, 8, 9]])\narray([1, 2, 3, ..., 7, 8, 9])\nWhen `axis` is specified, `values` must have the correct shape.\n>>> np.append([[1, 2, 3], [4, 5, 6]], [[7, 8, 9]], axis=0)\narray([[1, 2, 3],\n[4, 5, 6],\n[7, 8, 9]])\n>>> np.append([[1, 2, 3], [4, 5, 6]], [7, 8, 9], axis=0)\nTraceback (most recent call last):\n...\nValueError: all the input arrays must have same number of dimensions, but\nthe array at index 0 has 2 dimension(s) and the array at index 1 has 1\ndimension(s)"
      }
    },
    {
      "name": "apply_along_axis",
      "signature": "apply_along_axis(func1d, axis, arr, *args, **kwargs)",
      "documentation": {
        "description": "Apply a function to 1-D slices along the given axis.\nExecute `func1d(a, *args, **kwargs)` where `func1d` operates on 1-D arrays\nand `a` is a 1-D slice of `arr` along `axis`.\nThis is equivalent to (but faster than) the following use of `ndindex` and\n`s_`, which sets each of ``ii``, ``jj``, and ``kk`` to a tuple of indices::\nNi, Nk = a.shape[:axis], a.shape[axis+1:]\nfor ii in ndindex(Ni):\nfor kk in ndindex(Nk):\nf = func1d(arr[ii + s_[:,] + kk])\nNj = f.shape\nfor jj in ndindex(Nj):\nout[ii + jj + kk] = f[jj]\nEquivalently, eliminating the inner loop, this can be expressed as::\nNi, Nk = a.shape[:axis], a.shape[axis+1:]\nfor ii in ndindex(Ni):\nfor kk in ndindex(Nk):\nout[ii + s_[...,] + kk] = func1d(arr[ii + s_[:,] + kk])",
        "parameters": {
          "func1d": {
            "type": "function (M,) -> (Nj...)",
            "description": "This function should accept 1-D arrays. It is applied to 1-D\nslices of `arr` along the specified axis."
          },
          "axis": {
            "type": "integer",
            "description": "Axis along which `arr` is sliced."
          },
          "arr": {
            "type": "ndarray (Ni..., M, Nk...)",
            "description": "Input array."
          },
          "args": {
            "type": "any",
            "description": "Additional arguments to `func1d`."
          },
          "kwargs": {
            "type": "any",
            "description": "Additional named arguments to `func1d`.\n.. versionadded:: 1.9.0"
          }
        },
        "returns": "-------\nout : ndarray  (Ni..., Nj..., Nk...)\nThe output array. The shape of `out` is identical to the shape of\n`arr`, except along the `axis` dimension. This axis is removed, and\nreplaced with new dimensions equal to the shape of the return value\nof `func1d`. So if `func1d` returns a scalar `out` will have one\nfewer dimensions than `arr`.",
        "raises": "",
        "see_also": "--------\napply_over_axes : Apply a function repeatedly over multiple axes.",
        "notes": "",
        "examples": "--------\n>>> def my_func(a):\n...     \"\"\"Average first and last element of a 1-D array\"\"\"\n...     return (a[0] + a[-1]) * 0.5\n>>> b = np.array([[1,2,3], [4,5,6], [7,8,9]])\n>>> np.apply_along_axis(my_func, 0, b)\narray([4., 5., 6.])\n>>> np.apply_along_axis(my_func, 1, b)\narray([2.,  5.,  8.])\nFor a function that returns a 1D array, the number of dimensions in\n`outarr` is the same as `arr`.\n>>> b = np.array([[8,1,7], [4,3,9], [5,2,6]])\n>>> np.apply_along_axis(sorted, 1, b)\narray([[1, 7, 8],\n[3, 4, 9],\n[2, 5, 6]])\nFor a function that returns a higher dimensional array, those dimensions\nare inserted in place of the `axis` dimension.\n>>> b = np.array([[1,2,3], [4,5,6], [7,8,9]])\n>>> np.apply_along_axis(np.diag, -1, b)\narray([[[1, 0, 0],\n[0, 2, 0],\n[0, 0, 3]],\n[[4, 0, 0],\n[0, 5, 0],\n[0, 0, 6]],\n[[7, 0, 0],\n[0, 8, 0],\n[0, 0, 9]]])"
      }
    },
    {
      "name": "apply_over_axes",
      "signature": "apply_over_axes(func, a, axes)",
      "documentation": {
        "description": "Apply a function repeatedly over multiple axes.\n`func` is called as `res = func(a, axis)`, where `axis` is the first\nelement of `axes`.  The result `res` of the function call must have\neither the same dimensions as `a` or one less dimension.  If `res`\nhas one less dimension than `a`, a dimension is inserted before\n`axis`.  The call to `func` is then repeated for each axis in `axes`,\nwith `res` as the first argument.",
        "parameters": {
          "func": {
            "type": "function",
            "description": "This function must take two arguments, `func(a, axis)`."
          },
          "a": {
            "type": "array_like",
            "description": "Input array."
          },
          "axes": {
            "type": "array_like",
            "description": "Axes over which `func` is applied; the elements must be integers."
          }
        },
        "returns": "-------\napply_over_axis : ndarray\nThe output array.  The number of dimensions is the same as `a`,\nbut the shape can be different.  This depends on whether `func`\nchanges the shape of its output with respect to its input.",
        "raises": "",
        "see_also": "--------\napply_along_axis :\nApply a function to 1-D slices of an array along the given axis.",
        "notes": "-----\nThis function is equivalent to tuple axis arguments to reorderable ufuncs\nwith keepdims=True. Tuple axis arguments to ufuncs have been available since\nversion 1.7.0.",
        "examples": "--------\n>>> a = np.arange(24).reshape(2,3,4)\n>>> a\narray([[[ 0,  1,  2,  3],\n[ 4,  5,  6,  7],\n[ 8,  9, 10, 11]],\n[[12, 13, 14, 15],\n[16, 17, 18, 19],\n[20, 21, 22, 23]]])\nSum over axes 0 and 2. The result has same number of dimensions\nas the original array:\n>>> np.apply_over_axes(np.sum, a, [0,2])\narray([[[ 60],\n[ 92],\n[124]]])\nTuple axis arguments to ufuncs are equivalent:\n>>> np.sum(a, axis=(0,2), keepdims=True)\narray([[[ 60],\n[ 92],\n[124]]])"
      }
    },
    {
      "name": "array_split",
      "signature": "array_split(ary, indices_or_sections, axis=0)",
      "documentation": {
        "description": "Split an array into multiple sub-arrays.\nPlease refer to the ``split`` documentation.  The only difference\nbetween these functions is that ``array_split`` allows\n`indices_or_sections` to be an integer that does *not* equally\ndivide the axis. For an array of length l that should be split\ninto n sections, it returns l % n sub-arrays of size l//n + 1\nand the rest of size l//n.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "--------\nsplit : Split array into multiple sub-arrays of equal size.",
        "notes": "",
        "examples": "--------\n>>> x = np.arange(8.0)\n>>> np.array_split(x, 3)\n[array([0.,  1.,  2.]), array([3.,  4.,  5.]), array([6.,  7.])]\n>>> x = np.arange(9)\n>>> np.array_split(x, 4)\n[array([0, 1, 2]), array([3, 4]), array([5, 6]), array([7, 8])]"
      }
    },
    {
      "name": "asarray_chkfinite",
      "signature": "asarray_chkfinite(a, dtype=None, order=None)",
      "documentation": {
        "description": "Convert the input to an array, checking for NaNs or Infs.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input data, in any form that can be converted to an array.  This\nincludes lists, lists of tuples, tuples, tuples of tuples, tuples\nof lists and ndarrays.  Success requires no NaNs or Infs."
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "By default, the data-type is inferred from the input data."
          },
          "order": {
            "type": "{'C', 'F', 'A', 'K'}, optional",
            "description": "Memory layout.  'A' and 'K' depend on the order of input array a.\n'C' row-major (C-style),\n'F' column-major (Fortran-style) memory representation.\n'A' (any) means 'F' if `a` is Fortran contiguous, 'C' otherwise\n'K' (keep) preserve input order\nDefaults to 'C'."
          }
        },
        "returns": "-------\nout : ndarray\nArray interpretation of `a`.  No copy is performed if the input\nis already an ndarray.  If `a` is a subclass of ndarray, a base\nclass ndarray is returned.",
        "raises": "------\nValueError\n>>> a = [1, 2, np.inf]\n>>> try:\n...     np.asarray_chkfinite(a)\n... except ValueError:\n...     print('ValueError')\n...\nValueError",
        "see_also": "--------\nasarray : Create and array.\nasanyarray : Similar function which passes through subclasses.\nascontiguousarray : Convert input to a contiguous array.\nasfarray : Convert input to a floating point ndarray.\nasfortranarray : Convert input to an ndarray with column-major\nmemory order.\nfromiter : Create an array from an iterator.\nfromfunction : Construct an array by executing a function on grid\npositions.",
        "notes": "",
        "examples": "--------\nConvert a list into an array.  If all elements are finite\n``asarray_chkfinite`` is identical to ``asarray``.\n>>> a = [1, 2]\n>>> np.asarray_chkfinite(a, dtype=float)\narray([1., 2.])"
      }
    },
    {
      "name": "asfarray",
      "signature": "asfarray(a, dtype=<class 'numpy.float64'>)",
      "documentation": {
        "description": "Return an array converted to a float type.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "The input array."
          },
          "dtype": {
            "type": "str or dtype object, optional",
            "description": "Float type code to coerce input array `a`.  If `dtype` is one of the\n'int' dtypes, it is replaced with float64."
          }
        },
        "returns": "-------\nout : ndarray\nThe input `a` as a float ndarray.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n>>> np.asfarray([2, 3])\narray([2.,  3.])\n>>> np.asfarray([2, 3], dtype='float')\narray([2.,  3.])\n>>> np.asfarray([2, 3], dtype='int8')\narray([2.,  3.])"
      }
    },
    {
      "name": "average",
      "signature": "average(a, axis=None, weights=None, returned=False, *, keepdims=<no value>)",
      "documentation": {
        "description": "Compute the weighted average along the specified axis.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Array containing data to be averaged. If `a` is not an array, a\nconversion is attempted."
          },
          "axis": {
            "type": "None or int or tuple of ints, optional",
            "description": "Axis or axes along which to average `a`.  The default,\naxis=None, will average over all of the elements of the input array.\nIf axis is negative it counts from the last to the first axis.\n.. versionadded:: 1.7.0\nIf axis is a tuple of ints, averaging is performed on all of the axes\nspecified in the tuple instead of a single axis or all the axes as\nbefore."
          },
          "weights": {
            "type": "array_like, optional",
            "description": "An array of weights associated with the values in `a`. Each value in\n`a` contributes to the average according to its associated weight.\nThe weights array can either be 1-D (in which case its length must be\nthe size of `a` along the given axis) or of the same shape as `a`.\nIf `weights=None`, then all data in `a` are assumed to have a\nweight equal to one.  The 1-D calculation is::\navg = sum(a * weights) / sum(weights)\nThe only constraint on `weights` is that `sum(weights)` must not be 0."
          },
          "returned": {
            "type": "bool, optional",
            "description": "Default is `False`. If `True`, the tuple (`average`, `sum_of_weights`)\nis returned, otherwise only the average is returned.\nIf `weights=None`, `sum_of_weights` is equivalent to the number of\nelements over which the average is taken."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\nin the result as dimensions with size one. With this option,\nthe result will broadcast correctly against the original `a`.\n*Note:* `keepdims` will not work with instances of `numpy.matrix`\nor other classes whose methods do not support `keepdims`.\n.. versionadded:: 1.23.0"
          }
        },
        "returns": "-------\nretval, [sum_of_weights] : array_type or double\nReturn the average along the specified axis. When `returned` is `True`,\nreturn a tuple with the average as the first element and the sum\nof the weights as the second element. `sum_of_weights` is of the\nsame type as `retval`. The result dtype follows a genereal pattern.\nIf `weights` is None, the result dtype will be that of `a` , or ``float64``\nif `a` is integral. Otherwise, if `weights` is not None and `a` is non-\nintegral, the result type will be the type of lowest precision capable of\nrepresenting values of both `a` and `weights`. If `a` happens to be\nintegral, the previous rules still applies but the result dtype will\nat least be ``float64``.",
        "raises": "------\nZeroDivisionError\nWhen all weights along axis are zero. See `numpy.ma.average` for a\nversion robust to this type of error.\nTypeError\nWhen the length of 1D `weights` is not the same as the shape of `a`\nalong axis.",
        "see_also": "--------\nmean\nma.average : average for masked arrays -- useful if your data contains\n\"missing\" values\nnumpy.result_type : Returns the type that results from applying the\nnumpy type promotion rules to the arguments.",
        "notes": "",
        "examples": "--------\n>>> data = np.arange(1, 5)\n>>> data\narray([1, 2, 3, 4])\n>>> np.average(data)\n2.5\n>>> np.average(np.arange(1, 11), weights=np.arange(10, 0, -1))\n4.0\n>>> data = np.arange(6).reshape((3, 2))\n>>> data\narray([[0, 1],\n[2, 3],\n[4, 5]])\n>>> np.average(data, axis=1, weights=[1./4, 3./4])\narray([0.75, 2.75, 4.75])\n>>> np.average(data, weights=[1./4, 3./4])\nTraceback (most recent call last):\n...\nTypeError: Axis must be specified when shapes of a and weights differ.\n>>> a = np.ones(5, dtype=np.float128)\n>>> w = np.ones(5, dtype=np.complex64)\n>>> avg = np.average(a, weights=w)\n>>> print(avg.dtype)\ncomplex256\nWith ``keepdims=True``, the following result has shape (3, 1).\n>>> np.average(data, axis=1, keepdims=True)\narray([[0.5],\n[2.5],\n[4.5]])"
      }
    },
    {
      "name": "bartlett",
      "signature": "bartlett(M)",
      "documentation": {
        "description": "Return the Bartlett window.\nThe Bartlett window is very similar to a triangular window, except\nthat the end points are at zero.  It is often used in signal\nprocessing for tapering a signal, without generating too much\nripple in the frequency domain.",
        "parameters": {
          "M": {
            "type": "int",
            "description": "Number of points in the output window. If zero or less, an\nempty array is returned."
          }
        },
        "returns": "-------\nout : array\nThe triangular window, with the maximum value normalized to one\n(the value one appears only if the number of samples is odd), with\nthe first and last samples equal to zero.",
        "raises": "",
        "see_also": "--------\nblackman, hamming, hanning, kaiser",
        "notes": "-----\nThe Bartlett window is defined as\n.. math:: w(n) = \\frac{2}{M-1} \\left(\n\\frac{M-1}{2} - \\left|n - \\frac{M-1}{2}\\right|\n\\right)\nMost references to the Bartlett window come from the signal processing\nliterature, where it is used as one of many windowing functions for\nsmoothing values.  Note that convolution with this window produces linear\ninterpolation.  It is also known as an apodization (which means \"removing\nthe foot\", i.e. smoothing discontinuities at the beginning and end of the\nsampled signal) or tapering function. The Fourier transform of the\nBartlett window is the product of two sinc functions. Note the excellent\ndiscussion in Kanasewich [2]_.\nReferences\n----------\n.. [1] M.S. Bartlett, \"Periodogram Analysis and Continuous Spectra\",\nBiometrika 37, 1-16, 1950.\n.. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\",\nThe University of Alberta Press, 1975, pp. 109-110.\n.. [3] A.V. Oppenheim and R.W. Schafer, \"Discrete-Time Signal\nProcessing\", Prentice-Hall, 1999, pp. 468-471.\n.. [4] Wikipedia, \"Window function\",\nhttps://en.wikipedia.org/wiki/Window_function\n.. [5] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,\n\"Numerical Recipes\", Cambridge University Press, 1986, page 429.",
        "examples": "--------\n>>> import matplotlib.pyplot as plt\n>>> np.bartlett(12)\narray([ 0.        ,  0.18181818,  0.36363636,  0.54545455,  0.72727273, # may vary\n0.90909091,  0.90909091,  0.72727273,  0.54545455,  0.36363636,\n0.18181818,  0.        ])\nPlot the window and its frequency response (requires SciPy and matplotlib):\n>>> from numpy.fft import fft, fftshift\n>>> window = np.bartlett(51)\n>>> plt.plot(window)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Bartlett window\")\nText(0.5, 1.0, 'Bartlett window')\n>>> plt.ylabel(\"Amplitude\")\nText(0, 0.5, 'Amplitude')\n>>> plt.xlabel(\"Sample\")\nText(0.5, 0, 'Sample')\n>>> plt.show()\n>>> plt.figure()\n<Figure size 640x480 with 0 Axes>\n>>> A = fft(window, 2048) / 25.5\n>>> mag = np.abs(fftshift(A))\n>>> freq = np.linspace(-0.5, 0.5, len(A))\n>>> with np.errstate(divide='ignore', invalid='ignore'):\n...     response = 20 * np.log10(mag)\n...\n>>> response = np.clip(response, -100, 100)\n>>> plt.plot(freq, response)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Frequency response of Bartlett window\")\nText(0.5, 1.0, 'Frequency response of Bartlett window')\n>>> plt.ylabel(\"Magnitude [dB]\")\nText(0, 0.5, 'Magnitude [dB]')\n>>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\nText(0.5, 0, 'Normalized frequency [cycles per sample]')\n>>> _ = plt.axis('tight')\n>>> plt.show()"
      }
    },
    {
      "name": "bincount",
      "signature": "bincount(x, /, weights=None, minlength=0)",
      "documentation": {
        "description": "bincount(x, /, weights=None, minlength=0)\nCount number of occurrences of each value in array of non-negative ints.\nThe number of bins (of size 1) is one larger than the largest value in\n`x`. If `minlength` is specified, there will be at least this number\nof bins in the output array (though it will be longer if necessary,\ndepending on the contents of `x`).\nEach bin gives the number of occurrences of its index value in `x`.\nIf `weights` is specified the input array is weighted by it, i.e. if a\nvalue ``n`` is found at position ``i``, ``out[n] += weight[i]`` instead\nof ``out[n] += 1``.",
        "parameters": {
          "x": {
            "type": "array_like, 1 dimension, nonnegative ints",
            "description": "Input array."
          },
          "weights": {
            "type": "array_like, optional",
            "description": "Weights, array of the same shape as `x`."
          },
          "minlength": {
            "type": "int, optional",
            "description": "A minimum number of bins for the output array.\n.. versionadded:: 1.6.0"
          }
        },
        "returns": "-------\nout : ndarray of ints\nThe result of binning the input array.\nThe length of `out` is equal to ``np.amax(x)+1``.",
        "raises": "------\nValueError\nIf the input is not 1-dimensional, or contains elements with negative\nvalues, or if `minlength` is negative.\nTypeError\nIf the type of the input is float or complex.",
        "see_also": "--------\nhistogram, digitize, unique",
        "notes": "",
        "examples": "--------\n>>> np.bincount(np.arange(5))\narray([1, 1, 1, 1, 1])\n>>> np.bincount(np.array([0, 1, 1, 3, 2, 1, 7]))\narray([1, 3, 1, 1, 0, 0, 0, 1])\n>>> x = np.array([0, 1, 1, 3, 2, 1, 7, 23])\n>>> np.bincount(x).size == np.amax(x)+1\nTrue\nThe input array needs to be of integer dtype, otherwise a\nTypeError is raised:\n>>> np.bincount(np.arange(5, dtype=float))\nTraceback (most recent call last):\n...\nTypeError: Cannot cast array data from dtype('float64') to dtype('int64')\naccording to the rule 'safe'\nA possible use of ``bincount`` is to perform sums over\nvariable-size chunks of an array, using the ``weights`` keyword.\n>>> w = np.array([0.3, 0.5, 0.2, 0.7, 1., -0.6]) # weights\n>>> x = np.array([0, 1, 1, 2, 2, 2])\n>>> np.bincount(x,  weights=w)\narray([ 0.3,  0.7,  1.1])"
      }
    },
    {
      "name": "blackman",
      "signature": "blackman(M)",
      "documentation": {
        "description": "Return the Blackman window.\nThe Blackman window is a taper formed by using the first three\nterms of a summation of cosines. It was designed to have close to the\nminimal leakage possible.  It is close to optimal, only slightly worse\nthan a Kaiser window.",
        "parameters": {
          "M": {
            "type": "int",
            "description": "Number of points in the output window. If zero or less, an empty\narray is returned."
          }
        },
        "returns": "-------\nout : ndarray\nThe window, with the maximum value normalized to one (the value one\nappears only if the number of samples is odd).",
        "raises": "",
        "see_also": "--------\nbartlett, hamming, hanning, kaiser",
        "notes": "-----\nThe Blackman window is defined as\n.. math::  w(n) = 0.42 - 0.5 \\cos(2\\pi n/M) + 0.08 \\cos(4\\pi n/M)\nMost references to the Blackman window come from the signal processing\nliterature, where it is used as one of many windowing functions for\nsmoothing values.  It is also known as an apodization (which means\n\"removing the foot\", i.e. smoothing discontinuities at the beginning\nand end of the sampled signal) or tapering function. It is known as a\n\"near optimal\" tapering function, almost as good (by some measures)\nas the kaiser window.\nReferences\n----------\nBlackman, R.B. and Tukey, J.W., (1958) The measurement of power spectra,\nDover Publications, New York.\nOppenheim, A.V., and R.W. Schafer. Discrete-Time Signal Processing.\nUpper Saddle River, NJ: Prentice-Hall, 1999, pp. 468-471.",
        "examples": "--------\n>>> import matplotlib.pyplot as plt\n>>> np.blackman(12)\narray([-1.38777878e-17,   3.26064346e-02,   1.59903635e-01, # may vary\n4.14397981e-01,   7.36045180e-01,   9.67046769e-01,\n9.67046769e-01,   7.36045180e-01,   4.14397981e-01,\n1.59903635e-01,   3.26064346e-02,  -1.38777878e-17])\nPlot the window and the frequency response:\n>>> from numpy.fft import fft, fftshift\n>>> window = np.blackman(51)\n>>> plt.plot(window)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Blackman window\")\nText(0.5, 1.0, 'Blackman window')\n>>> plt.ylabel(\"Amplitude\")\nText(0, 0.5, 'Amplitude')\n>>> plt.xlabel(\"Sample\")\nText(0.5, 0, 'Sample')\n>>> plt.show()\n>>> plt.figure()\n<Figure size 640x480 with 0 Axes>\n>>> A = fft(window, 2048) / 25.5\n>>> mag = np.abs(fftshift(A))\n>>> freq = np.linspace(-0.5, 0.5, len(A))\n>>> with np.errstate(divide='ignore', invalid='ignore'):\n...     response = 20 * np.log10(mag)\n...\n>>> response = np.clip(response, -100, 100)\n>>> plt.plot(freq, response)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Frequency response of Blackman window\")\nText(0.5, 1.0, 'Frequency response of Blackman window')\n>>> plt.ylabel(\"Magnitude [dB]\")\nText(0, 0.5, 'Magnitude [dB]')\n>>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\nText(0.5, 0, 'Normalized frequency [cycles per sample]')\n>>> _ = plt.axis('tight')\n>>> plt.show()"
      }
    },
    {
      "name": "broadcast_arrays",
      "signature": "broadcast_arrays(*args, subok=False)",
      "documentation": {
        "description": "Broadcast any number of arrays against each other.",
        "parameters": {
          "subok": {
            "type": "bool, optional",
            "description": "If True, then sub-classes will be passed-through, otherwise\nthe returned arrays will be forced to be a base-class array (default)."
          }
        },
        "returns": "-------\nbroadcasted : list of arrays\nThese arrays are views on the original arrays.  They are typically\nnot contiguous.  Furthermore, more than one element of a\nbroadcasted array may refer to a single memory location. If you need\nto write to the arrays, make copies first. While you can set the\n``writable`` flag True, writing to a single output value may end up\nchanging more than one location in the output array.\n.. deprecated:: 1.17\nThe output is currently marked so that if written to, a deprecation\nwarning will be emitted. A future version will set the\n``writable`` flag False so writing to it will raise an error.",
        "raises": "",
        "see_also": "--------\nbroadcast\nbroadcast_to\nbroadcast_shapes",
        "notes": "",
        "examples": "--------\n>>> x = np.array([[1,2,3]])\n>>> y = np.array([[4],[5]])\n>>> np.broadcast_arrays(x, y)\n[array([[1, 2, 3],\n[1, 2, 3]]), array([[4, 4, 4],\n[5, 5, 5]])]\nHere is a useful idiom for getting contiguous copies instead of\nnon-contiguous views.\n>>> [np.array(a) for a in np.broadcast_arrays(x, y)]\n[array([[1, 2, 3],\n[1, 2, 3]]), array([[4, 4, 4],\n[5, 5, 5]])]"
      }
    },
    {
      "name": "broadcast_shapes",
      "signature": "broadcast_shapes(*args)",
      "documentation": {
        "description": "Broadcast the input shapes into a single shape.\n:ref:`Learn more about broadcasting here <basics.broadcasting>`.\n.. versionadded:: 1.20.0",
        "parameters": {},
        "returns": "-------\ntuple\nBroadcasted shape.",
        "raises": "------\nValueError\nIf the shapes are not compatible and cannot be broadcast according\nto NumPy's broadcasting rules.",
        "see_also": "--------\nbroadcast\nbroadcast_arrays\nbroadcast_to",
        "notes": "",
        "examples": "--------\n>>> np.broadcast_shapes((1, 2), (3, 1), (3, 2))\n(3, 2)\n>>> np.broadcast_shapes((6, 7), (5, 6, 1), (7,), (5, 1, 7))\n(5, 6, 7)"
      }
    },
    {
      "name": "broadcast_to",
      "signature": "broadcast_to(array, shape, subok=False)",
      "documentation": {
        "description": "Broadcast an array to a new shape.",
        "parameters": {
          "array": {
            "type": "array_like",
            "description": "The array to broadcast."
          },
          "shape": {
            "type": "tuple or int",
            "description": "The shape of the desired array. A single integer ``i`` is interpreted\nas ``(i,)``."
          },
          "subok": {
            "type": "bool, optional",
            "description": "If True, then sub-classes will be passed-through, otherwise\nthe returned array will be forced to be a base-class array (default)."
          }
        },
        "returns": "-------\nbroadcast : array\nA readonly view on the original array with the given shape. It is\ntypically not contiguous. Furthermore, more than one element of a\nbroadcasted array may refer to a single memory location.",
        "raises": "------\nValueError\nIf the array is not compatible with the new shape according to NumPy's\nbroadcasting rules.",
        "see_also": "--------\nbroadcast\nbroadcast_arrays\nbroadcast_shapes",
        "notes": "-----\n.. versionadded:: 1.10.0",
        "examples": "--------\n>>> x = np.array([1, 2, 3])\n>>> np.broadcast_to(x, (3, 3))\narray([[1, 2, 3],\n[1, 2, 3],\n[1, 2, 3]])"
      }
    },
    {
      "name": "byte_bounds",
      "signature": "byte_bounds(a)",
      "documentation": {
        "description": "",
        "parameters": {
          "a": {
            "type": "ndarray",
            "description": "Input array. It must conform to the Python-side of the array\ninterface."
          }
        },
        "returns": "-------\n(low, high) : tuple of 2 integers\nThe first integer is the first byte of the array, the second\ninteger is just past the last byte of the array.  If `a` is not\ncontiguous it will not use every byte between the (`low`, `high`)\nvalues.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n>>> I = np.eye(2, dtype='f'); I.dtype\ndtype('float32')\n>>> low, high = np.byte_bounds(I)\n>>> high - low == I.size*I.itemsize\nTrue\n>>> I = np.eye(2); I.dtype\ndtype('float64')\n>>> low, high = np.byte_bounds(I)\n>>> high - low == I.size*I.itemsize\nTrue"
      }
    },
    {
      "name": "column_stack",
      "signature": "column_stack(tup)",
      "documentation": {
        "description": "Stack 1-D arrays as columns into a 2-D array.\nTake a sequence of 1-D arrays and stack them as columns\nto make a single 2-D array. 2-D arrays are stacked as-is,\njust like with `hstack`.  1-D arrays are turned into 2-D columns\nfirst.",
        "parameters": {
          "tup": {
            "type": "sequence of 1-D or 2-D arrays.",
            "description": "Arrays to stack. All of them must have the same first dimension."
          }
        },
        "returns": "-------\nstacked : 2-D array\nThe array formed by stacking the given arrays.",
        "raises": "",
        "see_also": "--------\nstack, hstack, vstack, concatenate",
        "notes": "",
        "examples": "--------\n>>> a = np.array((1,2,3))\n>>> b = np.array((2,3,4))\n>>> np.column_stack((a,b))\narray([[1, 2],\n[2, 3],\n[3, 4]])"
      }
    },
    {
      "name": "common_type",
      "signature": "common_type(*arrays)",
      "documentation": {
        "description": "Return a scalar type which is common to the input arrays.\nThe return type will always be an inexact (i.e. floating point) scalar\ntype, even if all the arrays are integer arrays. If one of the inputs is\nan integer array, the minimum precision type that is returned is a\n64-bit floating point dtype.\nAll input arrays except int64 and uint64 can be safely cast to the\nreturned dtype without loss of information.",
        "parameters": {},
        "returns": "-------\nout : data type code\nData type code.",
        "raises": "",
        "see_also": "--------\ndtype, mintypecode",
        "notes": "",
        "examples": "--------\n>>> np.common_type(np.arange(2, dtype=np.float32))\n<class 'numpy.float32'>\n>>> np.common_type(np.arange(2, dtype=np.float32), np.arange(2))\n<class 'numpy.float64'>\n>>> np.common_type(np.arange(4), np.array([45, 6.j]), np.array([45.0]))\n<class 'numpy.complex128'>"
      }
    },
    {
      "name": "copy",
      "signature": "copy(a, order='K', subok=False)",
      "documentation": {
        "description": "Return an array copy of the given object.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input data."
          },
          "order": {
            "type": "{'C', 'F', 'A', 'K'}, optional",
            "description": "Controls the memory layout of the copy. 'C' means C-order,\n'F' means F-order, 'A' means 'F' if `a` is Fortran contiguous,\n'C' otherwise. 'K' means match the layout of `a` as closely\nas possible. (Note that this function and :meth:`ndarray.copy` are very\nsimilar, but have different default values for their order=\narguments.)"
          },
          "subok": {
            "type": "bool, optional",
            "description": "If True, then sub-classes will be passed-through, otherwise the\nreturned array will be forced to be a base-class array (defaults to False).\n.. versionadded:: 1.19.0"
          }
        },
        "returns": "-------\narr : ndarray\nArray interpretation of `a`.",
        "raises": "",
        "see_also": "--------\nndarray.copy : Preferred method for creating an array copy",
        "notes": "-----\nThis is equivalent to:\n>>> np.array(a, copy=True)  #doctest: +SKIP",
        "examples": "--------\nCreate an array x, with a reference y and a copy z:\n>>> x = np.array([1, 2, 3])\n>>> y = x\n>>> z = np.copy(x)\nNote that, when we modify x, y changes, but not z:\n>>> x[0] = 10\n>>> x[0] == y[0]\nTrue\n>>> x[0] == z[0]\nFalse\nNote that, np.copy clears previously set WRITEABLE=False flag.\n>>> a = np.array([1, 2, 3])\n>>> a.flags[\"WRITEABLE\"] = False\n>>> b = np.copy(a)\n>>> b.flags[\"WRITEABLE\"]\nTrue\n>>> b[0] = 3\n>>> b\narray([3, 2, 3])\nNote that np.copy is a shallow copy and will not copy object\nelements within arrays. This is mainly important for arrays\ncontaining Python objects. The new array will contain the\nsame object which may lead to surprises if that object can\nbe modified (is mutable):\n>>> a = np.array([1, 'm', [2, 3, 4]], dtype=object)\n>>> b = np.copy(a)\n>>> b[2][0] = 10\n>>> a\narray([1, 'm', list([10, 3, 4])], dtype=object)\nTo ensure all elements within an ``object`` array are copied,\nuse `copy.deepcopy`:\n>>> import copy\n>>> a = np.array([1, 'm', [2, 3, 4]], dtype=object)\n>>> c = copy.deepcopy(a)\n>>> c[2][0] = 10\n>>> c\narray([1, 'm', list([10, 3, 4])], dtype=object)\n>>> a\narray([1, 'm', list([2, 3, 4])], dtype=object)"
      }
    },
    {
      "name": "corrcoef",
      "signature": "corrcoef(x, y=None, rowvar=True, bias=<no value>, ddof=<no value>, *, dtype=None)",
      "documentation": {
        "description": "Return Pearson product-moment correlation coefficients.\nPlease refer to the documentation for `cov` for more detail.  The\nrelationship between the correlation coefficient matrix, `R`, and the\ncovariance matrix, `C`, is\n.. math:: R_{ij} = \\frac{ C_{ij} } { \\sqrt{ C_{ii} C_{jj} } }\nThe values of `R` are between -1 and 1, inclusive.",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "A 1-D or 2-D array containing multiple variables and observations.\nEach row of `x` represents a variable, and each column a single\nobservation of all those variables. Also see `rowvar` below."
          },
          "y": {
            "type": "array_like, optional",
            "description": "An additional set of variables and observations. `y` has the same\nshape as `x`."
          },
          "rowvar": {
            "type": "bool, optional",
            "description": "If `rowvar` is True (default), then each row represents a\nvariable, with observations in the columns. Otherwise, the relationship\nis transposed: each column represents a variable, while the rows\ncontain observations."
          },
          "bias": {
            "type": "_NoValue, optional",
            "description": "Has no effect, do not use.\n.. deprecated:: 1.10.0"
          },
          "ddof": {
            "type": "_NoValue, optional",
            "description": "Has no effect, do not use.\n.. deprecated:: 1.10.0"
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "Data-type of the result. By default, the return data-type will have\nat least `numpy.float64` precision.\n.. versionadded:: 1.20"
          }
        },
        "returns": "-------\nR : ndarray\nThe correlation coefficient matrix of the variables.",
        "raises": "",
        "see_also": "--------\ncov : Covariance matrix",
        "notes": "-----\nDue to floating point rounding the resulting array may not be Hermitian,\nthe diagonal elements may not be 1, and the elements may not satisfy the\ninequality abs(a) <= 1. The real and imaginary parts are clipped to the\ninterval [-1,  1] in an attempt to improve on that situation but is not\nmuch help in the complex case.\nThis function accepts but discards arguments `bias` and `ddof`.  This is\nfor backwards compatibility with previous versions of this function.  These\narguments had no effect on the return values of the function and can be\nsafely ignored in this and previous versions of numpy.",
        "examples": "--------\nIn this example we generate two random arrays, ``xarr`` and ``yarr``, and\ncompute the row-wise and column-wise Pearson correlation coefficients,\n``R``. Since ``rowvar`` is  true by  default, we first find the row-wise\nPearson correlation coefficients between the variables of ``xarr``.\n>>> import numpy as np\n>>> rng = np.random.default_rng(seed=42)\n>>> xarr = rng.random((3, 3))\n>>> xarr\narray([[0.77395605, 0.43887844, 0.85859792],\n[0.69736803, 0.09417735, 0.97562235],\n[0.7611397 , 0.78606431, 0.12811363]])\n>>> R1 = np.corrcoef(xarr)\n>>> R1\narray([[ 1.        ,  0.99256089, -0.68080986],\n[ 0.99256089,  1.        , -0.76492172],\n[-0.68080986, -0.76492172,  1.        ]])\nIf we add another set of variables and observations ``yarr``, we can\ncompute the row-wise Pearson correlation coefficients between the\nvariables in ``xarr`` and ``yarr``.\n>>> yarr = rng.random((3, 3))\n>>> yarr\narray([[0.45038594, 0.37079802, 0.92676499],\n[0.64386512, 0.82276161, 0.4434142 ],\n[0.22723872, 0.55458479, 0.06381726]])\n>>> R2 = np.corrcoef(xarr, yarr)\n>>> R2\narray([[ 1.        ,  0.99256089, -0.68080986,  0.75008178, -0.934284  ,\n-0.99004057],\n[ 0.99256089,  1.        , -0.76492172,  0.82502011, -0.97074098,\n-0.99981569],\n[-0.68080986, -0.76492172,  1.        , -0.99507202,  0.89721355,\n0.77714685],\n[ 0.75008178,  0.82502011, -0.99507202,  1.        , -0.93657855,\n-0.83571711],\n[-0.934284  , -0.97074098,  0.89721355, -0.93657855,  1.        ,\n0.97517215],\n[-0.99004057, -0.99981569,  0.77714685, -0.83571711,  0.97517215,\n1.        ]])\nFinally if we use the option ``rowvar=False``, the columns are now\nbeing treated as the variables and we will find the column-wise Pearson\ncorrelation coefficients between variables in ``xarr`` and ``yarr``.\n>>> R3 = np.corrcoef(xarr, yarr, rowvar=False)\n>>> R3\narray([[ 1.        ,  0.77598074, -0.47458546, -0.75078643, -0.9665554 ,\n0.22423734],\n[ 0.77598074,  1.        , -0.92346708, -0.99923895, -0.58826587,\n-0.44069024],\n[-0.47458546, -0.92346708,  1.        ,  0.93773029,  0.23297648,\n0.75137473],\n[-0.75078643, -0.99923895,  0.93773029,  1.        ,  0.55627469,\n0.47536961],\n[-0.9665554 , -0.58826587,  0.23297648,  0.55627469,  1.        ,\n-0.46666491],\n[ 0.22423734, -0.44069024,  0.75137473,  0.47536961, -0.46666491,\n1.        ]])"
      }
    },
    {
      "name": "cov",
      "signature": "cov(m, y=None, rowvar=True, bias=False, ddof=None, fweights=None, aweights=None, *, dtype=None)",
      "documentation": {
        "description": "Estimate a covariance matrix, given data and weights.\nCovariance indicates the level to which two variables vary together.\nIf we examine N-dimensional samples, :math:`X = [x_1, x_2, ... x_N]^T`,\nthen the covariance matrix element :math:`C_{ij}` is the covariance of\n:math:`x_i` and :math:`x_j`. The element :math:`C_{ii}` is the variance\nof :math:`x_i`.\nSee the notes for an outline of the algorithm.",
        "parameters": {
          "m": {
            "type": "array_like",
            "description": "A 1-D or 2-D array containing multiple variables and observations.\nEach row of `m` represents a variable, and each column a single\nobservation of all those variables. Also see `rowvar` below."
          },
          "y": {
            "type": "array_like, optional",
            "description": "An additional set of variables and observations. `y` has the same form\nas that of `m`."
          },
          "rowvar": {
            "type": "bool, optional",
            "description": "If `rowvar` is True (default), then each row represents a\nvariable, with observations in the columns. Otherwise, the relationship\nis transposed: each column represents a variable, while the rows\ncontain observations."
          },
          "bias": {
            "type": "bool, optional",
            "description": "Default normalization (False) is by ``(N - 1)``, where ``N`` is the\nnumber of observations given (unbiased estimate). If `bias` is True,\nthen normalization is by ``N``. These values can be overridden by using\nthe keyword ``ddof`` in numpy versions >= 1.5."
          },
          "ddof": {
            "type": "int, optional",
            "description": "If not ``None`` the default value implied by `bias` is overridden.\nNote that ``ddof=1`` will return the unbiased estimate, even if both\n`fweights` and `aweights` are specified, and ``ddof=0`` will return\nthe simple average. See the notes for the details. The default value\nis ``None``.\n.. versionadded:: 1.5"
          },
          "fweights": {
            "type": "array_like, int, optional",
            "description": "1-D array of integer frequency weights; the number of times each\nobservation vector should be repeated.\n.. versionadded:: 1.10"
          },
          "aweights": {
            "type": "array_like, optional",
            "description": "1-D array of observation vector weights. These relative weights are\ntypically large for observations considered \"important\" and smaller for\nobservations considered less \"important\". If ``ddof=0`` the array of\nweights can be used to assign probabilities to observation vectors.\n.. versionadded:: 1.10"
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "Data-type of the result. By default, the return data-type will have\nat least `numpy.float64` precision.\n.. versionadded:: 1.20"
          }
        },
        "returns": "-------\nout : ndarray\nThe covariance matrix of the variables.",
        "raises": "",
        "see_also": "--------\ncorrcoef : Normalized covariance matrix",
        "notes": "-----\nAssume that the observations are in the columns of the observation\narray `m` and let ``f = fweights`` and ``a = aweights`` for brevity. The\nsteps to compute the weighted covariance are as follows::\n>>> m = np.arange(10, dtype=np.float64)\n>>> f = np.arange(10) * 2\n>>> a = np.arange(10) ** 2.\n>>> ddof = 1\n>>> w = f * a\n>>> v1 = np.sum(w)\n>>> v2 = np.sum(w * a)\n>>> m -= np.sum(m * w, axis=None, keepdims=True) / v1\n>>> cov = np.dot(m * w, m.T) * v1 / (v1**2 - ddof * v2)\nNote that when ``a == 1``, the normalization factor\n``v1 / (v1**2 - ddof * v2)`` goes over to ``1 / (np.sum(f) - ddof)``\nas it should.",
        "examples": "--------\nConsider two variables, :math:`x_0` and :math:`x_1`, which\ncorrelate perfectly, but in opposite directions:\n>>> x = np.array([[0, 2], [1, 1], [2, 0]]).T\n>>> x\narray([[0, 1, 2],\n[2, 1, 0]])\nNote how :math:`x_0` increases while :math:`x_1` decreases. The covariance\nmatrix shows this clearly:\n>>> np.cov(x)\narray([[ 1., -1.],\n[-1.,  1.]])\nNote that element :math:`C_{0,1}`, which shows the correlation between\n:math:`x_0` and :math:`x_1`, is negative.\nFurther, note how `x` and `y` are combined:\n>>> x = [-2.1, -1,  4.3]\n>>> y = [3,  1.1,  0.12]\n>>> X = np.stack((x, y), axis=0)\n>>> np.cov(X)\narray([[11.71      , -4.286     ], # may vary\n[-4.286     ,  2.144133]])\n>>> np.cov(x, y)\narray([[11.71      , -4.286     ], # may vary\n[-4.286     ,  2.144133]])\n>>> np.cov(x)\narray(11.71)"
      }
    },
    {
      "name": "delete",
      "signature": "delete(arr, obj, axis=None)",
      "documentation": {
        "description": "Return a new array with sub-arrays along an axis deleted. For a one\ndimensional array, this returns those entries not returned by\n`arr[obj]`.",
        "parameters": {
          "arr": {
            "type": "array_like",
            "description": "Input array."
          },
          "obj": {
            "type": "slice, int or array of ints",
            "description": "Indicate indices of sub-arrays to remove along the specified axis.\n.. versionchanged:: 1.19.0\nBoolean indices are now treated as a mask of elements to remove,\nrather than being cast to the integers 0 and 1."
          },
          "axis": {
            "type": "int, optional",
            "description": "The axis along which to delete the subarray defined by `obj`.\nIf `axis` is None, `obj` is applied to the flattened array."
          }
        },
        "returns": "-------\nout : ndarray\nA copy of `arr` with the elements specified by `obj` removed. Note\nthat `delete` does not occur in-place. If `axis` is None, `out` is\na flattened array.",
        "raises": "",
        "see_also": "--------\ninsert : Insert elements into an array.\nappend : Append elements at the end of an array.",
        "notes": "-----\nOften it is preferable to use a boolean mask. For example:\n>>> arr = np.arange(12) + 1\n>>> mask = np.ones(len(arr), dtype=bool)\n>>> mask[[0,2,4]] = False\n>>> result = arr[mask,...]\nIs equivalent to ``np.delete(arr, [0,2,4], axis=0)``, but allows further\nuse of `mask`.",
        "examples": "--------\n>>> arr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n>>> arr\narray([[ 1,  2,  3,  4],\n[ 5,  6,  7,  8],\n[ 9, 10, 11, 12]])\n>>> np.delete(arr, 1, 0)\narray([[ 1,  2,  3,  4],\n[ 9, 10, 11, 12]])\n>>> np.delete(arr, np.s_[::2], 1)\narray([[ 2,  4],\n[ 6,  8],\n[10, 12]])\n>>> np.delete(arr, [1,3,5], None)\narray([ 1,  3,  5,  7,  8,  9, 10, 11, 12])"
      }
    },
    {
      "name": "deprecate",
      "signature": "deprecate(*args, **kwargs)",
      "documentation": {
        "description": "Issues a DeprecationWarning, adds warning to `old_name`'s\ndocstring, rebinds ``old_name.__name__`` and returns the new\nfunction object.\nThis function may also be used as a decorator.",
        "parameters": {
          "func": {
            "type": "function",
            "description": "The function to be deprecated."
          },
          "old_name": {
            "type": "str, optional",
            "description": "The name of the function to be deprecated. Default is None, in\nwhich case the name of `func` is used."
          },
          "new_name": {
            "type": "str, optional",
            "description": "The new name for the function. Default is None, in which case the\ndeprecation message is that `old_name` is deprecated. If given, the\ndeprecation message is that `old_name` is deprecated and `new_name`\nshould be used instead."
          },
          "message": {
            "type": "str, optional",
            "description": "Additional explanation of the deprecation.  Displayed in the\ndocstring after the warning."
          }
        },
        "returns": "-------\nold_func : function\nThe deprecated function.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\nNote that ``olduint`` returns a value after printing Deprecation\nWarning:\n>>> olduint = np.deprecate(np.uint)\nDeprecationWarning: `uint64` is deprecated! # may vary\n>>> olduint(6)\n6"
      }
    },
    {
      "name": "deprecate_with_doc",
      "signature": "deprecate_with_doc(msg)",
      "documentation": {
        "description": "Deprecates a function and includes the deprecation in its docstring.\nThis function is used as a decorator. It returns an object that can be\nused to issue a DeprecationWarning, by passing the to-be decorated\nfunction as argument, this adds warning to the to-be decorated function's\ndocstring and returns the new function object.",
        "parameters": {
          "msg": {
            "type": "str",
            "description": "Additional explanation of the deprecation. Displayed in the\ndocstring after the warning."
          }
        },
        "returns": "-------\nobj : object",
        "raises": "",
        "see_also": "--------\ndeprecate : Decorate a function such that it issues a `DeprecationWarning`",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "diag",
      "signature": "diag(v, k=0)",
      "documentation": {
        "description": "Extract a diagonal or construct a diagonal array.\nSee the more detailed documentation for ``numpy.diagonal`` if you use this\nfunction to extract a diagonal and wish to write to the resulting array;\nwhether it returns a copy or a view depends on what version of numpy you\nare using.",
        "parameters": {
          "v": {
            "type": "array_like",
            "description": "If `v` is a 2-D array, return a copy of its `k`-th diagonal.\nIf `v` is a 1-D array, return a 2-D array with `v` on the `k`-th\ndiagonal."
          },
          "k": {
            "type": "int, optional",
            "description": "Diagonal in question. The default is 0. Use `k>0` for diagonals\nabove the main diagonal, and `k<0` for diagonals below the main\ndiagonal."
          }
        },
        "returns": "-------\nout : ndarray\nThe extracted diagonal or constructed diagonal array.",
        "raises": "",
        "see_also": "--------\ndiagonal : Return specified diagonals.\ndiagflat : Create a 2-D array with the flattened input as a diagonal.\ntrace : Sum along diagonals.\ntriu : Upper triangle of an array.\ntril : Lower triangle of an array.",
        "notes": "",
        "examples": "--------\n>>> x = np.arange(9).reshape((3,3))\n>>> x\narray([[0, 1, 2],\n[3, 4, 5],\n[6, 7, 8]])\n>>> np.diag(x)\narray([0, 4, 8])\n>>> np.diag(x, k=1)\narray([1, 5])\n>>> np.diag(x, k=-1)\narray([3, 7])\n>>> np.diag(np.diag(x))\narray([[0, 0, 0],\n[0, 4, 0],\n[0, 0, 8]])"
      }
    },
    {
      "name": "diag_indices",
      "signature": "diag_indices(n, ndim=2)",
      "documentation": {
        "description": "Return the indices to access the main diagonal of an array.\nThis returns a tuple of indices that can be used to access the main\ndiagonal of an array `a` with ``a.ndim >= 2`` dimensions and shape\n(n, n, ..., n). For ``a.ndim = 2`` this is the usual diagonal, for\n``a.ndim > 2`` this is the set of indices to access ``a[i, i, ..., i]``\nfor ``i = [0..n-1]``.",
        "parameters": {
          "n": {
            "type": "int",
            "description": "The size, along each dimension, of the arrays for which the returned\nindices can be used."
          },
          "ndim": {
            "type": "int, optional",
            "description": "The number of dimensions."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\ndiag_indices_from",
        "notes": "-----\n.. versionadded:: 1.4.0",
        "examples": "--------\nCreate a set of indices to access the diagonal of a (4, 4) array:\n>>> di = np.diag_indices(4)\n>>> di\n(array([0, 1, 2, 3]), array([0, 1, 2, 3]))\n>>> a = np.arange(16).reshape(4, 4)\n>>> a\narray([[ 0,  1,  2,  3],\n[ 4,  5,  6,  7],\n[ 8,  9, 10, 11],\n[12, 13, 14, 15]])\n>>> a[di] = 100\n>>> a\narray([[100,   1,   2,   3],\n[  4, 100,   6,   7],\n[  8,   9, 100,  11],\n[ 12,  13,  14, 100]])\nNow, we create indices to manipulate a 3-D array:\n>>> d3 = np.diag_indices(2, 3)\n>>> d3\n(array([0, 1]), array([0, 1]), array([0, 1]))\nAnd use it to set the diagonal of an array of zeros to 1:\n>>> a = np.zeros((2, 2, 2), dtype=int)\n>>> a[d3] = 1\n>>> a\narray([[[1, 0],\n[0, 0]],\n[[0, 0],\n[0, 1]]])"
      }
    },
    {
      "name": "diag_indices_from",
      "signature": "diag_indices_from(arr)",
      "documentation": {
        "description": "Return the indices to access the main diagonal of an n-dimensional array.\nSee `diag_indices` for full details.",
        "parameters": {
          "arr": {
            "type": "array, at least 2-D",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\ndiag_indices",
        "notes": "-----\n.. versionadded:: 1.4.0",
        "examples": "--------\nCreate a 4 by 4 array.\n>>> a = np.arange(16).reshape(4, 4)\n>>> a\narray([[ 0,  1,  2,  3],\n[ 4,  5,  6,  7],\n[ 8,  9, 10, 11],\n[12, 13, 14, 15]])\nGet the indices of the diagonal elements.\n>>> di = np.diag_indices_from(a)\n>>> di\n(array([0, 1, 2, 3]), array([0, 1, 2, 3]))\n>>> a[di]\narray([ 0,  5, 10, 15])\nThis is simply syntactic sugar for diag_indices.\n>>> np.diag_indices(a.shape[0])\n(array([0, 1, 2, 3]), array([0, 1, 2, 3]))"
      }
    },
    {
      "name": "diagflat",
      "signature": "diagflat(v, k=0)",
      "documentation": {
        "description": "Create a two-dimensional array with the flattened input as a diagonal.",
        "parameters": {
          "v": {
            "type": "array_like",
            "description": "Input data, which is flattened and set as the `k`-th\ndiagonal of the output."
          },
          "k": {
            "type": "int, optional",
            "description": "Diagonal to set; 0, the default, corresponds to the \"main\" diagonal,\na positive (negative) `k` giving the number of the diagonal above\n(below) the main."
          }
        },
        "returns": "-------\nout : ndarray\nThe 2-D output array.",
        "raises": "",
        "see_also": "--------\ndiag : MATLAB work-alike for 1-D and 2-D arrays.\ndiagonal : Return specified diagonals.\ntrace : Sum along diagonals.",
        "notes": "",
        "examples": "--------\n>>> np.diagflat([[1,2], [3,4]])\narray([[1, 0, 0, 0],\n[0, 2, 0, 0],\n[0, 0, 3, 0],\n[0, 0, 0, 4]])\n>>> np.diagflat([1,2], 1)\narray([[0, 1, 0],\n[0, 0, 2],\n[0, 0, 0]])"
      }
    },
    {
      "name": "diff",
      "signature": "diff(a, n=1, axis=-1, prepend=<no value>, append=<no value>)",
      "documentation": {
        "description": "Calculate the n-th discrete difference along the given axis.\nThe first difference is given by ``out[i] = a[i+1] - a[i]`` along\nthe given axis, higher differences are calculated by using `diff`\nrecursively.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array"
          },
          "n": {
            "type": "int, optional",
            "description": "The number of times values are differenced. If zero, the input\nis returned as-is."
          },
          "axis": {
            "type": "int, optional",
            "description": "The axis along which the difference is taken, default is the\nlast axis.\nprepend, append : array_like, optional\nValues to prepend or append to `a` along axis prior to\nperforming the difference.  Scalar values are expanded to\narrays with length 1 in the direction of axis and the shape\nof the input array in along all other axes.  Otherwise the\ndimension and shape must match `a` except along axis.\n.. versionadded:: 1.16.0"
          }
        },
        "returns": "-------\ndiff : ndarray\nThe n-th differences. The shape of the output is the same as `a`\nexcept along `axis` where the dimension is smaller by `n`. The\ntype of the output is the same as the type of the difference\nbetween any two elements of `a`. This is the same as the type of\n`a` in most cases. A notable exception is `datetime64`, which\nresults in a `timedelta64` output array.",
        "raises": "",
        "see_also": "--------\ngradient, ediff1d, cumsum",
        "notes": "-----\nType is preserved for boolean arrays, so the result will contain\n`False` when consecutive elements are the same and `True` when they\ndiffer.\nFor unsigned integer arrays, the results will also be unsigned. This\nshould not be surprising, as the result is consistent with\ncalculating the difference directly:\n>>> u8_arr = np.array([1, 0], dtype=np.uint8)\n>>> np.diff(u8_arr)\narray([255], dtype=uint8)\n>>> u8_arr[1,...] - u8_arr[0,...]\n255\nIf this is not desirable, then the array should be cast to a larger\ninteger type first:\n>>> i16_arr = u8_arr.astype(np.int16)\n>>> np.diff(i16_arr)\narray([-1], dtype=int16)",
        "examples": "--------\n>>> x = np.array([1, 2, 4, 7, 0])\n>>> np.diff(x)\narray([ 1,  2,  3, -7])\n>>> np.diff(x, n=2)\narray([  1,   1, -10])\n>>> x = np.array([[1, 3, 6, 10], [0, 5, 6, 8]])\n>>> np.diff(x)\narray([[2, 3, 4],\n[5, 1, 2]])\n>>> np.diff(x, axis=0)\narray([[-1,  2,  0, -2]])\n>>> x = np.arange('1066-10-13', '1066-10-16', dtype=np.datetime64)\n>>> np.diff(x)\narray([1, 1], dtype='timedelta64[D]')"
      }
    },
    {
      "name": "digitize",
      "signature": "digitize(x, bins, right=False)",
      "documentation": {
        "description": "Return the indices of the bins to which each value in input array belongs.\n=========  =============  ============================\n`right`    order of bins  returned index `i` satisfies\n=========  =============  ============================\n``False``  increasing     ``bins[i-1] <= x < bins[i]``\n``True``   increasing     ``bins[i-1] < x <= bins[i]``\n``False``  decreasing     ``bins[i-1] > x >= bins[i]``\n``True``   decreasing     ``bins[i-1] >= x > bins[i]``\n=========  =============  ============================\nIf values in `x` are beyond the bounds of `bins`, 0 or ``len(bins)`` is\nreturned as appropriate.",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "Input array to be binned. Prior to NumPy 1.10.0, this array had to\nbe 1-dimensional, but can now have any shape."
          },
          "bins": {
            "type": "array_like",
            "description": "Array of bins. It has to be 1-dimensional and monotonic."
          },
          "right": {
            "type": "bool, optional",
            "description": "Indicating whether the intervals include the right or the left bin\nedge. Default behavior is (right==False) indicating that the interval\ndoes not include the right edge. The left bin end is open in this\ncase, i.e., bins[i-1] <= x < bins[i] is the default behavior for\nmonotonically increasing bins."
          }
        },
        "returns": "-------\nindices : ndarray of ints\nOutput array of indices, of same shape as `x`.",
        "raises": "------\nValueError\nIf `bins` is not monotonic.\nTypeError\nIf the type of the input is complex.",
        "see_also": "--------\nbincount, histogram, unique, searchsorted",
        "notes": "-----\nIf values in `x` are such that they fall outside the bin range,\nattempting to index `bins` with the indices that `digitize` returns\nwill result in an IndexError.\n.. versionadded:: 1.10.0\n`np.digitize` is  implemented in terms of `np.searchsorted`. This means\nthat a binary search is used to bin the values, which scales much better\nfor larger number of bins than the previous linear search. It also removes\nthe requirement for the input array to be 1-dimensional.\nFor monotonically _increasing_ `bins`, the following are equivalent::\nnp.digitize(x, bins, right=True)\nnp.searchsorted(bins, x, side='left')\nNote that as the order of the arguments are reversed, the side must be too.\nThe `searchsorted` call is marginally faster, as it does not do any\nmonotonicity checks. Perhaps more importantly, it supports all dtypes.",
        "examples": "--------\n>>> x = np.array([0.2, 6.4, 3.0, 1.6])\n>>> bins = np.array([0.0, 1.0, 2.5, 4.0, 10.0])\n>>> inds = np.digitize(x, bins)\n>>> inds\narray([1, 4, 3, 2])\n>>> for n in range(x.size):\n...   print(bins[inds[n]-1], \"<=\", x[n], \"<\", bins[inds[n]])\n...\n0.0 <= 0.2 < 1.0\n4.0 <= 6.4 < 10.0\n2.5 <= 3.0 < 4.0\n1.0 <= 1.6 < 2.5\n>>> x = np.array([1.2, 10.0, 12.4, 15.5, 20.])\n>>> bins = np.array([0, 5, 10, 15, 20])\n>>> np.digitize(x,bins,right=True)\narray([1, 2, 3, 4, 4])\n>>> np.digitize(x,bins,right=False)\narray([1, 3, 3, 4, 5])"
      }
    },
    {
      "name": "disp",
      "signature": "disp(mesg, device=None, linefeed=True)",
      "documentation": {
        "description": "Display a message on a device.",
        "parameters": {
          "mesg": {
            "type": "str",
            "description": "Message to display."
          },
          "device": {
            "type": "object",
            "description": "Device to write message. If None, defaults to ``sys.stdout`` which is\nvery similar to ``print``. `device` needs to have ``write()`` and\n``flush()`` methods."
          },
          "linefeed": {
            "type": "bool, optional",
            "description": "Option whether to print a line feed or not. Defaults to True."
          }
        },
        "returns": "",
        "raises": "------\nAttributeError\nIf `device` does not have a ``write()`` or ``flush()`` method.",
        "see_also": "",
        "notes": "",
        "examples": "--------\nBesides ``sys.stdout``, a file-like object can also be used as it has\nboth required methods:\n>>> from io import StringIO\n>>> buf = StringIO()\n>>> np.disp(u'\"Display\" in a file', device=buf)\n>>> buf.getvalue()\n'\"Display\" in a file\\n'"
      }
    },
    {
      "name": "dsplit",
      "signature": "dsplit(ary, indices_or_sections)",
      "documentation": {
        "description": "Split array into multiple sub-arrays along the 3rd axis (depth).\nPlease refer to the `split` documentation.  `dsplit` is equivalent\nto `split` with ``axis=2``, the array is always split along the third\naxis provided the array dimension is greater than or equal to 3.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "--------\nsplit : Split an array into multiple sub-arrays of equal size.",
        "notes": "",
        "examples": "--------\n>>> x = np.arange(16.0).reshape(2, 2, 4)\n>>> x\narray([[[ 0.,   1.,   2.,   3.],\n[ 4.,   5.,   6.,   7.]],\n[[ 8.,   9.,  10.,  11.],\n[12.,  13.,  14.,  15.]]])\n>>> np.dsplit(x, 2)\n[array([[[ 0.,  1.],\n[ 4.,  5.]],\n[[ 8.,  9.],\n[12., 13.]]]), array([[[ 2.,  3.],\n[ 6.,  7.]],\n[[10., 11.],\n[14., 15.]]])]\n>>> np.dsplit(x, np.array([3, 6]))\n[array([[[ 0.,   1.,   2.],\n[ 4.,   5.,   6.]],\n[[ 8.,   9.,  10.],\n[12.,  13.,  14.]]]),\narray([[[ 3.],\n[ 7.]],\n[[11.],\n[15.]]]),\narray([], shape=(2, 2, 0), dtype=float64)]"
      }
    },
    {
      "name": "dstack",
      "signature": "dstack(tup)",
      "documentation": {
        "description": "Stack arrays in sequence depth wise (along third axis).\nThis is equivalent to concatenation along the third axis after 2-D arrays\nof shape `(M,N)` have been reshaped to `(M,N,1)` and 1-D arrays of shape\n`(N,)` have been reshaped to `(1,N,1)`. Rebuilds arrays divided by\n`dsplit`.\nThis function makes most sense for arrays with up to 3 dimensions. For\ninstance, for pixel-data with a height (first axis), width (second axis),\nand r/g/b channels (third axis). The functions `concatenate`, `stack` and\n`block` provide more general stacking and concatenation operations.",
        "parameters": {
          "tup": {
            "type": "sequence of arrays",
            "description": "The arrays must have the same shape along all but the third axis.\n1-D or 2-D arrays must have the same shape."
          }
        },
        "returns": "-------\nstacked : ndarray\nThe array formed by stacking the given arrays, will be at least 3-D.",
        "raises": "",
        "see_also": "--------\nconcatenate : Join a sequence of arrays along an existing axis.\nstack : Join a sequence of arrays along a new axis.\nblock : Assemble an nd-array from nested lists of blocks.\nvstack : Stack arrays in sequence vertically (row wise).\nhstack : Stack arrays in sequence horizontally (column wise).\ncolumn_stack : Stack 1-D arrays as columns into a 2-D array.\ndsplit : Split array along third axis.",
        "notes": "",
        "examples": "--------\n>>> a = np.array((1,2,3))\n>>> b = np.array((2,3,4))\n>>> np.dstack((a,b))\narray([[[1, 2],\n[2, 3],\n[3, 4]]])\n>>> a = np.array([[1],[2],[3]])\n>>> b = np.array([[2],[3],[4]])\n>>> np.dstack((a,b))\narray([[[1, 2]],\n[[2, 3]],\n[[3, 4]]])"
      }
    },
    {
      "name": "ediff1d",
      "signature": "ediff1d(ary, to_end=None, to_begin=None)",
      "documentation": {
        "description": "The differences between consecutive elements of an array.",
        "parameters": {
          "ary": {
            "type": "array_like",
            "description": "If necessary, will be flattened before the differences are taken."
          },
          "to_end": {
            "type": "array_like, optional",
            "description": "Number(s) to append at the end of the returned differences."
          },
          "to_begin": {
            "type": "array_like, optional",
            "description": "Number(s) to prepend at the beginning of the returned differences."
          }
        },
        "returns": "-------\nediff1d : ndarray\nThe differences. Loosely, this is ``ary.flat[1:] - ary.flat[:-1]``.",
        "raises": "",
        "see_also": "--------\ndiff, gradient",
        "notes": "-----\nWhen applied to masked arrays, this function drops the mask information\nif the `to_begin` and/or `to_end` parameters are used.",
        "examples": "--------\n>>> x = np.array([1, 2, 4, 7, 0])\n>>> np.ediff1d(x)\narray([ 1,  2,  3, -7])\n>>> np.ediff1d(x, to_begin=-99, to_end=np.array([88, 99]))\narray([-99,   1,   2, ...,  -7,  88,  99])\nThe returned array is always 1D.\n>>> y = [[1, 2, 4], [1, 6, 24]]\n>>> np.ediff1d(y)\narray([ 1,  2, -3,  5, 18])"
      }
    },
    {
      "name": "expand_dims",
      "signature": "expand_dims(a, axis)",
      "documentation": {
        "description": "Expand the shape of an array.\nInsert a new axis that will appear at the `axis` position in the expanded\narray shape.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array."
          },
          "axis": {
            "type": "int or tuple of ints",
            "description": "Position in the expanded axes where the new axis (or axes) is placed.\n.. deprecated:: 1.13.0\nPassing an axis where ``axis > a.ndim`` will be treated as\n``axis == a.ndim``, and passing ``axis < -a.ndim - 1`` will\nbe treated as ``axis == 0``. This behavior is deprecated.\n.. versionchanged:: 1.18.0\nA tuple of axes is now supported.  Out of range axes as\ndescribed above are now forbidden and raise an `AxisError`."
          }
        },
        "returns": "-------\nresult : ndarray\nView of `a` with the number of dimensions increased.",
        "raises": "",
        "see_also": "--------\nsqueeze : The inverse operation, removing singleton dimensions\nreshape : Insert, remove, and combine dimensions, and resize existing ones\ndoc.indexing, atleast_1d, atleast_2d, atleast_3d",
        "notes": "",
        "examples": "--------\n>>> x = np.array([1, 2])\n>>> x.shape\n(2,)\nThe following is equivalent to ``x[np.newaxis, :]`` or ``x[np.newaxis]``:\n>>> y = np.expand_dims(x, axis=0)\n>>> y\narray([[1, 2]])\n>>> y.shape\n(1, 2)\nThe following is equivalent to ``x[:, np.newaxis]``:\n>>> y = np.expand_dims(x, axis=1)\n>>> y\narray([[1],\n[2]])\n>>> y.shape\n(2, 1)\n``axis`` may also be a tuple:\n>>> y = np.expand_dims(x, axis=(0, 1))\n>>> y\narray([[[1, 2]]])\n>>> y = np.expand_dims(x, axis=(2, 0))\n>>> y\narray([[[1],\n[2]]])\nNote that some examples may use ``None`` instead of ``np.newaxis``.  These\nare the same objects:\n>>> np.newaxis is None\nTrue"
      }
    },
    {
      "name": "extract",
      "signature": "extract(condition, arr)",
      "documentation": {
        "description": "Return the elements of an array that satisfy some condition.\nThis is equivalent to ``np.compress(ravel(condition), ravel(arr))``.  If\n`condition` is boolean ``np.extract`` is equivalent to ``arr[condition]``.\nNote that `place` does the exact opposite of `extract`.",
        "parameters": {
          "condition": {
            "type": "array_like",
            "description": "An array whose nonzero or True entries indicate the elements of `arr`\nto extract."
          },
          "arr": {
            "type": "array_like",
            "description": "Input array of the same size as `condition`."
          }
        },
        "returns": "-------\nextract : ndarray\nRank 1 array of values from `arr` where `condition` is True.",
        "raises": "",
        "see_also": "--------\ntake, put, copyto, compress, place",
        "notes": "",
        "examples": "--------\n>>> arr = np.arange(12).reshape((3, 4))\n>>> arr\narray([[ 0,  1,  2,  3],\n[ 4,  5,  6,  7],\n[ 8,  9, 10, 11]])\n>>> condition = np.mod(arr, 3)==0\n>>> condition\narray([[ True, False, False,  True],\n[False, False,  True, False],\n[False,  True, False, False]])\n>>> np.extract(condition, arr)\narray([0, 3, 6, 9])\nIf `condition` is boolean:\n>>> arr[condition]\narray([0, 3, 6, 9])"
      }
    },
    {
      "name": "eye",
      "signature": "eye(N, M=None, k=0, dtype=<class 'float'>, order='C', *, like=None)",
      "documentation": {
        "description": "Return a 2-D array with ones on the diagonal and zeros elsewhere.",
        "parameters": {
          "N": {
            "type": "int",
            "description": "Number of rows in the output."
          },
          "M": {
            "type": "int, optional",
            "description": "Number of columns in the output. If None, defaults to `N`."
          },
          "k": {
            "type": "int, optional",
            "description": "Index of the diagonal: 0 (the default) refers to the main diagonal,\na positive value refers to an upper diagonal, and a negative value\nto a lower diagonal."
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "Data-type of the returned array."
          },
          "order": {
            "type": "{'C', 'F'}, optional",
            "description": "Whether the output should be stored in row-major (C-style) or\ncolumn-major (Fortran-style) order in memory.\n.. versionadded:: 1.14.0"
          },
          "like": {
            "type": "array_like, optional",
            "description": "Reference object to allow the creation of arrays which are not\nNumPy arrays. If an array-like passed in as ``like`` supports\nthe ``__array_function__`` protocol, the result will be defined\nby it. In this case, it ensures the creation of an array object\ncompatible with that passed in via this argument.\n.. versionadded:: 1.20.0"
          }
        },
        "returns": "-------\nI : ndarray of shape (N,M)\nAn array where all elements are equal to zero, except for the `k`-th\ndiagonal, whose values are equal to one.",
        "raises": "",
        "see_also": "--------\nidentity : (almost) equivalent function\ndiag : diagonal 2-D array from a 1-D array specified by the user.",
        "notes": "",
        "examples": "--------\n>>> np.eye(2, dtype=int)\narray([[1, 0],\n[0, 1]])\n>>> np.eye(3, k=1)\narray([[0.,  1.,  0.],\n[0.,  0.,  1.],\n[0.,  0.,  0.]])"
      }
    },
    {
      "name": "fill_diagonal",
      "signature": "fill_diagonal(a, val, wrap=False)",
      "documentation": {
        "description": "Fill the main diagonal of the given array of any dimensionality.\nFor an array `a` with ``a.ndim >= 2``, the diagonal is the list of\nlocations with indices ``a[i, ..., i]`` all identical. This function\nmodifies the input array in-place, it does not return a value.",
        "parameters": {
          "a": {
            "type": "array, at least 2-D.",
            "description": "Array whose diagonal is to be filled, it gets modified in-place."
          },
          "val": {
            "type": "scalar or array_like",
            "description": "Value(s) to write on the diagonal. If `val` is scalar, the value is\nwritten along the diagonal. If array-like, the flattened `val` is\nwritten along the diagonal, repeating if necessary to fill all\ndiagonal entries."
          },
          "wrap": {
            "type": "bool",
            "description": "For tall matrices in NumPy version up to 1.6.2, the\ndiagonal \"wrapped\" after N columns. You can have this behavior\nwith this option. This affects only tall matrices.\nSee also\n--------\ndiag_indices, diag_indices_from"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "-----\n.. versionadded:: 1.4.0\nThis functionality can be obtained via `diag_indices`, but internally\nthis version uses a much faster implementation that never constructs the\nindices and uses simple slicing.",
        "examples": "--------\n>>> a = np.zeros((3, 3), int)\n>>> np.fill_diagonal(a, 5)\n>>> a\narray([[5, 0, 0],\n[0, 5, 0],\n[0, 0, 5]])\nThe same function can operate on a 4-D array:\n>>> a = np.zeros((3, 3, 3, 3), int)\n>>> np.fill_diagonal(a, 4)\nWe only show a few blocks for clarity:\n>>> a[0, 0]\narray([[4, 0, 0],\n[0, 0, 0],\n[0, 0, 0]])\n>>> a[1, 1]\narray([[0, 0, 0],\n[0, 4, 0],\n[0, 0, 0]])\n>>> a[2, 2]\narray([[0, 0, 0],\n[0, 0, 0],\n[0, 0, 4]])\nThe wrap option affects only tall matrices:\n>>> # tall matrices no wrap\n>>> a = np.zeros((5, 3), int)\n>>> np.fill_diagonal(a, 4)\n>>> a\narray([[4, 0, 0],\n[0, 4, 0],\n[0, 0, 4],\n[0, 0, 0],\n[0, 0, 0]])\n>>> # tall matrices wrap\n>>> a = np.zeros((5, 3), int)\n>>> np.fill_diagonal(a, 4, wrap=True)\n>>> a\narray([[4, 0, 0],\n[0, 4, 0],\n[0, 0, 4],\n[0, 0, 0],\n[4, 0, 0]])\n>>> # wide matrices\n>>> a = np.zeros((3, 5), int)\n>>> np.fill_diagonal(a, 4, wrap=True)\n>>> a\narray([[4, 0, 0, 0, 0],\n[0, 4, 0, 0, 0],\n[0, 0, 4, 0, 0]])\nThe anti-diagonal can be filled by reversing the order of elements\nusing either `numpy.flipud` or `numpy.fliplr`.\n>>> a = np.zeros((3, 3), int);\n>>> np.fill_diagonal(np.fliplr(a), [1,2,3])  # Horizontal flip\n>>> a\narray([[0, 0, 1],\n[0, 2, 0],\n[3, 0, 0]])\n>>> np.fill_diagonal(np.flipud(a), [1,2,3])  # Vertical flip\n>>> a\narray([[0, 0, 3],\n[0, 2, 0],\n[1, 0, 0]])\nNote that the order in which the diagonal is filled varies depending\non the flip function."
      }
    },
    {
      "name": "fix",
      "signature": "fix(x, out=None)",
      "documentation": {
        "description": "Round to nearest integer towards zero.\nRound an array of floats element-wise to nearest integer towards zero.\nThe rounded values are returned as floats.",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "An array of floats to be rounded"
          },
          "out": {
            "type": "ndarray, optional",
            "description": "A location into which the result is stored. If provided, it must have\na shape that the input broadcasts to. If not provided or None, a\nfreshly-allocated array is returned."
          }
        },
        "returns": "-------\nout : ndarray of floats\nA float array with the same dimensions as the input.\nIf second argument is not supplied then a float array is returned\nwith the rounded values.\nIf a second argument is supplied the result is stored there.\nThe return value `out` is then a reference to that array.",
        "raises": "",
        "see_also": "--------\nrint, trunc, floor, ceil\naround : Round to given number of decimals",
        "notes": "",
        "examples": "--------\n>>> np.fix(3.14)\n3.0\n>>> np.fix(3)\n3.0\n>>> np.fix([2.1, 2.9, -2.1, -2.9])\narray([ 2.,  2., -2., -2.])"
      }
    },
    {
      "name": "flip",
      "signature": "flip(m, axis=None)",
      "documentation": {
        "description": "Reverse the order of elements in an array along the given axis.\nThe shape of the array is preserved, but the elements are reordered.\n.. versionadded:: 1.12.0",
        "parameters": {
          "m": {
            "type": "array_like",
            "description": "Input array."
          },
          "axis": {
            "type": "None or int or tuple of ints, optional",
            "description": "Axis or axes along which to flip over. The default,\naxis=None, will flip over all of the axes of the input array.\nIf axis is negative it counts from the last to the first axis.\nIf axis is a tuple of ints, flipping is performed on all of the axes\nspecified in the tuple.\n.. versionchanged:: 1.15.0\nNone and tuples of axes are supported"
          }
        },
        "returns": "-------\nout : array_like\nA view of `m` with the entries of axis reversed.  Since a view is\nreturned, this operation is done in constant time.",
        "raises": "",
        "see_also": "--------\nflipud : Flip an array vertically (axis=0).\nfliplr : Flip an array horizontally (axis=1).",
        "notes": "-----\nflip(m, 0) is equivalent to flipud(m).\nflip(m, 1) is equivalent to fliplr(m).\nflip(m, n) corresponds to ``m[...,::-1,...]`` with ``::-1`` at position n.\nflip(m) corresponds to ``m[::-1,::-1,...,::-1]`` with ``::-1`` at all\npositions.\nflip(m, (0, 1)) corresponds to ``m[::-1,::-1,...]`` with ``::-1`` at\nposition 0 and position 1.",
        "examples": "--------\n>>> A = np.arange(8).reshape((2,2,2))\n>>> A\narray([[[0, 1],\n[2, 3]],\n[[4, 5],\n[6, 7]]])\n>>> np.flip(A, 0)\narray([[[4, 5],\n[6, 7]],\n[[0, 1],\n[2, 3]]])\n>>> np.flip(A, 1)\narray([[[2, 3],\n[0, 1]],\n[[6, 7],\n[4, 5]]])\n>>> np.flip(A)\narray([[[7, 6],\n[5, 4]],\n[[3, 2],\n[1, 0]]])\n>>> np.flip(A, (0, 2))\narray([[[5, 4],\n[7, 6]],\n[[1, 0],\n[3, 2]]])\n>>> A = np.random.randn(3,4,5)\n>>> np.all(np.flip(A,2) == A[:,:,::-1,...])\nTrue"
      }
    },
    {
      "name": "fliplr",
      "signature": "fliplr(m)",
      "documentation": {
        "description": "Reverse the order of elements along axis 1 (left/right).\nFor a 2-D array, this flips the entries in each row in the left/right\ndirection. Columns are preserved, but appear in a different order than\nbefore.",
        "parameters": {
          "m": {
            "type": "array_like",
            "description": "Input array, must be at least 2-D."
          }
        },
        "returns": "-------\nf : ndarray\nA view of `m` with the columns reversed.  Since a view\nis returned, this operation is :math:`\\mathcal O(1)`.",
        "raises": "",
        "see_also": "--------\nflipud : Flip array in the up/down direction.\nflip : Flip array in one or more dimensions.\nrot90 : Rotate array counterclockwise.",
        "notes": "-----\nEquivalent to ``m[:,::-1]`` or ``np.flip(m, axis=1)``.\nRequires the array to be at least 2-D.",
        "examples": "--------\n>>> A = np.diag([1.,2.,3.])\n>>> A\narray([[1.,  0.,  0.],\n[0.,  2.,  0.],\n[0.,  0.,  3.]])\n>>> np.fliplr(A)\narray([[0.,  0.,  1.],\n[0.,  2.,  0.],\n[3.,  0.,  0.]])\n>>> A = np.random.randn(2,3,5)\n>>> np.all(np.fliplr(A) == A[:,::-1,...])\nTrue"
      }
    },
    {
      "name": "flipud",
      "signature": "flipud(m)",
      "documentation": {
        "description": "Reverse the order of elements along axis 0 (up/down).\nFor a 2-D array, this flips the entries in each column in the up/down\ndirection. Rows are preserved, but appear in a different order than before.",
        "parameters": {
          "m": {
            "type": "array_like",
            "description": "Input array."
          }
        },
        "returns": "-------\nout : array_like\nA view of `m` with the rows reversed.  Since a view is\nreturned, this operation is :math:`\\mathcal O(1)`.",
        "raises": "",
        "see_also": "--------\nfliplr : Flip array in the left/right direction.\nflip : Flip array in one or more dimensions.\nrot90 : Rotate array counterclockwise.",
        "notes": "-----\nEquivalent to ``m[::-1, ...]`` or ``np.flip(m, axis=0)``.\nRequires the array to be at least 1-D.",
        "examples": "--------\n>>> A = np.diag([1.0, 2, 3])\n>>> A\narray([[1.,  0.,  0.],\n[0.,  2.,  0.],\n[0.,  0.,  3.]])\n>>> np.flipud(A)\narray([[0.,  0.,  3.],\n[0.,  2.,  0.],\n[1.,  0.,  0.]])\n>>> A = np.random.randn(2,3,5)\n>>> np.all(np.flipud(A) == A[::-1,...])\nTrue\n>>> np.flipud([1,2])\narray([2, 1])"
      }
    },
    {
      "name": "fromregex",
      "signature": "fromregex(file, regexp, dtype, encoding=None)",
      "documentation": {
        "description": "Construct an array from a text file, using regular expression parsing.\nThe returned array is always a structured array, and is constructed from\nall matches of the regular expression in the file. Groups in the regular\nexpression are converted to fields of the structured array.",
        "parameters": {
          "file": {
            "type": "path or file",
            "description": "Filename or file object to read.\n.. versionchanged:: 1.22.0\nNow accepts `os.PathLike` implementations."
          },
          "regexp": {
            "type": "str or regexp",
            "description": "Regular expression used to parse the file.\nGroups in the regular expression correspond to fields in the dtype."
          },
          "dtype": {
            "type": "dtype or list of dtypes",
            "description": "Dtype for the structured array; must be a structured datatype."
          },
          "encoding": {
            "type": "str, optional",
            "description": "Encoding used to decode the inputfile. Does not apply to input streams.\n.. versionadded:: 1.14.0"
          }
        },
        "returns": "-------\noutput : ndarray\nThe output array, containing the part of the content of `file` that\nwas matched by `regexp`. `output` is always a structured array.",
        "raises": "------\nTypeError\nWhen `dtype` is not a valid dtype for a structured array.",
        "see_also": "--------\nfromstring, loadtxt",
        "notes": "-----\nDtypes for structured arrays can be specified in several forms, but all\nforms specify at least the data type and field name. For details see\n`basics.rec`.",
        "examples": "--------\n>>> from io import StringIO\n>>> text = StringIO(\"1312 foo\\n1534  bar\\n444   qux\")\n>>> regexp = r\"(\\d+)\\s+(...)\"  # match [digits, whitespace, anything]\n>>> output = np.fromregex(text, regexp,\n...                       [('num', np.int64), ('key', 'S3')])\n>>> output\narray([(1312, b'foo'), (1534, b'bar'), ( 444, b'qux')],\ndtype=[('num', '<i8'), ('key', 'S3')])\n>>> output['num']\narray([1312, 1534,  444])"
      }
    },
    {
      "name": "genfromtxt",
      "signature": "genfromtxt(fname, dtype=<class 'float'>, comments='#', delimiter=None, skip_header=0, skip_footer=0, converters=None, missing_values=None, filling_values=None, usecols=None, names=None, excludelist=None, deletechars=\" !#$%&'()*+,-./:;<=>?@[\\\\]^{|}~\", replace_space='_', autostrip=False, case_sensitive=True, defaultfmt='f%i', unpack=None, usemask=False, loose=True, invalid_raise=True, max_rows=None, encoding='bytes', *, ndmin=0, like=None)",
      "documentation": {
        "description": "Load data from a text file, with missing values handled as specified.\nEach line past the first `skip_header` lines is split at the `delimiter`\ncharacter, and characters following the `comments` character are discarded.",
        "parameters": {
          "fname": {
            "type": "file, str, pathlib.Path, list of str, generator",
            "description": "File, filename, list, or generator to read.  If the filename\nextension is ``.gz`` or ``.bz2``, the file is first decompressed. Note\nthat generators must return bytes or strings. The strings\nin a list or produced by a generator are treated as lines."
          },
          "dtype": {
            "type": "dtype, optional",
            "description": "Data type of the resulting array.\nIf None, the dtypes will be determined by the contents of each\ncolumn, individually."
          },
          "comments": {
            "type": "str, optional",
            "description": "The character used to indicate the start of a comment.\nAll the characters occurring on a line after a comment are discarded."
          },
          "delimiter": {
            "type": "str, int, or sequence, optional",
            "description": "The string used to separate values.  By default, any consecutive\nwhitespaces act as delimiter.  An integer or sequence of integers\ncan also be provided as width(s) of each field."
          },
          "skiprows": {
            "type": "int, optional",
            "description": "`skiprows` was removed in numpy 1.10. Please use `skip_header` instead."
          },
          "skip_header": {
            "type": "int, optional",
            "description": "The number of lines to skip at the beginning of the file."
          },
          "skip_footer": {
            "type": "int, optional",
            "description": "The number of lines to skip at the end of the file."
          },
          "converters": {
            "type": "variable, optional",
            "description": "The set of functions that convert the data of a column to a value.\nThe converters can also be used to provide a default value\nfor missing data: ``converters = {3: lambda s: float(s or 0)}``."
          },
          "missing": {
            "type": "variable, optional",
            "description": "`missing` was removed in numpy 1.10. Please use `missing_values`\ninstead."
          },
          "missing_values": {
            "type": "variable, optional",
            "description": "The set of strings corresponding to missing data."
          },
          "filling_values": {
            "type": "variable, optional",
            "description": "The set of values to be used as default when the data are missing."
          },
          "usecols": {
            "type": "sequence, optional",
            "description": "Which columns to read, with 0 being the first.  For example,\n``usecols = (1, 4, 5)`` will extract the 2nd, 5th and 6th columns."
          },
          "names": {
            "type": "{None, True, str, sequence}, optional",
            "description": "If `names` is True, the field names are read from the first line after\nthe first `skip_header` lines. This line can optionally be preceded\nby a comment delimiter. If `names` is a sequence or a single-string of\ncomma-separated names, the names will be used to define the field names\nin a structured dtype. If `names` is None, the names of the dtype\nfields will be used, if any."
          },
          "excludelist": {
            "type": "sequence, optional",
            "description": "A list of names to exclude. This list is appended to the default list\n['return','file','print']. Excluded names are appended with an"
          },
          "underscore": {
            "type": "for example, `file` would become `file_`.",
            "description": ""
          },
          "deletechars": {
            "type": "str, optional",
            "description": "A string combining invalid characters that must be deleted from the\nnames."
          },
          "defaultfmt": {
            "type": "str, optional",
            "description": "A format used to define default field names, such as \"f%i\" or \"f_%02i\"."
          },
          "autostrip": {
            "type": "bool, optional",
            "description": "Whether to automatically strip white spaces from the variables."
          },
          "replace_space": {
            "type": "char, optional",
            "description": "Character(s) used in replacement of white spaces in the variable\nnames. By default, use a '_'."
          },
          "case_sensitive": {
            "type": "{True, False, 'upper', 'lower'}, optional",
            "description": "If True, field names are case sensitive.\nIf False or 'upper', field names are converted to upper case.\nIf 'lower', field names are converted to lower case."
          },
          "unpack": {
            "type": "bool, optional",
            "description": "If True, the returned array is transposed, so that arguments may be\nunpacked using ``x, y, z = genfromtxt(...)``.  When used with a\nstructured data-type, arrays are returned for each field.\nDefault is False."
          },
          "usemask": {
            "type": "bool, optional",
            "description": "If True, return a masked array.\nIf False, return a regular array."
          },
          "loose": {
            "type": "bool, optional",
            "description": "If True, do not raise errors for invalid values."
          },
          "invalid_raise": {
            "type": "bool, optional",
            "description": "If True, an exception is raised if an inconsistency is detected in the\nnumber of columns.\nIf False, a warning is emitted and the offending lines are skipped."
          },
          "max_rows": {
            "type": "int,  optional",
            "description": "The maximum number of rows to read. Must not be used with skip_footer\nat the same time.  If given, the value must be at least 1. Default is\nto read the entire file.\n.. versionadded:: 1.10.0"
          },
          "encoding": {
            "type": "str, optional",
            "description": "Encoding used to decode the inputfile. Does not apply when `fname` is\na file object.  The special value 'bytes' enables backward compatibility\nworkarounds that ensure that you receive byte arrays when possible\nand passes latin1 encoded strings to converters. Override this value to\nreceive unicode arrays and pass strings as input to converters.  If set\nto None the system default is used. The default value is 'bytes'.\n.. versionadded:: 1.14.0"
          },
          "ndmin": {
            "type": "int, optional",
            "description": "Same parameter as `loadtxt`\n.. versionadded:: 1.23.0"
          },
          "like": {
            "type": "array_like, optional",
            "description": "Reference object to allow the creation of arrays which are not\nNumPy arrays. If an array-like passed in as ``like`` supports\nthe ``__array_function__`` protocol, the result will be defined\nby it. In this case, it ensures the creation of an array object\ncompatible with that passed in via this argument.\n.. versionadded:: 1.20.0"
          }
        },
        "returns": "-------\nout : ndarray\nData read from the text file. If `usemask` is True, this is a\nmasked array.",
        "raises": "",
        "see_also": "--------\nnumpy.loadtxt : equivalent function when no data is missing.",
        "notes": "-----\n* When spaces are used as delimiters, or when no delimiter has been given\nas input, there should not be any missing data between two fields.\n* When the variables are named (either by a flexible dtype or with `names`),\nthere must not be any header in the file (else a ValueError\nexception is raised).\n* Individual values are not stripped of spaces by default.\nWhen using a custom converter, make sure the function does remove spaces.\nReferences\n----------\n.. [1] NumPy User Guide, section `I/O with NumPy\n<https://docs.scipy.org/doc/numpy/user/basics.io.genfromtxt.html>`_.",
        "examples": "--------\n>>> from io import StringIO\n>>> import numpy as np\nComma delimited file with mixed dtype\n>>> s = StringIO(u\"1,1.3,abcde\")\n>>> data = np.genfromtxt(s, dtype=[('myint','i8'),('myfloat','f8'),\n... ('mystring','S5')], delimiter=\",\")\n>>> data\narray((1, 1.3, b'abcde'),\ndtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])\nUsing dtype = None\n>>> _ = s.seek(0) # needed for StringIO example only\n>>> data = np.genfromtxt(s, dtype=None,\n... names = ['myint','myfloat','mystring'], delimiter=\",\")\n>>> data\narray((1, 1.3, b'abcde'),\ndtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])\nSpecifying dtype and names\n>>> _ = s.seek(0)\n>>> data = np.genfromtxt(s, dtype=\"i8,f8,S5\",\n... names=['myint','myfloat','mystring'], delimiter=\",\")\n>>> data\narray((1, 1.3, b'abcde'),\ndtype=[('myint', '<i8'), ('myfloat', '<f8'), ('mystring', 'S5')])\nAn example with fixed-width columns\n>>> s = StringIO(u\"11.3abcde\")\n>>> data = np.genfromtxt(s, dtype=None, names=['intvar','fltvar','strvar'],\n...     delimiter=[1,3,5])\n>>> data\narray((1, 1.3, b'abcde'),\ndtype=[('intvar', '<i8'), ('fltvar', '<f8'), ('strvar', 'S5')])\nAn example to show comments\n>>> f = StringIO('''\n... text,# of chars\n... hello world,11\n... numpy,5''')\n>>> np.genfromtxt(f, dtype='S12,S12', delimiter=',')\narray([(b'text', b''), (b'hello world', b'11'), (b'numpy', b'5')],\ndtype=[('f0', 'S12'), ('f1', 'S12')])"
      }
    },
    {
      "name": "get_array_wrap",
      "signature": "get_array_wrap(*args)",
      "documentation": {
        "description": "Find the wrapper for the array with the highest priority.\nIn case of ties, leftmost wins. If no wrapper is found, return None",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "get_include",
      "signature": "get_include()",
      "documentation": {
        "description": "Return the directory that contains the NumPy \\*.h header files.\nExtension modules that need to compile against NumPy should use this\nfunction to locate the appropriate include directory.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "-----\nWhen using ``distutils``, for example in ``setup.py``::\nimport numpy as np\n...\nExtension('extension_name', ...\ninclude_dirs=[np.get_include()])\n...",
        "examples": ""
      }
    },
    {
      "name": "gradient",
      "signature": "gradient(f, *varargs, axis=None, edge_order=1)",
      "documentation": {
        "description": "Return the gradient of an N-dimensional array.\nThe gradient is computed using second order accurate central differences\nin the interior points and either first or second order accurate one-sides\n(forward or backwards) differences at the boundaries.\nThe returned gradient hence has the same shape as the input array.",
        "parameters": {
          "f": {
            "type": "array_like",
            "description": "An N-dimensional array containing samples of a scalar function."
          },
          "varargs": {
            "type": "list of scalar or array, optional",
            "description": "Spacing between f values. Default unitary spacing for all dimensions.\nSpacing can be specified using:\n1. single scalar to specify a sample distance for all dimensions.\n2. N scalars to specify a constant sample distance for each dimension.\ni.e. `dx`, `dy`, `dz`, ...\n3. N arrays to specify the coordinates of the values along each\ndimension of F. The length of the array must match the size of\nthe corresponding dimension\n4. Any combination of N scalars/arrays with the meaning of 2. and 3.\nIf `axis` is given, the number of varargs must equal the number of axes."
          },
          "Default": {
            "type": "1.",
            "description": ""
          },
          "edge_order": {
            "type": "{1, 2}, optional",
            "description": "Gradient is calculated using N-th order accurate differences\nat the boundaries. Default: 1.\n.. versionadded:: 1.9.1"
          },
          "axis": {
            "type": "None or int or tuple of ints, optional",
            "description": "Gradient is calculated only along the given axis or axes\nThe default (axis = None) is to calculate the gradient for all the axes\nof the input array. axis may be negative, in which case it counts from\nthe last to the first axis.\n.. versionadded:: 1.11.0"
          }
        },
        "returns": "-------\ngradient : ndarray or list of ndarray\nA list of ndarrays (or a single ndarray if there is only one dimension)\ncorresponding to the derivatives of f with respect to each dimension.\nEach derivative has the same shape as f.",
        "raises": "",
        "see_also": "",
        "notes": "-----\nAssuming that :math:`f\\in C^{3}` (i.e., :math:`f` has at least 3 continuous\nderivatives) and let :math:`h_{*}` be a non-homogeneous stepsize, we\nminimize the \"consistency error\" :math:`\\eta_{i}` between the true gradient\nand its estimate from a linear combination of the neighboring grid-points:\n.. math::\n\\eta_{i} = f_{i}^{\\left(1\\right)} -\n\\left[ \\alpha f\\left(x_{i}\\right) +\n\\beta f\\left(x_{i} + h_{d}\\right) +\n\\gamma f\\left(x_{i}-h_{s}\\right)\n\\right]\nBy substituting :math:`f(x_{i} + h_{d})` and :math:`f(x_{i} - h_{s})`\nwith their Taylor series expansion, this translates into solving\nthe following the linear system:\n.. math::\n\\left\\{\n\\begin{array}{r}\n\\alpha+\\beta+\\gamma=0 \\\\\n\\beta h_{d}-\\gamma h_{s}=1 \\\\\n\\beta h_{d}^{2}+\\gamma h_{s}^{2}=0\n\\end{array}\n\\right.\nThe resulting approximation of :math:`f_{i}^{(1)}` is the following:\n.. math::\n\\hat f_{i}^{(1)} =\n\\frac{\nh_{s}^{2}f\\left(x_{i} + h_{d}\\right)\n+ \\left(h_{d}^{2} - h_{s}^{2}\\right)f\\left(x_{i}\\right)\n- h_{d}^{2}f\\left(x_{i}-h_{s}\\right)}\n{ h_{s}h_{d}\\left(h_{d} + h_{s}\\right)}\n+ \\mathcal{O}\\left(\\frac{h_{d}h_{s}^{2}\n+ h_{s}h_{d}^{2}}{h_{d}\n+ h_{s}}\\right)\nIt is worth noting that if :math:`h_{s}=h_{d}`\n(i.e., data are evenly spaced)\nwe find the standard second order approximation:\n.. math::\n\\hat f_{i}^{(1)}=\n\\frac{f\\left(x_{i+1}\\right) - f\\left(x_{i-1}\\right)}{2h}\n+ \\mathcal{O}\\left(h^{2}\\right)\nWith a similar procedure the forward/backward approximations used for\nboundaries can be derived.\nReferences\n----------\n.. [1]  Quarteroni A., Sacco R., Saleri F. (2007) Numerical Mathematics\n(Texts in Applied Mathematics). New York: Springer.\n.. [2]  Durran D. R. (1999) Numerical Methods for Wave Equations\nin Geophysical Fluid Dynamics. New York: Springer.\n.. [3]  Fornberg B. (1988) Generation of Finite Difference Formulas on\nArbitrarily Spaced Grids,\nMathematics of Computation 51, no. 184 : 699-706.\n`PDF <http://www.ams.org/journals/mcom/1988-51-184/\nS0025-5718-1988-0935077-0/S0025-5718-1988-0935077-0.pdf>`_.",
        "examples": "--------\n>>> f = np.array([1, 2, 4, 7, 11, 16], dtype=float)\n>>> np.gradient(f)\narray([1. , 1.5, 2.5, 3.5, 4.5, 5. ])\n>>> np.gradient(f, 2)\narray([0.5 ,  0.75,  1.25,  1.75,  2.25,  2.5 ])\nSpacing can be also specified with an array that represents the coordinates\nof the values F along the dimensions.\nFor instance a uniform spacing:\n>>> x = np.arange(f.size)\n>>> np.gradient(f, x)\narray([1. ,  1.5,  2.5,  3.5,  4.5,  5. ])\nOr a non uniform one:\n>>> x = np.array([0., 1., 1.5, 3.5, 4., 6.], dtype=float)\n>>> np.gradient(f, x)\narray([1. ,  3. ,  3.5,  6.7,  6.9,  2.5])\nFor two dimensional arrays, the return will be two arrays ordered by\naxis. In this example the first array stands for the gradient in\nrows and the second one in columns direction:\n>>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float))\n[array([[ 2.,  2., -1.],\n[ 2.,  2., -1.]]), array([[1. , 2.5, 4. ],\n[1. , 1. , 1. ]])]\nIn this example the spacing is also specified:\nuniform for axis=0 and non uniform for axis=1\n>>> dx = 2.\n>>> y = [1., 1.5, 3.5]\n>>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float), dx, y)\n[array([[ 1. ,  1. , -0.5],\n[ 1. ,  1. , -0.5]]), array([[2. , 2. , 2. ],\n[2. , 1.7, 0.5]])]\nIt is possible to specify how boundaries are treated using `edge_order`\n>>> x = np.array([0, 1, 2, 3, 4])\n>>> f = x**2\n>>> np.gradient(f, edge_order=1)\narray([1.,  2.,  4.,  6.,  7.])\n>>> np.gradient(f, edge_order=2)\narray([0., 2., 4., 6., 8.])\nThe `axis` keyword can be used to specify a subset of axes of which the\ngradient is calculated\n>>> np.gradient(np.array([[1, 2, 6], [3, 4, 5]], dtype=float), axis=0)\narray([[ 2.,  2., -1.],\n[ 2.,  2., -1.]])"
      }
    },
    {
      "name": "hamming",
      "signature": "hamming(M)",
      "documentation": {
        "description": "Return the Hamming window.\nThe Hamming window is a taper formed by using a weighted cosine.",
        "parameters": {
          "M": {
            "type": "int",
            "description": "Number of points in the output window. If zero or less, an\nempty array is returned."
          }
        },
        "returns": "-------\nout : ndarray\nThe window, with the maximum value normalized to one (the value\none appears only if the number of samples is odd).",
        "raises": "",
        "see_also": "--------\nbartlett, blackman, hanning, kaiser",
        "notes": "-----\nThe Hamming window is defined as\n.. math::  w(n) = 0.54 - 0.46\\cos\\left(\\frac{2\\pi{n}}{M-1}\\right)\n\\qquad 0 \\leq n \\leq M-1\nThe Hamming was named for R. W. Hamming, an associate of J. W. Tukey\nand is described in Blackman and Tukey. It was recommended for\nsmoothing the truncated autocovariance function in the time domain.\nMost references to the Hamming window come from the signal processing\nliterature, where it is used as one of many windowing functions for\nsmoothing values.  It is also known as an apodization (which means\n\"removing the foot\", i.e. smoothing discontinuities at the beginning\nand end of the sampled signal) or tapering function.\nReferences\n----------\n.. [1] Blackman, R.B. and Tukey, J.W., (1958) The measurement of power\nspectra, Dover Publications, New York.\n.. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\", The\nUniversity of Alberta Press, 1975, pp. 109-110.\n.. [3] Wikipedia, \"Window function\",\nhttps://en.wikipedia.org/wiki/Window_function\n.. [4] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,\n\"Numerical Recipes\", Cambridge University Press, 1986, page 425.",
        "examples": "--------\n>>> np.hamming(12)\narray([ 0.08      ,  0.15302337,  0.34890909,  0.60546483,  0.84123594, # may vary\n0.98136677,  0.98136677,  0.84123594,  0.60546483,  0.34890909,\n0.15302337,  0.08      ])\nPlot the window and the frequency response:\n>>> import matplotlib.pyplot as plt\n>>> from numpy.fft import fft, fftshift\n>>> window = np.hamming(51)\n>>> plt.plot(window)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Hamming window\")\nText(0.5, 1.0, 'Hamming window')\n>>> plt.ylabel(\"Amplitude\")\nText(0, 0.5, 'Amplitude')\n>>> plt.xlabel(\"Sample\")\nText(0.5, 0, 'Sample')\n>>> plt.show()\n>>> plt.figure()\n<Figure size 640x480 with 0 Axes>\n>>> A = fft(window, 2048) / 25.5\n>>> mag = np.abs(fftshift(A))\n>>> freq = np.linspace(-0.5, 0.5, len(A))\n>>> response = 20 * np.log10(mag)\n>>> response = np.clip(response, -100, 100)\n>>> plt.plot(freq, response)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Frequency response of Hamming window\")\nText(0.5, 1.0, 'Frequency response of Hamming window')\n>>> plt.ylabel(\"Magnitude [dB]\")\nText(0, 0.5, 'Magnitude [dB]')\n>>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\nText(0.5, 0, 'Normalized frequency [cycles per sample]')\n>>> plt.axis('tight')\n...\n>>> plt.show()"
      }
    },
    {
      "name": "hanning",
      "signature": "hanning(M)",
      "documentation": {
        "description": "Return the Hanning window.\nThe Hanning window is a taper formed by using a weighted cosine.",
        "parameters": {
          "M": {
            "type": "int",
            "description": "Number of points in the output window. If zero or less, an\nempty array is returned."
          }
        },
        "returns": "-------\nout : ndarray, shape(M,)\nThe window, with the maximum value normalized to one (the value\none appears only if `M` is odd).",
        "raises": "",
        "see_also": "--------\nbartlett, blackman, hamming, kaiser",
        "notes": "-----\nThe Hanning window is defined as\n.. math::  w(n) = 0.5 - 0.5\\cos\\left(\\frac{2\\pi{n}}{M-1}\\right)\n\\qquad 0 \\leq n \\leq M-1\nThe Hanning was named for Julius von Hann, an Austrian meteorologist.\nIt is also known as the Cosine Bell. Some authors prefer that it be\ncalled a Hann window, to help avoid confusion with the very similar\nHamming window.\nMost references to the Hanning window come from the signal processing\nliterature, where it is used as one of many windowing functions for\nsmoothing values.  It is also known as an apodization (which means\n\"removing the foot\", i.e. smoothing discontinuities at the beginning\nand end of the sampled signal) or tapering function.\nReferences\n----------\n.. [1] Blackman, R.B. and Tukey, J.W., (1958) The measurement of power\nspectra, Dover Publications, New York.\n.. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\",\nThe University of Alberta Press, 1975, pp. 106-108.\n.. [3] Wikipedia, \"Window function\",\nhttps://en.wikipedia.org/wiki/Window_function\n.. [4] W.H. Press,  B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling,\n\"Numerical Recipes\", Cambridge University Press, 1986, page 425.",
        "examples": "--------\n>>> np.hanning(12)\narray([0.        , 0.07937323, 0.29229249, 0.57115742, 0.82743037,\n0.97974649, 0.97974649, 0.82743037, 0.57115742, 0.29229249,\n0.07937323, 0.        ])\nPlot the window and its frequency response:\n>>> import matplotlib.pyplot as plt\n>>> from numpy.fft import fft, fftshift\n>>> window = np.hanning(51)\n>>> plt.plot(window)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Hann window\")\nText(0.5, 1.0, 'Hann window')\n>>> plt.ylabel(\"Amplitude\")\nText(0, 0.5, 'Amplitude')\n>>> plt.xlabel(\"Sample\")\nText(0.5, 0, 'Sample')\n>>> plt.show()\n>>> plt.figure()\n<Figure size 640x480 with 0 Axes>\n>>> A = fft(window, 2048) / 25.5\n>>> mag = np.abs(fftshift(A))\n>>> freq = np.linspace(-0.5, 0.5, len(A))\n>>> with np.errstate(divide='ignore', invalid='ignore'):\n...     response = 20 * np.log10(mag)\n...\n>>> response = np.clip(response, -100, 100)\n>>> plt.plot(freq, response)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Frequency response of the Hann window\")\nText(0.5, 1.0, 'Frequency response of the Hann window')\n>>> plt.ylabel(\"Magnitude [dB]\")\nText(0, 0.5, 'Magnitude [dB]')\n>>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\nText(0.5, 0, 'Normalized frequency [cycles per sample]')\n>>> plt.axis('tight')\n...\n>>> plt.show()"
      }
    },
    {
      "name": "histogram",
      "signature": "histogram(a, bins=10, range=None, density=None, weights=None)",
      "documentation": {
        "description": "Compute the histogram of a dataset.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input data. The histogram is computed over the flattened array."
          },
          "bins": {
            "type": "int or sequence of scalars or str, optional",
            "description": "If `bins` is an int, it defines the number of equal-width\nbins in the given range (10, by default). If `bins` is a\nsequence, it defines a monotonically increasing array of bin edges,\nincluding the rightmost edge, allowing for non-uniform bin widths.\n.. versionadded:: 1.11.0\nIf `bins` is a string, it defines the method used to calculate the\noptimal bin width, as defined by `histogram_bin_edges`."
          },
          "range": {
            "type": "(float, float), optional",
            "description": "The lower and upper range of the bins.  If not provided, range\nis simply ``(a.min(), a.max())``.  Values outside the range are\nignored. The first element of the range must be less than or\nequal to the second. `range` affects the automatic bin\ncomputation as well. While bin width is computed to be optimal\nbased on the actual data within `range`, the bin count will fill\nthe entire range including portions containing no data."
          },
          "weights": {
            "type": "array_like, optional",
            "description": "An array of weights, of the same shape as `a`.  Each value in\n`a` only contributes its associated weight towards the bin count\n(instead of 1). If `density` is True, the weights are\nnormalized, so that the integral of the density over the range\nremains 1."
          },
          "density": {
            "type": "bool, optional",
            "description": "If ``False``, the result will contain the number of samples in\neach bin. If ``True``, the result is the value of the\nprobability *density* function at the bin, normalized such that\nthe *integral* over the range is 1. Note that the sum of the\nhistogram values will not be equal to 1 unless bins of unity\nwidth are chosen; it is not a probability *mass* function."
          }
        },
        "returns": "-------\nhist : array\nThe values of the histogram. See `density` and `weights` for a\ndescription of the possible semantics.\nbin_edges : array of dtype float\nReturn the bin edges ``(length(hist)+1)``.",
        "raises": "",
        "see_also": "--------\nhistogramdd, bincount, searchsorted, digitize, histogram_bin_edges",
        "notes": "-----\nAll but the last (righthand-most) bin is half-open.  In other words,\nif `bins` is::\n[1, 2, 3, 4]\nthen the first bin is ``[1, 2)`` (including 1, but excluding 2) and\nthe second ``[2, 3)``.  The last bin, however, is ``[3, 4]``, which\n*includes* 4.",
        "examples": "--------\n>>> np.histogram([1, 2, 1], bins=[0, 1, 2, 3])\n(array([0, 2, 1]), array([0, 1, 2, 3]))\n>>> np.histogram(np.arange(4), bins=np.arange(5), density=True)\n(array([0.25, 0.25, 0.25, 0.25]), array([0, 1, 2, 3, 4]))\n>>> np.histogram([[1, 2, 1], [1, 0, 1]], bins=[0,1,2,3])\n(array([1, 4, 1]), array([0, 1, 2, 3]))\n>>> a = np.arange(5)\n>>> hist, bin_edges = np.histogram(a, density=True)\n>>> hist\narray([0.5, 0. , 0.5, 0. , 0. , 0.5, 0. , 0.5, 0. , 0.5])\n>>> hist.sum()\n2.4999999999999996\n>>> np.sum(hist * np.diff(bin_edges))\n1.0\n.. versionadded:: 1.11.0\nAutomated Bin Selection Methods example, using 2 peak random data\nwith 2000 points:\n>>> import matplotlib.pyplot as plt\n>>> rng = np.random.RandomState(10)  # deterministic random data\n>>> a = np.hstack((rng.normal(size=1000),\n...                rng.normal(loc=5, scale=2, size=1000)))\n>>> _ = plt.hist(a, bins='auto')  # arguments are passed to np.histogram\n>>> plt.title(\"Histogram with 'auto' bins\")\nText(0.5, 1.0, \"Histogram with 'auto' bins\")\n>>> plt.show()"
      }
    },
    {
      "name": "histogram2d",
      "signature": "histogram2d(x, y, bins=10, range=None, density=None, weights=None)",
      "documentation": {
        "description": "Compute the bi-dimensional histogram of two data samples.",
        "parameters": {
          "x": {
            "type": "array_like, shape (N,)",
            "description": "An array containing the x coordinates of the points to be\nhistogrammed."
          },
          "y": {
            "type": "array_like, shape (N,)",
            "description": "An array containing the y coordinates of the points to be\nhistogrammed."
          },
          "bins": {
            "type": "int or array_like or [int, int] or [array, array], optional",
            "description": "The bin specification:\n* If int, the number of bins for the two dimensions (nx=ny=bins).\n* If array_like, the bin edges for the two dimensions\n(x_edges=y_edges=bins).\n* If [int, int], the number of bins in each dimension\n(nx, ny = bins).\n* If [array, array], the bin edges in each dimension\n(x_edges, y_edges = bins).\n* A combination [int, array] or [array, int], where int\nis the number of bins and array is the bin edges."
          },
          "range": {
            "type": "array_like, shape(2,2), optional",
            "description": "The leftmost and rightmost edges of the bins along each dimension\n(if not specified explicitly in the `bins` parameters):\n``[[xmin, xmax], [ymin, ymax]]``. All values outside of this range\nwill be considered outliers and not tallied in the histogram."
          },
          "density": {
            "type": "bool, optional",
            "description": "If False, the default, returns the number of samples in each bin.\nIf True, returns the probability *density* function at the bin,\n``bin_count / sample_count / bin_area``."
          },
          "weights": {
            "type": "array_like, shape(N,), optional",
            "description": "An array of values ``w_i`` weighing each sample ``(x_i, y_i)``.\nWeights are normalized to 1 if `density` is True. If `density` is\nFalse, the values of the returned histogram are equal to the sum of\nthe weights belonging to the samples falling into each bin."
          }
        },
        "returns": "-------\nH : ndarray, shape(nx, ny)\nThe bi-dimensional histogram of samples `x` and `y`. Values in `x`\nare histogrammed along the first dimension and values in `y` are\nhistogrammed along the second dimension.\nxedges : ndarray, shape(nx+1,)\nThe bin edges along the first dimension.\nyedges : ndarray, shape(ny+1,)\nThe bin edges along the second dimension.",
        "raises": "",
        "see_also": "--------\nhistogram : 1D histogram\nhistogramdd : Multidimensional histogram",
        "notes": "-----\nWhen `density` is True, then the returned histogram is the sample\ndensity, defined such that the sum over bins of the product\n``bin_value * bin_area`` is 1.\nPlease note that the histogram does not follow the Cartesian convention\nwhere `x` values are on the abscissa and `y` values on the ordinate\naxis.  Rather, `x` is histogrammed along the first dimension of the\narray (vertical), and `y` along the second dimension of the array\n(horizontal).  This ensures compatibility with `histogramdd`.",
        "examples": "--------\n>>> from matplotlib.image import NonUniformImage\n>>> import matplotlib.pyplot as plt\nConstruct a 2-D histogram with variable bin width. First define the bin\nedges:\n>>> xedges = [0, 1, 3, 5]\n>>> yedges = [0, 2, 3, 4, 6]\nNext we create a histogram H with random bin content:\n>>> x = np.random.normal(2, 1, 100)\n>>> y = np.random.normal(1, 1, 100)\n>>> H, xedges, yedges = np.histogram2d(x, y, bins=(xedges, yedges))\n>>> # Histogram does not follow Cartesian convention (see Notes),\n>>> # therefore transpose H for visualization purposes.\n>>> H = H.T\n:func:`imshow <matplotlib.pyplot.imshow>` can only display square bins:\n>>> fig = plt.figure(figsize=(7, 3))\n>>> ax = fig.add_subplot(131, title='imshow: square bins')\n>>> plt.imshow(H, interpolation='nearest', origin='lower',\n...         extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]])\n<matplotlib.image.AxesImage object at 0x...>\n:func:`pcolormesh <matplotlib.pyplot.pcolormesh>` can display actual edges:\n>>> ax = fig.add_subplot(132, title='pcolormesh: actual edges',\n...         aspect='equal')\n>>> X, Y = np.meshgrid(xedges, yedges)\n>>> ax.pcolormesh(X, Y, H)\n<matplotlib.collections.QuadMesh object at 0x...>\n:class:`NonUniformImage <matplotlib.image.NonUniformImage>` can be used to\ndisplay actual bin edges with interpolation:\n>>> ax = fig.add_subplot(133, title='NonUniformImage: interpolated',\n...         aspect='equal', xlim=xedges[[0, -1]], ylim=yedges[[0, -1]])\n>>> im = NonUniformImage(ax, interpolation='bilinear')\n>>> xcenters = (xedges[:-1] + xedges[1:]) / 2\n>>> ycenters = (yedges[:-1] + yedges[1:]) / 2\n>>> im.set_data(xcenters, ycenters, H)\n>>> ax.add_image(im)\n>>> plt.show()\nIt is also possible to construct a 2-D histogram without specifying bin\nedges:\n>>> # Generate non-symmetric test data\n>>> n = 10000\n>>> x = np.linspace(1, 100, n)\n>>> y = 2*np.log(x) + np.random.rand(n) - 0.5\n>>> # Compute 2d histogram. Note the order of x/y and xedges/yedges\n>>> H, yedges, xedges = np.histogram2d(y, x, bins=20)\nNow we can plot the histogram using\n:func:`pcolormesh <matplotlib.pyplot.pcolormesh>`, and a\n:func:`hexbin <matplotlib.pyplot.hexbin>` for comparison.\n>>> # Plot histogram using pcolormesh\n>>> fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n>>> ax1.pcolormesh(xedges, yedges, H, cmap='rainbow')\n>>> ax1.plot(x, 2*np.log(x), 'k-')\n>>> ax1.set_xlim(x.min(), x.max())\n>>> ax1.set_ylim(y.min(), y.max())\n>>> ax1.set_xlabel('x')\n>>> ax1.set_ylabel('y')\n>>> ax1.set_title('histogram2d')\n>>> ax1.grid()\n>>> # Create hexbin plot for comparison\n>>> ax2.hexbin(x, y, gridsize=20, cmap='rainbow')\n>>> ax2.plot(x, 2*np.log(x), 'k-')\n>>> ax2.set_title('hexbin')\n>>> ax2.set_xlim(x.min(), x.max())\n>>> ax2.set_xlabel('x')\n>>> ax2.grid()\n>>> plt.show()"
      }
    },
    {
      "name": "histogram_bin_edges",
      "signature": "histogram_bin_edges(a, bins=10, range=None, weights=None)",
      "documentation": {
        "description": "Function to calculate only the edges of the bins used by the `histogram`\nfunction.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input data. The histogram is computed over the flattened array."
          },
          "bins": {
            "type": "int or sequence of scalars or str, optional",
            "description": "If `bins` is an int, it defines the number of equal-width\nbins in the given range (10, by default). If `bins` is a\nsequence, it defines the bin edges, including the rightmost\nedge, allowing for non-uniform bin widths.\nIf `bins` is a string from the list below, `histogram_bin_edges` will use\nthe method chosen to calculate the optimal bin width and\nconsequently the number of bins (see `Notes` for more detail on\nthe estimators) from the data that falls within the requested\nrange. While the bin width will be optimal for the actual data\nin the range, the number of bins will be computed to fill the\nentire range, including the empty portions. For visualisation,\nusing the 'auto' option is suggested. Weighted data is not\nsupported for automated bin size selection.\n'auto'\nMaximum of the 'sturges' and 'fd' estimators. Provides good\nall around performance.\n'fd' (Freedman Diaconis Estimator)\nRobust (resilient to outliers) estimator that takes into\naccount data variability and data size.\n'doane'\nAn improved version of Sturges' estimator that works better\nwith non-normal datasets.\n'scott'\nLess robust estimator that takes into account data variability\nand data size.\n'stone'\nEstimator based on leave-one-out cross-validation estimate of\nthe integrated squared error. Can be regarded as a generalization\nof Scott's rule.\n'rice'\nEstimator does not take variability into account, only data\nsize. Commonly overestimates number of bins required.\n'sturges'\nR's default method, only accounts for data size. Only\noptimal for gaussian data and underestimates number of bins\nfor large non-gaussian datasets.\n'sqrt'\nSquare root (of data size) estimator, used by Excel and\nother programs for its speed and simplicity."
          },
          "range": {
            "type": "(float, float), optional",
            "description": "The lower and upper range of the bins.  If not provided, range\nis simply ``(a.min(), a.max())``.  Values outside the range are\nignored. The first element of the range must be less than or\nequal to the second. `range` affects the automatic bin\ncomputation as well. While bin width is computed to be optimal\nbased on the actual data within `range`, the bin count will fill\nthe entire range including portions containing no data."
          },
          "weights": {
            "type": "array_like, optional",
            "description": "An array of weights, of the same shape as `a`.  Each value in\n`a` only contributes its associated weight towards the bin count\n(instead of 1). This is currently not used by any of the bin estimators,\nbut may be in the future."
          }
        },
        "returns": "-------\nbin_edges : array of dtype float\nThe edges to pass into `histogram`",
        "raises": "",
        "see_also": "--------\nhistogram",
        "notes": "-----\nThe methods to estimate the optimal number of bins are well founded\nin literature, and are inspired by the choices R provides for\nhistogram visualisation. Note that having the number of bins\nproportional to :math:`n^{1/3}` is asymptotically optimal, which is\nwhy it appears in most estimators. These are simply plug-in methods\nthat give good starting points for number of bins. In the equations\nbelow, :math:`h` is the binwidth and :math:`n_h` is the number of\nbins. All estimators that compute bin counts are recast to bin width\nusing the `ptp` of the data. The final bin count is obtained from\n``np.round(np.ceil(range / h))``. The final bin width is often less\nthan what is returned by the estimators below.\n'auto' (maximum of the 'sturges' and 'fd' estimators)\nA compromise to get a good value. For small datasets the Sturges\nvalue will usually be chosen, while larger datasets will usually\ndefault to FD.  Avoids the overly conservative behaviour of FD\nand Sturges for small and large datasets respectively.\nSwitchover point is usually :math:`a.size \\approx 1000`.\n'fd' (Freedman Diaconis Estimator)\n.. math:: h = 2 \\frac{IQR}{n^{1/3}}\nThe binwidth is proportional to the interquartile range (IQR)\nand inversely proportional to cube root of a.size. Can be too\nconservative for small datasets, but is quite good for large\ndatasets. The IQR is very robust to outliers.\n'scott'\n.. math:: h = \\sigma \\sqrt[3]{\\frac{24 \\sqrt{\\pi}}{n}}\nThe binwidth is proportional to the standard deviation of the\ndata and inversely proportional to cube root of ``x.size``. Can\nbe too conservative for small datasets, but is quite good for\nlarge datasets. The standard deviation is not very robust to\noutliers. Values are very similar to the Freedman-Diaconis\nestimator in the absence of outliers.\n'rice'\n.. math:: n_h = 2n^{1/3}\nThe number of bins is only proportional to cube root of\n``a.size``. It tends to overestimate the number of bins and it\ndoes not take into account data variability.\n'sturges'\n.. math:: n_h = \\log _{2}(n) + 1\nThe number of bins is the base 2 log of ``a.size``.  This\nestimator assumes normality of data and is too conservative for\nlarger, non-normal datasets. This is the default method in R's\n``hist`` method.\n'doane'\n.. math:: n_h = 1 + \\log_{2}(n) +\n\\log_{2}\\left(1 + \\frac{|g_1|}{\\sigma_{g_1}}\\right)\ng_1 = mean\\left[\\left(\\frac{x - \\mu}{\\sigma}\\right)^3\\right]\n\\sigma_{g_1} = \\sqrt{\\frac{6(n - 2)}{(n + 1)(n + 3)}}\nAn improved version of Sturges' formula that produces better\nestimates for non-normal datasets. This estimator attempts to\naccount for the skew of the data.\n'sqrt'\n.. math:: n_h = \\sqrt n\nThe simplest and fastest estimator. Only takes into account the\ndata size.",
        "examples": "--------\n>>> arr = np.array([0, 0, 0, 1, 2, 3, 3, 4, 5])\n>>> np.histogram_bin_edges(arr, bins='auto', range=(0, 1))\narray([0.  , 0.25, 0.5 , 0.75, 1.  ])\n>>> np.histogram_bin_edges(arr, bins=2)\narray([0. , 2.5, 5. ])\nFor consistency with histogram, an array of pre-computed bins is\npassed through unmodified:\n>>> np.histogram_bin_edges(arr, [1, 2])\narray([1, 2])\nThis function allows one set of bins to be computed, and reused across\nmultiple histograms:\n>>> shared_bins = np.histogram_bin_edges(arr, bins='auto')\n>>> shared_bins\narray([0., 1., 2., 3., 4., 5.])\n>>> group_id = np.array([0, 1, 1, 0, 1, 1, 0, 1, 1])\n>>> hist_0, _ = np.histogram(arr[group_id == 0], bins=shared_bins)\n>>> hist_1, _ = np.histogram(arr[group_id == 1], bins=shared_bins)\n>>> hist_0; hist_1\narray([1, 1, 0, 1, 0])\narray([2, 0, 1, 1, 2])\nWhich gives more easily comparable results than using separate bins for\neach histogram:\n>>> hist_0, bins_0 = np.histogram(arr[group_id == 0], bins='auto')\n>>> hist_1, bins_1 = np.histogram(arr[group_id == 1], bins='auto')\n>>> hist_0; hist_1\narray([1, 1, 1])\narray([2, 1, 1, 2])\n>>> bins_0; bins_1\narray([0., 1., 2., 3.])\narray([0.  , 1.25, 2.5 , 3.75, 5.  ])"
      }
    },
    {
      "name": "histogramdd",
      "signature": "histogramdd(sample, bins=10, range=None, density=None, weights=None)",
      "documentation": {
        "description": "Compute the multidimensional histogram of some data.",
        "parameters": {
          "sample": {
            "type": "(N, D) array, or (N, D) array_like",
            "description": "The data to be histogrammed.\nNote the unusual interpretation of sample when an array_like:\n* When an array, each row is a coordinate in a D-dimensional space -\nsuch as ``histogramdd(np.array([p1, p2, p3]))``.\n* When an array_like, each element is the list of values for single\ncoordinate - such as ``histogramdd((X, Y, Z))``.\nThe first form should be preferred."
          },
          "bins": {
            "type": "sequence or int, optional",
            "description": "The bin specification:\n* A sequence of arrays describing the monotonically increasing bin\nedges along each dimension.\n* The number of bins for each dimension (nx, ny, ... =bins)\n* The number of bins for all dimensions (nx=ny=...=bins)."
          },
          "range": {
            "type": "sequence, optional",
            "description": "A sequence of length D, each an optional (lower, upper) tuple giving\nthe outer bin edges to be used if the edges are not given explicitly in\n`bins`.\nAn entry of None in the sequence results in the minimum and maximum\nvalues being used for the corresponding dimension.\nThe default, None, is equivalent to passing a tuple of D None values."
          },
          "density": {
            "type": "bool, optional",
            "description": "If False, the default, returns the number of samples in each bin.\nIf True, returns the probability *density* function at the bin,\n``bin_count / sample_count / bin_volume``."
          },
          "weights": {
            "type": "(N,) array_like, optional",
            "description": "An array of values `w_i` weighing each sample `(x_i, y_i, z_i, ...)`.\nWeights are normalized to 1 if density is True. If density is False,\nthe values of the returned histogram are equal to the sum of the\nweights belonging to the samples falling into each bin."
          }
        },
        "returns": "-------\nH : ndarray\nThe multidimensional histogram of sample x. See density and weights\nfor the different possible semantics.\nedges : list\nA list of D arrays describing the bin edges for each dimension.",
        "raises": "",
        "see_also": "--------\nhistogram: 1-D histogram\nhistogram2d: 2-D histogram",
        "notes": "",
        "examples": "--------\n>>> r = np.random.randn(100,3)\n>>> H, edges = np.histogramdd(r, bins = (5, 8, 4))\n>>> H.shape, edges[0].size, edges[1].size, edges[2].size\n((5, 8, 4), 6, 9, 5)"
      }
    },
    {
      "name": "hsplit",
      "signature": "hsplit(ary, indices_or_sections)",
      "documentation": {
        "description": "Split an array into multiple sub-arrays horizontally (column-wise).\nPlease refer to the `split` documentation.  `hsplit` is equivalent\nto `split` with ``axis=1``, the array is always split along the second\naxis except for 1-D arrays, where it is split at ``axis=0``.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "--------\nsplit : Split an array into multiple sub-arrays of equal size.",
        "notes": "",
        "examples": "--------\n>>> x = np.arange(16.0).reshape(4, 4)\n>>> x\narray([[ 0.,   1.,   2.,   3.],\n[ 4.,   5.,   6.,   7.],\n[ 8.,   9.,  10.,  11.],\n[12.,  13.,  14.,  15.]])\n>>> np.hsplit(x, 2)\n[array([[  0.,   1.],\n[  4.,   5.],\n[  8.,   9.],\n[12.,  13.]]),\narray([[  2.,   3.],\n[  6.,   7.],\n[10.,  11.],\n[14.,  15.]])]\n>>> np.hsplit(x, np.array([3, 6]))\n[array([[ 0.,   1.,   2.],\n[ 4.,   5.,   6.],\n[ 8.,   9.,  10.],\n[12.,  13.,  14.]]),\narray([[ 3.],\n[ 7.],\n[11.],\n[15.]]),\narray([], shape=(4, 0), dtype=float64)]\nWith a higher dimensional array the split is still along the second axis.\n>>> x = np.arange(8.0).reshape(2, 2, 2)\n>>> x\narray([[[0.,  1.],\n[2.,  3.]],\n[[4.,  5.],\n[6.,  7.]]])\n>>> np.hsplit(x, 2)\n[array([[[0.,  1.]],\n[[4.,  5.]]]),\narray([[[2.,  3.]],\n[[6.,  7.]]])]\nWith a 1-D array, the split is along axis 0.\n>>> x = np.array([0, 1, 2, 3, 4, 5])\n>>> np.hsplit(x, 2)\n[array([0, 1, 2]), array([3, 4, 5])]"
      }
    },
    {
      "name": "i0",
      "signature": "i0(x)",
      "documentation": {
        "description": "Modified Bessel function of the first kind, order 0.\nUsually denoted :math:`I_0`.",
        "parameters": {
          "x": {
            "type": "array_like of float",
            "description": "Argument of the Bessel function."
          }
        },
        "returns": "-------\nout : ndarray, shape = x.shape, dtype = float\nThe modified Bessel function evaluated at each of the elements of `x`.",
        "raises": "",
        "see_also": "--------\nscipy.special.i0, scipy.special.iv, scipy.special.ive",
        "notes": "-----\nThe scipy implementation is recommended over this function: it is a\nproper ufunc written in C, and more than an order of magnitude faster.\nWe use the algorithm published by Clenshaw [1]_ and referenced by\nAbramowitz and Stegun [2]_, for which the function domain is\npartitioned into the two intervals [0,8] and (8,inf), and Chebyshev\npolynomial expansions are employed in each interval. Relative error on\nthe domain [0,30] using IEEE arithmetic is documented [3]_ as having a\npeak of 5.8e-16 with an rms of 1.4e-16 (n = 30000).\nReferences\n----------\n.. [1] C. W. Clenshaw, \"Chebyshev series for mathematical functions\", in\n*National Physical Laboratory Mathematical Tables*, vol. 5, London:\nHer Majesty's Stationery Office, 1962.\n.. [2] M. Abramowitz and I. A. Stegun, *Handbook of Mathematical\nFunctions*, 10th printing, New York: Dover, 1964, pp. 379.\nhttps://personal.math.ubc.ca/~cbm/aands/page_379.htm\n.. [3] https://metacpan.org/pod/distribution/Math-Cephes/lib/Math/Cephes.pod#i0:-Modified-Bessel-function-of-order-zero",
        "examples": "--------\n>>> np.i0(0.)\narray(1.0)\n>>> np.i0([0, 1, 2, 3])\narray([1.        , 1.26606588, 2.2795853 , 4.88079259])"
      }
    },
    {
      "name": "imag",
      "signature": "imag(val)",
      "documentation": {
        "description": "Return the imaginary part of the complex argument.",
        "parameters": {
          "val": {
            "type": "array_like",
            "description": "Input array."
          }
        },
        "returns": "-------\nout : ndarray or scalar\nThe imaginary component of the complex argument. If `val` is real,\nthe type of `val` is used for the output.  If `val` has complex\nelements, the returned type is float.",
        "raises": "",
        "see_also": "--------\nreal, angle, real_if_close",
        "notes": "",
        "examples": "--------\n>>> a = np.array([1+2j, 3+4j, 5+6j])\n>>> a.imag\narray([2.,  4.,  6.])\n>>> a.imag = np.array([8, 10, 12])\n>>> a\narray([1. +8.j,  3.+10.j,  5.+12.j])\n>>> np.imag(1 + 1j)\n1.0"
      }
    },
    {
      "name": "in1d",
      "signature": "in1d(ar1, ar2, assume_unique=False, invert=False, *, kind=None)",
      "documentation": {
        "description": "Test whether each element of a 1-D array is also present in a second array.",
        "parameters": {
          "ar1": {
            "type": "(M,) array_like",
            "description": "Input array."
          },
          "ar2": {
            "type": "array_like",
            "description": "The values against which to test each value of `ar1`."
          },
          "assume_unique": {
            "type": "bool, optional",
            "description": "If True, the input arrays are both assumed to be unique, which\ncan speed up the calculation.  Default is False."
          },
          "invert": {
            "type": "bool, optional",
            "description": "If True, the values in the returned array are inverted (that is,\nFalse where an element of `ar1` is in `ar2` and True otherwise).\nDefault is False. ``np.in1d(a, b, invert=True)`` is equivalent\nto (but is faster than) ``np.invert(in1d(a, b))``."
          },
          "kind": {
            "type": "{None, 'sort', 'table'}, optional",
            "description": "The algorithm to use. This will not affect the final result,\nbut will affect the speed and memory use. The default, None,\nwill select automatically based on memory considerations.\n* If 'sort', will use a mergesort-based approach. This will have\na memory usage of roughly 6 times the sum of the sizes of\n`ar1` and `ar2`, not accounting for size of dtypes.\n* If 'table', will use a lookup table approach similar\nto a counting sort. This is only available for boolean and\ninteger arrays. This will have a memory usage of the\nsize of `ar1` plus the max-min value of `ar2`. `assume_unique`\nhas no effect when the 'table' option is used.\n* If None, will automatically choose 'table' if\nthe required memory allocation is less than or equal to\n6 times the sum of the sizes of `ar1` and `ar2`,\notherwise will use 'sort'. This is done to not use\na large amount of memory by default, even though\n'table' may be faster in most cases. If 'table' is chosen,\n`assume_unique` will have no effect.\n.. versionadded:: 1.8.0"
          }
        },
        "returns": "where an element of `ar1` is in `ar2` and False otherwise.\nWe recommend using :func:`isin` instead of `in1d` for new code.\n-------\nin1d : (M,) ndarray, bool\nThe values `ar1[in1d]` are in `ar2`.",
        "raises": "",
        "see_also": "--------\nisin                  : Version of this function that preserves the\nshape of ar1.\nnumpy.lib.arraysetops : Module with a number of other functions for\nperforming set operations on arrays.",
        "notes": "-----\n`in1d` can be considered as an element-wise function version of the\npython keyword `in`, for 1-D sequences. ``in1d(a, b)`` is roughly\nequivalent to ``np.array([item in b for item in a])``.\nHowever, this idea fails if `ar2` is a set, or similar (non-sequence)\ncontainer:  As ``ar2`` is converted to an array, in those cases\n``asarray(ar2)`` is an object array rather than the expected array of\ncontained values.\nUsing ``kind='table'`` tends to be faster than `kind='sort'` if the\nfollowing relationship is true:\n``log10(len(ar2)) > (log10(max(ar2)-min(ar2)) - 2.27) / 0.927``,\nbut may use greater memory. The default value for `kind` will\nbe automatically selected based only on memory usage, so one may\nmanually set ``kind='table'`` if memory constraints can be relaxed.\n.. versionadded:: 1.4.0",
        "examples": "--------\n>>> test = np.array([0, 1, 2, 5, 0])\n>>> states = [0, 2]\n>>> mask = np.in1d(test, states)\n>>> mask\narray([ True, False,  True, False,  True])\n>>> test[mask]\narray([0, 2, 0])\n>>> mask = np.in1d(test, states, invert=True)\n>>> mask\narray([False,  True, False,  True, False])\n>>> test[mask]\narray([1, 5])"
      }
    },
    {
      "name": "info",
      "signature": "info(object=None, maxwidth=76, output=None, toplevel='numpy')",
      "documentation": {
        "description": "Get help information for an array, function, class, or module.",
        "parameters": {
          "object": {
            "type": "object or str, optional",
            "description": "Input object or name to get information about. If `object` is\nan `ndarray` instance, information about the array is printed.\nIf `object` is a numpy object, its docstring is given. If it is\na string, available modules are searched for matching objects.\nIf None, information about `info` itself is returned."
          },
          "maxwidth": {
            "type": "int, optional",
            "description": "Printing width."
          },
          "output": {
            "type": "file like object, optional",
            "description": "File like object that the output is written to, default is\n``None``, in which case ``sys.stdout`` will be used.\nThe object has to be opened in 'w' or 'a' mode."
          },
          "toplevel": {
            "type": "str, optional",
            "description": "Start search at this level."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\nsource, lookfor",
        "notes": "-----\nWhen used interactively with an object, ``np.info(obj)`` is equivalent\nto ``help(obj)`` on the Python prompt or ``obj?`` on the IPython\nprompt.",
        "examples": "--------\n>>> np.info(np.polyval) # doctest: +SKIP\npolyval(p, x)\nEvaluate the polynomial p at x.\n...\nWhen using a string for `object` it is possible to get multiple results.\n>>> np.info('fft') # doctest: +SKIP\n*** Found in numpy ***\nCore FFT routines\n...\n*** Found in numpy.fft ***\nfft(a, n=None, axis=-1)\n...\n*** Repeat reference found in numpy.fft.fftpack ***\n*** Total of 3 references found. ***\nWhen the argument is an array, information about the array is printed.\n>>> a = np.array([[1 + 2j, 3, -4], [-5j, 6, 0]], dtype=np.complex64)\n>>> np.info(a)\nclass:  ndarray\nshape:  (2, 3)\nstrides:  (24, 8)\nitemsize:  8\naligned:  True\ncontiguous:  True\nfortran:  False\ndata pointer: 0x562b6e0d2860  # may vary\nbyteorder:  little\nbyteswap:  False\ntype: complex64"
      }
    },
    {
      "name": "insert",
      "signature": "insert(arr, obj, values, axis=None)",
      "documentation": {
        "description": "Insert values along the given axis before the given indices.",
        "parameters": {
          "arr": {
            "type": "array_like",
            "description": "Input array."
          },
          "obj": {
            "type": "int, slice or sequence of ints",
            "description": "Object that defines the index or indices before which `values` is\ninserted.\n.. versionadded:: 1.8.0\nSupport for multiple insertions when `obj` is a single scalar or a\nsequence with one element (similar to calling insert multiple\ntimes)."
          },
          "values": {
            "type": "array_like",
            "description": "Values to insert into `arr`. If the type of `values` is different\nfrom that of `arr`, `values` is converted to the type of `arr`.\n`values` should be shaped so that ``arr[...,obj,...] = values``\nis legal."
          },
          "axis": {
            "type": "int, optional",
            "description": "Axis along which to insert `values`.  If `axis` is None then `arr`\nis flattened first."
          }
        },
        "returns": "-------\nout : ndarray\nA copy of `arr` with `values` inserted.  Note that `insert`\ndoes not occur in-place: a new array is returned. If\n`axis` is None, `out` is a flattened array.",
        "raises": "",
        "see_also": "--------\nappend : Append elements at the end of an array.\nconcatenate : Join a sequence of arrays along an existing axis.\ndelete : Delete elements from an array.",
        "notes": "-----\nNote that for higher dimensional inserts ``obj=0`` behaves very different\nfrom ``obj=[0]`` just like ``arr[:,0,:] = values`` is different from\n``arr[:,[0],:] = values``.",
        "examples": "--------\n>>> a = np.array([[1, 1], [2, 2], [3, 3]])\n>>> a\narray([[1, 1],\n[2, 2],\n[3, 3]])\n>>> np.insert(a, 1, 5)\narray([1, 5, 1, ..., 2, 3, 3])\n>>> np.insert(a, 1, 5, axis=1)\narray([[1, 5, 1],\n[2, 5, 2],\n[3, 5, 3]])\nDifference between sequence and scalars:\n>>> np.insert(a, [1], [[1],[2],[3]], axis=1)\narray([[1, 1, 1],\n[2, 2, 2],\n[3, 3, 3]])\n>>> np.array_equal(np.insert(a, 1, [1, 2, 3], axis=1),\n...                np.insert(a, [1], [[1],[2],[3]], axis=1))\nTrue\n>>> b = a.flatten()\n>>> b\narray([1, 1, 2, 2, 3, 3])\n>>> np.insert(b, [2, 2], [5, 6])\narray([1, 1, 5, ..., 2, 3, 3])\n>>> np.insert(b, slice(2, 4), [5, 6])\narray([1, 1, 5, ..., 2, 3, 3])\n>>> np.insert(b, [2, 2], [7.13, False]) # type casting\narray([1, 1, 7, ..., 2, 3, 3])\n>>> x = np.arange(8).reshape(2, 4)\n>>> idx = (1, 3)\n>>> np.insert(x, idx, 999, axis=1)\narray([[  0, 999,   1,   2, 999,   3],\n[  4, 999,   5,   6, 999,   7]])"
      }
    },
    {
      "name": "interp",
      "signature": "interp(x, xp, fp, left=None, right=None, period=None)",
      "documentation": {
        "description": "One-dimensional linear interpolation for monotonically increasing sample points.",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "The x-coordinates at which to evaluate the interpolated values."
          },
          "xp": {
            "type": "1-D sequence of floats",
            "description": "The x-coordinates of the data points, must be increasing if argument\n`period` is not specified. Otherwise, `xp` is internally sorted after\nnormalizing the periodic boundaries with ``xp = xp % period``."
          },
          "fp": {
            "type": "1-D sequence of float or complex",
            "description": "The y-coordinates of the data points, same length as `xp`."
          },
          "left": {
            "type": "optional float or complex corresponding to fp",
            "description": "Value to return for `x < xp[0]`, default is `fp[0]`."
          },
          "right": {
            "type": "optional float or complex corresponding to fp",
            "description": "Value to return for `x > xp[-1]`, default is `fp[-1]`."
          },
          "period": {
            "type": "None or float, optional",
            "description": "A period for the x-coordinates. This parameter allows the proper\ninterpolation of angular x-coordinates. Parameters `left` and `right`\nare ignored if `period` is specified.\n.. versionadded:: 1.10.0"
          }
        },
        "returns": "with given discrete data points (`xp`, `fp`), evaluated at `x`.\n-------\ny : float or complex (corresponding to fp) or ndarray\nThe interpolated values, same shape as `x`.",
        "raises": "------\nValueError\nIf `xp` and `fp` have different length\nIf `xp` or `fp` are not 1-D sequences\nIf `period == 0`",
        "see_also": "--------\nscipy.interpolate\nWarnings\n--------\nThe x-coordinate sequence is expected to be increasing, but this is not\nexplicitly enforced.  However, if the sequence `xp` is non-increasing,\ninterpolation results are meaningless.\nNote that, since NaN is unsortable, `xp` also cannot contain NaNs.\nA simple check for `xp` being strictly increasing is::\nnp.all(np.diff(xp) > 0)",
        "notes": "",
        "examples": "--------\n>>> xp = [1, 2, 3]\n>>> fp = [3, 2, 0]\n>>> np.interp(2.5, xp, fp)\n1.0\n>>> np.interp([0, 1, 1.5, 2.72, 3.14], xp, fp)\narray([3.  , 3.  , 2.5 , 0.56, 0.  ])\n>>> UNDEF = -99.0\n>>> np.interp(3.14, xp, fp, right=UNDEF)\n-99.0\nPlot an interpolant to the sine function:\n>>> x = np.linspace(0, 2*np.pi, 10)\n>>> y = np.sin(x)\n>>> xvals = np.linspace(0, 2*np.pi, 50)\n>>> yinterp = np.interp(xvals, x, y)\n>>> import matplotlib.pyplot as plt\n>>> plt.plot(x, y, 'o')\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.plot(xvals, yinterp, '-x')\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.show()\nInterpolation with periodic x-coordinates:\n>>> x = [-180, -170, -185, 185, -10, -5, 0, 365]\n>>> xp = [190, -190, 350, -350]\n>>> fp = [5, 10, 3, 4]\n>>> np.interp(x, xp, fp, period=360)\narray([7.5 , 5.  , 8.75, 6.25, 3.  , 3.25, 3.5 , 3.75])\nComplex interpolation:\n>>> x = [1.5, 4.0]\n>>> xp = [2,3,5]\n>>> fp = [1.0j, 0, 2+3j]\n>>> np.interp(x, xp, fp)\narray([0.+1.j , 1.+1.5j])"
      }
    },
    {
      "name": "intersect1d",
      "signature": "intersect1d(ar1, ar2, assume_unique=False, return_indices=False)",
      "documentation": {
        "description": "Find the intersection of two arrays.\nReturn the sorted, unique values that are in both of the input arrays.",
        "parameters": {
          "assume_unique": {
            "type": "bool",
            "description": "If True, the input arrays are both assumed to be unique, which\ncan speed up the calculation.  If True but ``ar1`` or ``ar2`` are not\nunique, incorrect results and out-of-bounds indices could result.\nDefault is False."
          },
          "return_indices": {
            "type": "bool",
            "description": "If True, the indices which correspond to the intersection of the two\narrays are returned. The first instance of a value is used if there are\nmultiple. Default is False.\n.. versionadded:: 1.15.0"
          }
        },
        "returns": "-------\nintersect1d : ndarray\nSorted 1D array of common and unique elements.\ncomm1 : ndarray\nThe indices of the first occurrences of the common values in `ar1`.\nOnly provided if `return_indices` is True.\ncomm2 : ndarray\nThe indices of the first occurrences of the common values in `ar2`.\nOnly provided if `return_indices` is True.",
        "raises": "",
        "see_also": "--------\nnumpy.lib.arraysetops : Module with a number of other functions for\nperforming set operations on arrays.",
        "notes": "",
        "examples": "--------\n>>> np.intersect1d([1, 3, 4, 3], [3, 1, 2, 1])\narray([1, 3])\nTo intersect more than two arrays, use functools.reduce:\n>>> from functools import reduce\n>>> reduce(np.intersect1d, ([1, 3, 4, 3], [3, 1, 2, 1], [6, 3, 4, 2]))\narray([3])\nTo return the indices of the values common to the input arrays\nalong with the intersected values:\n>>> x = np.array([1, 1, 2, 3, 4])\n>>> y = np.array([2, 1, 4, 6])\n>>> xy, x_ind, y_ind = np.intersect1d(x, y, return_indices=True)\n>>> x_ind, y_ind\n(array([0, 2, 4]), array([1, 0, 2]))\n>>> xy, x[x_ind], y[y_ind]\n(array([1, 2, 4]), array([1, 2, 4]), array([1, 2, 4]))"
      }
    },
    {
      "name": "iscomplex",
      "signature": "iscomplex(x)",
      "documentation": {
        "description": "",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "Input array."
          }
        },
        "returns": "What is tested is whether the input has a non-zero imaginary part, not if\nthe input type is complex.\n-------\nout : ndarray of bools\nOutput array.",
        "raises": "",
        "see_also": "--------\nisreal\niscomplexobj : Return True if x is a complex type or an array of complex\nnumbers.",
        "notes": "",
        "examples": "--------\n>>> np.iscomplex([1+1j, 1+0j, 4.5, 3, 2, 2j])\narray([ True, False, False, False, False,  True])"
      }
    },
    {
      "name": "iscomplexobj",
      "signature": "iscomplexobj(x)",
      "documentation": {
        "description": "Check for a complex type or an array of complex numbers.\nThe type of the input is checked, not the value. Even if the input\nhas an imaginary part equal to zero, `iscomplexobj` evaluates to True.",
        "parameters": {
          "x": {
            "type": "any",
            "description": "The input can be of any type and shape."
          }
        },
        "returns": "-------\niscomplexobj : bool\nThe return value, True if `x` is of a complex type or has at least\none complex element.",
        "raises": "",
        "see_also": "--------\nisrealobj, iscomplex",
        "notes": "",
        "examples": "--------\n>>> np.iscomplexobj(1)\nFalse\n>>> np.iscomplexobj(1+0j)\nTrue\n>>> np.iscomplexobj([3, 1+0j, True])\nTrue"
      }
    },
    {
      "name": "isin",
      "signature": "isin(element, test_elements, assume_unique=False, invert=False, *, kind=None)",
      "documentation": {
        "description": "Calculates ``element in test_elements``, broadcasting over `element` only.",
        "parameters": {
          "element": {
            "type": "array_like",
            "description": "Input array."
          },
          "test_elements": {
            "type": "array_like",
            "description": "The values against which to test each value of `element`.\nThis argument is flattened if it is an array or array_like.\nSee notes for behavior with non-array-like parameters."
          },
          "assume_unique": {
            "type": "bool, optional",
            "description": "If True, the input arrays are both assumed to be unique, which\ncan speed up the calculation.  Default is False."
          },
          "invert": {
            "type": "bool, optional",
            "description": "If True, the values in the returned array are inverted, as if\ncalculating `element not in test_elements`. Default is False.\n``np.isin(a, b, invert=True)`` is equivalent to (but faster\nthan) ``np.invert(np.isin(a, b))``."
          },
          "kind": {
            "type": "{None, 'sort', 'table'}, optional",
            "description": "The algorithm to use. This will not affect the final result,\nbut will affect the speed and memory use. The default, None,\nwill select automatically based on memory considerations.\n* If 'sort', will use a mergesort-based approach. This will have\na memory usage of roughly 6 times the sum of the sizes of\n`ar1` and `ar2`, not accounting for size of dtypes.\n* If 'table', will use a lookup table approach similar\nto a counting sort. This is only available for boolean and\ninteger arrays. This will have a memory usage of the\nsize of `ar1` plus the max-min value of `ar2`. `assume_unique`\nhas no effect when the 'table' option is used.\n* If None, will automatically choose 'table' if\nthe required memory allocation is less than or equal to\n6 times the sum of the sizes of `ar1` and `ar2`,\notherwise will use 'sort'. This is done to not use\na large amount of memory by default, even though\n'table' may be faster in most cases. If 'table' is chosen,\n`assume_unique` will have no effect."
          }
        },
        "returns": "where an element of `element` is in `test_elements` and False otherwise.\n-------\nisin : ndarray, bool\nHas the same shape as `element`. The values `element[isin]`\nare in `test_elements`.",
        "raises": "",
        "see_also": "--------\nin1d                  : Flattened version of this function.\nnumpy.lib.arraysetops : Module with a number of other functions for\nperforming set operations on arrays.",
        "notes": "-----\n`isin` is an element-wise function version of the python keyword `in`.\n``isin(a, b)`` is roughly equivalent to\n``np.array([item in b for item in a])`` if `a` and `b` are 1-D sequences.\n`element` and `test_elements` are converted to arrays if they are not\nalready. If `test_elements` is a set (or other non-sequence collection)\nit will be converted to an object array with one element, rather than an\narray of the values contained in `test_elements`. This is a consequence\nof the `array` constructor's way of handling non-sequence collections.\nConverting the set to a list usually gives the desired behavior.\nUsing ``kind='table'`` tends to be faster than `kind='sort'` if the\nfollowing relationship is true:\n``log10(len(ar2)) > (log10(max(ar2)-min(ar2)) - 2.27) / 0.927``,\nbut may use greater memory. The default value for `kind` will\nbe automatically selected based only on memory usage, so one may\nmanually set ``kind='table'`` if memory constraints can be relaxed.\n.. versionadded:: 1.13.0",
        "examples": "--------\n>>> element = 2*np.arange(4).reshape((2, 2))\n>>> element\narray([[0, 2],\n[4, 6]])\n>>> test_elements = [1, 2, 4, 8]\n>>> mask = np.isin(element, test_elements)\n>>> mask\narray([[False,  True],\n[ True, False]])\n>>> element[mask]\narray([2, 4])\nThe indices of the matched values can be obtained with `nonzero`:\n>>> np.nonzero(mask)\n(array([0, 1]), array([1, 0]))\nThe test can also be inverted:\n>>> mask = np.isin(element, test_elements, invert=True)\n>>> mask\narray([[ True, False],\n[False,  True]])\n>>> element[mask]\narray([0, 6])\nBecause of how `array` handles sets, the following does not\nwork as expected:\n>>> test_set = {1, 2, 4, 8}\n>>> np.isin(element, test_set)\narray([[False, False],\n[False, False]])\nCasting the set to a list gives the expected result:\n>>> np.isin(element, list(test_set))\narray([[False,  True],\n[ True, False]])"
      }
    },
    {
      "name": "isneginf",
      "signature": "isneginf(x, out=None)",
      "documentation": {
        "description": "Test element-wise for negative infinity, return result as bool array.",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "The input array."
          },
          "out": {
            "type": "array_like, optional",
            "description": "A location into which the result is stored. If provided, it must have a\nshape that the input broadcasts to. If not provided or None, a\nfreshly-allocated boolean array is returned."
          }
        },
        "returns": "-------\nout : ndarray\nA boolean array with the same dimensions as the input.\nIf second argument is not supplied then a numpy boolean array is\nreturned with values True where the corresponding element of the\ninput is negative infinity and values False where the element of\nthe input is not negative infinity.\nIf a second argument is supplied the result is stored there. If the\ntype of that array is a numeric type the result is represented as\nzeros and ones, if the type is boolean then as False and True. The\nreturn value `out` is then a reference to that array.",
        "raises": "",
        "see_also": "--------\nisinf, isposinf, isnan, isfinite",
        "notes": "-----\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic\n(IEEE 754).\nErrors result if the second argument is also supplied when x is a scalar\ninput, if first and second arguments have different shapes, or if the\nfirst argument has complex values.",
        "examples": "--------\n>>> np.isneginf(np.NINF)\nTrue\n>>> np.isneginf(np.inf)\nFalse\n>>> np.isneginf(np.PINF)\nFalse\n>>> np.isneginf([-np.inf, 0., np.inf])\narray([ True, False, False])\n>>> x = np.array([-np.inf, 0., np.inf])\n>>> y = np.array([2, 2, 2])\n>>> np.isneginf(x, y)\narray([1, 0, 0])\n>>> y\narray([1, 0, 0])"
      }
    },
    {
      "name": "isposinf",
      "signature": "isposinf(x, out=None)",
      "documentation": {
        "description": "Test element-wise for positive infinity, return result as bool array.",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "The input array."
          },
          "out": {
            "type": "array_like, optional",
            "description": "A location into which the result is stored. If provided, it must have a\nshape that the input broadcasts to. If not provided or None, a\nfreshly-allocated boolean array is returned."
          }
        },
        "returns": "-------\nout : ndarray\nA boolean array with the same dimensions as the input.\nIf second argument is not supplied then a boolean array is returned\nwith values True where the corresponding element of the input is\npositive infinity and values False where the element of the input is\nnot positive infinity.\nIf a second argument is supplied the result is stored there. If the\ntype of that array is a numeric type the result is represented as zeros\nand ones, if the type is boolean then as False and True.\nThe return value `out` is then a reference to that array.",
        "raises": "",
        "see_also": "--------\nisinf, isneginf, isfinite, isnan",
        "notes": "-----\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic\n(IEEE 754).\nErrors result if the second argument is also supplied when x is a scalar\ninput, if first and second arguments have different shapes, or if the\nfirst argument has complex values",
        "examples": "--------\n>>> np.isposinf(np.PINF)\nTrue\n>>> np.isposinf(np.inf)\nTrue\n>>> np.isposinf(np.NINF)\nFalse\n>>> np.isposinf([-np.inf, 0., np.inf])\narray([False, False,  True])\n>>> x = np.array([-np.inf, 0., np.inf])\n>>> y = np.array([2, 2, 2])\n>>> np.isposinf(x, y)\narray([0, 0, 1])\n>>> y\narray([0, 0, 1])"
      }
    },
    {
      "name": "isreal",
      "signature": "isreal(x)",
      "documentation": {
        "description": "",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "Input array."
          }
        },
        "returns": "If element has complex type with zero complex part, the return value\nfor that element is True.\n-------\nout : ndarray, bool\nBoolean array of same shape as `x`.\nany of the elements is complex.\n>>> a = np.array([1, \"2\", 3+4j], dtype=object)\n>>> np.isreal(a)\narray([ True,  True,  True])\nisreal should not be used with object arrays\n>>> a = np.array([1+2j, 2+1j], dtype=object)\n>>> np.isreal(a)\narray([ True,  True])",
        "raises": "",
        "see_also": "--------\niscomplex\nisrealobj : Return True if x is not a complex type.",
        "notes": "-----\n`isreal` may behave unexpectedly for string or object arrays (see examples)",
        "examples": "--------\n>>> a = np.array([1+1j, 1+0j, 4.5, 3, 2, 2j], dtype=complex)\n>>> np.isreal(a)\narray([False,  True,  True,  True,  True, False])\nThe function does not work on string arrays.\n>>> a = np.array([2j, \"a\"], dtype=\"U\")\n>>> np.isreal(a)  # Warns about non-elementwise comparison\nFalse"
      }
    },
    {
      "name": "isrealobj",
      "signature": "isrealobj(x)",
      "documentation": {
        "description": "Return True if x is a not complex type or an array of complex numbers.\nThe type of the input is checked, not the value. So even if the input\nhas an imaginary part equal to zero, `isrealobj` evaluates to False\nif the data type is complex.",
        "parameters": {
          "x": {
            "type": "any",
            "description": "The input can be of any type and shape."
          }
        },
        "returns": "-------\ny : bool\nThe return value, False if `x` is of a complex type.",
        "raises": "",
        "see_also": "--------\niscomplexobj, isreal",
        "notes": "-----\nThe function is only meant for arrays with numerical values but it\naccepts all other objects. Since it assumes array input, the return\nvalue of other objects may be True.\n>>> np.isrealobj('A string')\nTrue\n>>> np.isrealobj(False)\nTrue\n>>> np.isrealobj(None)\nTrue",
        "examples": "--------\n>>> np.isrealobj(1)\nTrue\n>>> np.isrealobj(1+0j)\nFalse\n>>> np.isrealobj([3, 1+0j, True])\nFalse"
      }
    },
    {
      "name": "issubclass_",
      "signature": "issubclass_(arg1, arg2)",
      "documentation": {
        "description": "Determine if a class is a subclass of a second class.\n`issubclass_` is equivalent to the Python built-in ``issubclass``,\nexcept that it returns False instead of raising a TypeError if one\nof the arguments is not a class.",
        "parameters": {
          "arg1": {
            "type": "class",
            "description": "Input class. True is returned if `arg1` is a subclass of `arg2`."
          },
          "arg2": {
            "type": "class or tuple of classes.",
            "description": "Input class. If a tuple of classes, True is returned if `arg1` is a\nsubclass of any of the tuple elements."
          }
        },
        "returns": "-------\nout : bool\nWhether `arg1` is a subclass of `arg2` or not.",
        "raises": "",
        "see_also": "--------\nissubsctype, issubdtype, issctype",
        "notes": "",
        "examples": "--------\n>>> np.issubclass_(np.int32, int)\nFalse\n>>> np.issubclass_(np.int32, float)\nFalse\n>>> np.issubclass_(np.float64, float)\nTrue"
      }
    },
    {
      "name": "issubdtype",
      "signature": "issubdtype(arg1, arg2)",
      "documentation": {
        "description": "",
        "parameters": {},
        "returns": "This is like the builtin :func:`issubclass`, but for `dtype`\\ s.\n-------\nout : bool",
        "raises": "",
        "see_also": "--------\n:ref:`arrays.scalars` : Overview of the numpy type hierarchy.\nissubsctype, issubclass_",
        "notes": "",
        "examples": "--------\n`issubdtype` can be used to check the type of arrays:\n>>> ints = np.array([1, 2, 3], dtype=np.int32)\n>>> np.issubdtype(ints.dtype, np.integer)\nTrue\n>>> np.issubdtype(ints.dtype, np.floating)\nFalse\n>>> floats = np.array([1, 2, 3], dtype=np.float32)\n>>> np.issubdtype(floats.dtype, np.integer)\nFalse\n>>> np.issubdtype(floats.dtype, np.floating)\nTrue\nSimilar types of different sizes are not subdtypes of each other:\n>>> np.issubdtype(np.float64, np.float32)\nFalse\n>>> np.issubdtype(np.float32, np.float64)\nFalse\nbut both are subtypes of `floating`:\n>>> np.issubdtype(np.float64, np.floating)\nTrue\n>>> np.issubdtype(np.float32, np.floating)\nTrue\nFor convenience, dtype-like objects are allowed too:\n>>> np.issubdtype('S1', np.string_)\nTrue\n>>> np.issubdtype('i4', np.signedinteger)\nTrue"
      }
    },
    {
      "name": "issubsctype",
      "signature": "issubsctype(arg1, arg2)",
      "documentation": {
        "description": "Determine if the first argument is a subclass of the second argument.",
        "parameters": {},
        "returns": "-------\nout : bool\nThe result.",
        "raises": "",
        "see_also": "--------\nissctype, issubdtype, obj2sctype",
        "notes": "",
        "examples": "--------\n>>> np.issubsctype('S8', str)\nFalse\n>>> np.issubsctype(np.array([1]), int)\nTrue\n>>> np.issubsctype(np.array([1]), float)\nFalse"
      }
    },
    {
      "name": "iterable",
      "signature": "iterable(y)",
      "documentation": {
        "description": "Check whether or not an object can be iterated over.",
        "parameters": {
          "y": {
            "type": "object",
            "description": "Input object."
          }
        },
        "returns": "-------\nb : bool\nReturn ``True`` if the object has an iterator method or is a\nsequence and ``False`` otherwise.",
        "raises": "",
        "see_also": "",
        "notes": "-----\nIn most cases, the results of ``np.iterable(obj)`` are consistent with\n``isinstance(obj, collections.abc.Iterable)``. One notable exception is\nthe treatment of 0-dimensional arrays::\n>>> from collections.abc import Iterable\n>>> a = np.array(1.0)  # 0-dimensional numpy array\n>>> isinstance(a, Iterable)\nTrue\n>>> np.iterable(a)\nFalse",
        "examples": "--------\n>>> np.iterable([1, 2, 3])\nTrue\n>>> np.iterable(2)\nFalse"
      }
    },
    {
      "name": "ix_",
      "signature": "ix_(*args)",
      "documentation": {
        "description": "Construct an open mesh from multiple sequences.\nThis function takes N 1-D sequences and returns N outputs with N\ndimensions each, such that the shape is 1 in all but one dimension\nand the dimension with the non-unit shape value cycles through all\nN dimensions.\nUsing `ix_` one can quickly construct index arrays that will index\nthe cross product. ``a[np.ix_([1,3],[2,5])]`` returns the array\n``[[a[1,2] a[1,5]], [a[3,2] a[3,5]]]``.",
        "parameters": {
          "args": {
            "type": "1-D sequences",
            "description": "Each sequence should be of integer or boolean type.\nBoolean sequences will be interpreted as boolean masks for the\ncorresponding dimension (equivalent to passing in\n``np.nonzero(boolean_sequence)``)."
          }
        },
        "returns": "-------\nout : tuple of ndarrays\nN arrays with N dimensions each, with N the number of input\nsequences. Together these arrays form an open mesh.",
        "raises": "",
        "see_also": "--------\nogrid, mgrid, meshgrid",
        "notes": "",
        "examples": "--------\n>>> a = np.arange(10).reshape(2, 5)\n>>> a\narray([[0, 1, 2, 3, 4],\n[5, 6, 7, 8, 9]])\n>>> ixgrid = np.ix_([0, 1], [2, 4])\n>>> ixgrid\n(array([[0],\n[1]]), array([[2, 4]]))\n>>> ixgrid[0].shape, ixgrid[1].shape\n((2, 1), (1, 2))\n>>> a[ixgrid]\narray([[2, 4],\n[7, 9]])\n>>> ixgrid = np.ix_([True, True], [2, 4])\n>>> a[ixgrid]\narray([[2, 4],\n[7, 9]])\n>>> ixgrid = np.ix_([True, True], [False, False, True, False, True])\n>>> a[ixgrid]\narray([[2, 4],\n[7, 9]])"
      }
    },
    {
      "name": "kaiser",
      "signature": "kaiser(M, beta)",
      "documentation": {
        "description": "Return the Kaiser window.\nThe Kaiser window is a taper formed by using a Bessel function.",
        "parameters": {
          "M": {
            "type": "int",
            "description": "Number of points in the output window. If zero or less, an\nempty array is returned."
          },
          "beta": {
            "type": "float",
            "description": "Shape parameter for window."
          }
        },
        "returns": "-------\nout : array\nThe window, with the maximum value normalized to one (the value\none appears only if the number of samples is odd).",
        "raises": "",
        "see_also": "--------\nbartlett, blackman, hamming, hanning",
        "notes": "-----\nThe Kaiser window is defined as\n.. math::  w(n) = I_0\\left( \\beta \\sqrt{1-\\frac{4n^2}{(M-1)^2}}\n\\right)/I_0(\\beta)\nwith\n.. math:: \\quad -\\frac{M-1}{2} \\leq n \\leq \\frac{M-1}{2},\nwhere :math:`I_0` is the modified zeroth-order Bessel function.\nThe Kaiser was named for Jim Kaiser, who discovered a simple\napproximation to the DPSS window based on Bessel functions.  The Kaiser\nwindow is a very good approximation to the Digital Prolate Spheroidal\nSequence, or Slepian window, which is the transform which maximizes the\nenergy in the main lobe of the window relative to total energy.\nThe Kaiser can approximate many other windows by varying the beta\nparameter.\n====  =======================\nbeta  Window shape\n====  =======================\n0     Rectangular\n5     Similar to a Hamming\n6     Similar to a Hanning\n8.6   Similar to a Blackman\n====  =======================\nA beta value of 14 is probably a good starting point. Note that as beta\ngets large, the window narrows, and so the number of samples needs to be\nlarge enough to sample the increasingly narrow spike, otherwise NaNs will\nget returned.\nMost references to the Kaiser window come from the signal processing\nliterature, where it is used as one of many windowing functions for\nsmoothing values.  It is also known as an apodization (which means\n\"removing the foot\", i.e. smoothing discontinuities at the beginning\nand end of the sampled signal) or tapering function.\nReferences\n----------\n.. [1] J. F. Kaiser, \"Digital Filters\" - Ch 7 in \"Systems analysis by\ndigital computer\", Editors: F.F. Kuo and J.F. Kaiser, p 218-285.\nJohn Wiley and Sons, New York, (1966).\n.. [2] E.R. Kanasewich, \"Time Sequence Analysis in Geophysics\", The\nUniversity of Alberta Press, 1975, pp. 177-178.\n.. [3] Wikipedia, \"Window function\",\nhttps://en.wikipedia.org/wiki/Window_function",
        "examples": "--------\n>>> import matplotlib.pyplot as plt\n>>> np.kaiser(12, 14)\narray([7.72686684e-06, 3.46009194e-03, 4.65200189e-02, # may vary\n2.29737120e-01, 5.99885316e-01, 9.45674898e-01,\n9.45674898e-01, 5.99885316e-01, 2.29737120e-01,\n4.65200189e-02, 3.46009194e-03, 7.72686684e-06])\nPlot the window and the frequency response:\n>>> from numpy.fft import fft, fftshift\n>>> window = np.kaiser(51, 14)\n>>> plt.plot(window)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Kaiser window\")\nText(0.5, 1.0, 'Kaiser window')\n>>> plt.ylabel(\"Amplitude\")\nText(0, 0.5, 'Amplitude')\n>>> plt.xlabel(\"Sample\")\nText(0.5, 0, 'Sample')\n>>> plt.show()\n>>> plt.figure()\n<Figure size 640x480 with 0 Axes>\n>>> A = fft(window, 2048) / 25.5\n>>> mag = np.abs(fftshift(A))\n>>> freq = np.linspace(-0.5, 0.5, len(A))\n>>> response = 20 * np.log10(mag)\n>>> response = np.clip(response, -100, 100)\n>>> plt.plot(freq, response)\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Frequency response of Kaiser window\")\nText(0.5, 1.0, 'Frequency response of Kaiser window')\n>>> plt.ylabel(\"Magnitude [dB]\")\nText(0, 0.5, 'Magnitude [dB]')\n>>> plt.xlabel(\"Normalized frequency [cycles per sample]\")\nText(0.5, 0, 'Normalized frequency [cycles per sample]')\n>>> plt.axis('tight')\n(-0.5, 0.5, -100.0, ...) # may vary\n>>> plt.show()"
      }
    },
    {
      "name": "kron",
      "signature": "kron(a, b)",
      "documentation": {
        "description": "Kronecker product of two arrays.\nComputes the Kronecker product, a composite array made of blocks of the\nsecond array scaled by the first.",
        "parameters": {},
        "returns": "-------\nout : ndarray",
        "raises": "",
        "see_also": "--------\nouter : The outer product",
        "notes": "-----\nThe function assumes that the number of dimensions of `a` and `b`\nare the same, if necessary prepending the smallest with ones.\nIf ``a.shape = (r0,r1,..,rN)`` and ``b.shape = (s0,s1,...,sN)``,\nthe Kronecker product has shape ``(r0*s0, r1*s1, ..., rN*SN)``.\nThe elements are products of elements from `a` and `b`, organized\nexplicitly by::\nkron(a,b)[k0,k1,...,kN] = a[i0,i1,...,iN] * b[j0,j1,...,jN]\nwhere::\nkt = it * st + jt,  t = 0,...,N\nIn the common 2-D case (N=1), the block structure can be visualized::\n[[ a[0,0]*b,   a[0,1]*b,  ... , a[0,-1]*b  ],\n[  ...                              ...   ],\n[ a[-1,0]*b,  a[-1,1]*b, ... , a[-1,-1]*b ]]",
        "examples": "--------\n>>> np.kron([1,10,100], [5,6,7])\narray([  5,   6,   7, ..., 500, 600, 700])\n>>> np.kron([5,6,7], [1,10,100])\narray([  5,  50, 500, ...,   7,  70, 700])\n>>> np.kron(np.eye(2), np.ones((2,2)))\narray([[1.,  1.,  0.,  0.],\n[1.,  1.,  0.,  0.],\n[0.,  0.,  1.,  1.],\n[0.,  0.,  1.,  1.]])\n>>> a = np.arange(100).reshape((2,5,2,5))\n>>> b = np.arange(24).reshape((2,3,4))\n>>> c = np.kron(a,b)\n>>> c.shape\n(2, 10, 6, 20)\n>>> I = (1,3,0,2)\n>>> J = (0,2,1)\n>>> J1 = (0,) + J             # extend to ndim=4\n>>> S1 = (1,) + b.shape\n>>> K = tuple(np.array(I) * np.array(S1) + np.array(J1))\n>>> c[K] == a[I]*b[J]\nTrue"
      }
    },
    {
      "name": "load",
      "signature": "load(file, mmap_mode=None, allow_pickle=False, fix_imports=True, encoding='ASCII', *, max_header_size=10000)",
      "documentation": {
        "description": "Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files.\n.. warning:: Loading files that contain object arrays uses the ``pickle``\nmodule, which is not secure against erroneous or maliciously\nconstructed data. Consider passing ``allow_pickle=False`` to\nload data that is known not to contain object arrays for the\nsafer handling of untrusted sources.",
        "parameters": {
          "file": {
            "type": "file-like object, string, or pathlib.Path",
            "description": "The file to read. File-like objects must support the\n``seek()`` and ``read()`` methods and must always\nbe opened in binary mode.  Pickled files require that the\nfile-like object support the ``readline()`` method as well."
          },
          "mmap_mode": {
            "type": "{None, 'r+', 'r', 'w+', 'c'}, optional",
            "description": "If not None, then memory-map the file, using the given mode (see\n`numpy.memmap` for a detailed description of the modes).  A\nmemory-mapped array is kept on disk. However, it can be accessed\nand sliced like any ndarray.  Memory mapping is especially useful\nfor accessing small fragments of large files without reading the\nentire file into memory."
          },
          "allow_pickle": {
            "type": "bool, optional",
            "description": "Allow loading pickled object arrays stored in npy files. Reasons for\ndisallowing pickles include security, as loading pickled data can\nexecute arbitrary code. If pickles are disallowed, loading object\narrays will fail. Default: False\n.. versionchanged:: 1.16.3\nMade default False in response to CVE-2019-6446."
          },
          "fix_imports": {
            "type": "bool, optional",
            "description": "Only useful when loading Python 2 generated pickled files on Python 3,\nwhich includes npy/npz files containing object arrays. If `fix_imports`\nis True, pickle will try to map the old Python 2 names to the new names\nused in Python 3."
          },
          "encoding": {
            "type": "str, optional",
            "description": "What encoding to use when reading Python 2 strings. Only useful when\nloading Python 2 generated pickled files in Python 3, which includes\nnpy/npz files containing object arrays. Values other than 'latin1',\n'ASCII', and 'bytes' are not allowed, as they can corrupt numerical\ndata. Default: 'ASCII'"
          },
          "max_header_size": {
            "type": "int, optional",
            "description": "Maximum allowed size of the header.  Large headers may not be safe\nto load securely and thus require explicitly passing a larger value."
          },
          "See": {
            "type": "py:func:`ast.literal_eval()` for details.",
            "description": "This option is ignored when `allow_pickle` is passed.  In that case\nthe file is by definition trusted and the limit is unnecessary."
          }
        },
        "returns": "-------\nresult : array, tuple, dict, etc.\nData stored in the file. For ``.npz`` files, the returned instance\nof NpzFile class must be closed to avoid leaking file descriptors.",
        "raises": "------\nOSError\nIf the input file does not exist or cannot be read.\nUnpicklingError\nIf ``allow_pickle=True``, but the file cannot be loaded as a pickle.\nValueError\nThe file contains an object array, but ``allow_pickle=False`` given.\nEOFError\nWhen calling ``np.load`` multiple times on the same file handle,\nif all data has already been read",
        "see_also": "--------\nsave, savez, savez_compressed, loadtxt\nmemmap : Create a memory-map to an array stored in a file on disk.\nlib.format.open_memmap : Create or load a memory-mapped ``.npy`` file.",
        "notes": "-----\n- If the file contains pickle data, then whatever object is stored\nin the pickle is returned.\n- If the file is a ``.npy`` file, then a single array is returned.\n- If the file is a ``.npz`` file, then a dictionary-like object is\nreturned, containing ``{filename: array}`` key-value pairs, one for\neach file in the archive.\n- If the file is a ``.npz`` file, the returned value supports the\ncontext manager protocol in a similar fashion to the open function::\nwith load('foo.npz') as data:\na = data['a']\nThe underlying file descriptor is closed when exiting the 'with'\nblock.",
        "examples": "--------\nStore data to disk, and load it again:\n>>> np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]]))\n>>> np.load('/tmp/123.npy')\narray([[1, 2, 3],\n[4, 5, 6]])\nStore compressed data to disk, and load it again:\n>>> a=np.array([[1, 2, 3], [4, 5, 6]])\n>>> b=np.array([1, 2])\n>>> np.savez('/tmp/123.npz', a=a, b=b)\n>>> data = np.load('/tmp/123.npz')\n>>> data['a']\narray([[1, 2, 3],\n[4, 5, 6]])\n>>> data['b']\narray([1, 2])\n>>> data.close()\nMem-map the stored array, and then access the second row\ndirectly from disk:\n>>> X = np.load('/tmp/123.npy', mmap_mode='r')\n>>> X[1, :]\nmemmap([4, 5, 6])"
      }
    },
    {
      "name": "loadtxt",
      "signature": "loadtxt(fname, dtype=<class 'float'>, comments='#', delimiter=None, converters=None, skiprows=0, usecols=None, unpack=False, ndmin=0, encoding='bytes', max_rows=None, *, quotechar=None, like=None)",
      "documentation": {
        "description": "Load data from a text file.",
        "parameters": {
          "fname": {
            "type": "file, str, pathlib.Path, list of str, generator",
            "description": "File, filename, list, or generator to read.  If the filename\nextension is ``.gz`` or ``.bz2``, the file is first decompressed. Note\nthat generators must return bytes or strings. The strings\nin a list or produced by a generator are treated as lines."
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "Data-type of the resulting array; default: float.  If this is a\nstructured data-type, the resulting array will be 1-dimensional, and\neach row will be interpreted as an element of the array.  In this\ncase, the number of columns used must match the number of fields in\nthe data-type."
          },
          "comments": {
            "type": "str or sequence of str or None, optional",
            "description": "The characters or list of characters used to indicate the start of a\ncomment. None implies no comments. For backwards compatibility, byte\nstrings will be decoded as 'latin1'. The default is '#'."
          },
          "delimiter": {
            "type": "str, optional",
            "description": "The character used to separate the values. For backwards compatibility,\nbyte strings will be decoded as 'latin1'. The default is whitespace.\n.. versionchanged:: 1.23.0\nOnly single character delimiters are supported. Newline characters\ncannot be used as the delimiter."
          },
          "converters": {
            "type": "dict or callable, optional",
            "description": "Converter functions to customize value parsing. If `converters` is\ncallable, the function is applied to all columns, else it must be a\ndict that maps column number to a parser function.\nSee examples for further details."
          },
          "Default": {
            "type": "None.",
            "description": ".. versionchanged:: 1.23.0\nThe ability to pass a single callable to be applied to all columns\nwas added."
          },
          "skiprows": {
            "type": "int, optional",
            "description": "Skip the first `skiprows` lines, including comments; default: 0."
          },
          "usecols": {
            "type": "int or sequence, optional",
            "description": "Which columns to read, with 0 being the first. For example,\n``usecols = (1,4,5)`` will extract the 2nd, 5th and 6th columns.\nThe default, None, results in all columns being read.\n.. versionchanged:: 1.11.0\nWhen a single column has to be read it is possible to use\nan integer instead of a tuple. E.g ``usecols = 3`` reads the\nfourth column the same way as ``usecols = (3,)`` would."
          },
          "unpack": {
            "type": "bool, optional",
            "description": "If True, the returned array is transposed, so that arguments may be\nunpacked using ``x, y, z = loadtxt(...)``.  When used with a\nstructured data-type, arrays are returned for each field.\nDefault is False."
          },
          "ndmin": {
            "type": "int, optional",
            "description": "The returned array will have at least `ndmin` dimensions.\nOtherwise mono-dimensional axes will be squeezed.\nLegal values: 0 (default), 1 or 2.\n.. versionadded:: 1.6.0"
          },
          "encoding": {
            "type": "str, optional",
            "description": "Encoding used to decode the inputfile. Does not apply to input streams.\nThe special value 'bytes' enables backward compatibility workarounds\nthat ensures you receive byte arrays as results if possible and passes\n'latin1' encoded strings to converters. Override this value to receive\nunicode arrays and pass strings as input to converters.  If set to None\nthe system default is used. The default value is 'bytes'.\n.. versionadded:: 1.14.0"
          },
          "max_rows": {
            "type": "int, optional",
            "description": "Read `max_rows` rows of content after `skiprows` lines. The default is\nto read all the rows. Note that empty rows containing no data such as\nempty lines and comment lines are not counted towards `max_rows`,\nwhile such lines are counted in `skiprows`.\n.. versionadded:: 1.16.0\n.. versionchanged:: 1.23.0\nLines containing no data, including comment lines (e.g., lines\nstarting with '#' or as specified via `comments`) are not counted\ntowards `max_rows`."
          },
          "quotechar": {
            "type": "unicode character or None, optional",
            "description": "The character used to denote the start and end of a quoted item.\nOccurrences of the delimiter or comment characters are ignored within\na quoted item. The default value is ``quotechar=None``, which means\nquoting support is disabled.\nIf two consecutive instances of `quotechar` are found within a quoted\nfield, the first is treated as an escape character. See examples.\n.. versionadded:: 1.23.0"
          },
          "like": {
            "type": "array_like, optional",
            "description": "Reference object to allow the creation of arrays which are not\nNumPy arrays. If an array-like passed in as ``like`` supports\nthe ``__array_function__`` protocol, the result will be defined\nby it. In this case, it ensures the creation of an array object\ncompatible with that passed in via this argument.\n.. versionadded:: 1.20.0"
          }
        },
        "returns": "-------\nout : ndarray\nData read from the text file.",
        "raises": "",
        "see_also": "--------\nload, fromstring, fromregex\ngenfromtxt : Load data with missing values handled as specified.\nscipy.io.loadmat : reads MATLAB data files",
        "notes": "-----\nThis function aims to be a fast reader for simply formatted files.  The\n`genfromtxt` function provides more sophisticated handling of, e.g.,\nlines with missing values.\nEach row in the input text file must have the same number of values to be\nable to read all values. If all rows do not have same number of values, a\nsubset of up to n columns (where n is the least number of values present\nin all rows) can be read by specifying the columns via `usecols`.\n.. versionadded:: 1.10.0\nThe strings produced by the Python float.hex method can be used as\ninput for floats.",
        "examples": "--------\n>>> from io import StringIO   # StringIO behaves like a file object\n>>> c = StringIO(\"0 1\\n2 3\")\n>>> np.loadtxt(c)\narray([[0., 1.],\n[2., 3.]])\n>>> d = StringIO(\"M 21 72\\nF 35 58\")\n>>> np.loadtxt(d, dtype={'names': ('gender', 'age', 'weight'),\n...                      'formats': ('S1', 'i4', 'f4')})\narray([(b'M', 21, 72.), (b'F', 35, 58.)],\ndtype=[('gender', 'S1'), ('age', '<i4'), ('weight', '<f4')])\n>>> c = StringIO(\"1,0,2\\n3,0,4\")\n>>> x, y = np.loadtxt(c, delimiter=',', usecols=(0, 2), unpack=True)\n>>> x\narray([1., 3.])\n>>> y\narray([2., 4.])\nThe `converters` argument is used to specify functions to preprocess the\ntext prior to parsing. `converters` can be a dictionary that maps\npreprocessing functions to each column:\n>>> s = StringIO(\"1.618, 2.296\\n3.141, 4.669\\n\")\n>>> conv = {\n...     0: lambda x: np.floor(float(x)),  # conversion fn for column 0\n...     1: lambda x: np.ceil(float(x)),  # conversion fn for column 1\n... }\n>>> np.loadtxt(s, delimiter=\",\", converters=conv)\narray([[1., 3.],\n[3., 5.]])\n`converters` can be a callable instead of a dictionary, in which case it\nis applied to all columns:\n>>> s = StringIO(\"0xDE 0xAD\\n0xC0 0xDE\")\n>>> import functools\n>>> conv = functools.partial(int, base=16)\n>>> np.loadtxt(s, converters=conv)\narray([[222., 173.],\n[192., 222.]])\nThis example shows how `converters` can be used to convert a field\nwith a trailing minus sign into a negative number.\n>>> s = StringIO('10.01 31.25-\\n19.22 64.31\\n17.57- 63.94')\n>>> def conv(fld):\n...     return -float(fld[:-1]) if fld.endswith(b'-') else float(fld)\n...\n>>> np.loadtxt(s, converters=conv)\narray([[ 10.01, -31.25],\n[ 19.22,  64.31],\n[-17.57,  63.94]])\nUsing a callable as the converter can be particularly useful for handling\nvalues with different formatting, e.g. floats with underscores:\n>>> s = StringIO(\"1 2.7 100_000\")\n>>> np.loadtxt(s, converters=float)\narray([1.e+00, 2.7e+00, 1.e+05])\nThis idea can be extended to automatically handle values specified in\nmany different formats:\n>>> def conv(val):\n...     try:\n...         return float(val)\n...     except ValueError:\n...         return float.fromhex(val)\n>>> s = StringIO(\"1, 2.5, 3_000, 0b4, 0x1.4000000000000p+2\")\n>>> np.loadtxt(s, delimiter=\",\", converters=conv, encoding=None)\narray([1.0e+00, 2.5e+00, 3.0e+03, 1.8e+02, 5.0e+00])\nNote that with the default ``encoding=\"bytes\"``, the inputs to the\nconverter function are latin-1 encoded byte strings. To deactivate the\nimplicit encoding prior to conversion, use ``encoding=None``\n>>> s = StringIO('10.01 31.25-\\n19.22 64.31\\n17.57- 63.94')\n>>> conv = lambda x: -float(x[:-1]) if x.endswith('-') else float(x)\n>>> np.loadtxt(s, converters=conv, encoding=None)\narray([[ 10.01, -31.25],\n[ 19.22,  64.31],\n[-17.57,  63.94]])\nSupport for quoted fields is enabled with the `quotechar` parameter.\nComment and delimiter characters are ignored when they appear within a\nquoted item delineated by `quotechar`:\n>>> s = StringIO('\"alpha, #42\", 10.0\\n\"beta, #64\", 2.0\\n')\n>>> dtype = np.dtype([(\"label\", \"U12\"), (\"value\", float)])\n>>> np.loadtxt(s, dtype=dtype, delimiter=\",\", quotechar='\"')\narray([('alpha, #42', 10.), ('beta, #64',  2.)],\ndtype=[('label', '<U12'), ('value', '<f8')])\nQuoted fields can be separated by multiple whitespace characters:\n>>> s = StringIO('\"alpha, #42\"       10.0\\n\"beta, #64\" 2.0\\n')\n>>> dtype = np.dtype([(\"label\", \"U12\"), (\"value\", float)])\n>>> np.loadtxt(s, dtype=dtype, delimiter=None, quotechar='\"')\narray([('alpha, #42', 10.), ('beta, #64',  2.)],\ndtype=[('label', '<U12'), ('value', '<f8')])\nTwo consecutive quote characters within a quoted field are treated as a\nsingle escaped character:\n>>> s = StringIO('\"Hello, my name is \"\"Monty\"\"!\"')\n>>> np.loadtxt(s, dtype=\"U\", delimiter=\",\", quotechar='\"')\narray('Hello, my name is \"Monty\"!', dtype='<U26')\nRead subset of columns when all rows do not contain equal number of values:\n>>> d = StringIO(\"1 2\\n2 4\\n3 9 12\\n4 16 20\")\n>>> np.loadtxt(d, usecols=(0, 1))\narray([[ 1.,  2.],\n[ 2.,  4.],\n[ 3.,  9.],\n[ 4., 16.]])"
      }
    },
    {
      "name": "lookfor",
      "signature": "lookfor(what, module=None, import_modules=True, regenerate=False, output=None)",
      "documentation": {
        "description": "Do a keyword search on docstrings.\nA list of objects that matched the search is displayed,\nsorted by relevance. All given keywords need to be found in the\ndocstring for it to be returned as a result, but the order does\nnot matter.",
        "parameters": {
          "what": {
            "type": "str",
            "description": "String containing words to look for."
          },
          "module": {
            "type": "str or list, optional",
            "description": "Name of module(s) whose docstrings to go through."
          },
          "import_modules": {
            "type": "bool, optional",
            "description": "Whether to import sub-modules in packages. Default is True."
          },
          "regenerate": {
            "type": "bool, optional",
            "description": "Whether to re-generate the docstring cache. Default is False."
          },
          "output": {
            "type": "file-like, optional",
            "description": "File-like object to write the output to. If omitted, use a pager."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\nsource, info",
        "notes": "-----\nRelevance is determined only roughly, by checking if the keywords occur\nin the function name, at the start of a docstring, etc.",
        "examples": "--------\n>>> np.lookfor('binary representation') # doctest: +SKIP\nSearch results for 'binary representation'\n------------------------------------------\nnumpy.binary_repr\nReturn the binary representation of the input number as a string.\nnumpy.core.setup_common.long_double_representation\nGiven a binary dump as given by GNU od -b, look for long double\nnumpy.base_repr\nReturn a string representation of a number in the given base system.\n..."
      }
    },
    {
      "name": "mask_indices",
      "signature": "mask_indices(n, mask_func, k=0)",
      "documentation": {
        "description": "Return the indices to access (n, n) arrays, given a masking function.\nAssume `mask_func` is a function that, for a square array a of size\n``(n, n)`` with a possible offset argument `k`, when called as\n``mask_func(a, k)`` returns a new array with zeros in certain locations\n(functions like `triu` or `tril` do precisely this). Then this function\nreturns the indices where the non-zero values would be located.",
        "parameters": {
          "n": {
            "type": "int",
            "description": "The returned indices will be valid to access arrays of shape (n, n)."
          },
          "mask_func": {
            "type": "callable",
            "description": "A function whose call signature is similar to that of `triu`, `tril`.\nThat is, ``mask_func(x, k)`` returns a boolean array, shaped like `x`.\n`k` is an optional argument to the function."
          },
          "k": {
            "type": "scalar",
            "description": "An optional argument which is passed through to `mask_func`. Functions\nlike `triu`, `tril` take a second argument that is interpreted as an\noffset."
          }
        },
        "returns": "-------\nindices : tuple of arrays.\nThe `n` arrays of indices corresponding to the locations where\n``mask_func(np.ones((n, n)), k)`` is True.",
        "raises": "",
        "see_also": "--------\ntriu, tril, triu_indices, tril_indices",
        "notes": "-----\n.. versionadded:: 1.4.0",
        "examples": "--------\nThese are the indices that would allow you to access the upper triangular\npart of any 3x3 array:\n>>> iu = np.mask_indices(3, np.triu)\nFor example, if `a` is a 3x3 array:\n>>> a = np.arange(9).reshape(3, 3)\n>>> a\narray([[0, 1, 2],\n[3, 4, 5],\n[6, 7, 8]])\n>>> a[iu]\narray([0, 1, 2, 4, 5, 8])\nAn offset can be passed also to the masking function.  This gets us the\nindices starting on the first diagonal right of the main one:\n>>> iu1 = np.mask_indices(3, np.triu, 1)\nwith which we now extract only three elements:\n>>> a[iu1]\narray([1, 2, 5])"
      }
    },
    {
      "name": "median",
      "signature": "median(a, axis=None, out=None, overwrite_input=False, keepdims=False)",
      "documentation": {
        "description": "Compute the median along the specified axis.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array or object that can be converted to an array."
          },
          "axis": {
            "type": "{int, sequence of int, None}, optional",
            "description": "Axis or axes along which the medians are computed. The default\nis to compute the median along a flattened version of the array.\nA sequence of axes is supported since version 1.9.0."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must\nhave the same shape and buffer length as the expected output,\nbut the type (of the output) will be cast if necessary."
          },
          "overwrite_input": {
            "type": "bool, optional",
            "description": "If True, then allow use of memory of input array `a` for\ncalculations. The input array will be modified by the call to\n`median`. This will save memory when you do not need to preserve\nthe contents of the input array. Treat the input as undefined,\nbut it will probably be fully or partially sorted. Default is\nFalse. If `overwrite_input` is ``True`` and `a` is not already an\n`ndarray`, an error will be raised."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\nin the result as dimensions with size one. With this option,\nthe result will broadcast correctly against the original `arr`.\n.. versionadded:: 1.9.0"
          }
        },
        "returns": "-------\nmedian : ndarray\nA new array holding the result. If the input contains integers\nor floats smaller than ``float64``, then the output data-type is\n``np.float64``.  Otherwise, the data-type of the output is the\nsame as that of the input. If `out` is specified, that array is\nreturned instead.",
        "raises": "",
        "see_also": "--------\nmean, percentile",
        "notes": "-----\nGiven a vector ``V`` of length ``N``, the median of ``V`` is the\nmiddle value of a sorted copy of ``V``, ``V_sorted`` - i\ne., ``V_sorted[(N-1)/2]``, when ``N`` is odd, and the average of the\ntwo middle values of ``V_sorted`` when ``N`` is even.",
        "examples": "--------\n>>> a = np.array([[10, 7, 4], [3, 2, 1]])\n>>> a\narray([[10,  7,  4],\n[ 3,  2,  1]])\n>>> np.median(a)\n3.5\n>>> np.median(a, axis=0)\narray([6.5, 4.5, 2.5])\n>>> np.median(a, axis=1)\narray([7.,  2.])\n>>> m = np.median(a, axis=0)\n>>> out = np.zeros_like(m)\n>>> np.median(a, axis=0, out=m)\narray([6.5,  4.5,  2.5])\n>>> m\narray([6.5,  4.5,  2.5])\n>>> b = a.copy()\n>>> np.median(b, axis=1, overwrite_input=True)\narray([7.,  2.])\n>>> assert not np.all(a==b)\n>>> b = a.copy()\n>>> np.median(b, axis=None, overwrite_input=True)\n3.5\n>>> assert not np.all(a==b)"
      }
    },
    {
      "name": "meshgrid",
      "signature": "meshgrid(*xi, copy=True, sparse=False, indexing='xy')",
      "documentation": {
        "description": "Return a list of coordinate matrices from coordinate vectors.\nMake N-D coordinate arrays for vectorized evaluations of\nN-D scalar/vector fields over N-D grids, given\none-dimensional coordinate arrays x1, x2,..., xn.\n.. versionchanged:: 1.9\n1-D and 0-D cases are allowed.",
        "parameters": {
          "indexing": {
            "type": "{'xy', 'ij'}, optional",
            "description": "Cartesian ('xy', default) or matrix ('ij') indexing of output.\nSee Notes for more details.\n.. versionadded:: 1.7.0"
          },
          "sparse": {
            "type": "bool, optional",
            "description": "If True the shape of the returned coordinate array for dimension *i*\nis reduced from ``(N1, ..., Ni, ... Nn)`` to\n``(1, ..., 1, Ni, 1, ..., 1)``.  These sparse coordinate grids are\nintended to be use with :ref:`basics.broadcasting`.  When all\ncoordinates are used in an expression, broadcasting still leads to a\nfully-dimensonal result array.\nDefault is False.\n.. versionadded:: 1.7.0"
          },
          "copy": {
            "type": "bool, optional",
            "description": "If False, a view into the original arrays are returned in order to\nconserve memory.  Default is True.  Please note that\n``sparse=False, copy=False`` will likely return non-contiguous\narrays.  Furthermore, more than one element of a broadcast array\nmay refer to a single memory location.  If you need to write to the\narrays, make copies first.\n.. versionadded:: 1.7.0"
          }
        },
        "returns": "-------\nX1, X2,..., XN : list of ndarrays\nFor vectors `x1`, `x2`,..., `xn` with lengths ``Ni=len(xi)``,\nreturns ``(N1, N2, N3,..., Nn)`` shaped arrays if indexing='ij'\nor ``(N2, N1, N3,..., Nn)`` shaped arrays if indexing='xy'\nwith the elements of `xi` repeated to fill the matrix along\nthe first dimension for `x1`, the second for `x2` and so on.",
        "raises": "",
        "see_also": "--------\nmgrid : Construct a multi-dimensional \"meshgrid\" using indexing notation.\nogrid : Construct an open multi-dimensional \"meshgrid\" using indexing\nnotation.\nhow-to-index",
        "notes": "-----\nThis function supports both indexing conventions through the indexing\nkeyword argument.  Giving the string 'ij' returns a meshgrid with\nmatrix indexing, while 'xy' returns a meshgrid with Cartesian indexing.\nIn the 2-D case with inputs of length M and N, the outputs are of shape\n(N, M) for 'xy' indexing and (M, N) for 'ij' indexing.  In the 3-D case\nwith inputs of length M, N and P, outputs are of shape (N, M, P) for\n'xy' indexing and (M, N, P) for 'ij' indexing.  The difference is\nillustrated by the following code snippet::\nxv, yv = np.meshgrid(x, y, indexing='ij')\nfor i in range(nx):\nfor j in range(ny):\n# treat xv[i,j], yv[i,j]\nxv, yv = np.meshgrid(x, y, indexing='xy')\nfor i in range(nx):\nfor j in range(ny):\n# treat xv[j,i], yv[j,i]\nIn the 1-D and 0-D case, the indexing and sparse keywords have no effect.",
        "examples": "--------\n>>> nx, ny = (3, 2)\n>>> x = np.linspace(0, 1, nx)\n>>> y = np.linspace(0, 1, ny)\n>>> xv, yv = np.meshgrid(x, y)\n>>> xv\narray([[0. , 0.5, 1. ],\n[0. , 0.5, 1. ]])\n>>> yv\narray([[0.,  0.,  0.],\n[1.,  1.,  1.]])\nThe result of `meshgrid` is a coordinate grid:\n>>> import matplotlib.pyplot as plt\n>>> plt.plot(xv, yv, marker='o', color='k', linestyle='none')\n>>> plt.show()\nYou can create sparse output arrays to save memory and computation time.\n>>> xv, yv = np.meshgrid(x, y, sparse=True)\n>>> xv\narray([[0. ,  0.5,  1. ]])\n>>> yv\narray([[0.],\n[1.]])\n`meshgrid` is very useful to evaluate functions on a grid. If the\nfunction depends on all coordinates, both dense and sparse outputs can be\nused.\n>>> x = np.linspace(-5, 5, 101)\n>>> y = np.linspace(-5, 5, 101)\n>>> # full coordinate arrays\n>>> xx, yy = np.meshgrid(x, y)\n>>> zz = np.sqrt(xx**2 + yy**2)\n>>> xx.shape, yy.shape, zz.shape\n((101, 101), (101, 101), (101, 101))\n>>> # sparse coordinate arrays\n>>> xs, ys = np.meshgrid(x, y, sparse=True)\n>>> zs = np.sqrt(xs**2 + ys**2)\n>>> xs.shape, ys.shape, zs.shape\n((1, 101), (101, 1), (101, 101))\n>>> np.array_equal(zz, zs)\nTrue\n>>> h = plt.contourf(x, y, zs)\n>>> plt.axis('scaled')\n>>> plt.colorbar()\n>>> plt.show()"
      }
    },
    {
      "name": "mintypecode",
      "signature": "mintypecode(typechars, typeset='GDFgdf', default='d')",
      "documentation": {
        "description": "Return the character for the minimum-size type to which given types can\nbe safely cast.\nThe returned type character must represent the smallest size dtype such\nthat an array of the returned type can handle the data from an array of\nall types in `typechars` (or if `typechars` is an array, then its\ndtype.char).",
        "parameters": {
          "typechars": {
            "type": "list of str or array_like",
            "description": "If a list of strings, each string should represent a dtype.\nIf array_like, the character representation of the array dtype is used."
          },
          "typeset": {
            "type": "str or list of str, optional",
            "description": "The set of characters that the returned character is chosen from.\nThe default set is 'GDFgdf'."
          },
          "default": {
            "type": "str, optional",
            "description": "The default character, this is returned if none of the characters in\n`typechars` matches a character in `typeset`."
          }
        },
        "returns": "-------\ntypechar : str\nThe character representing the minimum-size type that was found.",
        "raises": "",
        "see_also": "--------\ndtype, sctype2char, maximum_sctype",
        "notes": "",
        "examples": "--------\n>>> np.mintypecode(['d', 'f', 'S'])\n'd'\n>>> x = np.array([1.1, 2-3.j])\n>>> np.mintypecode(x)\n'D'\n>>> np.mintypecode('abceh', default='G')\n'G'"
      }
    },
    {
      "name": "msort",
      "signature": "msort(a)",
      "documentation": {
        "description": "Return a copy of an array sorted along the first axis.\n.. deprecated:: 1.24\nmsort is deprecated, use ``np.sort(a, axis=0)`` instead.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Array to be sorted."
          }
        },
        "returns": "-------\nsorted_array : ndarray\nArray of the same type and shape as `a`.",
        "raises": "",
        "see_also": "--------\nsort",
        "notes": "-----\n``np.msort(a)`` is equivalent to  ``np.sort(a, axis=0)``.",
        "examples": "--------\n>>> a = np.array([[1, 4], [3, 1]])\n>>> np.msort(a)  # sort along the first axis\narray([[1, 1],\n[3, 4]])"
      }
    },
    {
      "name": "nan_to_num",
      "signature": "nan_to_num(x, copy=True, nan=0.0, posinf=None, neginf=None)",
      "documentation": {
        "description": "Replace NaN with zero and infinity with large finite numbers (default\nbehaviour) or with the numbers defined by the user using the `nan`,\n`posinf` and/or `neginf` keywords.\nIf `x` is inexact, NaN is replaced by zero or by the user defined value in\n`nan` keyword, infinity is replaced by the largest finite floating point\nvalues representable by ``x.dtype`` or by the user defined value in\n`posinf` keyword and -infinity is replaced by the most negative finite\nfloating point values representable by ``x.dtype`` or by the user defined\nvalue in `neginf` keyword.\nFor complex dtypes, the above is applied to each of the real and\nimaginary components of `x` separately.\nIf `x` is not inexact, then no replacements are made.",
        "parameters": {
          "x": {
            "type": "scalar or array_like",
            "description": "Input data."
          },
          "copy": {
            "type": "bool, optional",
            "description": "Whether to create a copy of `x` (True) or to replace values\nin-place (False). The in-place operation only occurs if\ncasting to an array does not require a copy.\nDefault is True.\n.. versionadded:: 1.13"
          },
          "nan": {
            "type": "int, float, optional",
            "description": "Value to be used to fill NaN values. If no value is passed\nthen NaN values will be replaced with 0.0.\n.. versionadded:: 1.17"
          },
          "posinf": {
            "type": "int, float, optional",
            "description": "Value to be used to fill positive infinity values. If no value is\npassed then positive infinity values will be replaced with a very\nlarge number.\n.. versionadded:: 1.17"
          },
          "neginf": {
            "type": "int, float, optional",
            "description": "Value to be used to fill negative infinity values. If no value is\npassed then negative infinity values will be replaced with a very\nsmall (or negative) number.\n.. versionadded:: 1.17"
          }
        },
        "returns": "-------\nout : ndarray\n`x`, with the non-finite values replaced. If `copy` is False, this may\nbe `x` itself.",
        "raises": "",
        "see_also": "--------\nisinf : Shows which elements are positive or negative infinity.\nisneginf : Shows which elements are negative infinity.\nisposinf : Shows which elements are positive infinity.\nisnan : Shows which elements are Not a Number (NaN).\nisfinite : Shows which elements are finite (not NaN, not infinity)",
        "notes": "-----\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic\n(IEEE 754). This means that Not a Number is not equivalent to infinity.",
        "examples": "--------\n>>> np.nan_to_num(np.inf)\n1.7976931348623157e+308\n>>> np.nan_to_num(-np.inf)\n-1.7976931348623157e+308\n>>> np.nan_to_num(np.nan)\n0.0\n>>> x = np.array([np.inf, -np.inf, np.nan, -128, 128])\n>>> np.nan_to_num(x)\narray([ 1.79769313e+308, -1.79769313e+308,  0.00000000e+000, # may vary\n-1.28000000e+002,  1.28000000e+002])\n>>> np.nan_to_num(x, nan=-9999, posinf=33333333, neginf=33333333)\narray([ 3.3333333e+07,  3.3333333e+07, -9.9990000e+03,\n-1.2800000e+02,  1.2800000e+02])\n>>> y = np.array([complex(np.inf, np.nan), np.nan, complex(np.nan, np.inf)])\narray([  1.79769313e+308,  -1.79769313e+308,   0.00000000e+000, # may vary\n-1.28000000e+002,   1.28000000e+002])\n>>> np.nan_to_num(y)\narray([  1.79769313e+308 +0.00000000e+000j, # may vary\n0.00000000e+000 +0.00000000e+000j,\n0.00000000e+000 +1.79769313e+308j])\n>>> np.nan_to_num(y, nan=111111, posinf=222222)\narray([222222.+111111.j, 111111.     +0.j, 111111.+222222.j])"
      }
    },
    {
      "name": "nanargmax",
      "signature": "nanargmax(a, axis=None, out=None, *, keepdims=<no value>)",
      "documentation": {
        "description": "Return the indices of the maximum values in the specified axis ignoring\nNaNs. For all-NaN slices ``ValueError`` is raised. Warning: the\nresults cannot be trusted if a slice contains only NaNs and -Infs.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input data."
          },
          "axis": {
            "type": "int, optional",
            "description": "Axis along which to operate.  By default flattened input is used."
          },
          "out": {
            "type": "array, optional",
            "description": "If provided, the result will be inserted into this array. It should\nbe of the appropriate shape and dtype.\n.. versionadded:: 1.22.0"
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\nin the result as dimensions with size one. With this option,\nthe result will broadcast correctly against the array.\n.. versionadded:: 1.22.0"
          }
        },
        "returns": "-------\nindex_array : ndarray\nAn array of indices or a single index value.",
        "raises": "",
        "see_also": "--------\nargmax, nanargmin",
        "notes": "",
        "examples": "--------\n>>> a = np.array([[np.nan, 4], [2, 3]])\n>>> np.argmax(a)\n0\n>>> np.nanargmax(a)\n1\n>>> np.nanargmax(a, axis=0)\narray([1, 0])\n>>> np.nanargmax(a, axis=1)\narray([1, 1])"
      }
    },
    {
      "name": "nanargmin",
      "signature": "nanargmin(a, axis=None, out=None, *, keepdims=<no value>)",
      "documentation": {
        "description": "Return the indices of the minimum values in the specified axis ignoring\nNaNs. For all-NaN slices ``ValueError`` is raised. Warning: the results\ncannot be trusted if a slice contains only NaNs and Infs.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input data."
          },
          "axis": {
            "type": "int, optional",
            "description": "Axis along which to operate.  By default flattened input is used."
          },
          "out": {
            "type": "array, optional",
            "description": "If provided, the result will be inserted into this array. It should\nbe of the appropriate shape and dtype.\n.. versionadded:: 1.22.0"
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\nin the result as dimensions with size one. With this option,\nthe result will broadcast correctly against the array.\n.. versionadded:: 1.22.0"
          }
        },
        "returns": "-------\nindex_array : ndarray\nAn array of indices or a single index value.",
        "raises": "",
        "see_also": "--------\nargmin, nanargmax",
        "notes": "",
        "examples": "--------\n>>> a = np.array([[np.nan, 4], [2, 3]])\n>>> np.argmin(a)\n0\n>>> np.nanargmin(a)\n2\n>>> np.nanargmin(a, axis=0)\narray([1, 1])\n>>> np.nanargmin(a, axis=1)\narray([1, 0])"
      }
    },
    {
      "name": "nancumprod",
      "signature": "nancumprod(a, axis=None, dtype=None, out=None)",
      "documentation": {
        "description": "Return the cumulative product of array elements over a given axis treating Not a\nNumbers (NaNs) as one.  The cumulative product does not change when NaNs are\nencountered and leading NaNs are replaced by ones.\nOnes are returned for slices that are all-NaN or empty.\n.. versionadded:: 1.12.0",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array."
          },
          "axis": {
            "type": "int, optional",
            "description": "Axis along which the cumulative product is computed.  By default\nthe input is flattened."
          },
          "dtype": {
            "type": "dtype, optional",
            "description": "Type of the returned array, as well as of the accumulator in which\nthe elements are multiplied.  If *dtype* is not specified, it\ndefaults to the dtype of `a`, unless `a` has an integer dtype with\na precision less than that of the default platform integer.  In\nthat case, the default platform integer is used instead."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must\nhave the same shape and buffer length as the expected output\nbut the type of the resulting values will be cast if necessary."
          }
        },
        "returns": "-------\nnancumprod : ndarray\nA new array holding the result is returned unless `out` is\nspecified, in which case it is returned.",
        "raises": "",
        "see_also": "--------\nnumpy.cumprod : Cumulative product across array propagating NaNs.\nisnan : Show which elements are NaN.",
        "notes": "",
        "examples": "--------\n>>> np.nancumprod(1)\narray([1])\n>>> np.nancumprod([1])\narray([1])\n>>> np.nancumprod([1, np.nan])\narray([1.,  1.])\n>>> a = np.array([[1, 2], [3, np.nan]])\n>>> np.nancumprod(a)\narray([1.,  2.,  6.,  6.])\n>>> np.nancumprod(a, axis=0)\narray([[1.,  2.],\n[3.,  2.]])\n>>> np.nancumprod(a, axis=1)\narray([[1.,  2.],\n[3.,  3.]])"
      }
    },
    {
      "name": "nancumsum",
      "signature": "nancumsum(a, axis=None, dtype=None, out=None)",
      "documentation": {
        "description": "Return the cumulative sum of array elements over a given axis treating Not a\nNumbers (NaNs) as zero.  The cumulative sum does not change when NaNs are\nencountered and leading NaNs are replaced by zeros.\nZeros are returned for slices that are all-NaN or empty.\n.. versionadded:: 1.12.0",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array."
          },
          "axis": {
            "type": "int, optional",
            "description": "Axis along which the cumulative sum is computed. The default\n(None) is to compute the cumsum over the flattened array."
          },
          "dtype": {
            "type": "dtype, optional",
            "description": "Type of the returned array and of the accumulator in which the\nelements are summed.  If `dtype` is not specified, it defaults\nto the dtype of `a`, unless `a` has an integer dtype with a\nprecision less than that of the default platform integer.  In\nthat case, the default platform integer is used."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must\nhave the same shape and buffer length as the expected output\nbut the type will be cast if necessary. See :ref:`ufuncs-output-type` for\nmore details."
          }
        },
        "returns": "-------\nnancumsum : ndarray.\nA new array holding the result is returned unless `out` is\nspecified, in which it is returned. The result has the same\nsize as `a`, and the same shape as `a` if `axis` is not None\nor `a` is a 1-d array.",
        "raises": "",
        "see_also": "--------\nnumpy.cumsum : Cumulative sum across array propagating NaNs.\nisnan : Show which elements are NaN.",
        "notes": "",
        "examples": "--------\n>>> np.nancumsum(1)\narray([1])\n>>> np.nancumsum([1])\narray([1])\n>>> np.nancumsum([1, np.nan])\narray([1.,  1.])\n>>> a = np.array([[1, 2], [3, np.nan]])\n>>> np.nancumsum(a)\narray([1.,  3.,  6.,  6.])\n>>> np.nancumsum(a, axis=0)\narray([[1.,  2.],\n[4.,  2.]])\n>>> np.nancumsum(a, axis=1)\narray([[1.,  3.],\n[3.,  3.]])"
      }
    },
    {
      "name": "nanmax",
      "signature": "nanmax(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)",
      "documentation": {
        "description": "Return the maximum of an array or maximum along an axis, ignoring any\nNaNs.  When all-NaN slices are encountered a ``RuntimeWarning`` is\nraised and NaN is returned for that slice.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Array containing numbers whose maximum is desired. If `a` is not an\narray, a conversion is attempted."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the maximum is computed. The default is to compute\nthe maximum of the flattened array."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternate output array in which to place the result.  The default\nis ``None``; if provided, it must have the same shape as the\nexpected output, but the type will be cast if necessary. See\n:ref:`ufuncs-output-type` for more details.\n.. versionadded:: 1.8.0"
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\nin the result as dimensions with size one. With this option,\nthe result will broadcast correctly against the original `a`.\nIf the value is anything but the default, then\n`keepdims` will be passed through to the `max` method\nof sub-classes of `ndarray`.  If the sub-classes methods\ndoes not implement `keepdims` any exceptions will be raised.\n.. versionadded:: 1.8.0"
          },
          "initial": {
            "type": "scalar, optional",
            "description": "The minimum value of an output element. Must be present to allow\ncomputation on empty slice. See `~numpy.ufunc.reduce` for details.\n.. versionadded:: 1.22.0"
          },
          "where": {
            "type": "array_like of bool, optional",
            "description": "Elements to compare for the maximum. See `~numpy.ufunc.reduce`\nfor details.\n.. versionadded:: 1.22.0"
          }
        },
        "returns": "-------\nnanmax : ndarray\nAn array with the same shape as `a`, with the specified axis removed.\nIf `a` is a 0-d array, or if axis is None, an ndarray scalar is\nreturned.  The same dtype as `a` is returned.",
        "raises": "",
        "see_also": "--------\nnanmin :\nThe minimum value of an array along a given axis, ignoring any NaNs.\namax :\nThe maximum value of an array along a given axis, propagating any NaNs.\nfmax :\nElement-wise maximum of two arrays, ignoring any NaNs.\nmaximum :\nElement-wise maximum of two arrays, propagating any NaNs.\nisnan :\nShows which elements are Not a Number (NaN).\nisfinite:\nShows which elements are neither NaN nor infinity.\namin, fmin, minimum",
        "notes": "-----\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic\n(IEEE 754). This means that Not a Number is not equivalent to infinity.\nPositive infinity is treated as a very large number and negative\ninfinity is treated as a very small (i.e. negative) number.\nIf the input has a integer type the function is equivalent to np.max.",
        "examples": "--------\n>>> a = np.array([[1, 2], [3, np.nan]])\n>>> np.nanmax(a)\n3.0\n>>> np.nanmax(a, axis=0)\narray([3.,  2.])\n>>> np.nanmax(a, axis=1)\narray([2.,  3.])\nWhen positive infinity and negative infinity are present:\n>>> np.nanmax([1, 2, np.nan, np.NINF])\n2.0\n>>> np.nanmax([1, 2, np.nan, np.inf])\ninf"
      }
    },
    {
      "name": "nanmean",
      "signature": "nanmean(a, axis=None, dtype=None, out=None, keepdims=<no value>, *, where=<no value>)",
      "documentation": {
        "description": "Compute the arithmetic mean along the specified axis, ignoring NaNs.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Array containing numbers whose mean is desired. If `a` is not an\narray, a conversion is attempted."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the means are computed. The default is to compute\nthe mean of the flattened array."
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "Type to use in computing the mean.  For integer inputs, the default\nis `float64`; for inexact inputs, it is the same as the input\ndtype."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternate output array in which to place the result.  The default\nis ``None``; if provided, it must have the same shape as the\nexpected output, but the type will be cast if necessary. See\n:ref:`ufuncs-output-type` for more details."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\nin the result as dimensions with size one. With this option,\nthe result will broadcast correctly against the original `a`.\nIf the value is anything but the default, then\n`keepdims` will be passed through to the `mean` or `sum` methods\nof sub-classes of `ndarray`.  If the sub-classes methods\ndoes not implement `keepdims` any exceptions will be raised."
          },
          "where": {
            "type": "array_like of bool, optional",
            "description": "Elements to include in the mean. See `~numpy.ufunc.reduce` for details.\n.. versionadded:: 1.22.0"
          }
        },
        "returns": "the flattened array by default, otherwise over the specified axis.\n`float64` intermediate and return values are used for integer inputs.\nFor all-NaN slices, NaN is returned and a `RuntimeWarning` is raised.\n.. versionadded:: 1.8.0\n-------\nm : ndarray, see dtype parameter above\nIf `out=None`, returns a new array containing the mean values,\notherwise a reference to the output array is returned. Nan is\nreturned for slices that contain only NaNs.",
        "raises": "",
        "see_also": "--------\naverage : Weighted average\nmean : Arithmetic mean taken while not ignoring NaNs\nvar, nanvar",
        "notes": "-----\nThe arithmetic mean is the sum of the non-NaN elements along the axis\ndivided by the number of non-NaN elements.\nNote that for floating-point input, the mean is computed using the same\nprecision the input has.  Depending on the input data, this can cause\nthe results to be inaccurate, especially for `float32`.  Specifying a\nhigher-precision accumulator using the `dtype` keyword can alleviate\nthis issue.",
        "examples": "--------\n>>> a = np.array([[1, np.nan], [3, 4]])\n>>> np.nanmean(a)\n2.6666666666666665\n>>> np.nanmean(a, axis=0)\narray([2.,  4.])\n>>> np.nanmean(a, axis=1)\narray([1.,  3.5]) # may vary"
      }
    },
    {
      "name": "nanmedian",
      "signature": "nanmedian(a, axis=None, out=None, overwrite_input=False, keepdims=<no value>)",
      "documentation": {
        "description": "Compute the median along the specified axis, while ignoring NaNs.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array or object that can be converted to an array."
          },
          "axis": {
            "type": "{int, sequence of int, None}, optional",
            "description": "Axis or axes along which the medians are computed. The default\nis to compute the median along a flattened version of the array.\nA sequence of axes is supported since version 1.9.0."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must\nhave the same shape and buffer length as the expected output,\nbut the type (of the output) will be cast if necessary."
          },
          "overwrite_input": {
            "type": "bool, optional",
            "description": "If True, then allow use of memory of input array `a` for\ncalculations. The input array will be modified by the call to\n`median`. This will save memory when you do not need to preserve\nthe contents of the input array. Treat the input as undefined,\nbut it will probably be fully or partially sorted. Default is\nFalse. If `overwrite_input` is ``True`` and `a` is not already an\n`ndarray`, an error will be raised."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\nin the result as dimensions with size one. With this option,\nthe result will broadcast correctly against the original `a`.\nIf this is anything but the default value it will be passed\nthrough (in the special case of an empty array) to the\n`mean` function of the underlying array.  If the array is\na sub-class and `mean` does not have the kwarg `keepdims` this\nwill raise a RuntimeError."
          }
        },
        "returns": ".. versionadded:: 1.9.0\n-------\nmedian : ndarray\nA new array holding the result. If the input contains integers\nor floats smaller than ``float64``, then the output data-type is\n``np.float64``.  Otherwise, the data-type of the output is the\nsame as that of the input. If `out` is specified, that array is\nreturned instead.",
        "raises": "",
        "see_also": "--------\nmean, median, percentile",
        "notes": "-----\nGiven a vector ``V`` of length ``N``, the median of ``V`` is the\nmiddle value of a sorted copy of ``V``, ``V_sorted`` - i.e.,\n``V_sorted[(N-1)/2]``, when ``N`` is odd and the average of the two\nmiddle values of ``V_sorted`` when ``N`` is even.",
        "examples": "--------\n>>> a = np.array([[10.0, 7, 4], [3, 2, 1]])\n>>> a[0, 1] = np.nan\n>>> a\narray([[10., nan,  4.],\n[ 3.,  2.,  1.]])\n>>> np.median(a)\nnan\n>>> np.nanmedian(a)\n3.0\n>>> np.nanmedian(a, axis=0)\narray([6.5, 2. , 2.5])\n>>> np.median(a, axis=1)\narray([nan,  2.])\n>>> b = a.copy()\n>>> np.nanmedian(b, axis=1, overwrite_input=True)\narray([7.,  2.])\n>>> assert not np.all(a==b)\n>>> b = a.copy()\n>>> np.nanmedian(b, axis=None, overwrite_input=True)\n3.0\n>>> assert not np.all(a==b)"
      }
    },
    {
      "name": "nanmin",
      "signature": "nanmin(a, axis=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)",
      "documentation": {
        "description": "Return minimum of an array or minimum along an axis, ignoring any NaNs.\nWhen all-NaN slices are encountered a ``RuntimeWarning`` is raised and\nNan is returned for that slice.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Array containing numbers whose minimum is desired. If `a` is not an\narray, a conversion is attempted."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the minimum is computed. The default is to compute\nthe minimum of the flattened array."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternate output array in which to place the result.  The default\nis ``None``; if provided, it must have the same shape as the\nexpected output, but the type will be cast if necessary. See\n:ref:`ufuncs-output-type` for more details.\n.. versionadded:: 1.8.0"
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\nin the result as dimensions with size one. With this option,\nthe result will broadcast correctly against the original `a`.\nIf the value is anything but the default, then\n`keepdims` will be passed through to the `min` method\nof sub-classes of `ndarray`.  If the sub-classes methods\ndoes not implement `keepdims` any exceptions will be raised.\n.. versionadded:: 1.8.0"
          },
          "initial": {
            "type": "scalar, optional",
            "description": "The maximum value of an output element. Must be present to allow\ncomputation on empty slice. See `~numpy.ufunc.reduce` for details.\n.. versionadded:: 1.22.0"
          },
          "where": {
            "type": "array_like of bool, optional",
            "description": "Elements to compare for the minimum. See `~numpy.ufunc.reduce`\nfor details.\n.. versionadded:: 1.22.0"
          }
        },
        "returns": "-------\nnanmin : ndarray\nAn array with the same shape as `a`, with the specified axis\nremoved.  If `a` is a 0-d array, or if axis is None, an ndarray\nscalar is returned.  The same dtype as `a` is returned.",
        "raises": "",
        "see_also": "--------\nnanmax :\nThe maximum value of an array along a given axis, ignoring any NaNs.\namin :\nThe minimum value of an array along a given axis, propagating any NaNs.\nfmin :\nElement-wise minimum of two arrays, ignoring any NaNs.\nminimum :\nElement-wise minimum of two arrays, propagating any NaNs.\nisnan :\nShows which elements are Not a Number (NaN).\nisfinite:\nShows which elements are neither NaN nor infinity.\namax, fmax, maximum",
        "notes": "-----\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic\n(IEEE 754). This means that Not a Number is not equivalent to infinity.\nPositive infinity is treated as a very large number and negative\ninfinity is treated as a very small (i.e. negative) number.\nIf the input has a integer type the function is equivalent to np.min.",
        "examples": "--------\n>>> a = np.array([[1, 2], [3, np.nan]])\n>>> np.nanmin(a)\n1.0\n>>> np.nanmin(a, axis=0)\narray([1.,  2.])\n>>> np.nanmin(a, axis=1)\narray([1.,  3.])\nWhen positive infinity and negative infinity are present:\n>>> np.nanmin([1, 2, np.nan, np.inf])\n1.0\n>>> np.nanmin([1, 2, np.nan, np.NINF])\n-inf"
      }
    },
    {
      "name": "nanpercentile",
      "signature": "nanpercentile(a, q, axis=None, out=None, overwrite_input=False, method='linear', keepdims=<no value>, *, interpolation=None)",
      "documentation": {
        "description": "Compute the qth percentile of the data along the specified axis,\nwhile ignoring nan values.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array or object that can be converted to an array, containing\nnan values to be ignored."
          },
          "q": {
            "type": "array_like of float",
            "description": "Percentile or sequence of percentiles to compute, which must be\nbetween 0 and 100 inclusive."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the percentiles are computed. The default\nis to compute the percentile(s) along a flattened version of the\narray."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must have\nthe same shape and buffer length as the expected output, but the\ntype (of the output) will be cast if necessary."
          },
          "overwrite_input": {
            "type": "bool, optional",
            "description": "If True, then allow the input array `a` to be modified by\nintermediate calculations, to save memory. In this case, the\ncontents of the input `a` after this function completes is\nundefined."
          },
          "method": {
            "type": "str, optional",
            "description": "This parameter specifies the method to use for estimating the\npercentile.  There are many different methods, some unique to NumPy.\nSee the notes for explanation.  The options sorted by their R type\nas summarized in the H&F paper [1]_ are:\n1. 'inverted_cdf'\n2. 'averaged_inverted_cdf'\n3. 'closest_observation'\n4. 'interpolated_inverted_cdf'\n5. 'hazen'\n6. 'weibull'\n7. 'linear'  (default)\n8. 'median_unbiased'\n9. 'normal_unbiased'\nThe first three methods are discontinuous.  NumPy further defines the\nfollowing discontinuous variations of the default 'linear' (7.) option:\n* 'lower'\n* 'higher',\n* 'midpoint'\n* 'nearest'\n.. versionchanged:: 1.22.0\nThis argument was previously called \"interpolation\" and only\noffered the \"linear\" default and last four options."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left in\nthe result as dimensions with size one. With this option, the\nresult will broadcast correctly against the original array `a`.\nIf this is anything but the default value it will be passed\nthrough (in the special case of an empty array) to the\n`mean` function of the underlying array.  If the array is\na sub-class and `mean` does not have the kwarg `keepdims` this\nwill raise a RuntimeError."
          },
          "interpolation": {
            "type": "str, optional",
            "description": "Deprecated name for the method keyword argument.\n.. deprecated:: 1.22.0"
          }
        },
        "returns": ".. versionadded:: 1.9.0\n-------\npercentile : scalar or ndarray\nIf `q` is a single percentile and `axis=None`, then the result\nis a scalar. If multiple percentiles are given, first axis of\nthe result corresponds to the percentiles. The other axes are\nthe axes that remain after the reduction of `a`. If the input\ncontains integers or floats smaller than ``float64``, the output\ndata-type is ``float64``. Otherwise, the output data-type is the\nsame as that of the input. If `out` is specified, that array is\nreturned instead.",
        "raises": "",
        "see_also": "--------\nnanmean\nnanmedian : equivalent to ``nanpercentile(..., 50)``\npercentile, median, mean\nnanquantile : equivalent to nanpercentile, except q in range [0, 1].",
        "notes": "-----\nFor more information please see `numpy.percentile`",
        "examples": "--------\n>>> a = np.array([[10., 7., 4.], [3., 2., 1.]])\n>>> a[0][1] = np.nan\n>>> a\narray([[10.,  nan,   4.],\n[ 3.,   2.,   1.]])\n>>> np.percentile(a, 50)\nnan\n>>> np.nanpercentile(a, 50)\n3.0\n>>> np.nanpercentile(a, 50, axis=0)\narray([6.5, 2. , 2.5])\n>>> np.nanpercentile(a, 50, axis=1, keepdims=True)\narray([[7.],\n[2.]])\n>>> m = np.nanpercentile(a, 50, axis=0)\n>>> out = np.zeros_like(m)\n>>> np.nanpercentile(a, 50, axis=0, out=out)\narray([6.5, 2. , 2.5])\n>>> m\narray([6.5,  2. ,  2.5])\n>>> b = a.copy()\n>>> np.nanpercentile(b, 50, axis=1, overwrite_input=True)\narray([7., 2.])\n>>> assert not np.all(a==b)\nReferences\n----------\n.. [1] R. J. Hyndman and Y. Fan,\n\"Sample quantiles in statistical packages,\"\nThe American Statistician, 50(4), pp. 361-365, 1996"
      }
    },
    {
      "name": "nanprod",
      "signature": "nanprod(a, axis=None, dtype=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)",
      "documentation": {
        "description": "Return the product of array elements over a given axis treating Not a\nNumbers (NaNs) as ones.\nOne is returned for slices that are all-NaN or empty.\n.. versionadded:: 1.10.0",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Array containing numbers whose product is desired. If `a` is not an\narray, a conversion is attempted."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the product is computed. The default is to compute\nthe product of the flattened array."
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "The type of the returned array and of the accumulator in which the\nelements are summed.  By default, the dtype of `a` is used.  An\nexception is when `a` has an integer type with less precision than\nthe platform (u)intp. In that case, the default will be either\n(u)int32 or (u)int64 depending on whether the platform is 32 or 64\nbits. For inexact inputs, dtype must be inexact."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternate output array in which to place the result.  The default\nis ``None``. If provided, it must have the same shape as the\nexpected output, but the type will be cast if necessary. See\n:ref:`ufuncs-output-type` for more details. The casting of NaN to integer\ncan yield unexpected results."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will\nbroadcast correctly against the original `arr`."
          },
          "initial": {
            "type": "scalar, optional",
            "description": "The starting value for this product. See `~numpy.ufunc.reduce`\nfor details.\n.. versionadded:: 1.22.0"
          },
          "where": {
            "type": "array_like of bool, optional",
            "description": "Elements to include in the product. See `~numpy.ufunc.reduce`\nfor details.\n.. versionadded:: 1.22.0"
          }
        },
        "returns": "-------\nnanprod : ndarray\nA new array holding the result is returned unless `out` is\nspecified, in which case it is returned.",
        "raises": "",
        "see_also": "--------\nnumpy.prod : Product across array propagating NaNs.\nisnan : Show which elements are NaN.",
        "notes": "",
        "examples": "--------\n>>> np.nanprod(1)\n1\n>>> np.nanprod([1])\n1\n>>> np.nanprod([1, np.nan])\n1.0\n>>> a = np.array([[1, 2], [3, np.nan]])\n>>> np.nanprod(a)\n6.0\n>>> np.nanprod(a, axis=0)\narray([3., 2.])"
      }
    },
    {
      "name": "nanquantile",
      "signature": "nanquantile(a, q, axis=None, out=None, overwrite_input=False, method='linear', keepdims=<no value>, *, interpolation=None)",
      "documentation": {
        "description": "Compute the qth quantile of the data along the specified axis,\nwhile ignoring nan values.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array or object that can be converted to an array, containing\nnan values to be ignored"
          },
          "q": {
            "type": "array_like of float",
            "description": "Probability or sequence of probabilities for the quantiles to compute.\nValues must be between 0 and 1 inclusive."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the quantiles are computed. The\ndefault is to compute the quantile(s) along a flattened\nversion of the array."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must\nhave the same shape and buffer length as the expected output,\nbut the type (of the output) will be cast if necessary."
          },
          "overwrite_input": {
            "type": "bool, optional",
            "description": "If True, then allow the input array `a` to be modified by intermediate\ncalculations, to save memory. In this case, the contents of the input\n`a` after this function completes is undefined."
          },
          "method": {
            "type": "str, optional",
            "description": "This parameter specifies the method to use for estimating the\nquantile.  There are many different methods, some unique to NumPy.\nSee the notes for explanation.  The options sorted by their R type\nas summarized in the H&F paper [1]_ are:\n1. 'inverted_cdf'\n2. 'averaged_inverted_cdf'\n3. 'closest_observation'\n4. 'interpolated_inverted_cdf'\n5. 'hazen'\n6. 'weibull'\n7. 'linear'  (default)\n8. 'median_unbiased'\n9. 'normal_unbiased'\nThe first three methods are discontinuous.  NumPy further defines the\nfollowing discontinuous variations of the default 'linear' (7.) option:\n* 'lower'\n* 'higher',\n* 'midpoint'\n* 'nearest'\n.. versionchanged:: 1.22.0\nThis argument was previously called \"interpolation\" and only\noffered the \"linear\" default and last four options."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left in\nthe result as dimensions with size one. With this option, the\nresult will broadcast correctly against the original array `a`.\nIf this is anything but the default value it will be passed\nthrough (in the special case of an empty array) to the\n`mean` function of the underlying array.  If the array is\na sub-class and `mean` does not have the kwarg `keepdims` this\nwill raise a RuntimeError."
          },
          "interpolation": {
            "type": "str, optional",
            "description": "Deprecated name for the method keyword argument.\n.. deprecated:: 1.22.0"
          }
        },
        "returns": ".. versionadded:: 1.15.0\n-------\nquantile : scalar or ndarray\nIf `q` is a single probability and `axis=None`, then the result\nis a scalar. If multiple probability levels are given, first axis of\nthe result corresponds to the quantiles. The other axes are\nthe axes that remain after the reduction of `a`. If the input\ncontains integers or floats smaller than ``float64``, the output\ndata-type is ``float64``. Otherwise, the output data-type is the\nsame as that of the input. If `out` is specified, that array is\nreturned instead.",
        "raises": "",
        "see_also": "--------\nquantile\nnanmean, nanmedian\nnanmedian : equivalent to ``nanquantile(..., 0.5)``\nnanpercentile : same as nanquantile, but with q in the range [0, 100].",
        "notes": "-----\nFor more information please see `numpy.quantile`",
        "examples": "--------\n>>> a = np.array([[10., 7., 4.], [3., 2., 1.]])\n>>> a[0][1] = np.nan\n>>> a\narray([[10.,  nan,   4.],\n[ 3.,   2.,   1.]])\n>>> np.quantile(a, 0.5)\nnan\n>>> np.nanquantile(a, 0.5)\n3.0\n>>> np.nanquantile(a, 0.5, axis=0)\narray([6.5, 2. , 2.5])\n>>> np.nanquantile(a, 0.5, axis=1, keepdims=True)\narray([[7.],\n[2.]])\n>>> m = np.nanquantile(a, 0.5, axis=0)\n>>> out = np.zeros_like(m)\n>>> np.nanquantile(a, 0.5, axis=0, out=out)\narray([6.5, 2. , 2.5])\n>>> m\narray([6.5,  2. ,  2.5])\n>>> b = a.copy()\n>>> np.nanquantile(b, 0.5, axis=1, overwrite_input=True)\narray([7., 2.])\n>>> assert not np.all(a==b)\nReferences\n----------\n.. [1] R. J. Hyndman and Y. Fan,\n\"Sample quantiles in statistical packages,\"\nThe American Statistician, 50(4), pp. 361-365, 1996"
      }
    },
    {
      "name": "nanstd",
      "signature": "nanstd(a, axis=None, dtype=None, out=None, ddof=0, keepdims=<no value>, *, where=<no value>)",
      "documentation": {
        "description": "Compute the standard deviation along the specified axis, while\nignoring NaNs.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Calculate the standard deviation of the non-NaN values."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the standard deviation is computed. The default is\nto compute the standard deviation of the flattened array."
          },
          "dtype": {
            "type": "dtype, optional",
            "description": "Type to use in computing the standard deviation. For arrays of\ninteger type the default is float64, for arrays of float types it\nis the same as the array type."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must have\nthe same shape as the expected output but the type (of the\ncalculated values) will be cast if necessary."
          },
          "ddof": {
            "type": "int, optional",
            "description": "Means Delta Degrees of Freedom.  The divisor used in calculations\nis ``N - ddof``, where ``N`` represents the number of non-NaN\nelements.  By default `ddof` is zero."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\nin the result as dimensions with size one. With this option,\nthe result will broadcast correctly against the original `a`.\nIf this value is anything but the default it is passed through\nas-is to the relevant functions of the sub-classes.  If these\nfunctions do not have a `keepdims` kwarg, a RuntimeError will\nbe raised."
          },
          "where": {
            "type": "array_like of bool, optional",
            "description": "Elements to include in the standard deviation.\nSee `~numpy.ufunc.reduce` for details.\n.. versionadded:: 1.22.0"
          }
        },
        "returns": "distribution, of the non-NaN array elements. The standard deviation is\ncomputed for the flattened array by default, otherwise over the\nspecified axis.\nFor all-NaN slices or slices with zero degrees of freedom, NaN is\nreturned and a `RuntimeWarning` is raised.\n.. versionadded:: 1.8.0\n-------\nstandard_deviation : ndarray, see dtype parameter above.\nIf `out` is None, return a new array containing the standard\ndeviation, otherwise return a reference to the output array. If\nddof is >= the number of non-NaN elements in a slice or the slice\ncontains only NaNs, then the result for that slice is NaN.",
        "raises": "",
        "see_also": "--------\nvar, mean, std\nnanvar, nanmean\n:ref:`ufuncs-output-type`",
        "notes": "-----\nThe standard deviation is the square root of the average of the squared\ndeviations from the mean: ``std = sqrt(mean(abs(x - x.mean())**2))``.\nThe average squared deviation is normally calculated as\n``x.sum() / N``, where ``N = len(x)``.  If, however, `ddof` is\nspecified, the divisor ``N - ddof`` is used instead. In standard\nstatistical practice, ``ddof=1`` provides an unbiased estimator of the\nvariance of the infinite population. ``ddof=0`` provides a maximum\nlikelihood estimate of the variance for normally distributed variables.\nThe standard deviation computed in this function is the square root of\nthe estimated variance, so even with ``ddof=1``, it will not be an\nunbiased estimate of the standard deviation per se.\nNote that, for complex numbers, `std` takes the absolute value before\nsquaring, so that the result is always real and nonnegative.\nFor floating-point input, the *std* is computed using the same\nprecision the input has. Depending on the input data, this can cause\nthe results to be inaccurate, especially for float32 (see example\nbelow).  Specifying a higher-accuracy accumulator using the `dtype`\nkeyword can alleviate this issue.",
        "examples": "--------\n>>> a = np.array([[1, np.nan], [3, 4]])\n>>> np.nanstd(a)\n1.247219128924647\n>>> np.nanstd(a, axis=0)\narray([1., 0.])\n>>> np.nanstd(a, axis=1)\narray([0.,  0.5]) # may vary"
      }
    },
    {
      "name": "nansum",
      "signature": "nansum(a, axis=None, dtype=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)",
      "documentation": {
        "description": "Return the sum of array elements over a given axis treating Not a\nNumbers (NaNs) as zero.\nIn NumPy versions <= 1.9.0 Nan is returned for slices that are all-NaN or\nempty. In later versions zero is returned.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Array containing numbers whose sum is desired. If `a` is not an\narray, a conversion is attempted."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the sum is computed. The default is to compute the\nsum of the flattened array."
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "The type of the returned array and of the accumulator in which the\nelements are summed.  By default, the dtype of `a` is used.  An\nexception is when `a` has an integer type with less precision than\nthe platform (u)intp. In that case, the default will be either\n(u)int32 or (u)int64 depending on whether the platform is 32 or 64\nbits. For inexact inputs, dtype must be inexact.\n.. versionadded:: 1.8.0"
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternate output array in which to place the result.  The default\nis ``None``. If provided, it must have the same shape as the\nexpected output, but the type will be cast if necessary.  See\n:ref:`ufuncs-output-type` for more details. The casting of NaN to integer\ncan yield unexpected results.\n.. versionadded:: 1.8.0"
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\nin the result as dimensions with size one. With this option,\nthe result will broadcast correctly against the original `a`.\nIf the value is anything but the default, then\n`keepdims` will be passed through to the `mean` or `sum` methods\nof sub-classes of `ndarray`.  If the sub-classes methods\ndoes not implement `keepdims` any exceptions will be raised.\n.. versionadded:: 1.8.0"
          },
          "initial": {
            "type": "scalar, optional",
            "description": "Starting value for the sum. See `~numpy.ufunc.reduce` for details.\n.. versionadded:: 1.22.0"
          },
          "where": {
            "type": "array_like of bool, optional",
            "description": "Elements to include in the sum. See `~numpy.ufunc.reduce` for details.\n.. versionadded:: 1.22.0"
          }
        },
        "returns": "-------\nnansum : ndarray.\nA new array holding the result is returned unless `out` is\nspecified, in which it is returned. The result has the same\nsize as `a`, and the same shape as `a` if `axis` is not None\nor `a` is a 1-d array.",
        "raises": "",
        "see_also": "--------\nnumpy.sum : Sum across array propagating NaNs.\nisnan : Show which elements are NaN.\nisfinite : Show which elements are not NaN or +/-inf.",
        "notes": "-----\nIf both positive and negative infinity are present, the sum will be Not\nA Number (NaN).",
        "examples": "--------\n>>> np.nansum(1)\n1\n>>> np.nansum([1])\n1\n>>> np.nansum([1, np.nan])\n1.0\n>>> a = np.array([[1, 1], [1, np.nan]])\n>>> np.nansum(a)\n3.0\n>>> np.nansum(a, axis=0)\narray([2.,  1.])\n>>> np.nansum([1, np.nan, np.inf])\ninf\n>>> np.nansum([1, np.nan, np.NINF])\n-inf\n>>> from numpy.testing import suppress_warnings\n>>> with suppress_warnings() as sup:\n...     sup.filter(RuntimeWarning)\n...     np.nansum([1, np.nan, np.inf, -np.inf]) # both +/- infinity present\nnan"
      }
    },
    {
      "name": "nanvar",
      "signature": "nanvar(a, axis=None, dtype=None, out=None, ddof=0, keepdims=<no value>, *, where=<no value>)",
      "documentation": {
        "description": "Compute the variance along the specified axis, while ignoring NaNs.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Array containing numbers whose variance is desired.  If `a` is not an\narray, a conversion is attempted."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the variance is computed.  The default is to compute\nthe variance of the flattened array."
          },
          "dtype": {
            "type": "data-type, optional",
            "description": "Type to use in computing the variance.  For arrays of integer type\nthe default is `float64`; for arrays of float types it is the same as\nthe array type."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternate output array in which to place the result.  It must have\nthe same shape as the expected output, but the type is cast if\nnecessary."
          },
          "ddof": {
            "type": "int, optional",
            "description": "\"Delta Degrees of Freedom\": the divisor used in the calculation is\n``N - ddof``, where ``N`` represents the number of non-NaN\nelements. By default `ddof` is zero."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left\nin the result as dimensions with size one. With this option,\nthe result will broadcast correctly against the original `a`."
          },
          "where": {
            "type": "array_like of bool, optional",
            "description": "Elements to include in the variance. See `~numpy.ufunc.reduce` for\ndetails.\n.. versionadded:: 1.22.0"
          }
        },
        "returns": "a distribution.  The variance is computed for the flattened array by\ndefault, otherwise over the specified axis.\nFor all-NaN slices or slices with zero degrees of freedom, NaN is\nreturned and a `RuntimeWarning` is raised.\n.. versionadded:: 1.8.0\n-------\nvariance : ndarray, see dtype parameter above\nIf `out` is None, return a new array containing the variance,\notherwise return a reference to the output array. If ddof is >= the\nnumber of non-NaN elements in a slice or the slice contains only\nNaNs, then the result for that slice is NaN.",
        "raises": "",
        "see_also": "--------\nstd : Standard deviation\nmean : Average\nvar : Variance while not ignoring NaNs\nnanstd, nanmean\n:ref:`ufuncs-output-type`",
        "notes": "-----\nThe variance is the average of the squared deviations from the mean,\ni.e.,  ``var = mean(abs(x - x.mean())**2)``.\nThe mean is normally calculated as ``x.sum() / N``, where ``N = len(x)``.\nIf, however, `ddof` is specified, the divisor ``N - ddof`` is used\ninstead.  In standard statistical practice, ``ddof=1`` provides an\nunbiased estimator of the variance of a hypothetical infinite\npopulation.  ``ddof=0`` provides a maximum likelihood estimate of the\nvariance for normally distributed variables.\nNote that for complex numbers, the absolute value is taken before\nsquaring, so that the result is always real and nonnegative.\nFor floating-point input, the variance is computed using the same\nprecision the input has.  Depending on the input data, this can cause\nthe results to be inaccurate, especially for `float32` (see example\nbelow).  Specifying a higher-accuracy accumulator using the ``dtype``\nkeyword can alleviate this issue.\nFor this function to work on sub-classes of ndarray, they must define\n`sum` with the kwarg `keepdims`",
        "examples": "--------\n>>> a = np.array([[1, np.nan], [3, 4]])\n>>> np.nanvar(a)\n1.5555555555555554\n>>> np.nanvar(a, axis=0)\narray([1.,  0.])\n>>> np.nanvar(a, axis=1)\narray([0.,  0.25])  # may vary"
      }
    },
    {
      "name": "packbits",
      "signature": "packbits(a, /, axis=None, bitorder='big')",
      "documentation": {
        "description": "packbits(a, /, axis=None, bitorder='big')\nPacks the elements of a binary-valued array into bits in a uint8 array.\nThe result is padded to full bytes by inserting zero bits at the end.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "An array of integers or booleans whose elements should be packed to\nbits."
          },
          "axis": {
            "type": "int, optional",
            "description": "The dimension over which bit-packing is done.\n``None`` implies packing the flattened array."
          },
          "bitorder": {
            "type": "{'big', 'little'}, optional",
            "description": "The order of the input bits. 'big' will mimic bin(val),\n``[0, 0, 0, 0, 0, 0, 1, 1] => 3 = 0b00000011``, 'little' will\nreverse the order so ``[1, 1, 0, 0, 0, 0, 0, 0] => 3``.\nDefaults to 'big'.\n.. versionadded:: 1.17.0"
          }
        },
        "returns": "-------\npacked : ndarray\nArray of type uint8 whose elements represent bits corresponding to the\nlogical (0 or nonzero) value of the input elements. The shape of\n`packed` has the same number of dimensions as the input (unless `axis`\nis None, in which case the output is 1-D).",
        "raises": "",
        "see_also": "--------\nunpackbits: Unpacks elements of a uint8 array into a binary-valued output\narray.",
        "notes": "",
        "examples": "--------\n>>> a = np.array([[[1,0,1],\n...                [0,1,0]],\n...               [[1,1,0],\n...                [0,0,1]]])\n>>> b = np.packbits(a, axis=-1)\n>>> b\narray([[[160],\n[ 64]],\n[[192],\n[ 32]]], dtype=uint8)\nNote that in binary 160 = 1010 0000, 64 = 0100 0000, 192 = 1100 0000,\nand 32 = 0010 0000."
      }
    },
    {
      "name": "pad",
      "signature": "pad(array, pad_width, mode='constant', **kwargs)",
      "documentation": {
        "description": "Pad an array.",
        "parameters": {
          "array": {
            "type": "array_like of rank N",
            "description": "The array to pad."
          },
          "pad_width": {
            "type": "{sequence, array_like, int}",
            "description": "Number of values padded to the edges of each axis.\n``((before_1, after_1), ... (before_N, after_N))`` unique pad widths\nfor each axis.\n``(before, after)`` or ``((before, after),)`` yields same before\nand after pad for each axis.\n``(pad,)`` or ``int`` is a shortcut for before = after = pad width\nfor all axes."
          },
          "mode": {
            "type": "str or function, optional",
            "description": "One of the following string values or a user supplied function.\n'constant' (default)\nPads with a constant value.\n'edge'\nPads with the edge values of array.\n'linear_ramp'\nPads with the linear ramp between end_value and the\narray edge value.\n'maximum'\nPads with the maximum value of all or part of the\nvector along each axis.\n'mean'\nPads with the mean value of all or part of the\nvector along each axis.\n'median'\nPads with the median value of all or part of the\nvector along each axis.\n'minimum'\nPads with the minimum value of all or part of the\nvector along each axis.\n'reflect'\nPads with the reflection of the vector mirrored on\nthe first and last values of the vector along each\naxis.\n'symmetric'\nPads with the reflection of the vector mirrored\nalong the edge of the array.\n'wrap'\nPads with the wrap of the vector along the axis.\nThe first values are used to pad the end and the\nend values are used to pad the beginning.\n'empty'\nPads with undefined values.\n.. versionadded:: 1.17\n<function>\nPadding function, see Notes."
          },
          "stat_length": {
            "type": "sequence or int, optional",
            "description": "Used in 'maximum', 'mean', 'median', and 'minimum'.  Number of\nvalues at edge of each axis used to calculate the statistic value.\n``((before_1, after_1), ... (before_N, after_N))`` unique statistic\nlengths for each axis.\n``(before, after)`` or ``((before, after),)`` yields same before\nand after statistic lengths for each axis.\n``(stat_length,)`` or ``int`` is a shortcut for\n``before = after = statistic`` length for all axes.\nDefault is ``None``, to use the entire axis."
          },
          "constant_values": {
            "type": "sequence or scalar, optional",
            "description": "Used in 'constant'.  The values to set the padded values for each\naxis.\n``((before_1, after_1), ... (before_N, after_N))`` unique pad constants\nfor each axis.\n``(before, after)`` or ``((before, after),)`` yields same before\nand after constants for each axis.\n``(constant,)`` or ``constant`` is a shortcut for\n``before = after = constant`` for all axes.\nDefault is 0."
          },
          "end_values": {
            "type": "sequence or scalar, optional",
            "description": "Used in 'linear_ramp'.  The values used for the ending value of the\nlinear_ramp and that will form the edge of the padded array.\n``((before_1, after_1), ... (before_N, after_N))`` unique end values\nfor each axis.\n``(before, after)`` or ``((before, after),)`` yields same before\nand after end values for each axis.\n``(constant,)`` or ``constant`` is a shortcut for\n``before = after = constant`` for all axes.\nDefault is 0."
          },
          "reflect_type": {
            "type": "{'even', 'odd'}, optional",
            "description": "Used in 'reflect', and 'symmetric'.  The 'even' style is the\ndefault with an unaltered reflection around the edge value.  For\nthe 'odd' style, the extended part of the array is created by\nsubtracting the reflected values from two times the edge value."
          }
        },
        "returns": "-------\npad : ndarray\nPadded array of rank equal to `array` with shape increased\naccording to `pad_width`.",
        "raises": "",
        "see_also": "",
        "notes": "-----\n.. versionadded:: 1.7.0\nFor an array with rank greater than 1, some of the padding of later\naxes is calculated from padding of previous axes.  This is easiest to\nthink about with a rank 2 array where the corners of the padded array\nare calculated by using padded values from the first axis.\nThe padding function, if used, should modify a rank 1 array in-place. It\nhas the following signature::\npadding_func(vector, iaxis_pad_width, iaxis, kwargs)\nwhere\nvector : ndarray\nA rank 1 array already padded with zeros.  Padded values are\nvector[:iaxis_pad_width[0]] and vector[-iaxis_pad_width[1]:].\niaxis_pad_width : tuple\nA 2-tuple of ints, iaxis_pad_width[0] represents the number of\nvalues padded at the beginning of vector where\niaxis_pad_width[1] represents the number of values padded at\nthe end of vector.\niaxis : int\nThe axis currently being calculated.\nkwargs : dict\nAny keyword arguments the function requires.",
        "examples": "--------\n>>> a = [1, 2, 3, 4, 5]\n>>> np.pad(a, (2, 3), 'constant', constant_values=(4, 6))\narray([4, 4, 1, ..., 6, 6, 6])\n>>> np.pad(a, (2, 3), 'edge')\narray([1, 1, 1, ..., 5, 5, 5])\n>>> np.pad(a, (2, 3), 'linear_ramp', end_values=(5, -4))\narray([ 5,  3,  1,  2,  3,  4,  5,  2, -1, -4])\n>>> np.pad(a, (2,), 'maximum')\narray([5, 5, 1, 2, 3, 4, 5, 5, 5])\n>>> np.pad(a, (2,), 'mean')\narray([3, 3, 1, 2, 3, 4, 5, 3, 3])\n>>> np.pad(a, (2,), 'median')\narray([3, 3, 1, 2, 3, 4, 5, 3, 3])\n>>> a = [[1, 2], [3, 4]]\n>>> np.pad(a, ((3, 2), (2, 3)), 'minimum')\narray([[1, 1, 1, 2, 1, 1, 1],\n[1, 1, 1, 2, 1, 1, 1],\n[1, 1, 1, 2, 1, 1, 1],\n[1, 1, 1, 2, 1, 1, 1],\n[3, 3, 3, 4, 3, 3, 3],\n[1, 1, 1, 2, 1, 1, 1],\n[1, 1, 1, 2, 1, 1, 1]])\n>>> a = [1, 2, 3, 4, 5]\n>>> np.pad(a, (2, 3), 'reflect')\narray([3, 2, 1, 2, 3, 4, 5, 4, 3, 2])\n>>> np.pad(a, (2, 3), 'reflect', reflect_type='odd')\narray([-1,  0,  1,  2,  3,  4,  5,  6,  7,  8])\n>>> np.pad(a, (2, 3), 'symmetric')\narray([2, 1, 1, 2, 3, 4, 5, 5, 4, 3])\n>>> np.pad(a, (2, 3), 'symmetric', reflect_type='odd')\narray([0, 1, 1, 2, 3, 4, 5, 5, 6, 7])\n>>> np.pad(a, (2, 3), 'wrap')\narray([4, 5, 1, 2, 3, 4, 5, 1, 2, 3])\n>>> def pad_with(vector, pad_width, iaxis, kwargs):\n...     pad_value = kwargs.get('padder', 10)\n...     vector[:pad_width[0]] = pad_value\n...     vector[-pad_width[1]:] = pad_value\n>>> a = np.arange(6)\n>>> a = a.reshape((2, 3))\n>>> np.pad(a, 2, pad_with)\narray([[10, 10, 10, 10, 10, 10, 10],\n[10, 10, 10, 10, 10, 10, 10],\n[10, 10,  0,  1,  2, 10, 10],\n[10, 10,  3,  4,  5, 10, 10],\n[10, 10, 10, 10, 10, 10, 10],\n[10, 10, 10, 10, 10, 10, 10]])\n>>> np.pad(a, 2, pad_with, padder=100)\narray([[100, 100, 100, 100, 100, 100, 100],\n[100, 100, 100, 100, 100, 100, 100],\n[100, 100,   0,   1,   2, 100, 100],\n[100, 100,   3,   4,   5, 100, 100],\n[100, 100, 100, 100, 100, 100, 100],\n[100, 100, 100, 100, 100, 100, 100]])"
      }
    },
    {
      "name": "percentile",
      "signature": "percentile(a, q, axis=None, out=None, overwrite_input=False, method='linear', keepdims=False, *, interpolation=None)",
      "documentation": {
        "description": "Compute the q-th percentile of the data along the specified axis.",
        "parameters": {
          "a": {
            "type": "array_like of real numbers",
            "description": "Input array or object that can be converted to an array."
          },
          "q": {
            "type": "array_like of float",
            "description": "Percentage or sequence of percentages for the percentiles to compute.\nValues must be between 0 and 100 inclusive."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the percentiles are computed. The\ndefault is to compute the percentile(s) along a flattened\nversion of the array.\n.. versionchanged:: 1.9.0\nA tuple of axes is supported"
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must\nhave the same shape and buffer length as the expected output,\nbut the type (of the output) will be cast if necessary."
          },
          "overwrite_input": {
            "type": "bool, optional",
            "description": "If True, then allow the input array `a` to be modified by intermediate\ncalculations, to save memory. In this case, the contents of the input\n`a` after this function completes is undefined."
          },
          "method": {
            "type": "str, optional",
            "description": "This parameter specifies the method to use for estimating the\npercentile.  There are many different methods, some unique to NumPy.\nSee the notes for explanation.  The options sorted by their R type\nas summarized in the H&F paper [1]_ are:\n1. 'inverted_cdf'\n2. 'averaged_inverted_cdf'\n3. 'closest_observation'\n4. 'interpolated_inverted_cdf'\n5. 'hazen'\n6. 'weibull'\n7. 'linear'  (default)\n8. 'median_unbiased'\n9. 'normal_unbiased'\nThe first three methods are discontinuous.  NumPy further defines the\nfollowing discontinuous variations of the default 'linear' (7.) option:\n* 'lower'\n* 'higher',\n* 'midpoint'\n* 'nearest'\n.. versionchanged:: 1.22.0\nThis argument was previously called \"interpolation\" and only\noffered the \"linear\" default and last four options."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left in\nthe result as dimensions with size one. With this option, the\nresult will broadcast correctly against the original array `a`.\n.. versionadded:: 1.9.0"
          },
          "interpolation": {
            "type": "str, optional",
            "description": "Deprecated name for the method keyword argument.\n.. deprecated:: 1.22.0"
          }
        },
        "returns": "-------\npercentile : scalar or ndarray\nIf `q` is a single percentile and `axis=None`, then the result\nis a scalar. If multiple percentiles are given, first axis of\nthe result corresponds to the percentiles. The other axes are\nthe axes that remain after the reduction of `a`. If the input\ncontains integers or floats smaller than ``float64``, the output\ndata-type is ``float64``. Otherwise, the output data-type is the\nsame as that of the input. If `out` is specified, that array is\nreturned instead.",
        "raises": "",
        "see_also": "--------\nmean\nmedian : equivalent to ``percentile(..., 50)``\nnanpercentile\nquantile : equivalent to percentile, except q in the range [0, 1].",
        "notes": "-----\nGiven a vector ``V`` of length ``n``, the q-th percentile of ``V`` is\nthe value ``q/100`` of the way from the minimum to the maximum in a\nsorted copy of ``V``. The values and distances of the two nearest\nneighbors as well as the `method` parameter will determine the\npercentile if the normalized ranking does not match the location of\n``q`` exactly. This function is the same as the median if ``q=50``, the\nsame as the minimum if ``q=0`` and the same as the maximum if\n``q=100``.\nThe optional `method` parameter specifies the method to use when the\ndesired percentile lies between two indexes ``i`` and ``j = i + 1``.\nIn that case, we first determine ``i + g``, a virtual index that lies\nbetween ``i`` and ``j``, where  ``i`` is the floor and ``g`` is the\nfractional part of the index. The final result is, then, an interpolation\nof ``a[i]`` and ``a[j]`` based on ``g``. During the computation of ``g``,\n``i`` and ``j`` are modified using correction constants ``alpha`` and\n``beta`` whose choices depend on the ``method`` used. Finally, note that\nsince Python uses 0-based indexing, the code subtracts another 1 from the\nindex internally.\nThe following formula determines the virtual index ``i + g``, the location\nof the percentile in the sorted sample:\n.. math::\ni + g = (q / 100) * ( n - alpha - beta + 1 ) + alpha\nThe different methods then work as follows\ninverted_cdf:\nmethod 1 of H&F [1]_.\nThis method gives discontinuous results:\n* if g > 0 ; then take j\n* if g = 0 ; then take i\naveraged_inverted_cdf:\nmethod 2 of H&F [1]_.\nThis method give discontinuous results:\n* if g > 0 ; then take j\n* if g = 0 ; then average between bounds\nclosest_observation:\nmethod 3 of H&F [1]_.\nThis method give discontinuous results:\n* if g > 0 ; then take j\n* if g = 0 and index is odd ; then take j\n* if g = 0 and index is even ; then take i\ninterpolated_inverted_cdf:\nmethod 4 of H&F [1]_.\nThis method give continuous results using:\n* alpha = 0\n* beta = 1\nhazen:\nmethod 5 of H&F [1]_.\nThis method give continuous results using:\n* alpha = 1/2\n* beta = 1/2\nweibull:\nmethod 6 of H&F [1]_.\nThis method give continuous results using:\n* alpha = 0\n* beta = 0\nlinear:\nmethod 7 of H&F [1]_.\nThis method give continuous results using:\n* alpha = 1\n* beta = 1\nmedian_unbiased:\nmethod 8 of H&F [1]_.\nThis method is probably the best method if the sample\ndistribution function is unknown (see reference).\nThis method give continuous results using:\n* alpha = 1/3\n* beta = 1/3\nnormal_unbiased:\nmethod 9 of H&F [1]_.\nThis method is probably the best method if the sample\ndistribution function is known to be normal.\nThis method give continuous results using:\n* alpha = 3/8\n* beta = 3/8\nlower:\nNumPy method kept for backwards compatibility.\nTakes ``i`` as the interpolation point.\nhigher:\nNumPy method kept for backwards compatibility.\nTakes ``j`` as the interpolation point.\nnearest:\nNumPy method kept for backwards compatibility.\nTakes ``i`` or ``j``, whichever is nearest.\nmidpoint:\nNumPy method kept for backwards compatibility.\nUses ``(i + j) / 2``.",
        "examples": "--------\n>>> a = np.array([[10, 7, 4], [3, 2, 1]])\n>>> a\narray([[10,  7,  4],\n[ 3,  2,  1]])\n>>> np.percentile(a, 50)\n3.5\n>>> np.percentile(a, 50, axis=0)\narray([6.5, 4.5, 2.5])\n>>> np.percentile(a, 50, axis=1)\narray([7.,  2.])\n>>> np.percentile(a, 50, axis=1, keepdims=True)\narray([[7.],\n[2.]])\n>>> m = np.percentile(a, 50, axis=0)\n>>> out = np.zeros_like(m)\n>>> np.percentile(a, 50, axis=0, out=out)\narray([6.5, 4.5, 2.5])\n>>> m\narray([6.5, 4.5, 2.5])\n>>> b = a.copy()\n>>> np.percentile(b, 50, axis=1, overwrite_input=True)\narray([7.,  2.])\n>>> assert not np.all(a == b)\nThe different methods can be visualized graphically:\n.. plot::\nimport matplotlib.pyplot as plt\na = np.arange(4)\np = np.linspace(0, 100, 6001)\nax = plt.gca()\nlines = [\n('linear', '-', 'C0'),\n('inverted_cdf', ':', 'C1'),\n# Almost the same as `inverted_cdf`:\n('averaged_inverted_cdf', '-.', 'C1'),\n('closest_observation', ':', 'C2'),\n('interpolated_inverted_cdf', '--', 'C1'),\n('hazen', '--', 'C3'),\n('weibull', '-.', 'C4'),\n('median_unbiased', '--', 'C5'),\n('normal_unbiased', '-.', 'C6'),\n]\nfor method, style, color in lines:\nax.plot(\np, np.percentile(a, p, method=method),\nlabel=method, linestyle=style, color=color)\nax.set(\ntitle='Percentiles for different methods and data: ' + str(a),\nxlabel='Percentile',\nylabel='Estimated percentile value',\nyticks=a)\nax.legend(bbox_to_anchor=(1.03, 1))\nplt.tight_layout()\nplt.show()\nReferences\n----------\n.. [1] R. J. Hyndman and Y. Fan,\n\"Sample quantiles in statistical packages,\"\nThe American Statistician, 50(4), pp. 361-365, 1996"
      }
    },
    {
      "name": "piecewise",
      "signature": "piecewise(x, condlist, funclist, *args, **kw)",
      "documentation": {
        "description": "Evaluate a piecewise-defined function.\nGiven a set of conditions and corresponding functions, evaluate each\nfunction on the input data wherever its condition is true.",
        "parameters": {
          "x": {
            "type": "ndarray or scalar",
            "description": "The input domain."
          },
          "condlist": {
            "type": "list of bool arrays or bool scalars",
            "description": "Each boolean array corresponds to a function in `funclist`.  Wherever\n`condlist[i]` is True, `funclist[i](x)` is used as the output value.\nEach boolean array in `condlist` selects a piece of `x`,\nand should therefore be of the same shape as `x`.\nThe length of `condlist` must correspond to that of `funclist`.\nIf one extra function is given, i.e. if\n``len(funclist) == len(condlist) + 1``, then that extra function\nis the default value, used wherever all conditions are false."
          },
          "funclist": {
            "type": "list of callables, f(x,*args,**kw), or scalars",
            "description": "Each function is evaluated over `x` wherever its corresponding\ncondition is True.  It should take a 1d array as input and give an 1d\narray or a scalar value as output.  If, instead of a callable,\na scalar is provided then a constant function (``lambda x: scalar``) is\nassumed."
          },
          "args": {
            "type": "tuple, optional",
            "description": "Any further arguments given to `piecewise` are passed to the functions\nupon execution, i.e., if called ``piecewise(..., ..., 1, 'a')``, then\neach function is called as ``f(x, 1, 'a')``."
          },
          "kw": {
            "type": "dict, optional",
            "description": "Keyword arguments used in calling `piecewise` are passed to the\nfunctions upon execution, i.e., if called\n``piecewise(..., ..., alpha=1)``, then each function is called as\n``f(x, alpha=1)``."
          }
        },
        "returns": "-------\nout : ndarray\nThe output is the same shape and type as x and is found by\ncalling the functions in `funclist` on the appropriate portions of `x`,\nas defined by the boolean arrays in `condlist`.  Portions not covered\nby any condition have a default value of 0.",
        "raises": "",
        "see_also": "--------\nchoose, select, where",
        "notes": "-----\nThis is similar to choose or select, except that functions are\nevaluated on elements of `x` that satisfy the corresponding condition from\n`condlist`.\nThe result is::\n|--\n|funclist[0](x[condlist[0]])\nout = |funclist[1](x[condlist[1]])\n|...\n|funclist[n2](x[condlist[n2]])\n|--",
        "examples": "--------\nDefine the sigma function, which is -1 for ``x < 0`` and +1 for ``x >= 0``.\n>>> x = np.linspace(-2.5, 2.5, 6)\n>>> np.piecewise(x, [x < 0, x >= 0], [-1, 1])\narray([-1., -1., -1.,  1.,  1.,  1.])\nDefine the absolute value, which is ``-x`` for ``x <0`` and ``x`` for\n``x >= 0``.\n>>> np.piecewise(x, [x < 0, x >= 0], [lambda x: -x, lambda x: x])\narray([2.5,  1.5,  0.5,  0.5,  1.5,  2.5])\nApply the same function to a scalar value.\n>>> y = -2\n>>> np.piecewise(y, [y < 0, y >= 0], [lambda x: -x, lambda x: x])\narray(2)"
      }
    },
    {
      "name": "place",
      "signature": "place(arr, mask, vals)",
      "documentation": {
        "description": "Change elements of an array based on conditional and input values.\nSimilar to ``np.copyto(arr, vals, where=mask)``, the difference is that\n`place` uses the first N elements of `vals`, where N is the number of\nTrue values in `mask`, while `copyto` uses the elements where `mask`\nis True.\nNote that `extract` does the exact opposite of `place`.",
        "parameters": {
          "arr": {
            "type": "ndarray",
            "description": "Array to put data into."
          },
          "mask": {
            "type": "array_like",
            "description": "Boolean mask array. Must have the same size as `a`."
          },
          "vals": {
            "type": "1-D sequence",
            "description": "Values to put into `a`. Only the first N elements are used, where\nN is the number of True values in `mask`. If `vals` is smaller\nthan N, it will be repeated, and if elements of `a` are to be masked,\nthis sequence must be non-empty."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\ncopyto, put, take, extract",
        "notes": "",
        "examples": "--------\n>>> arr = np.arange(6).reshape(2, 3)\n>>> np.place(arr, arr>2, [44, 55])\n>>> arr\narray([[ 0,  1,  2],\n[44, 55, 44]])"
      }
    },
    {
      "name": "poly",
      "signature": "poly(seq_of_zeros)",
      "documentation": {
        "description": "Find the coefficients of a polynomial with the given sequence of roots.\n.. note::\nThis forms part of the old polynomial API. Since version 1.4, the\nnew polynomial API defined in `numpy.polynomial` is preferred.\nA summary of the differences can be found in the\n:doc:`transition guide </reference/routines.polynomials>`.",
        "parameters": {
          "seq_of_zeros": {
            "type": "array_like, shape (N,) or (N, N)",
            "description": "A sequence of polynomial roots, or a square array or matrix object."
          }
        },
        "returns": "is one for the given sequence of zeros (multiple roots must be included\nin the sequence as many times as their multiplicity; see Examples).\nA square matrix (or array, which will be treated as a matrix) can also\nbe given, in which case the coefficients of the characteristic polynomial\nof the matrix are returned.\n-------\nc : ndarray\n1D array of polynomial coefficients from highest to lowest degree:\n``c[0] * x**(N) + c[1] * x**(N-1) + ... + c[N-1] * x + c[N]``\nwhere c[0] always equals 1.",
        "raises": "------\nValueError\nIf input is the wrong shape (the input must be a 1-D or square\n2-D array).",
        "see_also": "--------\npolyval : Compute polynomial values.\nroots : Return the roots of a polynomial.\npolyfit : Least squares polynomial fit.\npoly1d : A one-dimensional polynomial class.",
        "notes": "-----\nSpecifying the roots of a polynomial still leaves one degree of\nfreedom, typically represented by an undetermined leading\ncoefficient. [1]_ In the case of this function, that coefficient -\nthe first one in the returned array - is always taken as one. (If\nfor some reason you have one other point, the only automatic way\npresently to leverage that information is to use ``polyfit``.)\nThe characteristic polynomial, :math:`p_a(t)`, of an `n`-by-`n`\nmatrix **A** is given by\n:math:`p_a(t) = \\mathrm{det}(t\\, \\mathbf{I} - \\mathbf{A})`,\nwhere **I** is the `n`-by-`n` identity matrix. [2]_\nReferences\n----------\n.. [1] M. Sullivan and M. Sullivan, III, \"Algebra and Trigonometry,\nEnhanced With Graphing Utilities,\" Prentice-Hall, pg. 318, 1996.\n.. [2] G. Strang, \"Linear Algebra and Its Applications, 2nd Edition,\"\nAcademic Press, pg. 182, 1980.",
        "examples": "--------\nGiven a sequence of a polynomial's zeros:\n>>> np.poly((0, 0, 0)) # Multiple root example\narray([1., 0., 0., 0.])\nThe line above represents z**3 + 0*z**2 + 0*z + 0.\n>>> np.poly((-1./2, 0, 1./2))\narray([ 1.  ,  0.  , -0.25,  0.  ])\nThe line above represents z**3 - z/4\n>>> np.poly((np.random.random(1)[0], 0, np.random.random(1)[0]))\narray([ 1.        , -0.77086955,  0.08618131,  0.        ]) # random\nGiven a square array object:\n>>> P = np.array([[0, 1./3], [-1./2, 0]])\n>>> np.poly(P)\narray([1.        , 0.        , 0.16666667])\nNote how in all cases the leading coefficient is always 1."
      }
    },
    {
      "name": "polyadd",
      "signature": "polyadd(a1, a2)",
      "documentation": {
        "description": "Find the sum of two polynomials.\n.. note::\nThis forms part of the old polynomial API. Since version 1.4, the\nnew polynomial API defined in `numpy.polynomial` is preferred.\nA summary of the differences can be found in the\n:doc:`transition guide </reference/routines.polynomials>`.",
        "parameters": {},
        "returns": "Each input must be either a poly1d object or a 1D sequence of polynomial\ncoefficients, from highest to lowest degree.\n-------\nout : ndarray or poly1d object\nThe sum of the inputs. If either input is a poly1d object, then the\noutput is also a poly1d object. Otherwise, it is a 1D array of\npolynomial coefficients from highest to lowest degree.",
        "raises": "",
        "see_also": "--------\npoly1d : A one-dimensional polynomial class.\npoly, polyadd, polyder, polydiv, polyfit, polyint, polysub, polyval",
        "notes": "",
        "examples": "--------\n>>> np.polyadd([1, 2], [9, 5, 4])\narray([9, 6, 6])\nUsing poly1d objects:\n>>> p1 = np.poly1d([1, 2])\n>>> p2 = np.poly1d([9, 5, 4])\n>>> print(p1)\n1 x + 2\n>>> print(p2)\n2\n9 x + 5 x + 4\n>>> print(np.polyadd(p1, p2))\n2\n9 x + 6 x + 6"
      }
    },
    {
      "name": "polyder",
      "signature": "polyder(p, m=1)",
      "documentation": {
        "description": "Return the derivative of the specified order of a polynomial.\n.. note::\nThis forms part of the old polynomial API. Since version 1.4, the\nnew polynomial API defined in `numpy.polynomial` is preferred.\nA summary of the differences can be found in the\n:doc:`transition guide </reference/routines.polynomials>`.",
        "parameters": {
          "p": {
            "type": "poly1d or sequence",
            "description": "Polynomial to differentiate.\nA sequence is interpreted as polynomial coefficients, see `poly1d`."
          },
          "m": {
            "type": "int, optional",
            "description": "Order of differentiation (default: 1)"
          }
        },
        "returns": "-------\nder : poly1d\nA new polynomial representing the derivative.",
        "raises": "",
        "see_also": "--------\npolyint : Anti-derivative of a polynomial.\npoly1d : Class for one-dimensional polynomials.",
        "notes": "",
        "examples": "--------\nThe derivative of the polynomial :math:`x^3 + x^2 + x^1 + 1` is:\n>>> p = np.poly1d([1,1,1,1])\n>>> p2 = np.polyder(p)\n>>> p2\npoly1d([3, 2, 1])\nwhich evaluates to:\n>>> p2(2.)\n17.0\nWe can verify this, approximating the derivative with\n``(f(x + h) - f(x))/h``:\n>>> (p(2. + 0.001) - p(2.)) / 0.001\n17.007000999997857\nThe fourth-order derivative of a 3rd-order polynomial is zero:\n>>> np.polyder(p, 2)\npoly1d([6, 2])\n>>> np.polyder(p, 3)\npoly1d([6])\n>>> np.polyder(p, 4)\npoly1d([0])"
      }
    },
    {
      "name": "polydiv",
      "signature": "polydiv(u, v)",
      "documentation": {
        "description": "",
        "parameters": {
          "u": {
            "type": "array_like or poly1d",
            "description": "Dividend polynomial's coefficients."
          },
          "v": {
            "type": "array_like or poly1d",
            "description": "Divisor polynomial's coefficients."
          }
        },
        "returns": ".. note::\nThis forms part of the old polynomial API. Since version 1.4, the\nnew polynomial API defined in `numpy.polynomial` is preferred.\nA summary of the differences can be found in the\n:doc:`transition guide </reference/routines.polynomials>`.\nThe input arrays are the coefficients (including any coefficients\nequal to zero) of the \"numerator\" (dividend) and \"denominator\"\n(divisor) polynomials, respectively.\n-------\nq : ndarray\nCoefficients, including those equal to zero, of the quotient.\nr : ndarray\nCoefficients, including those equal to zero, of the remainder.",
        "raises": "",
        "see_also": "--------\npoly, polyadd, polyder, polydiv, polyfit, polyint, polymul, polysub\npolyval",
        "notes": "-----\nBoth `u` and `v` must be 0-d or 1-d (ndim = 0 or 1), but `u.ndim` need\nnot equal `v.ndim`. In other words, all four possible combinations -\n``u.ndim = v.ndim = 0``, ``u.ndim = v.ndim = 1``,\n``u.ndim = 1, v.ndim = 0``, and ``u.ndim = 0, v.ndim = 1`` - work.",
        "examples": "--------\n.. math:: \\frac{3x^2 + 5x + 2}{2x + 1} = 1.5x + 1.75, remainder 0.25\n>>> x = np.array([3.0, 5.0, 2.0])\n>>> y = np.array([2.0, 1.0])\n>>> np.polydiv(x, y)\n(array([1.5 , 1.75]), array([0.25]))"
      }
    },
    {
      "name": "polyfit",
      "signature": "polyfit(x, y, deg, rcond=None, full=False, w=None, cov=False)",
      "documentation": {
        "description": "Least squares polynomial fit.\n.. note::\nThis forms part of the old polynomial API. Since version 1.4, the\nnew polynomial API defined in `numpy.polynomial` is preferred.\nA summary of the differences can be found in the\n:doc:`transition guide </reference/routines.polynomials>`.\nFit a polynomial ``p(x) = p[0] * x**deg + ... + p[deg]`` of degree `deg`\nto points `(x, y)`. Returns a vector of coefficients `p` that minimises\nthe squared error in the order `deg`, `deg-1`, ... `0`.\nThe `Polynomial.fit <numpy.polynomial.polynomial.Polynomial.fit>` class\nmethod is recommended for new code as it is more stable numerically. See\nthe documentation of the method for more information.",
        "parameters": {
          "x": {
            "type": "array_like, shape (M,)",
            "description": "x-coordinates of the M sample points ``(x[i], y[i])``."
          },
          "y": {
            "type": "array_like, shape (M,) or (M, K)",
            "description": "y-coordinates of the sample points. Several data sets of sample\npoints sharing the same x-coordinates can be fitted at once by\npassing in a 2D-array that contains one dataset per column."
          },
          "deg": {
            "type": "int",
            "description": "Degree of the fitting polynomial"
          },
          "rcond": {
            "type": "float, optional",
            "description": "Relative condition number of the fit. Singular values smaller than\nthis relative to the largest singular value will be ignored. The\ndefault value is len(x)*eps, where eps is the relative precision of\nthe float type, about 2e-16 in most cases."
          },
          "full": {
            "type": "bool, optional",
            "description": "Switch determining nature of return value. When it is False (the\ndefault) just the coefficients are returned, when True diagnostic\ninformation from the singular value decomposition is also returned."
          },
          "w": {
            "type": "array_like, shape (M,), optional",
            "description": "Weights. If not None, the weight ``w[i]`` applies to the unsquared\nresidual ``y[i] - y_hat[i]`` at ``x[i]``. Ideally the weights are\nchosen so that the errors of the products ``w[i]*y[i]`` all have the\nsame variance.  When using inverse-variance weighting, use\n``w[i] = 1/sigma(y[i])``.  The default value is None."
          },
          "cov": {
            "type": "bool or str, optional",
            "description": "If given and not `False`, return not just the estimate but also its\ncovariance matrix. By default, the covariance are scaled by\nchi2/dof, where dof = M - (deg + 1), i.e., the weights are presumed\nto be unreliable except in a relative sense and everything is scaled\nsuch that the reduced chi2 is unity. This scaling is omitted if\n``cov='unscaled'``, as is relevant for the case that the weights are\nw = 1/sigma, with sigma known to be a reliable estimate of the\nuncertainty."
          }
        },
        "returns": "-------\np : ndarray, shape (deg + 1,) or (deg + 1, K)\nPolynomial coefficients, highest power first.  If `y` was 2-D, the\ncoefficients for `k`-th data set are in ``p[:,k]``.\nresiduals, rank, singular_values, rcond\nThese values are only returned if ``full == True``\n- residuals -- sum of squared residuals of the least squares fit\n- rank -- the effective rank of the scaled Vandermonde\ncoefficient matrix\n- singular_values -- singular values of the scaled Vandermonde\ncoefficient matrix\n- rcond -- value of `rcond`.\nFor more details, see `numpy.linalg.lstsq`.\nV : ndarray, shape (M,M) or (M,M,K)\nPresent only if ``full == False`` and ``cov == True``.  The covariance\nmatrix of the polynomial coefficient estimates.  The diagonal of\nthis matrix are the variance estimates for each coefficient.  If y\nis a 2-D array, then the covariance matrix for the `k`-th data set\nare in ``V[:,:,k]``\nWarns\n-----\nRankWarning\nThe rank of the coefficient matrix in the least-squares fit is\ndeficient. The warning is only raised if ``full == False``.\nThe warnings can be turned off by\n>>> import warnings\n>>> warnings.simplefilter('ignore', np.RankWarning)",
        "raises": "",
        "see_also": "--------\npolyval : Compute polynomial values.\nlinalg.lstsq : Computes a least-squares fit.\nscipy.interpolate.UnivariateSpline : Computes spline fits.",
        "notes": "-----\nThe solution minimizes the squared error\n.. math::\nE = \\sum_{j=0}^k |p(x_j) - y_j|^2\nin the equations::\nx[0]**n * p[0] + ... + x[0] * p[n-1] + p[n] = y[0]\nx[1]**n * p[0] + ... + x[1] * p[n-1] + p[n] = y[1]\n...\nx[k]**n * p[0] + ... + x[k] * p[n-1] + p[n] = y[k]\nThe coefficient matrix of the coefficients `p` is a Vandermonde matrix.\n`polyfit` issues a `RankWarning` when the least-squares fit is badly\nconditioned. This implies that the best fit is not well-defined due\nto numerical error. The results may be improved by lowering the polynomial\ndegree or by replacing `x` by `x` - `x`.mean(). The `rcond` parameter\ncan also be set to a value smaller than its default, but the resulting\nfit may be spurious: including contributions from the small singular\nvalues can add numerical noise to the result.\nNote that fitting polynomial coefficients is inherently badly conditioned\nwhen the degree of the polynomial is large or the interval of sample points\nis badly centered. The quality of the fit should always be checked in these\ncases. When polynomial fits are not satisfactory, splines may be a good\nalternative.\nReferences\n----------\n.. [1] Wikipedia, \"Curve fitting\",\nhttps://en.wikipedia.org/wiki/Curve_fitting\n.. [2] Wikipedia, \"Polynomial interpolation\",\nhttps://en.wikipedia.org/wiki/Polynomial_interpolation",
        "examples": "--------\n>>> import warnings\n>>> x = np.array([0.0, 1.0, 2.0, 3.0,  4.0,  5.0])\n>>> y = np.array([0.0, 0.8, 0.9, 0.1, -0.8, -1.0])\n>>> z = np.polyfit(x, y, 3)\n>>> z\narray([ 0.08703704, -0.81349206,  1.69312169, -0.03968254]) # may vary\nIt is convenient to use `poly1d` objects for dealing with polynomials:\n>>> p = np.poly1d(z)\n>>> p(0.5)\n0.6143849206349179 # may vary\n>>> p(3.5)\n-0.34732142857143039 # may vary\n>>> p(10)\n22.579365079365115 # may vary\nHigh-order polynomials may oscillate wildly:\n>>> with warnings.catch_warnings():\n...     warnings.simplefilter('ignore', np.RankWarning)\n...     p30 = np.poly1d(np.polyfit(x, y, 30))\n...\n>>> p30(4)\n-0.80000000000000204 # may vary\n>>> p30(5)\n-0.99999999999999445 # may vary\n>>> p30(4.5)\n-0.10547061179440398 # may vary\nIllustration:\n>>> import matplotlib.pyplot as plt\n>>> xp = np.linspace(-2, 6, 100)\n>>> _ = plt.plot(x, y, '.', xp, p(xp), '-', xp, p30(xp), '--')\n>>> plt.ylim(-2,2)\n(-2, 2)\n>>> plt.show()"
      }
    },
    {
      "name": "polyint",
      "signature": "polyint(p, m=1, k=None)",
      "documentation": {
        "description": "Return an antiderivative (indefinite integral) of a polynomial.\n.. note::\nThis forms part of the old polynomial API. Since version 1.4, the\nnew polynomial API defined in `numpy.polynomial` is preferred.\nA summary of the differences can be found in the\n:doc:`transition guide </reference/routines.polynomials>`.\nThe returned order `m` antiderivative `P` of polynomial `p` satisfies\n:math:`\\frac{d^m}{dx^m}P(x) = p(x)` and is defined up to `m - 1`\nintegration constants `k`. The constants determine the low-order\npolynomial part\n.. math:: \\frac{k_{m-1}}{0!} x^0 + \\ldots + \\frac{k_0}{(m-1)!}x^{m-1}\nof `P` so that :math:`P^{(j)}(0) = k_{m-j-1}`.",
        "parameters": {
          "p": {
            "type": "array_like or poly1d",
            "description": "Polynomial to integrate.\nA sequence is interpreted as polynomial coefficients, see `poly1d`."
          },
          "m": {
            "type": "int, optional",
            "description": "Order of the antiderivative. (Default: 1)"
          },
          "k": {
            "type": "list of `m` scalars or scalar, optional",
            "description": "Integration constants. They are given in the order of integration:\nthose corresponding to highest-order terms come first.\nIf ``None`` (default), all constants are assumed to be zero.\nIf `m = 1`, a single scalar can be given instead of a list."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\npolyder : derivative of a polynomial\npoly1d.integ : equivalent method",
        "notes": "",
        "examples": "--------\nThe defining property of the antiderivative:\n>>> p = np.poly1d([1,1,1])\n>>> P = np.polyint(p)\n>>> P\npoly1d([ 0.33333333,  0.5       ,  1.        ,  0.        ]) # may vary\n>>> np.polyder(P) == p\nTrue\nThe integration constants default to zero, but can be specified:\n>>> P = np.polyint(p, 3)\n>>> P(0)\n0.0\n>>> np.polyder(P)(0)\n0.0\n>>> np.polyder(P, 2)(0)\n0.0\n>>> P = np.polyint(p, 3, k=[6,5,3])\n>>> P\npoly1d([ 0.01666667,  0.04166667,  0.16666667,  3. ,  5. ,  3. ]) # may vary\nNote that 3 = 6 / 2!, and that the constants are given in the order of\nintegrations. Constant of the highest-order polynomial term comes first:\n>>> np.polyder(P, 2)(0)\n6.0\n>>> np.polyder(P, 1)(0)\n5.0\n>>> P(0)\n3.0"
      }
    },
    {
      "name": "polymul",
      "signature": "polymul(a1, a2)",
      "documentation": {
        "description": "Find the product of two polynomials.\n.. note::\nThis forms part of the old polynomial API. Since version 1.4, the\nnew polynomial API defined in `numpy.polynomial` is preferred.\nA summary of the differences can be found in the\n:doc:`transition guide </reference/routines.polynomials>`.\nFinds the polynomial resulting from the multiplication of the two input\npolynomials. Each input must be either a poly1d object or a 1D sequence\nof polynomial coefficients, from highest to lowest degree.",
        "parameters": {},
        "returns": "-------\nout : ndarray or poly1d object\nThe polynomial resulting from the multiplication of the inputs. If\neither inputs is a poly1d object, then the output is also a poly1d\nobject. Otherwise, it is a 1D array of polynomial coefficients from\nhighest to lowest degree.",
        "raises": "",
        "see_also": "--------\npoly1d : A one-dimensional polynomial class.\npoly, polyadd, polyder, polydiv, polyfit, polyint, polysub, polyval\nconvolve : Array convolution. Same output as polymul, but has parameter\nfor overlap mode.",
        "notes": "",
        "examples": "--------\n>>> np.polymul([1, 2, 3], [9, 5, 1])\narray([ 9, 23, 38, 17,  3])\nUsing poly1d objects:\n>>> p1 = np.poly1d([1, 2, 3])\n>>> p2 = np.poly1d([9, 5, 1])\n>>> print(p1)\n2\n1 x + 2 x + 3\n>>> print(p2)\n2\n9 x + 5 x + 1\n>>> print(np.polymul(p1, p2))\n4      3      2\n9 x + 23 x + 38 x + 17 x + 3"
      }
    },
    {
      "name": "polysub",
      "signature": "polysub(a1, a2)",
      "documentation": {
        "description": "Difference (subtraction) of two polynomials.\n.. note::\nThis forms part of the old polynomial API. Since version 1.4, the\nnew polynomial API defined in `numpy.polynomial` is preferred.\nA summary of the differences can be found in the\n:doc:`transition guide </reference/routines.polynomials>`.\nGiven two polynomials `a1` and `a2`, returns ``a1 - a2``.\n`a1` and `a2` can be either array_like sequences of the polynomials'\ncoefficients (including coefficients equal to zero), or `poly1d` objects.",
        "parameters": {},
        "returns": "-------\nout : ndarray or poly1d\nArray or `poly1d` object of the difference polynomial's coefficients.",
        "raises": "",
        "see_also": "--------\npolyval, polydiv, polymul, polyadd",
        "notes": "",
        "examples": "--------\n.. math:: (2 x^2 + 10 x - 2) - (3 x^2 + 10 x -4) = (-x^2 + 2)\n>>> np.polysub([2, 10, -2], [3, 10, -4])\narray([-1,  0,  2])"
      }
    },
    {
      "name": "polyval",
      "signature": "polyval(p, x)",
      "documentation": {
        "description": "Evaluate a polynomial at specific values.\n.. note::\nThis forms part of the old polynomial API. Since version 1.4, the\nnew polynomial API defined in `numpy.polynomial` is preferred.\nA summary of the differences can be found in the\n:doc:`transition guide </reference/routines.polynomials>`.\nIf `p` is of length N, this function returns the value:\n``p[0]*x**(N-1) + p[1]*x**(N-2) + ... + p[N-2]*x + p[N-1]``\nIf `x` is a sequence, then ``p(x)`` is returned for each element of ``x``.\nIf `x` is another polynomial then the composite polynomial ``p(x(t))``\nis returned.",
        "parameters": {
          "p": {
            "type": "array_like or poly1d object",
            "description": "1D array of polynomial coefficients (including coefficients equal\nto zero) from highest degree to the constant term, or an\ninstance of poly1d."
          },
          "x": {
            "type": "array_like or poly1d object",
            "description": "A number, an array of numbers, or an instance of poly1d, at\nwhich to evaluate `p`."
          }
        },
        "returns": "-------\nvalues : ndarray or poly1d\nIf `x` is a poly1d instance, the result is the composition of the two\npolynomials, i.e., `x` is \"substituted\" in `p` and the simplified\nresult is returned. In addition, the type of `x` - array_like or\npoly1d - governs the type of the output: `x` array_like => `values`\narray_like, `x` a poly1d object => `values` is also.",
        "raises": "",
        "see_also": "--------\npoly1d: A polynomial class.",
        "notes": "-----\nHorner's scheme [1]_ is used to evaluate the polynomial. Even so,\nfor polynomials of high degree the values may be inaccurate due to\nrounding errors. Use carefully.\nIf `x` is a subtype of `ndarray` the return value will be of the same type.\nReferences\n----------\n.. [1] I. N. Bronshtein, K. A. Semendyayev, and K. A. Hirsch (Eng.\ntrans. Ed.), *Handbook of Mathematics*, New York, Van Nostrand\nReinhold Co., 1985, pg. 720.",
        "examples": "--------\n>>> np.polyval([3,0,1], 5)  # 3 * 5**2 + 0 * 5**1 + 1\n76\n>>> np.polyval([3,0,1], np.poly1d(5))\npoly1d([76])\n>>> np.polyval(np.poly1d([3,0,1]), 5)\n76\n>>> np.polyval(np.poly1d([3,0,1]), np.poly1d(5))\npoly1d([76])"
      }
    },
    {
      "name": "put_along_axis",
      "signature": "put_along_axis(arr, indices, values, axis)",
      "documentation": {
        "description": "Put values into the destination array by matching 1d index and data slices.\nThis iterates over matching 1d slices oriented along the specified axis in\nthe index and data arrays, and uses the former to place values into the\nlatter. These slices can be different lengths.\nFunctions returning an index along an axis, like `argsort` and\n`argpartition`, produce suitable indices for this function.\n.. versionadded:: 1.15.0",
        "parameters": {
          "arr": {
            "type": "ndarray (Ni..., M, Nk...)",
            "description": "Destination array."
          },
          "indices": {
            "type": "ndarray (Ni..., J, Nk...)",
            "description": "Indices to change along each 1d slice of `arr`. This must match the\ndimension of arr, but dimensions in Ni and Nj may be 1 to broadcast\nagainst `arr`."
          },
          "values": {
            "type": "array_like (Ni..., J, Nk...)",
            "description": "values to insert at those indices. Its shape and dimension are\nbroadcast to match that of `indices`."
          },
          "axis": {
            "type": "int",
            "description": "The axis to take 1d slices along. If axis is None, the destination\narray is treated as if a flattened 1d view had been created of it."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\ntake_along_axis :\nTake values from the input array by matching 1d index and data slices",
        "notes": "-----\nThis is equivalent to (but faster than) the following use of `ndindex` and\n`s_`, which sets each of ``ii`` and ``kk`` to a tuple of indices::\nNi, M, Nk = a.shape[:axis], a.shape[axis], a.shape[axis+1:]\nJ = indices.shape[axis]  # Need not equal M\nfor ii in ndindex(Ni):\nfor kk in ndindex(Nk):\na_1d       = a      [ii + s_[:,] + kk]\nindices_1d = indices[ii + s_[:,] + kk]\nvalues_1d  = values [ii + s_[:,] + kk]\nfor j in range(J):\na_1d[indices_1d[j]] = values_1d[j]\nEquivalently, eliminating the inner loop, the last two lines would be::\na_1d[indices_1d] = values_1d",
        "examples": "--------\nFor this sample array\n>>> a = np.array([[10, 30, 20], [60, 40, 50]])\nWe can replace the maximum values with:\n>>> ai = np.argmax(a, axis=1, keepdims=True)\n>>> ai\narray([[1],\n[0]])\n>>> np.put_along_axis(a, ai, 99, axis=1)\n>>> a\narray([[10, 99, 20],\n[99, 40, 50]])"
      }
    },
    {
      "name": "quantile",
      "signature": "quantile(a, q, axis=None, out=None, overwrite_input=False, method='linear', keepdims=False, *, interpolation=None)",
      "documentation": {
        "description": "Compute the q-th quantile of the data along the specified axis.\n.. versionadded:: 1.15.0",
        "parameters": {
          "a": {
            "type": "array_like of real numbers",
            "description": "Input array or object that can be converted to an array."
          },
          "q": {
            "type": "array_like of float",
            "description": "Probability or sequence of probabilities for the quantiles to compute.\nValues must be between 0 and 1 inclusive."
          },
          "axis": {
            "type": "{int, tuple of int, None}, optional",
            "description": "Axis or axes along which the quantiles are computed. The default is\nto compute the quantile(s) along a flattened version of the array."
          },
          "out": {
            "type": "ndarray, optional",
            "description": "Alternative output array in which to place the result. It must have\nthe same shape and buffer length as the expected output, but the\ntype (of the output) will be cast if necessary."
          },
          "overwrite_input": {
            "type": "bool, optional",
            "description": "If True, then allow the input array `a` to be modified by\nintermediate calculations, to save memory. In this case, the\ncontents of the input `a` after this function completes is\nundefined."
          },
          "method": {
            "type": "str, optional",
            "description": "This parameter specifies the method to use for estimating the\nquantile.  There are many different methods, some unique to NumPy.\nSee the notes for explanation.  The options sorted by their R type\nas summarized in the H&F paper [1]_ are:\n1. 'inverted_cdf'\n2. 'averaged_inverted_cdf'\n3. 'closest_observation'\n4. 'interpolated_inverted_cdf'\n5. 'hazen'\n6. 'weibull'\n7. 'linear'  (default)\n8. 'median_unbiased'\n9. 'normal_unbiased'\nThe first three methods are discontinuous.  NumPy further defines the\nfollowing discontinuous variations of the default 'linear' (7.) option:\n* 'lower'\n* 'higher',\n* 'midpoint'\n* 'nearest'\n.. versionchanged:: 1.22.0\nThis argument was previously called \"interpolation\" and only\noffered the \"linear\" default and last four options."
          },
          "keepdims": {
            "type": "bool, optional",
            "description": "If this is set to True, the axes which are reduced are left in\nthe result as dimensions with size one. With this option, the\nresult will broadcast correctly against the original array `a`."
          },
          "interpolation": {
            "type": "str, optional",
            "description": "Deprecated name for the method keyword argument.\n.. deprecated:: 1.22.0"
          }
        },
        "returns": "-------\nquantile : scalar or ndarray\nIf `q` is a single probability and `axis=None`, then the result\nis a scalar. If multiple probabilies levels are given, first axis of\nthe result corresponds to the quantiles. The other axes are\nthe axes that remain after the reduction of `a`. If the input\ncontains integers or floats smaller than ``float64``, the output\ndata-type is ``float64``. Otherwise, the output data-type is the\nsame as that of the input. If `out` is specified, that array is\nreturned instead.",
        "raises": "",
        "see_also": "--------\nmean\npercentile : equivalent to quantile, but with q in the range [0, 100].\nmedian : equivalent to ``quantile(..., 0.5)``\nnanquantile",
        "notes": "-----\nGiven a vector ``V`` of length ``n``, the q-th quantile of ``V`` is\nthe value ``q`` of the way from the minimum to the maximum in a\nsorted copy of ``V``. The values and distances of the two nearest\nneighbors as well as the `method` parameter will determine the\nquantile if the normalized ranking does not match the location of\n``q`` exactly. This function is the same as the median if ``q=0.5``, the\nsame as the minimum if ``q=0.0`` and the same as the maximum if\n``q=1.0``.\nThe optional `method` parameter specifies the method to use when the\ndesired quantile lies between two indexes ``i`` and ``j = i + 1``.\nIn that case, we first determine ``i + g``, a virtual index that lies\nbetween ``i`` and ``j``, where  ``i`` is the floor and ``g`` is the\nfractional part of the index. The final result is, then, an interpolation\nof ``a[i]`` and ``a[j]`` based on ``g``. During the computation of ``g``,\n``i`` and ``j`` are modified using correction constants ``alpha`` and\n``beta`` whose choices depend on the ``method`` used. Finally, note that\nsince Python uses 0-based indexing, the code subtracts another 1 from the\nindex internally.\nThe following formula determines the virtual index ``i + g``, the location\nof the quantile in the sorted sample:\n.. math::\ni + g = q * ( n - alpha - beta + 1 ) + alpha\nThe different methods then work as follows\ninverted_cdf:\nmethod 1 of H&F [1]_.\nThis method gives discontinuous results:\n* if g > 0 ; then take j\n* if g = 0 ; then take i\naveraged_inverted_cdf:\nmethod 2 of H&F [1]_.\nThis method gives discontinuous results:\n* if g > 0 ; then take j\n* if g = 0 ; then average between bounds\nclosest_observation:\nmethod 3 of H&F [1]_.\nThis method gives discontinuous results:\n* if g > 0 ; then take j\n* if g = 0 and index is odd ; then take j\n* if g = 0 and index is even ; then take i\ninterpolated_inverted_cdf:\nmethod 4 of H&F [1]_.\nThis method gives continuous results using:\n* alpha = 0\n* beta = 1\nhazen:\nmethod 5 of H&F [1]_.\nThis method gives continuous results using:\n* alpha = 1/2\n* beta = 1/2\nweibull:\nmethod 6 of H&F [1]_.\nThis method gives continuous results using:\n* alpha = 0\n* beta = 0\nlinear:\nmethod 7 of H&F [1]_.\nThis method gives continuous results using:\n* alpha = 1\n* beta = 1\nmedian_unbiased:\nmethod 8 of H&F [1]_.\nThis method is probably the best method if the sample\ndistribution function is unknown (see reference).\nThis method gives continuous results using:\n* alpha = 1/3\n* beta = 1/3\nnormal_unbiased:\nmethod 9 of H&F [1]_.\nThis method is probably the best method if the sample\ndistribution function is known to be normal.\nThis method gives continuous results using:\n* alpha = 3/8\n* beta = 3/8\nlower:\nNumPy method kept for backwards compatibility.\nTakes ``i`` as the interpolation point.\nhigher:\nNumPy method kept for backwards compatibility.\nTakes ``j`` as the interpolation point.\nnearest:\nNumPy method kept for backwards compatibility.\nTakes ``i`` or ``j``, whichever is nearest.\nmidpoint:\nNumPy method kept for backwards compatibility.\nUses ``(i + j) / 2``.",
        "examples": "--------\n>>> a = np.array([[10, 7, 4], [3, 2, 1]])\n>>> a\narray([[10,  7,  4],\n[ 3,  2,  1]])\n>>> np.quantile(a, 0.5)\n3.5\n>>> np.quantile(a, 0.5, axis=0)\narray([6.5, 4.5, 2.5])\n>>> np.quantile(a, 0.5, axis=1)\narray([7.,  2.])\n>>> np.quantile(a, 0.5, axis=1, keepdims=True)\narray([[7.],\n[2.]])\n>>> m = np.quantile(a, 0.5, axis=0)\n>>> out = np.zeros_like(m)\n>>> np.quantile(a, 0.5, axis=0, out=out)\narray([6.5, 4.5, 2.5])\n>>> m\narray([6.5, 4.5, 2.5])\n>>> b = a.copy()\n>>> np.quantile(b, 0.5, axis=1, overwrite_input=True)\narray([7.,  2.])\n>>> assert not np.all(a == b)\nSee also `numpy.percentile` for a visualization of most methods.\nReferences\n----------\n.. [1] R. J. Hyndman and Y. Fan,\n\"Sample quantiles in statistical packages,\"\nThe American Statistician, 50(4), pp. 361-365, 1996"
      }
    },
    {
      "name": "ravel_multi_index",
      "signature": "ravel_multi_index(multi_index, dims, mode='raise', order='C')",
      "documentation": {
        "description": "ravel_multi_index(multi_index, dims, mode='raise', order='C')\nConverts a tuple of index arrays into an array of flat\nindices, applying boundary modes to the multi-index.",
        "parameters": {
          "multi_index": {
            "type": "tuple of array_like",
            "description": "A tuple of integer arrays, one array for each dimension."
          },
          "dims": {
            "type": "tuple of ints",
            "description": "The shape of array into which the indices from ``multi_index`` apply."
          },
          "mode": {
            "type": "{'raise', 'wrap', 'clip'}, optional",
            "description": "Specifies how out-of-bounds indices are handled.  Can specify\neither one mode or a tuple of modes, one mode per index.\n* 'raise' -- raise an error (default)\n* 'wrap' -- wrap around\n* 'clip' -- clip to the range\nIn 'clip' mode, a negative index which would normally\nwrap will clip to 0 instead."
          },
          "order": {
            "type": "{'C', 'F'}, optional",
            "description": "Determines whether the multi-index should be viewed as\nindexing in row-major (C-style) or column-major\n(Fortran-style) order."
          }
        },
        "returns": "-------\nraveled_indices : ndarray\nAn array of indices into the flattened version of an array\nof dimensions ``dims``.",
        "raises": "",
        "see_also": "--------\nunravel_index",
        "notes": "-----\n.. versionadded:: 1.6.0",
        "examples": "--------\n>>> arr = np.array([[3,6,6],[4,5,1]])\n>>> np.ravel_multi_index(arr, (7,6))\narray([22, 41, 37])\n>>> np.ravel_multi_index(arr, (7,6), order='F')\narray([31, 41, 13])\n>>> np.ravel_multi_index(arr, (4,6), mode='clip')\narray([22, 23, 19])\n>>> np.ravel_multi_index(arr, (4,4), mode=('clip','wrap'))\narray([12, 13, 13])\n>>> np.ravel_multi_index((3,1,4,1), (6,7,8,9))\n1621"
      }
    },
    {
      "name": "real",
      "signature": "real(val)",
      "documentation": {
        "description": "Return the real part of the complex argument.",
        "parameters": {
          "val": {
            "type": "array_like",
            "description": "Input array."
          }
        },
        "returns": "-------\nout : ndarray or scalar\nThe real component of the complex argument. If `val` is real, the type\nof `val` is used for the output.  If `val` has complex elements, the\nreturned type is float.",
        "raises": "",
        "see_also": "--------\nreal_if_close, imag, angle",
        "notes": "",
        "examples": "--------\n>>> a = np.array([1+2j, 3+4j, 5+6j])\n>>> a.real\narray([1.,  3.,  5.])\n>>> a.real = 9\n>>> a\narray([9.+2.j,  9.+4.j,  9.+6.j])\n>>> a.real = np.array([9, 8, 7])\n>>> a\narray([9.+2.j,  8.+4.j,  7.+6.j])\n>>> np.real(1 + 1j)\n1.0"
      }
    },
    {
      "name": "real_if_close",
      "signature": "real_if_close(a, tol=100)",
      "documentation": {
        "description": "If input is complex with all imaginary parts close to zero, return\nreal parts.\n\"Close to zero\" is defined as `tol` * (machine epsilon of the type for\n`a`).",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array."
          },
          "tol": {
            "type": "float",
            "description": "Tolerance in machine epsilons for the complex part of the elements\nin the array. If the tolerance is <=1, then the absolute tolerance\nis used."
          }
        },
        "returns": "-------\nout : ndarray\nIf `a` is real, the type of `a` is used for the output.  If `a`\nhas complex elements, the returned type is float.",
        "raises": "",
        "see_also": "--------\nreal, imag, angle",
        "notes": "-----\nMachine epsilon varies from machine to machine and between data types\nbut Python floats on most platforms have a machine epsilon equal to\n2.2204460492503131e-16.  You can use 'np.finfo(float).eps' to print\nout the machine epsilon for floats.",
        "examples": "--------\n>>> np.finfo(float).eps\n2.2204460492503131e-16 # may vary\n>>> np.real_if_close([2.1 + 4e-14j, 5.2 + 3e-15j], tol=1000)\narray([2.1, 5.2])\n>>> np.real_if_close([2.1 + 4e-13j, 5.2 + 3e-15j], tol=1000)\narray([2.1+4.e-13j, 5.2 + 3e-15j])"
      }
    },
    {
      "name": "recfromcsv",
      "signature": "recfromcsv(fname, **kwargs)",
      "documentation": {
        "description": "Load ASCII data stored in a comma-separated file.\nThe returned array is a record array (if ``usemask=False``, see\n`recarray`) or a masked record array (if ``usemask=True``,\nsee `ma.mrecords.MaskedRecords`).",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "--------\nnumpy.genfromtxt : generic function to load ASCII data.",
        "notes": "-----\nBy default, `dtype` is None, which means that the data-type of the output\narray will be determined from the data.",
        "examples": ""
      }
    },
    {
      "name": "recfromtxt",
      "signature": "recfromtxt(fname, **kwargs)",
      "documentation": {
        "description": "Load ASCII data from a file and return it in a record array.\nIf ``usemask=False`` a standard `recarray` is returned,\nif ``usemask=True`` a MaskedRecords array is returned.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "--------\nnumpy.genfromtxt : generic function",
        "notes": "-----\nBy default, `dtype` is None, which means that the data-type of the output\narray will be determined from the data.",
        "examples": ""
      }
    },
    {
      "name": "roots",
      "signature": "roots(p)",
      "documentation": {
        "description": "Return the roots of a polynomial with coefficients given in p.\n.. note::\nThis forms part of the old polynomial API. Since version 1.4, the\nnew polynomial API defined in `numpy.polynomial` is preferred.\nA summary of the differences can be found in the\n:doc:`transition guide </reference/routines.polynomials>`.\nThe values in the rank-1 array `p` are coefficients of a polynomial.\nIf the length of `p` is n+1 then the polynomial is described by::\np[0] * x**n + p[1] * x**(n-1) + ... + p[n-1]*x + p[n]",
        "parameters": {
          "p": {
            "type": "array_like",
            "description": "Rank-1 array of polynomial coefficients."
          }
        },
        "returns": "-------\nout : ndarray\nAn array containing the roots of the polynomial.",
        "raises": "------\nValueError\nWhen `p` cannot be converted to a rank-1 array.\nSee also\n--------\npoly : Find the coefficients of a polynomial with a given sequence\nof roots.\npolyval : Compute polynomial values.\npolyfit : Least squares polynomial fit.\npoly1d : A one-dimensional polynomial class.",
        "see_also": "",
        "notes": "-----\nThe algorithm relies on computing the eigenvalues of the\ncompanion matrix [1]_.\nReferences\n----------\n.. [1] R. A. Horn & C. R. Johnson, *Matrix Analysis*.  Cambridge, UK:\nCambridge University Press, 1999, pp. 146-7.",
        "examples": "--------\n>>> coeff = [3.2, 2, 1]\n>>> np.roots(coeff)\narray([-0.3125+0.46351241j, -0.3125-0.46351241j])"
      }
    },
    {
      "name": "rot90",
      "signature": "rot90(m, k=1, axes=(0, 1))",
      "documentation": {
        "description": "Rotate an array by 90 degrees in the plane specified by axes.\nRotation direction is from the first towards the second axis.\nThis means for a 2D array with the default `k` and `axes`, the\nrotation will be counterclockwise.",
        "parameters": {
          "m": {
            "type": "array_like",
            "description": "Array of two or more dimensions."
          },
          "k": {
            "type": "integer",
            "description": "Number of times the array is rotated by 90 degrees."
          },
          "axes": {
            "type": "(2,) array_like",
            "description": "The array is rotated in the plane defined by the axes.\nAxes must be different.\n.. versionadded:: 1.12.0"
          }
        },
        "returns": "-------\ny : ndarray\nA rotated view of `m`.",
        "raises": "",
        "see_also": "--------\nflip : Reverse the order of elements in an array along the given axis.\nfliplr : Flip an array horizontally.\nflipud : Flip an array vertically.",
        "notes": "-----\n``rot90(m, k=1, axes=(1,0))``  is the reverse of\n``rot90(m, k=1, axes=(0,1))``\n``rot90(m, k=1, axes=(1,0))`` is equivalent to\n``rot90(m, k=-1, axes=(0,1))``",
        "examples": "--------\n>>> m = np.array([[1,2],[3,4]], int)\n>>> m\narray([[1, 2],\n[3, 4]])\n>>> np.rot90(m)\narray([[2, 4],\n[1, 3]])\n>>> np.rot90(m, 2)\narray([[4, 3],\n[2, 1]])\n>>> m = np.arange(8).reshape((2,2,2))\n>>> np.rot90(m, 1, (1,2))\narray([[[1, 3],\n[0, 2]],\n[[5, 7],\n[4, 6]]])"
      }
    },
    {
      "name": "row_stack",
      "signature": "vstack(tup, *, dtype=None, casting='same_kind')",
      "documentation": {
        "description": "Stack arrays in sequence vertically (row wise).\nThis is equivalent to concatenation along the first axis after 1-D arrays\nof shape `(N,)` have been reshaped to `(1,N)`. Rebuilds arrays divided by\n`vsplit`.\nThis function makes most sense for arrays with up to 3 dimensions. For\ninstance, for pixel-data with a height (first axis), width (second axis),\nand r/g/b channels (third axis). The functions `concatenate`, `stack` and\n`block` provide more general stacking and concatenation operations.\n``np.row_stack`` is an alias for `vstack`. They are the same function.",
        "parameters": {
          "tup": {
            "type": "sequence of ndarrays",
            "description": "The arrays must have the same shape along all but the first axis.\n1-D arrays must have the same length."
          },
          "dtype": {
            "type": "str or dtype",
            "description": "If provided, the destination array will have this dtype. Cannot be\nprovided together with `out`.\n.. versionadded:: 1.24"
          },
          "casting": {
            "type": "{'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional",
            "description": "Controls what kind of data casting may occur. Defaults to 'same_kind'.\n.. versionadded:: 1.24"
          }
        },
        "returns": "-------\nstacked : ndarray\nThe array formed by stacking the given arrays, will be at least 2-D.",
        "raises": "",
        "see_also": "--------\nconcatenate : Join a sequence of arrays along an existing axis.\nstack : Join a sequence of arrays along a new axis.\nblock : Assemble an nd-array from nested lists of blocks.\nhstack : Stack arrays in sequence horizontally (column wise).\ndstack : Stack arrays in sequence depth wise (along third axis).\ncolumn_stack : Stack 1-D arrays as columns into a 2-D array.\nvsplit : Split an array into multiple sub-arrays vertically (row-wise).",
        "notes": "",
        "examples": "--------\n>>> a = np.array([1, 2, 3])\n>>> b = np.array([4, 5, 6])\n>>> np.vstack((a,b))\narray([[1, 2, 3],\n[4, 5, 6]])\n>>> a = np.array([[1], [2], [3]])\n>>> b = np.array([[4], [5], [6]])\n>>> np.vstack((a,b))\narray([[1],\n[2],\n[3],\n[4],\n[5],\n[6]])"
      }
    },
    {
      "name": "safe_eval",
      "signature": "safe_eval(source)",
      "documentation": {
        "description": "Protected string evaluation.\nEvaluate a string containing a Python literal expression without\nallowing the execution of arbitrary non-literal code.\n.. warning::\nThis function is identical to :py:meth:`ast.literal_eval` and\nhas the same security implications.  It may not always be safe\nto evaluate large input strings.",
        "parameters": {
          "source": {
            "type": "str",
            "description": "The string to evaluate."
          }
        },
        "returns": "-------\nobj : object\nThe result of evaluating `source`.",
        "raises": "------\nSyntaxError\nIf the code has invalid Python syntax, or if it contains\nnon-literal code.",
        "see_also": "",
        "notes": "",
        "examples": "--------\n>>> np.safe_eval('1')\n1\n>>> np.safe_eval('[1, 2, 3]')\n[1, 2, 3]\n>>> np.safe_eval('{\"foo\": (\"bar\", 10.0)}')\n{'foo': ('bar', 10.0)}\n>>> np.safe_eval('import os')\nTraceback (most recent call last):\n...\nSyntaxError: invalid syntax\n>>> np.safe_eval('open(\"/home/user/.ssh/id_dsa\").read()')\nTraceback (most recent call last):\n...\nValueError: malformed node or string: <_ast.Call object at 0x...>"
      }
    },
    {
      "name": "save",
      "signature": "save(file, arr, allow_pickle=True, fix_imports=True)",
      "documentation": {
        "description": "Save an array to a binary file in NumPy ``.npy`` format.",
        "parameters": {
          "file": {
            "type": "file, str, or pathlib.Path",
            "description": "File or filename to which the data is saved.  If file is a file-object,\nthen the filename is unchanged.  If file is a string or Path, a ``.npy``\nextension will be appended to the filename if it does not already\nhave one."
          },
          "arr": {
            "type": "array_like",
            "description": "Array data to be saved."
          },
          "allow_pickle": {
            "type": "bool, optional",
            "description": "Allow saving object arrays using Python pickles. Reasons for disallowing\npickles include security (loading pickled data can execute arbitrary\ncode) and portability (pickled objects may not be loadable on different\nPython installations, for example if the stored objects require libraries\nthat are not available, and not all pickled data is compatible between\nPython 2 and Python 3)."
          },
          "Default": {
            "type": "True",
            "description": ""
          },
          "fix_imports": {
            "type": "bool, optional",
            "description": "Only useful in forcing objects in object arrays on Python 3 to be\npickled in a Python 2 compatible way. If `fix_imports` is True, pickle\nwill try to map the new Python 3 names to the old module names used in\nPython 2, so that the pickle data stream is readable with Python 2."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\nsavez : Save several arrays into a ``.npz`` archive\nsavetxt, load",
        "notes": "-----\nFor a description of the ``.npy`` format, see :py:mod:`numpy.lib.format`.\nAny data saved to the file is appended to the end of the file.",
        "examples": "--------\n>>> from tempfile import TemporaryFile\n>>> outfile = TemporaryFile()\n>>> x = np.arange(10)\n>>> np.save(outfile, x)\n>>> _ = outfile.seek(0) # Only needed here to simulate closing & reopening file\n>>> np.load(outfile)\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n>>> with open('test.npy', 'wb') as f:\n...     np.save(f, np.array([1, 2]))\n...     np.save(f, np.array([1, 3]))\n>>> with open('test.npy', 'rb') as f:\n...     a = np.load(f)\n...     b = np.load(f)\n>>> print(a, b)\n# [1 2] [1 3]"
      }
    },
    {
      "name": "savetxt",
      "signature": "savetxt(fname, X, fmt='%.18e', delimiter=' ', newline='\\n', header='', footer='', comments='# ', encoding=None)",
      "documentation": {
        "description": "Save an array to a text file.",
        "parameters": {
          "fname": {
            "type": "filename or file handle",
            "description": "If the filename ends in ``.gz``, the file is automatically saved in\ncompressed gzip format.  `loadtxt` understands gzipped files\ntransparently."
          },
          "X": {
            "type": "1D or 2D array_like",
            "description": "Data to be saved to a text file."
          },
          "fmt": {
            "type": "str or sequence of strs, optional",
            "description": "A single format (%10.5f), a sequence of formats, or a\nmulti-format string, e.g. 'Iteration %d -- %10.5f', in which\ncase `delimiter` is ignored. For complex `X`, the legal options\nfor `fmt` are:\n* a single specifier, `fmt='%.4e'`, resulting in numbers formatted\nlike `' (%s+%sj)' % (fmt, fmt)`\n* a full string specifying every real and imaginary part, e.g.\n`' %.4e %+.4ej %.4e %+.4ej %.4e %+.4ej'` for 3 columns\n* a list of specifiers, one per column - in this case, the real\nand imaginary part must have separate specifiers,\ne.g. `['%.3e + %.3ej', '(%.15e%+.15ej)']` for 2 columns"
          },
          "delimiter": {
            "type": "str, optional",
            "description": "String or character separating columns."
          },
          "newline": {
            "type": "str, optional",
            "description": "String or character separating lines.\n.. versionadded:: 1.5.0"
          },
          "header": {
            "type": "str, optional",
            "description": "String that will be written at the beginning of the file.\n.. versionadded:: 1.7.0"
          },
          "footer": {
            "type": "str, optional",
            "description": "String that will be written at the end of the file.\n.. versionadded:: 1.7.0"
          },
          "comments": {
            "type": "str, optional",
            "description": "String that will be prepended to the ``header`` and ``footer`` strings,\nto mark them as comments. Default: '# ',  as expected by e.g.\n``numpy.loadtxt``.\n.. versionadded:: 1.7.0"
          },
          "encoding": {
            "type": "{None, str}, optional",
            "description": "Encoding used to encode the outputfile. Does not apply to output\nstreams. If the encoding is something other than 'bytes' or 'latin1'\nyou will not be able to load the file in NumPy versions < 1.14. Default\nis 'latin1'.\n.. versionadded:: 1.14.0"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\nsave : Save an array to a binary file in NumPy ``.npy`` format\nsavez : Save several arrays into an uncompressed ``.npz`` archive\nsavez_compressed : Save several arrays into a compressed ``.npz`` archive",
        "notes": "-----\nFurther explanation of the `fmt` parameter\n(``%[flag]width[.precision]specifier``):\nflags:\n``-`` : left justify\n``+`` : Forces to precede result with + or -.\n``0`` : Left pad the number with zeros instead of space (see width).\nwidth:\nMinimum number of characters to be printed. The value is not truncated\nif it has more characters.\nprecision:\n- For integer specifiers (eg. ``d,i,o,x``), the minimum number of\ndigits.\n- For ``e, E`` and ``f`` specifiers, the number of digits to print\nafter the decimal point.\n- For ``g`` and ``G``, the maximum number of significant digits.\n- For ``s``, the maximum number of characters.\nspecifiers:\n``c`` : character\n``d`` or ``i`` : signed decimal integer\n``e`` or ``E`` : scientific notation with ``e`` or ``E``.\n``f`` : decimal floating point\n``g,G`` : use the shorter of ``e,E`` or ``f``\n``o`` : signed octal\n``s`` : string of characters\n``u`` : unsigned decimal integer\n``x,X`` : unsigned hexadecimal integer\nThis explanation of ``fmt`` is not complete, for an exhaustive\nspecification see [1]_.\nReferences\n----------\n.. [1] `Format Specification Mini-Language\n<https://docs.python.org/library/string.html#format-specification-mini-language>`_,\nPython Documentation.",
        "examples": "--------\n>>> x = y = z = np.arange(0.0,5.0,1.0)\n>>> np.savetxt('test.out', x, delimiter=',')   # X is an array\n>>> np.savetxt('test.out', (x,y,z))   # x,y,z equal sized 1D arrays\n>>> np.savetxt('test.out', x, fmt='%1.4e')   # use exponential notation"
      }
    },
    {
      "name": "savez",
      "signature": "savez(file, *args, **kwds)",
      "documentation": {
        "description": "Save several arrays into a single file in uncompressed ``.npz`` format.\nProvide arrays as keyword arguments to store them under the\ncorresponding name in the output file: ``savez(fn, x=x, y=y)``.\nIf arrays are specified as positional arguments, i.e., ``savez(fn,\nx, y)``, their names will be `arr_0`, `arr_1`, etc.",
        "parameters": {
          "file": {
            "type": "str or file",
            "description": "Either the filename (string) or an open file (file-like object)\nwhere the data will be saved. If file is a string or a Path, the\n``.npz`` extension will be appended to the filename if it is not\nalready there."
          },
          "args": {
            "type": "Arguments, optional",
            "description": "Arrays to save to the file. Please use keyword arguments (see\n`kwds` below) to assign names to arrays.  Arrays specified as\nargs will be named \"arr_0\", \"arr_1\", and so on."
          },
          "kwds": {
            "type": "Keyword arguments, optional",
            "description": "Arrays to save to the file. Each array will be saved to the\noutput file with its corresponding keyword name."
          }
        },
        "returns": "-------\nNone",
        "raises": "",
        "see_also": "--------\nsave : Save a single array to a binary file in NumPy format.\nsavetxt : Save an array to a file as plain text.\nsavez_compressed : Save several arrays into a compressed ``.npz`` archive",
        "notes": "-----\nThe ``.npz`` file format is a zipped archive of files named after the\nvariables they contain.  The archive is not compressed and each file\nin the archive contains one variable in ``.npy`` format. For a\ndescription of the ``.npy`` format, see :py:mod:`numpy.lib.format`.\nWhen opening the saved ``.npz`` file with `load` a `NpzFile` object is\nreturned. This is a dictionary-like object which can be queried for\nits list of arrays (with the ``.files`` attribute), and for the arrays\nthemselves.\nKeys passed in `kwds` are used as filenames inside the ZIP archive.\nTherefore, keys should be valid filenames; e.g., avoid keys that begin with\n``/`` or contain ``.``.\nWhen naming variables with keyword arguments, it is not possible to name a\nvariable ``file``, as this would cause the ``file`` argument to be defined\ntwice in the call to ``savez``.",
        "examples": "--------\n>>> from tempfile import TemporaryFile\n>>> outfile = TemporaryFile()\n>>> x = np.arange(10)\n>>> y = np.sin(x)\nUsing `savez` with \\*args, the arrays are saved with default names.\n>>> np.savez(outfile, x, y)\n>>> _ = outfile.seek(0) # Only needed here to simulate closing & reopening file\n>>> npzfile = np.load(outfile)\n>>> npzfile.files\n['arr_0', 'arr_1']\n>>> npzfile['arr_0']\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\nUsing `savez` with \\**kwds, the arrays are saved with the keyword names.\n>>> outfile = TemporaryFile()\n>>> np.savez(outfile, x=x, y=y)\n>>> _ = outfile.seek(0)\n>>> npzfile = np.load(outfile)\n>>> sorted(npzfile.files)\n['x', 'y']\n>>> npzfile['x']\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      }
    },
    {
      "name": "savez_compressed",
      "signature": "savez_compressed(file, *args, **kwds)",
      "documentation": {
        "description": "Save several arrays into a single file in compressed ``.npz`` format.\nProvide arrays as keyword arguments to store them under the\ncorresponding name in the output file: ``savez(fn, x=x, y=y)``.\nIf arrays are specified as positional arguments, i.e., ``savez(fn,\nx, y)``, their names will be `arr_0`, `arr_1`, etc.",
        "parameters": {
          "file": {
            "type": "str or file",
            "description": "Either the filename (string) or an open file (file-like object)\nwhere the data will be saved. If file is a string or a Path, the\n``.npz`` extension will be appended to the filename if it is not\nalready there."
          },
          "args": {
            "type": "Arguments, optional",
            "description": "Arrays to save to the file. Please use keyword arguments (see\n`kwds` below) to assign names to arrays.  Arrays specified as\nargs will be named \"arr_0\", \"arr_1\", and so on."
          },
          "kwds": {
            "type": "Keyword arguments, optional",
            "description": "Arrays to save to the file. Each array will be saved to the\noutput file with its corresponding keyword name."
          }
        },
        "returns": "-------\nNone",
        "raises": "",
        "see_also": "--------\nnumpy.save : Save a single array to a binary file in NumPy format.\nnumpy.savetxt : Save an array to a file as plain text.\nnumpy.savez : Save several arrays into an uncompressed ``.npz`` file format\nnumpy.load : Load the files created by savez_compressed.",
        "notes": "-----\nThe ``.npz`` file format is a zipped archive of files named after the\nvariables they contain.  The archive is compressed with\n``zipfile.ZIP_DEFLATED`` and each file in the archive contains one variable\nin ``.npy`` format. For a description of the ``.npy`` format, see\n:py:mod:`numpy.lib.format`.\nWhen opening the saved ``.npz`` file with `load` a `NpzFile` object is\nreturned. This is a dictionary-like object which can be queried for\nits list of arrays (with the ``.files`` attribute), and for the arrays\nthemselves.",
        "examples": "--------\n>>> test_array = np.random.rand(3, 2)\n>>> test_vector = np.random.rand(4)\n>>> np.savez_compressed('/tmp/123', a=test_array, b=test_vector)\n>>> loaded = np.load('/tmp/123.npz')\n>>> print(np.array_equal(test_array, loaded['a']))\nTrue\n>>> print(np.array_equal(test_vector, loaded['b']))\nTrue"
      }
    },
    {
      "name": "select",
      "signature": "select(condlist, choicelist, default=0)",
      "documentation": {
        "description": "Return an array drawn from elements in choicelist, depending on conditions.",
        "parameters": {
          "condlist": {
            "type": "list of bool ndarrays",
            "description": "The list of conditions which determine from which array in `choicelist`\nthe output elements are taken. When multiple conditions are satisfied,\nthe first one encountered in `condlist` is used."
          },
          "choicelist": {
            "type": "list of ndarrays",
            "description": "The list of arrays from which the output elements are taken. It has\nto be of the same length as `condlist`."
          },
          "default": {
            "type": "scalar, optional",
            "description": "The element inserted in `output` when all conditions evaluate to False."
          }
        },
        "returns": "-------\noutput : ndarray\nThe output at position m is the m-th element of the array in\n`choicelist` where the m-th element of the corresponding array in\n`condlist` is True.",
        "raises": "",
        "see_also": "--------\nwhere : Return elements from one of two arrays depending on condition.\ntake, choose, compress, diag, diagonal",
        "notes": "",
        "examples": "--------\n>>> x = np.arange(6)\n>>> condlist = [x<3, x>3]\n>>> choicelist = [x, x**2]\n>>> np.select(condlist, choicelist, 42)\narray([ 0,  1,  2, 42, 16, 25])\n>>> condlist = [x<=4, x>3]\n>>> choicelist = [x, x**2]\n>>> np.select(condlist, choicelist, 55)\narray([ 0,  1,  2,  3,  4, 25])"
      }
    },
    {
      "name": "setdiff1d",
      "signature": "setdiff1d(ar1, ar2, assume_unique=False)",
      "documentation": {
        "description": "Find the set difference of two arrays.\nReturn the unique values in `ar1` that are not in `ar2`.",
        "parameters": {
          "ar1": {
            "type": "array_like",
            "description": "Input array."
          },
          "ar2": {
            "type": "array_like",
            "description": "Input comparison array."
          },
          "assume_unique": {
            "type": "bool",
            "description": "If True, the input arrays are both assumed to be unique, which\ncan speed up the calculation.  Default is False."
          }
        },
        "returns": "-------\nsetdiff1d : ndarray\n1D array of values in `ar1` that are not in `ar2`. The result\nis sorted when `assume_unique=False`, but otherwise only sorted\nif the input is sorted.",
        "raises": "",
        "see_also": "--------\nnumpy.lib.arraysetops : Module with a number of other functions for\nperforming set operations on arrays.",
        "notes": "",
        "examples": "--------\n>>> a = np.array([1, 2, 3, 2, 4, 1])\n>>> b = np.array([3, 4, 5, 6])\n>>> np.setdiff1d(a, b)\narray([1, 2])"
      }
    },
    {
      "name": "setxor1d",
      "signature": "setxor1d(ar1, ar2, assume_unique=False)",
      "documentation": {
        "description": "Find the set exclusive-or of two arrays.\nReturn the sorted, unique values that are in only one (not both) of the\ninput arrays.",
        "parameters": {
          "assume_unique": {
            "type": "bool",
            "description": "If True, the input arrays are both assumed to be unique, which\ncan speed up the calculation.  Default is False."
          }
        },
        "returns": "-------\nsetxor1d : ndarray\nSorted 1D array of unique values that are in only one of the input\narrays.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n>>> a = np.array([1, 2, 3, 2, 4])\n>>> b = np.array([2, 3, 5, 7, 5])\n>>> np.setxor1d(a,b)\narray([1, 4, 5, 7])"
      }
    },
    {
      "name": "show_runtime",
      "signature": "show_runtime()",
      "documentation": {
        "description": "Print information about various resources in the system\nincluding available intrinsic support and BLAS/LAPACK library\nin use\n.. versionadded:: 1.24.0",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "--------\nshow_config : Show libraries in the system on which NumPy was built.",
        "notes": "-----\n1. Information is derived with the help of `threadpoolctl <https://pypi.org/project/threadpoolctl/>`_\nlibrary if available.\n2. SIMD related information is derived from ``__cpu_features__``,\n``__cpu_baseline__`` and ``__cpu_dispatch__``",
        "examples": ""
      }
    },
    {
      "name": "sinc",
      "signature": "sinc(x)",
      "documentation": {
        "description": "Return the normalized sinc function.\nThe sinc function is equal to :math:`\\sin(\\pi x)/(\\pi x)` for any argument\n:math:`x\\ne 0`. ``sinc(0)`` takes the limit value 1, making ``sinc`` not\nonly everywhere continuous but also infinitely differentiable.\n.. note::\nNote the normalization factor of ``pi`` used in the definition.\nThis is the most commonly used definition in signal processing.\nUse ``sinc(x / np.pi)`` to obtain the unnormalized sinc function\n:math:`\\sin(x)/x` that is more common in mathematics.",
        "parameters": {
          "x": {
            "type": "ndarray",
            "description": "Array (possibly multi-dimensional) of values for which to calculate\n``sinc(x)``."
          }
        },
        "returns": "-------\nout : ndarray\n``sinc(x)``, which has the same shape as the input.",
        "raises": "",
        "see_also": "",
        "notes": "-----\nThe name sinc is short for \"sine cardinal\" or \"sinus cardinalis\".\nThe sinc function is used in various signal processing applications,\nincluding in anti-aliasing, in the construction of a Lanczos resampling\nfilter, and in interpolation.\nFor bandlimited interpolation of discrete-time signals, the ideal\ninterpolation kernel is proportional to the sinc function.\nReferences\n----------\n.. [1] Weisstein, Eric W. \"Sinc Function.\" From MathWorld--A Wolfram Web\nResource. http://mathworld.wolfram.com/SincFunction.html\n.. [2] Wikipedia, \"Sinc function\",\nhttps://en.wikipedia.org/wiki/Sinc_function",
        "examples": "--------\n>>> import matplotlib.pyplot as plt\n>>> x = np.linspace(-4, 4, 41)\n>>> np.sinc(x)\narray([-3.89804309e-17,  -4.92362781e-02,  -8.40918587e-02, # may vary\n-8.90384387e-02,  -5.84680802e-02,   3.89804309e-17,\n6.68206631e-02,   1.16434881e-01,   1.26137788e-01,\n8.50444803e-02,  -3.89804309e-17,  -1.03943254e-01,\n-1.89206682e-01,  -2.16236208e-01,  -1.55914881e-01,\n3.89804309e-17,   2.33872321e-01,   5.04551152e-01,\n7.56826729e-01,   9.35489284e-01,   1.00000000e+00,\n9.35489284e-01,   7.56826729e-01,   5.04551152e-01,\n2.33872321e-01,   3.89804309e-17,  -1.55914881e-01,\n-2.16236208e-01,  -1.89206682e-01,  -1.03943254e-01,\n-3.89804309e-17,   8.50444803e-02,   1.26137788e-01,\n1.16434881e-01,   6.68206631e-02,   3.89804309e-17,\n-5.84680802e-02,  -8.90384387e-02,  -8.40918587e-02,\n-4.92362781e-02,  -3.89804309e-17])\n>>> plt.plot(x, np.sinc(x))\n[<matplotlib.lines.Line2D object at 0x...>]\n>>> plt.title(\"Sinc Function\")\nText(0.5, 1.0, 'Sinc Function')\n>>> plt.ylabel(\"Amplitude\")\nText(0, 0.5, 'Amplitude')\n>>> plt.xlabel(\"X\")\nText(0.5, 0, 'X')\n>>> plt.show()"
      }
    },
    {
      "name": "sort_complex",
      "signature": "sort_complex(a)",
      "documentation": {
        "description": "Sort a complex array using the real part first, then the imaginary part.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": "Input array"
          }
        },
        "returns": "-------\nout : complex ndarray\nAlways returns a sorted complex array.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n>>> np.sort_complex([5, 3, 6, 2, 1])\narray([1.+0.j, 2.+0.j, 3.+0.j, 5.+0.j, 6.+0.j])\n>>> np.sort_complex([1 + 2j, 2 - 1j, 3 - 2j, 3 - 3j, 3 + 5j])\narray([1.+2.j,  2.-1.j,  3.-3.j,  3.-2.j,  3.+5.j])"
      }
    },
    {
      "name": "source",
      "signature": "source(object, output=<_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'>)",
      "documentation": {
        "description": "Print or write to a file the source code for a NumPy object.\nThe source code is only returned for objects written in Python. Many\nfunctions and classes are defined in C and will therefore not return\nuseful information.",
        "parameters": {
          "object": {
            "type": "numpy object",
            "description": "Input object. This can be any object (function, class, module,\n...)."
          },
          "output": {
            "type": "file object, optional",
            "description": "If `output` not supplied then source code is printed to screen\n(sys.stdout).  File object must be created with either write 'w' or\nappend 'a' modes."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\nlookfor, info",
        "notes": "",
        "examples": "--------\n>>> np.source(np.interp)                        #doctest: +SKIP\nIn file: /usr/lib/python2.6/dist-packages/numpy/lib/function_base.py\ndef interp(x, xp, fp, left=None, right=None):\n\"\"\".... (full docstring printed)\"\"\"\nif isinstance(x, (float, int, number)):\nreturn compiled_interp([x], xp, fp, left, right).item()\nelse:\nreturn compiled_interp(x, xp, fp, left, right)\nThe source code is only returned for objects written in Python.\n>>> np.source(np.array)                         #doctest: +SKIP\nNot available for this object."
      }
    },
    {
      "name": "split",
      "signature": "split(ary, indices_or_sections, axis=0)",
      "documentation": {
        "description": "Split an array into multiple sub-arrays as views into `ary`.",
        "parameters": {
          "ary": {
            "type": "ndarray",
            "description": "Array to be divided into sub-arrays."
          },
          "indices_or_sections": {
            "type": "int or 1-D array",
            "description": "If `indices_or_sections` is an integer, N, the array will be divided\ninto N equal arrays along `axis`.  If such a split is not possible,\nan error is raised.\nIf `indices_or_sections` is a 1-D array of sorted integers, the entries\nindicate where along `axis` the array is split.  For example,\n``[2, 3]`` would, for ``axis=0``, result in\n- ary[:2]\n- ary[2:3]\n- ary[3:]\nIf an index exceeds the dimension of the array along `axis`,\nan empty sub-array is returned correspondingly."
          },
          "axis": {
            "type": "int, optional",
            "description": "The axis along which to split, default is 0."
          }
        },
        "returns": "-------\nsub-arrays : list of ndarrays\nA list of sub-arrays as views into `ary`.",
        "raises": "------\nValueError\nIf `indices_or_sections` is given as an integer, but\na split does not result in equal division.",
        "see_also": "--------\narray_split : Split an array into multiple sub-arrays of equal or\nnear-equal size.  Does not raise an exception if\nan equal division cannot be made.\nhsplit : Split array into multiple sub-arrays horizontally (column-wise).\nvsplit : Split array into multiple sub-arrays vertically (row wise).\ndsplit : Split array into multiple sub-arrays along the 3rd axis (depth).\nconcatenate : Join a sequence of arrays along an existing axis.\nstack : Join a sequence of arrays along a new axis.\nhstack : Stack arrays in sequence horizontally (column wise).\nvstack : Stack arrays in sequence vertically (row wise).\ndstack : Stack arrays in sequence depth wise (along third dimension).",
        "notes": "",
        "examples": "--------\n>>> x = np.arange(9.0)\n>>> np.split(x, 3)\n[array([0.,  1.,  2.]), array([3.,  4.,  5.]), array([6.,  7.,  8.])]\n>>> x = np.arange(8.0)\n>>> np.split(x, [3, 5, 6, 10])\n[array([0.,  1.,  2.]),\narray([3.,  4.]),\narray([5.]),\narray([6.,  7.]),\narray([], dtype=float64)]"
      }
    },
    {
      "name": "take_along_axis",
      "signature": "take_along_axis(arr, indices, axis)",
      "documentation": {
        "description": "Take values from the input array by matching 1d index and data slices.\nThis iterates over matching 1d slices oriented along the specified axis in\nthe index and data arrays, and uses the former to look up values in the\nlatter. These slices can be different lengths.\nFunctions returning an index along an axis, like `argsort` and\n`argpartition`, produce suitable indices for this function.\n.. versionadded:: 1.15.0",
        "parameters": {
          "arr": {
            "type": "ndarray (Ni..., M, Nk...)",
            "description": "Source array"
          },
          "indices": {
            "type": "ndarray (Ni..., J, Nk...)",
            "description": "Indices to take along each 1d slice of `arr`. This must match the\ndimension of arr, but dimensions Ni and Nj only need to broadcast\nagainst `arr`."
          },
          "axis": {
            "type": "int",
            "description": "The axis to take 1d slices along. If axis is None, the input array is\ntreated as if it had first been flattened to 1d, for consistency with\n`sort` and `argsort`."
          }
        },
        "returns": "-------\nout: ndarray (Ni..., J, Nk...)\nThe indexed result.",
        "raises": "",
        "see_also": "--------\ntake : Take along an axis, using the same indices for every 1d slice\nput_along_axis :\nPut values into the destination array by matching 1d index and data slices",
        "notes": "-----\nThis is equivalent to (but faster than) the following use of `ndindex` and\n`s_`, which sets each of ``ii`` and ``kk`` to a tuple of indices::\nNi, M, Nk = a.shape[:axis], a.shape[axis], a.shape[axis+1:]\nJ = indices.shape[axis]  # Need not equal M\nout = np.empty(Ni + (J,) + Nk)\nfor ii in ndindex(Ni):\nfor kk in ndindex(Nk):\na_1d       = a      [ii + s_[:,] + kk]\nindices_1d = indices[ii + s_[:,] + kk]\nout_1d     = out    [ii + s_[:,] + kk]\nfor j in range(J):\nout_1d[j] = a_1d[indices_1d[j]]\nEquivalently, eliminating the inner loop, the last two lines would be::\nout_1d[:] = a_1d[indices_1d]",
        "examples": "--------\nFor this sample array\n>>> a = np.array([[10, 30, 20], [60, 40, 50]])\nWe can sort either by using sort directly, or argsort and this function\n>>> np.sort(a, axis=1)\narray([[10, 20, 30],\n[40, 50, 60]])\n>>> ai = np.argsort(a, axis=1)\n>>> ai\narray([[0, 2, 1],\n[1, 2, 0]])\n>>> np.take_along_axis(a, ai, axis=1)\narray([[10, 20, 30],\n[40, 50, 60]])\nThe same works for max and min, if you maintain the trivial dimension\nwith ``keepdims``:\n>>> np.max(a, axis=1, keepdims=True)\narray([[30],\n[60]])\n>>> ai = np.argmax(a, axis=1, keepdims=True)\n>>> ai\narray([[1],\n[0]])\n>>> np.take_along_axis(a, ai, axis=1)\narray([[30],\n[60]])\nIf we want to get the max and min at the same time, we can stack the\nindices first\n>>> ai_min = np.argmin(a, axis=1, keepdims=True)\n>>> ai_max = np.argmax(a, axis=1, keepdims=True)\n>>> ai = np.concatenate([ai_min, ai_max], axis=1)\n>>> ai\narray([[0, 1],\n[1, 0]])\n>>> np.take_along_axis(a, ai, axis=1)\narray([[10, 30],\n[40, 60]])"
      }
    },
    {
      "name": "tile",
      "signature": "tile(A, reps)",
      "documentation": {
        "description": "Construct an array by repeating A the number of times given by reps.\nIf `reps` has length ``d``, the result will have dimension of\n``max(d, A.ndim)``.\nIf ``A.ndim < d``, `A` is promoted to be d-dimensional by prepending new\naxes. So a shape (3,) array is promoted to (1, 3) for 2-D replication,\nor shape (1, 1, 3) for 3-D replication. If this is not the desired\nbehavior, promote `A` to d-dimensions manually before calling this\nfunction.\nIf ``A.ndim > d``, `reps` is promoted to `A`.ndim by pre-pending 1's to it.\nThus for an `A` of shape (2, 3, 4, 5), a `reps` of (2, 2) is treated as\n(1, 1, 2, 2).\nNote : Although tile may be used for broadcasting, it is strongly\nrecommended to use numpy's broadcasting operations and functions.",
        "parameters": {
          "A": {
            "type": "array_like",
            "description": "The input array."
          },
          "reps": {
            "type": "array_like",
            "description": "The number of repetitions of `A` along each axis."
          }
        },
        "returns": "-------\nc : ndarray\nThe tiled output array.",
        "raises": "",
        "see_also": "--------\nrepeat : Repeat elements of an array.\nbroadcast_to : Broadcast an array to a new shape",
        "notes": "",
        "examples": "--------\n>>> a = np.array([0, 1, 2])\n>>> np.tile(a, 2)\narray([0, 1, 2, 0, 1, 2])\n>>> np.tile(a, (2, 2))\narray([[0, 1, 2, 0, 1, 2],\n[0, 1, 2, 0, 1, 2]])\n>>> np.tile(a, (2, 1, 2))\narray([[[0, 1, 2, 0, 1, 2]],\n[[0, 1, 2, 0, 1, 2]]])\n>>> b = np.array([[1, 2], [3, 4]])\n>>> np.tile(b, 2)\narray([[1, 2, 1, 2],\n[3, 4, 3, 4]])\n>>> np.tile(b, (2, 1))\narray([[1, 2],\n[3, 4],\n[1, 2],\n[3, 4]])\n>>> c = np.array([1,2,3,4])\n>>> np.tile(c,(4,1))\narray([[1, 2, 3, 4],\n[1, 2, 3, 4],\n[1, 2, 3, 4],\n[1, 2, 3, 4]])"
      }
    },
    {
      "name": "trapz",
      "signature": "trapz(y, x=None, dx=1.0, axis=-1)",
      "documentation": {
        "description": "Integrate along the given axis using the composite trapezoidal rule.\nIf `x` is provided, the integration happens in sequence along its\nelements - they are not sorted.\nIntegrate `y` (`x`) along each 1d slice on the given axis, compute\n:math:`\\int y(x) dx`.\nWhen `x` is specified, this integrates along the parametric curve,\ncomputing :math:`\\int_t y(t) dt =\n\\int_t y(t) \\left.\\frac{dx}{dt}\\right|_{x=x(t)} dt`.",
        "parameters": {
          "y": {
            "type": "array_like",
            "description": "Input array to integrate."
          },
          "x": {
            "type": "array_like, optional",
            "description": "The sample points corresponding to the `y` values. If `x` is None,\nthe sample points are assumed to be evenly spaced `dx` apart. The\ndefault is None."
          },
          "dx": {
            "type": "scalar, optional",
            "description": "The spacing between sample points when `x` is None. The default is 1."
          },
          "axis": {
            "type": "int, optional",
            "description": "The axis along which to integrate."
          }
        },
        "returns": "-------\ntrapz : float or ndarray\nDefinite integral of `y` = n-dimensional array as approximated along\na single axis by the trapezoidal rule. If `y` is a 1-dimensional array,\nthen the result is a float. If `n` is greater than 1, then the result\nis an `n`-1 dimensional array.",
        "raises": "",
        "see_also": "--------\nsum, cumsum",
        "notes": "-----\nImage [2]_ illustrates trapezoidal rule -- y-axis locations of points\nwill be taken from `y` array, by default x-axis distances between\npoints will be 1.0, alternatively they can be provided with `x` array\nor with `dx` scalar.  Return value will be equal to combined area under\nthe red lines.\nReferences\n----------\n.. [1] Wikipedia page: https://en.wikipedia.org/wiki/Trapezoidal_rule\n.. [2] Illustration image:\nhttps://en.wikipedia.org/wiki/File:Composite_trapezoidal_rule_illustration.png",
        "examples": "--------\nUse the trapezoidal rule on evenly spaced points:\n>>> np.trapz([1, 2, 3])\n4.0\nThe spacing between sample points can be selected by either the\n``x`` or ``dx`` arguments:\n>>> np.trapz([1, 2, 3], x=[4, 6, 8])\n8.0\n>>> np.trapz([1, 2, 3], dx=2)\n8.0\nUsing a decreasing ``x`` corresponds to integrating in reverse:\n>>> np.trapz([1, 2, 3], x=[8, 6, 4])\n-8.0\nMore generally ``x`` is used to integrate along a parametric curve. We can\nestimate the integral :math:`\\int_0^1 x^2 = 1/3` using:\n>>> x = np.linspace(0, 1, num=50)\n>>> y = x**2\n>>> np.trapz(y, x)\n0.33340274885464394\nOr estimate the area of a circle, noting we repeat the sample which closes\nthe curve:\n>>> theta = np.linspace(0, 2 * np.pi, num=1000, endpoint=True)\n>>> np.trapz(np.cos(theta), x=np.sin(theta))\n3.141571941375841\n``np.trapz`` can be applied along a specified axis to do multiple\ncomputations in one call:\n>>> a = np.arange(6).reshape(2, 3)\n>>> a\narray([[0, 1, 2],\n[3, 4, 5]])\n>>> np.trapz(a, axis=0)\narray([1.5, 2.5, 3.5])\n>>> np.trapz(a, axis=1)\narray([2.,  8.])"
      }
    },
    {
      "name": "tri",
      "signature": "tri(N, M=None, k=0, dtype=<class 'float'>, *, like=None)",
      "documentation": {
        "description": "An array with ones at and below the given diagonal and zeros elsewhere.",
        "parameters": {
          "N": {
            "type": "int",
            "description": "Number of rows in the array."
          },
          "M": {
            "type": "int, optional",
            "description": "Number of columns in the array.\nBy default, `M` is taken equal to `N`."
          },
          "k": {
            "type": "int, optional",
            "description": "The sub-diagonal at and below which the array is filled.\n`k` = 0 is the main diagonal, while `k` < 0 is below it,\nand `k` > 0 is above.  The default is 0."
          },
          "dtype": {
            "type": "dtype, optional",
            "description": "Data type of the returned array.  The default is float."
          },
          "like": {
            "type": "array_like, optional",
            "description": "Reference object to allow the creation of arrays which are not\nNumPy arrays. If an array-like passed in as ``like`` supports\nthe ``__array_function__`` protocol, the result will be defined\nby it. In this case, it ensures the creation of an array object\ncompatible with that passed in via this argument.\n.. versionadded:: 1.20.0"
          }
        },
        "returns": "-------\ntri : ndarray of shape (N, M)\nArray with its lower triangle filled with ones and zero elsewhere;\nin other words ``T[i,j] == 1`` for ``j <= i + k``, 0 otherwise.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n>>> np.tri(3, 5, 2, dtype=int)\narray([[1, 1, 1, 0, 0],\n[1, 1, 1, 1, 0],\n[1, 1, 1, 1, 1]])\n>>> np.tri(3, 5, -1)\narray([[0.,  0.,  0.,  0.,  0.],\n[1.,  0.,  0.,  0.,  0.],\n[1.,  1.,  0.,  0.,  0.]])"
      }
    },
    {
      "name": "tril",
      "signature": "tril(m, k=0)",
      "documentation": {
        "description": "Lower triangle of an array.\nReturn a copy of an array with elements above the `k`-th diagonal zeroed.\nFor arrays with ``ndim`` exceeding 2, `tril` will apply to the final two\naxes.",
        "parameters": {
          "m": {
            "type": "array_like, shape (..., M, N)",
            "description": "Input array."
          },
          "k": {
            "type": "int, optional",
            "description": "Diagonal above which to zero elements.  `k = 0` (the default) is the\nmain diagonal, `k < 0` is below it and `k > 0` is above."
          }
        },
        "returns": "-------\ntril : ndarray, shape (..., M, N)\nLower triangle of `m`, of same shape and data-type as `m`.",
        "raises": "",
        "see_also": "--------\ntriu : same thing, only for the upper triangle",
        "notes": "",
        "examples": "--------\n>>> np.tril([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], -1)\narray([[ 0,  0,  0],\n[ 4,  0,  0],\n[ 7,  8,  0],\n[10, 11, 12]])\n>>> np.tril(np.arange(3*4*5).reshape(3, 4, 5))\narray([[[ 0,  0,  0,  0,  0],\n[ 5,  6,  0,  0,  0],\n[10, 11, 12,  0,  0],\n[15, 16, 17, 18,  0]],\n[[20,  0,  0,  0,  0],\n[25, 26,  0,  0,  0],\n[30, 31, 32,  0,  0],\n[35, 36, 37, 38,  0]],\n[[40,  0,  0,  0,  0],\n[45, 46,  0,  0,  0],\n[50, 51, 52,  0,  0],\n[55, 56, 57, 58,  0]]])"
      }
    },
    {
      "name": "tril_indices",
      "signature": "tril_indices(n, k=0, m=None)",
      "documentation": {
        "description": "Return the indices for the lower-triangle of an (n, m) array.",
        "parameters": {
          "n": {
            "type": "int",
            "description": "The row dimension of the arrays for which the returned\nindices will be valid."
          },
          "k": {
            "type": "int, optional",
            "description": "Diagonal offset (see `tril` for details)."
          },
          "m": {
            "type": "int, optional",
            "description": ".. versionadded:: 1.9.0\nThe column dimension of the arrays for which the returned\narrays will be valid.\nBy default `m` is taken equal to `n`."
          }
        },
        "returns": "-------\ninds : tuple of arrays\nThe indices for the triangle. The returned tuple contains two arrays,\neach with the indices along one dimension of the array.\nSee also\n--------\ntriu_indices : similar function, for upper-triangular.\nmask_indices : generic function accepting an arbitrary mask function.\ntril, triu",
        "raises": "",
        "see_also": "",
        "notes": "-----\n.. versionadded:: 1.4.0",
        "examples": "--------\nCompute two different sets of indices to access 4x4 arrays, one for the\nlower triangular part starting at the main diagonal, and one starting two\ndiagonals further right:\n>>> il1 = np.tril_indices(4)\n>>> il2 = np.tril_indices(4, 2)\nHere is how they can be used with a sample array:\n>>> a = np.arange(16).reshape(4, 4)\n>>> a\narray([[ 0,  1,  2,  3],\n[ 4,  5,  6,  7],\n[ 8,  9, 10, 11],\n[12, 13, 14, 15]])\nBoth for indexing:\n>>> a[il1]\narray([ 0,  4,  5, ..., 13, 14, 15])\nAnd for assigning values:\n>>> a[il1] = -1\n>>> a\narray([[-1,  1,  2,  3],\n[-1, -1,  6,  7],\n[-1, -1, -1, 11],\n[-1, -1, -1, -1]])\nThese cover almost the whole array (two diagonals right of the main one):\n>>> a[il2] = -10\n>>> a\narray([[-10, -10, -10,   3],\n[-10, -10, -10, -10],\n[-10, -10, -10, -10],\n[-10, -10, -10, -10]])"
      }
    },
    {
      "name": "tril_indices_from",
      "signature": "tril_indices_from(arr, k=0)",
      "documentation": {
        "description": "Return the indices for the lower-triangle of arr.\nSee `tril_indices` for full details.",
        "parameters": {
          "arr": {
            "type": "array_like",
            "description": "The indices will be valid for square arrays whose dimensions are\nthe same as arr."
          },
          "k": {
            "type": "int, optional",
            "description": "Diagonal offset (see `tril` for details)."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\ntril_indices, tril, triu_indices_from",
        "notes": "-----\n.. versionadded:: 1.4.0",
        "examples": "--------\nCreate a 4 by 4 array.\n>>> a = np.arange(16).reshape(4, 4)\n>>> a\narray([[ 0,  1,  2,  3],\n[ 4,  5,  6,  7],\n[ 8,  9, 10, 11],\n[12, 13, 14, 15]])\nPass the array to get the indices of the lower triangular elements.\n>>> trili = np.tril_indices_from(a)\n>>> trili\n(array([0, 1, 1, 2, 2, 2, 3, 3, 3, 3]), array([0, 0, 1, 0, 1, 2, 0, 1, 2, 3]))\n>>> a[trili]\narray([ 0,  4,  5,  8,  9, 10, 12, 13, 14, 15])\nThis is syntactic sugar for tril_indices().\n>>> np.tril_indices(a.shape[0])\n(array([0, 1, 1, 2, 2, 2, 3, 3, 3, 3]), array([0, 0, 1, 0, 1, 2, 0, 1, 2, 3]))\nUse the `k` parameter to return the indices for the lower triangular array\nup to the k-th diagonal.\n>>> trili1 = np.tril_indices_from(a, k=1)\n>>> a[trili1]\narray([ 0,  1,  4,  5,  6,  8,  9, 10, 11, 12, 13, 14, 15])"
      }
    },
    {
      "name": "trim_zeros",
      "signature": "trim_zeros(filt, trim='fb')",
      "documentation": {
        "description": "Trim the leading and/or trailing zeros from a 1-D array or sequence.",
        "parameters": {
          "filt": {
            "type": "1-D array or sequence",
            "description": "Input array."
          },
          "trim": {
            "type": "str, optional",
            "description": "A string with 'f' representing trim from front and 'b' to trim from\nback. Default is 'fb', trim zeros from both front and back of the\narray."
          }
        },
        "returns": "-------\ntrimmed : 1-D array or sequence\nThe result of trimming the input. The input data type is preserved.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n>>> a = np.array((0, 0, 0, 1, 2, 3, 0, 2, 1, 0))\n>>> np.trim_zeros(a)\narray([1, 2, 3, 0, 2, 1])\n>>> np.trim_zeros(a, 'b')\narray([0, 0, 0, ..., 0, 2, 1])\nThe input data type is preserved, list/tuple in means list/tuple out.\n>>> np.trim_zeros([0, 1, 2, 0])\n[1, 2]"
      }
    },
    {
      "name": "triu",
      "signature": "triu(m, k=0)",
      "documentation": {
        "description": "Upper triangle of an array.\nReturn a copy of an array with the elements below the `k`-th diagonal\nzeroed. For arrays with ``ndim`` exceeding 2, `triu` will apply to the\nfinal two axes.\nPlease refer to the documentation for `tril` for further details.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "--------\ntril : lower triangle of an array",
        "notes": "",
        "examples": "--------\n>>> np.triu([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], -1)\narray([[ 1,  2,  3],\n[ 4,  5,  6],\n[ 0,  8,  9],\n[ 0,  0, 12]])\n>>> np.triu(np.arange(3*4*5).reshape(3, 4, 5))\narray([[[ 0,  1,  2,  3,  4],\n[ 0,  6,  7,  8,  9],\n[ 0,  0, 12, 13, 14],\n[ 0,  0,  0, 18, 19]],\n[[20, 21, 22, 23, 24],\n[ 0, 26, 27, 28, 29],\n[ 0,  0, 32, 33, 34],\n[ 0,  0,  0, 38, 39]],\n[[40, 41, 42, 43, 44],\n[ 0, 46, 47, 48, 49],\n[ 0,  0, 52, 53, 54],\n[ 0,  0,  0, 58, 59]]])"
      }
    },
    {
      "name": "triu_indices",
      "signature": "triu_indices(n, k=0, m=None)",
      "documentation": {
        "description": "Return the indices for the upper-triangle of an (n, m) array.",
        "parameters": {
          "n": {
            "type": "int",
            "description": "The size of the arrays for which the returned indices will\nbe valid."
          },
          "k": {
            "type": "int, optional",
            "description": "Diagonal offset (see `triu` for details)."
          },
          "m": {
            "type": "int, optional",
            "description": ".. versionadded:: 1.9.0\nThe column dimension of the arrays for which the returned\narrays will be valid.\nBy default `m` is taken equal to `n`."
          }
        },
        "returns": "-------\ninds : tuple, shape(2) of ndarrays, shape(`n`)\nThe indices for the triangle. The returned tuple contains two arrays,\neach with the indices along one dimension of the array.  Can be used\nto slice a ndarray of shape(`n`, `n`).\nSee also\n--------\ntril_indices : similar function, for lower-triangular.\nmask_indices : generic function accepting an arbitrary mask function.\ntriu, tril",
        "raises": "",
        "see_also": "",
        "notes": "-----\n.. versionadded:: 1.4.0",
        "examples": "--------\nCompute two different sets of indices to access 4x4 arrays, one for the\nupper triangular part starting at the main diagonal, and one starting two\ndiagonals further right:\n>>> iu1 = np.triu_indices(4)\n>>> iu2 = np.triu_indices(4, 2)\nHere is how they can be used with a sample array:\n>>> a = np.arange(16).reshape(4, 4)\n>>> a\narray([[ 0,  1,  2,  3],\n[ 4,  5,  6,  7],\n[ 8,  9, 10, 11],\n[12, 13, 14, 15]])\nBoth for indexing:\n>>> a[iu1]\narray([ 0,  1,  2, ..., 10, 11, 15])\nAnd for assigning values:\n>>> a[iu1] = -1\n>>> a\narray([[-1, -1, -1, -1],\n[ 4, -1, -1, -1],\n[ 8,  9, -1, -1],\n[12, 13, 14, -1]])\nThese cover only a small part of the whole array (two diagonals right\nof the main one):\n>>> a[iu2] = -10\n>>> a\narray([[ -1,  -1, -10, -10],\n[  4,  -1,  -1, -10],\n[  8,   9,  -1,  -1],\n[ 12,  13,  14,  -1]])"
      }
    },
    {
      "name": "triu_indices_from",
      "signature": "triu_indices_from(arr, k=0)",
      "documentation": {
        "description": "Return the indices for the upper-triangle of arr.\nSee `triu_indices` for full details.",
        "parameters": {
          "arr": {
            "type": "ndarray, shape(N, N)",
            "description": "The indices will be valid for square arrays."
          },
          "k": {
            "type": "int, optional",
            "description": "Diagonal offset (see `triu` for details)."
          }
        },
        "returns": "-------\ntriu_indices_from : tuple, shape(2) of ndarray, shape(N)\nIndices for the upper-triangle of `arr`.",
        "raises": "",
        "see_also": "--------\ntriu_indices, triu, tril_indices_from",
        "notes": "-----\n.. versionadded:: 1.4.0",
        "examples": "--------\nCreate a 4 by 4 array.\n>>> a = np.arange(16).reshape(4, 4)\n>>> a\narray([[ 0,  1,  2,  3],\n[ 4,  5,  6,  7],\n[ 8,  9, 10, 11],\n[12, 13, 14, 15]])\nPass the array to get the indices of the upper triangular elements.\n>>> triui = np.triu_indices_from(a)\n>>> triui\n(array([0, 0, 0, 0, 1, 1, 1, 2, 2, 3]), array([0, 1, 2, 3, 1, 2, 3, 2, 3, 3]))\n>>> a[triui]\narray([ 0,  1,  2,  3,  5,  6,  7, 10, 11, 15])\nThis is syntactic sugar for triu_indices().\n>>> np.triu_indices(a.shape[0])\n(array([0, 0, 0, 0, 1, 1, 1, 2, 2, 3]), array([0, 1, 2, 3, 1, 2, 3, 2, 3, 3]))\nUse the `k` parameter to return the indices for the upper triangular array\nfrom the k-th diagonal.\n>>> triuim1 = np.triu_indices_from(a, k=1)\n>>> a[triuim1]\narray([ 1,  2,  3,  6,  7, 11])"
      }
    },
    {
      "name": "typename",
      "signature": "typename(char)",
      "documentation": {
        "description": "Return a description for the given data type code.",
        "parameters": {
          "char": {
            "type": "str",
            "description": "Data type code."
          }
        },
        "returns": "-------\nout : str\nDescription of the input data type code.",
        "raises": "",
        "see_also": "--------\ndtype, typecodes",
        "notes": "",
        "examples": "--------\n>>> typechars = ['S1', '?', 'B', 'D', 'G', 'F', 'I', 'H', 'L', 'O', 'Q',\n...              'S', 'U', 'V', 'b', 'd', 'g', 'f', 'i', 'h', 'l', 'q']\n>>> for typechar in typechars:\n...     print(typechar, ' : ', np.typename(typechar))\n...\nS1  :  character\n?  :  bool\nB  :  unsigned char\nD  :  complex double precision\nG  :  complex long double precision\nF  :  complex single precision\nI  :  unsigned integer\nH  :  unsigned short\nL  :  unsigned long integer\nO  :  object\nQ  :  unsigned long long integer\nS  :  string\nU  :  unicode\nV  :  void\nb  :  signed char\nd  :  double precision\ng  :  long precision\nf  :  single precision\ni  :  integer\nh  :  short\nl  :  long integer\nq  :  long long integer"
      }
    },
    {
      "name": "union1d",
      "signature": "union1d(ar1, ar2)",
      "documentation": {
        "description": "Find the union of two arrays.\nReturn the unique, sorted array of values that are in either of the two\ninput arrays.",
        "parameters": {},
        "returns": "-------\nunion1d : ndarray\nUnique, sorted union of the input arrays.",
        "raises": "",
        "see_also": "--------\nnumpy.lib.arraysetops : Module with a number of other functions for\nperforming set operations on arrays.",
        "notes": "",
        "examples": "--------\n>>> np.union1d([-1, 0, 1], [-2, 0, 2])\narray([-2, -1,  0,  1,  2])\nTo find the union of more than two arrays, use functools.reduce:\n>>> from functools import reduce\n>>> reduce(np.union1d, ([1, 3, 4, 3], [3, 1, 2, 1], [6, 3, 4, 2]))\narray([1, 2, 3, 4, 6])"
      }
    },
    {
      "name": "unique",
      "signature": "unique(ar, return_index=False, return_inverse=False, return_counts=False, axis=None, *, equal_nan=True)",
      "documentation": {
        "description": "Find the unique elements of an array.",
        "parameters": {
          "ar": {
            "type": "array_like",
            "description": "Input array. Unless `axis` is specified, this will be flattened if it\nis not already 1-D."
          },
          "return_index": {
            "type": "bool, optional",
            "description": "If True, also return the indices of `ar` (along the specified axis,\nif provided, or in the flattened array) that result in the unique array."
          },
          "return_inverse": {
            "type": "bool, optional",
            "description": "If True, also return the indices of the unique array (for the specified\naxis, if provided) that can be used to reconstruct `ar`."
          },
          "return_counts": {
            "type": "bool, optional",
            "description": "If True, also return the number of times each unique item appears\nin `ar`."
          },
          "axis": {
            "type": "int or None, optional",
            "description": "The axis to operate on. If None, `ar` will be flattened. If an integer,\nthe subarrays indexed by the given axis will be flattened and treated\nas the elements of a 1-D array with the dimension of the given axis,\nsee the notes for more details.  Object arrays or structured arrays\nthat contain objects are not supported if the `axis` kwarg is used. The\ndefault is None.\n.. versionadded:: 1.13.0"
          },
          "equal_nan": {
            "type": "bool, optional",
            "description": "If True, collapses multiple NaN values in the return array into one.\n.. versionadded:: 1.24"
          }
        },
        "returns": "outputs in addition to the unique elements:\n* the indices of the input array that give the unique values\n* the indices of the unique array that reconstruct the input array\n* the number of times each unique value comes up in the input array\n-------\nunique : ndarray\nThe sorted unique values.\nunique_indices : ndarray, optional\nThe indices of the first occurrences of the unique values in the\noriginal array. Only provided if `return_index` is True.\nunique_inverse : ndarray, optional\nThe indices to reconstruct the original array from the\nunique array. Only provided if `return_inverse` is True.\nunique_counts : ndarray, optional\nThe number of times each of the unique values comes up in the\noriginal array. Only provided if `return_counts` is True.\n.. versionadded:: 1.9.0",
        "raises": "",
        "see_also": "--------\nnumpy.lib.arraysetops : Module with a number of other functions for\nperforming set operations on arrays.\nrepeat : Repeat elements of an array.",
        "notes": "-----\nWhen an axis is specified the subarrays indexed by the axis are sorted.\nThis is done by making the specified axis the first dimension of the array\n(move the axis to the first dimension to keep the order of the other axes)\nand then flattening the subarrays in C order. The flattened subarrays are\nthen viewed as a structured type with each element given a label, with the\neffect that we end up with a 1-D array of structured types that can be\ntreated in the same way as any other 1-D array. The result is that the\nflattened subarrays are sorted in lexicographic order starting with the\nfirst element.\n.. versionchanged: NumPy 1.21\nIf nan values are in the input array, a single nan is put\nto the end of the sorted unique values.\nAlso for complex arrays all NaN values are considered equivalent\n(no matter whether the NaN is in the real or imaginary part).\nAs the representant for the returned array the smallest one in the\nlexicographical order is chosen - see np.sort for how the lexicographical\norder is defined for complex arrays.",
        "examples": "--------\n>>> np.unique([1, 1, 2, 2, 3, 3])\narray([1, 2, 3])\n>>> a = np.array([[1, 1], [2, 3]])\n>>> np.unique(a)\narray([1, 2, 3])\nReturn the unique rows of a 2D array\n>>> a = np.array([[1, 0, 0], [1, 0, 0], [2, 3, 4]])\n>>> np.unique(a, axis=0)\narray([[1, 0, 0], [2, 3, 4]])\nReturn the indices of the original array that give the unique values:\n>>> a = np.array(['a', 'b', 'b', 'c', 'a'])\n>>> u, indices = np.unique(a, return_index=True)\n>>> u\narray(['a', 'b', 'c'], dtype='<U1')\n>>> indices\narray([0, 1, 3])\n>>> a[indices]\narray(['a', 'b', 'c'], dtype='<U1')\nReconstruct the input array from the unique values and inverse:\n>>> a = np.array([1, 2, 6, 4, 2, 3, 2])\n>>> u, indices = np.unique(a, return_inverse=True)\n>>> u\narray([1, 2, 3, 4, 6])\n>>> indices\narray([0, 1, 4, 3, 1, 2, 1])\n>>> u[indices]\narray([1, 2, 6, 4, 2, 3, 2])\nReconstruct the input values from the unique values and counts:\n>>> a = np.array([1, 2, 6, 4, 2, 3, 2])\n>>> values, counts = np.unique(a, return_counts=True)\n>>> values\narray([1, 2, 3, 4, 6])\n>>> counts\narray([1, 3, 1, 1, 1])\n>>> np.repeat(values, counts)\narray([1, 2, 2, 2, 3, 4, 6])    # original order not preserved"
      }
    },
    {
      "name": "unpackbits",
      "signature": "unpackbits(a, /, axis=None, count=None, bitorder='big')",
      "documentation": {
        "description": "unpackbits(a, /, axis=None, count=None, bitorder='big')\nUnpacks elements of a uint8 array into a binary-valued output array.\nEach element of `a` represents a bit-field that should be unpacked\ninto a binary-valued output array. The shape of the output array is\neither 1-D (if `axis` is ``None``) or the same shape as the input\narray with unpacking done along the axis specified.",
        "parameters": {
          "a": {
            "type": "ndarray, uint8 type",
            "description": "Input array."
          },
          "axis": {
            "type": "int, optional",
            "description": "The dimension over which bit-unpacking is done.\n``None`` implies unpacking the flattened array."
          },
          "count": {
            "type": "int or None, optional",
            "description": "The number of elements to unpack along `axis`, provided as a way\nof undoing the effect of packing a size that is not a multiple\nof eight. A non-negative number means to only unpack `count`\nbits. A negative number means to trim off that many bits from\nthe end. ``None`` means to unpack the entire array (the\ndefault). Counts larger than the available number of bits will\nadd zero padding to the output. Negative counts must not\nexceed the available number of bits.\n.. versionadded:: 1.17.0"
          },
          "bitorder": {
            "type": "{'big', 'little'}, optional",
            "description": "The order of the returned bits. 'big' will mimic bin(val),\n``3 = 0b00000011 => [0, 0, 0, 0, 0, 0, 1, 1]``, 'little' will reverse\nthe order to ``[1, 1, 0, 0, 0, 0, 0, 0]``.\nDefaults to 'big'.\n.. versionadded:: 1.17.0"
          }
        },
        "returns": "-------\nunpacked : ndarray, uint8 type\nThe elements are binary-valued (0 or 1).",
        "raises": "",
        "see_also": "--------\npackbits : Packs the elements of a binary-valued array into bits in\na uint8 array.",
        "notes": "",
        "examples": "--------\n>>> a = np.array([[2], [7], [23]], dtype=np.uint8)\n>>> a\narray([[ 2],\n[ 7],\n[23]], dtype=uint8)\n>>> b = np.unpackbits(a, axis=1)\n>>> b\narray([[0, 0, 0, 0, 0, 0, 1, 0],\n[0, 0, 0, 0, 0, 1, 1, 1],\n[0, 0, 0, 1, 0, 1, 1, 1]], dtype=uint8)\n>>> c = np.unpackbits(a, axis=1, count=-3)\n>>> c\narray([[0, 0, 0, 0, 0],\n[0, 0, 0, 0, 0],\n[0, 0, 0, 1, 0]], dtype=uint8)\n>>> p = np.packbits(b, axis=0)\n>>> np.unpackbits(p, axis=0)\narray([[0, 0, 0, 0, 0, 0, 1, 0],\n[0, 0, 0, 0, 0, 1, 1, 1],\n[0, 0, 0, 1, 0, 1, 1, 1],\n[0, 0, 0, 0, 0, 0, 0, 0],\n[0, 0, 0, 0, 0, 0, 0, 0],\n[0, 0, 0, 0, 0, 0, 0, 0],\n[0, 0, 0, 0, 0, 0, 0, 0],\n[0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)\n>>> np.array_equal(b, np.unpackbits(p, axis=0, count=b.shape[0]))\nTrue"
      }
    },
    {
      "name": "unravel_index",
      "signature": "unravel_index(indices, shape, order='C')",
      "documentation": {
        "description": "unravel_index(indices, shape, order='C')\nConverts a flat index or array of flat indices into a tuple\nof coordinate arrays.",
        "parameters": {
          "indices": {
            "type": "array_like",
            "description": "An integer array whose elements are indices into the flattened\nversion of an array of dimensions ``shape``. Before version 1.6.0,\nthis function accepted just one index value."
          },
          "shape": {
            "type": "tuple of ints",
            "description": "The shape of the array to use for unraveling ``indices``.\n.. versionchanged:: 1.16.0\nRenamed from ``dims`` to ``shape``."
          },
          "order": {
            "type": "{'C', 'F'}, optional",
            "description": "Determines whether the indices should be viewed as indexing in\nrow-major (C-style) or column-major (Fortran-style) order.\n.. versionadded:: 1.6.0"
          }
        },
        "returns": "-------\nunraveled_coords : tuple of ndarray\nEach array in the tuple has the same shape as the ``indices``\narray.",
        "raises": "",
        "see_also": "--------\nravel_multi_index",
        "notes": "",
        "examples": "--------\n>>> np.unravel_index([22, 41, 37], (7,6))\n(array([3, 6, 6]), array([4, 5, 1]))\n>>> np.unravel_index([31, 41, 13], (7,6), order='F')\n(array([3, 6, 6]), array([4, 5, 1]))\n>>> np.unravel_index(1621, (6,7,8,9))\n(3, 1, 4, 1)"
      }
    },
    {
      "name": "unwrap",
      "signature": "unwrap(p, discont=None, axis=-1, *, period=6.283185307179586)",
      "documentation": {
        "description": "Unwrap by taking the complement of large deltas with respect to the period.\nThis unwraps a signal `p` by changing elements which have an absolute\ndifference from their predecessor of more than ``max(discont, period/2)``\nto their `period`-complementary values.\nFor the default case where `period` is :math:`2\\pi` and `discont` is\n:math:`\\pi`, this unwraps a radian phase `p` such that adjacent differences\nare never greater than :math:`\\pi` by adding :math:`2k\\pi` for some\ninteger :math:`k`.",
        "parameters": {
          "p": {
            "type": "array_like",
            "description": "Input array."
          },
          "discont": {
            "type": "float, optional",
            "description": "Maximum discontinuity between values, default is ``period/2``.\nValues below ``period/2`` are treated as if they were ``period/2``.\nTo have an effect different from the default, `discont` should be\nlarger than ``period/2``."
          },
          "axis": {
            "type": "int, optional",
            "description": "Axis along which unwrap will operate, default is the last axis."
          },
          "period": {
            "type": "float, optional",
            "description": "Size of the range over which the input wraps. By default, it is\n``2 pi``.\n.. versionadded:: 1.21.0"
          }
        },
        "returns": "-------\nout : ndarray\nOutput array.",
        "raises": "",
        "see_also": "--------\nrad2deg, deg2rad",
        "notes": "-----\nIf the discontinuity in `p` is smaller than ``period/2``,\nbut larger than `discont`, no unwrapping is done because taking\nthe complement would only make the discontinuity larger.",
        "examples": "--------\n>>> phase = np.linspace(0, np.pi, num=5)\n>>> phase[3:] += np.pi\n>>> phase\narray([ 0.        ,  0.78539816,  1.57079633,  5.49778714,  6.28318531]) # may vary\n>>> np.unwrap(phase)\narray([ 0.        ,  0.78539816,  1.57079633, -0.78539816,  0.        ]) # may vary\n>>> np.unwrap([0, 1, 2, -1, 0], period=4)\narray([0, 1, 2, 3, 4])\n>>> np.unwrap([ 1, 2, 3, 4, 5, 6, 1, 2, 3], period=6)\narray([1, 2, 3, 4, 5, 6, 7, 8, 9])\n>>> np.unwrap([2, 3, 4, 5, 2, 3, 4, 5], period=4)\narray([2, 3, 4, 5, 6, 7, 8, 9])\n>>> phase_deg = np.mod(np.linspace(0 ,720, 19), 360) - 180\n>>> np.unwrap(phase_deg, period=360)\narray([-180., -140., -100.,  -60.,  -20.,   20.,   60.,  100.,  140.,\n180.,  220.,  260.,  300.,  340.,  380.,  420.,  460.,  500.,\n540.])"
      }
    },
    {
      "name": "vander",
      "signature": "vander(x, N=None, increasing=False)",
      "documentation": {
        "description": "Generate a Vandermonde matrix.\nThe columns of the output matrix are powers of the input vector. The\norder of the powers is determined by the `increasing` boolean argument.\nSpecifically, when `increasing` is False, the `i`-th output column is\nthe input vector raised element-wise to the power of ``N - i - 1``. Such\na matrix with a geometric progression in each row is named for Alexandre-\nTheophile Vandermonde.",
        "parameters": {
          "x": {
            "type": "array_like",
            "description": "1-D input array."
          },
          "N": {
            "type": "int, optional",
            "description": "Number of columns in the output.  If `N` is not specified, a square\narray is returned (``N = len(x)``)."
          },
          "increasing": {
            "type": "bool, optional",
            "description": "Order of the powers of the columns.  If True, the powers increase\nfrom left to right, if False (the default) they are reversed.\n.. versionadded:: 1.9.0"
          }
        },
        "returns": "-------\nout : ndarray\nVandermonde matrix.  If `increasing` is False, the first column is\n``x^(N-1)``, the second ``x^(N-2)`` and so forth. If `increasing` is\nTrue, the columns are ``x^0, x^1, ..., x^(N-1)``.",
        "raises": "",
        "see_also": "--------\npolynomial.polynomial.polyvander",
        "notes": "",
        "examples": "--------\n>>> x = np.array([1, 2, 3, 5])\n>>> N = 3\n>>> np.vander(x, N)\narray([[ 1,  1,  1],\n[ 4,  2,  1],\n[ 9,  3,  1],\n[25,  5,  1]])\n>>> np.column_stack([x**(N-1-i) for i in range(N)])\narray([[ 1,  1,  1],\n[ 4,  2,  1],\n[ 9,  3,  1],\n[25,  5,  1]])\n>>> x = np.array([1, 2, 3, 5])\n>>> np.vander(x)\narray([[  1,   1,   1,   1],\n[  8,   4,   2,   1],\n[ 27,   9,   3,   1],\n[125,  25,   5,   1]])\n>>> np.vander(x, increasing=True)\narray([[  1,   1,   1,   1],\n[  1,   2,   4,   8],\n[  1,   3,   9,  27],\n[  1,   5,  25, 125]])\nThe determinant of a square Vandermonde matrix is the product\nof the differences between the values of the input vector:\n>>> np.linalg.det(np.vander(x))\n48.000000000000043 # may vary\n>>> (5-3)*(5-2)*(5-1)*(3-2)*(3-1)*(2-1)\n48"
      }
    },
    {
      "name": "vsplit",
      "signature": "vsplit(ary, indices_or_sections)",
      "documentation": {
        "description": "Split an array into multiple sub-arrays vertically (row-wise).\nPlease refer to the ``split`` documentation.  ``vsplit`` is equivalent\nto ``split`` with `axis=0` (default), the array is always split along the\nfirst axis regardless of the array dimension.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "--------\nsplit : Split an array into multiple sub-arrays of equal size.",
        "notes": "",
        "examples": "--------\n>>> x = np.arange(16.0).reshape(4, 4)\n>>> x\narray([[ 0.,   1.,   2.,   3.],\n[ 4.,   5.,   6.,   7.],\n[ 8.,   9.,  10.,  11.],\n[12.,  13.,  14.,  15.]])\n>>> np.vsplit(x, 2)\n[array([[0., 1., 2., 3.],\n[4., 5., 6., 7.]]), array([[ 8.,  9., 10., 11.],\n[12., 13., 14., 15.]])]\n>>> np.vsplit(x, np.array([3, 6]))\n[array([[ 0.,  1.,  2.,  3.],\n[ 4.,  5.,  6.,  7.],\n[ 8.,  9., 10., 11.]]), array([[12., 13., 14., 15.]]), array([], shape=(0, 4), dtype=float64)]\nWith a higher dimensional array the split is still along the first axis.\n>>> x = np.arange(8.0).reshape(2, 2, 2)\n>>> x\narray([[[0.,  1.],\n[2.,  3.]],\n[[4.,  5.],\n[6.,  7.]]])\n>>> np.vsplit(x, 2)\n[array([[[0., 1.],\n[2., 3.]]]), array([[[4., 5.],\n[6., 7.]]])]"
      }
    },
    {
      "name": "who",
      "signature": "who(vardict=None)",
      "documentation": {
        "description": "Print the NumPy arrays in the given dictionary.\nIf there is no dictionary passed in or `vardict` is None then returns\nNumPy arrays in the globals() dictionary (all NumPy arrays in the\nnamespace).",
        "parameters": {
          "vardict": {
            "type": "dict, optional",
            "description": "A dictionary possibly containing ndarrays.  Default is globals()."
          }
        },
        "returns": "-------\nout : None",
        "raises": "",
        "see_also": "",
        "notes": "-----\nPrints out the name, shape, bytes and type of all of the ndarrays\npresent in `vardict`.",
        "examples": "--------\n>>> a = np.arange(10)\n>>> b = np.ones(20)\n>>> np.who()\nName            Shape            Bytes            Type\n===========================================================\na               10               80               int64\nb               20               160              float64\nUpper bound on total bytes  =       240\n>>> d = {'x': np.arange(2.0), 'y': np.arange(3.0), 'txt': 'Some str',\n... 'idx':5}\n>>> np.who(d)\nName            Shape            Bytes            Type\n===========================================================\nx               2                16               float64\ny               3                24               float64\nUpper bound on total bytes  =       40"
      }
    }
  ],
  "classes": [
    {
      "name": "Arrayterator",
      "documentation": {
        "description": "Buffered iterator for big arrays.\n`Arrayterator` creates a buffered iterator for reading big arrays in small\ncontiguous blocks. The class is useful for objects stored in the\nfile system. It allows iteration over the object *without* reading\neverything in memory; instead, small blocks are read and iterated over.\n`Arrayterator` can be used with any object that supports multidimensional\nslices. This includes NumPy arrays, but also variables from\nScientific.IO.NetCDF or pynetcdf for example.",
        "parameters": {
          "var": {
            "type": "array_like",
            "description": "The object to iterate over."
          },
          "buf_size": {
            "type": "int, optional",
            "description": "The buffer size. If `buf_size` is supplied, the maximum amount of\ndata that will be read into memory is `buf_size` elements.\nDefault is None, which will read as many element as possible\ninto memory.\nAttributes\n----------\nvar\nbuf_size\nstart\nstop\nstep\nshape\nflat"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\nndenumerate : Multidimensional array iterator.\nflatiter : Flat array iterator.\nmemmap : Create a memory-map to an array stored in a binary file on disk.",
        "notes": "-----\nThe algorithm works by first finding a \"running dimension\", along which\nthe blocks will be extracted. Given an array of dimensions\n``(d1, d2, ..., dn)``, e.g. if `buf_size` is smaller than ``d1``, the\nfirst dimension will be used. If, on the other hand,\n``d1 < buf_size < d1*d2`` the second dimension will be used, and so on.\nBlocks are extracted along this dimension, and when the last block is\nreturned the process continues from the next dimension, until all\nelements have been read.",
        "examples": "--------\n>>> a = np.arange(3 * 4 * 5 * 6).reshape(3, 4, 5, 6)\n>>> a_itor = np.lib.Arrayterator(a, 2)\n>>> a_itor.shape\n(3, 4, 5, 6)\nNow we can iterate over ``a_itor``, and it will return arrays of size\ntwo. Since `buf_size` was smaller than any dimension, the first\ndimension will be iterated over first:\n>>> for subarr in a_itor:\n...     if not subarr.all():\n...         print(subarr, subarr.shape) # doctest: +SKIP\n>>> # [[[[0 1]]]] (1, 1, 1, 2)"
      },
      "methods": []
    },
    {
      "name": "DataSource",
      "documentation": {
        "description": "DataSource(destpath='.')\nA generic data source file (file, http, ftp, ...).\nDataSources can be local files or remote files/URLs.  The files may\nalso be compressed or uncompressed. DataSource hides some of the\nlow-level details of downloading the file, allowing you to simply pass\nin a valid file path (or URL) and obtain a file object.",
        "parameters": {
          "destpath": {
            "type": "str or None, optional",
            "description": "Path to the directory where the source file gets downloaded to for\nuse.  If `destpath` is None, a temporary directory will be created.\nThe default path is the current directory."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "-----\nURLs require a scheme string (``http://``) to be used, without it they\nwill fail::\n>>> repos = np.DataSource()\n>>> repos.exists('www.google.com/index.html')\nFalse\n>>> repos.exists('http://www.google.com/index.html')\nTrue\nTemporary directories are deleted when the DataSource is deleted.",
        "examples": "--------\n::\n>>> ds = np.DataSource('/home/guido')\n>>> urlname = 'http://www.google.com/'\n>>> gfile = ds.open('http://www.google.com/')\n>>> ds.abspath(urlname)\n'/home/guido/www.google.com/index.html'\n>>> ds = np.DataSource(None)  # use with temporary file\n>>> ds.open('/home/guido/foobar.txt')\n<open file '/home/guido.foobar.txt', mode 'r' at 0x91d4430>\n>>> ds.abspath('/home/guido/foobar.txt')\n'/tmp/.../home/guido/foobar.txt'"
      },
      "methods": [
        {
          "name": "abspath",
          "signature": "abspath(self, path)",
          "documentation": {
            "description": "Return absolute path of file in the DataSource directory.\nIf `path` is an URL, then `abspath` will return either the location\nthe file exists locally or the location it would exist when opened\nusing the `open` method.",
            "parameters": {
              "path": {
                "type": "str",
                "description": "Can be a local file or a remote URL."
              }
            },
            "returns": "-------\nout : str\nComplete path, including the `DataSource` destination directory.",
            "raises": "",
            "see_also": "",
            "notes": "-----\nThe functionality is based on `os.path.abspath`.",
            "examples": ""
          }
        },
        {
          "name": "exists",
          "signature": "exists(self, path)",
          "documentation": {
            "description": "Test if path exists.\nTest if `path` exists as (and in this order):\n- a local file.\n- a remote URL that has been downloaded and stored locally in the\n`DataSource` directory.\n- a remote URL that has not been downloaded, but is valid and\naccessible.",
            "parameters": {
              "path": {
                "type": "str",
                "description": "Can be a local file or a remote URL."
              }
            },
            "returns": "-------\nout : bool\nTrue if `path` exists.",
            "raises": "",
            "see_also": "",
            "notes": "-----\nWhen `path` is an URL, `exists` will return True if it's either\nstored locally in the `DataSource` directory, or is a valid remote\nURL.  `DataSource` does not discriminate between the two, the file\nis accessible if it exists in either location.",
            "examples": ""
          }
        },
        {
          "name": "open",
          "signature": "open(self, path, mode='r', encoding=None, newline=None)",
          "documentation": {
            "description": "Open and return file-like object.\nIf `path` is an URL, it will be downloaded, stored in the\n`DataSource` directory and opened from there.",
            "parameters": {
              "path": {
                "type": "str",
                "description": "Local file path or URL to open."
              },
              "mode": {
                "type": "{'r', 'w', 'a'}, optional",
                "description": "Mode to open `path`.  Mode 'r' for reading, 'w' for writing,\n'a' to append. Available modes depend on the type of object\nspecified by `path`. Default is 'r'."
              },
              "encoding": {
                "type": "{None, str}, optional",
                "description": "Open text file with given encoding. The default encoding will be\nwhat `io.open` uses."
              },
              "newline": {
                "type": "{None, str}, optional",
                "description": "Newline to use when reading text file."
              }
            },
            "returns": "-------\nout : file object\nFile object.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "NumpyVersion",
      "documentation": {
        "description": "Parse and compare numpy version strings.\nNumPy has the following versioning scheme (numbers given are examples; they\ncan be > 9 in principle):\n- Released version: '1.8.0', '1.8.1', etc.\n- Alpha: '1.8.0a1', '1.8.0a2', etc.\n- Beta: '1.8.0b1', '1.8.0b2', etc.\n- Release candidates: '1.8.0rc1', '1.8.0rc2', etc.\n- Development versions: '1.8.0.dev-f1234afa' (git commit hash appended)\n- Development versions after a1: '1.8.0a1.dev-f1234afa',\n'1.8.0b2.dev-f1234afa',\n'1.8.1rc1.dev-f1234afa', etc.\n- Development versions (no git hash available): '1.8.0.dev-Unknown'\nComparing needs to be done against a valid version string or other\n`NumpyVersion` instance. Note that all development versions of the same\n(pre-)release compare equal.\n.. versionadded:: 1.9.0",
        "parameters": {
          "vstring": {
            "type": "str",
            "description": "NumPy version string (``np.__version__``)."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n>>> from numpy.lib import NumpyVersion\n>>> if NumpyVersion(np.__version__) < '1.7.0':\n...     print('skip')\n>>> # skip\n>>> NumpyVersion('1.7')  # raises ValueError, add \".0\"\nTraceback (most recent call last):\n...\nValueError: Not a valid numpy version string"
      },
      "methods": []
    },
    {
      "name": "RankWarning",
      "documentation": {
        "description": "Issued by `polyfit` when the Vandermonde matrix is rank deficient.\nFor more information, a way to suppress the warning, and an example of\n`RankWarning` being issued, see `polyfit`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "add_note",
          "signature": "add_note(...)",
          "documentation": {
            "description": "Exception.add_note(note) --\nadd a note to the exception",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_traceback",
          "signature": "with_traceback(...)",
          "documentation": {
            "description": "Exception.with_traceback(tb) --\nset self.__traceback__ to tb and return self.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "ndenumerate",
      "documentation": {
        "description": "Multidimensional index iterator.\nReturn an iterator yielding pairs of array coordinates and values.",
        "parameters": {
          "arr": {
            "type": "ndarray",
            "description": "Input array."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\nndindex, flatiter",
        "notes": "",
        "examples": "--------\n>>> a = np.array([[1, 2], [3, 4]])\n>>> for index, x in np.ndenumerate(a):\n...     print(index, x)\n(0, 0) 1\n(0, 1) 2\n(1, 0) 3\n(1, 1) 4"
      },
      "methods": []
    },
    {
      "name": "ndindex",
      "documentation": {
        "description": "An N-dimensional iterator object to index arrays.\nGiven the shape of an array, an `ndindex` instance iterates over\nthe N-dimensional index of the array. At each iteration a tuple\nof indices is returned, the last dimension is iterated over first.",
        "parameters": {
          "shape": {
            "type": "ints, or a single tuple of ints",
            "description": "The size of each dimension of the array can be passed as\nindividual parameters or as the elements of a tuple."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\nndenumerate, flatiter",
        "notes": "",
        "examples": "--------\nDimensions as individual arguments\n>>> for index in np.ndindex(3, 2, 1):\n...     print(index)\n(0, 0, 0)\n(0, 1, 0)\n(1, 0, 0)\n(1, 1, 0)\n(2, 0, 0)\n(2, 1, 0)\nSame dimensions - but in a tuple ``(3, 2, 1)``\n>>> for index in np.ndindex((3, 2, 1)):\n...     print(index)\n(0, 0, 0)\n(0, 1, 0)\n(1, 0, 0)\n(1, 1, 0)\n(2, 0, 0)\n(2, 1, 0)"
      },
      "methods": [
        {
          "name": "ndincr",
          "signature": "ndincr(self)",
          "documentation": {
            "description": "Increment the multi-dimensional index by one.\nThis method is for backward compatibility only: do not use.\n.. deprecated:: 1.20.0\nThis method has been advised against since numpy 1.8.0, but only\nstarted emitting DeprecationWarning as of this version.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "poly1d",
      "documentation": {
        "description": "A one-dimensional polynomial class.\n.. note::\nThis forms part of the old polynomial API. Since version 1.4, the\nnew polynomial API defined in `numpy.polynomial` is preferred.\nA summary of the differences can be found in the\n:doc:`transition guide </reference/routines.polynomials>`.\nA convenience class, used to encapsulate \"natural\" operations on\npolynomials so that said operations may take on their customary\nform in code (see Examples).",
        "parameters": {
          "c_or_r": {
            "type": "array_like",
            "description": "The polynomial's coefficients, in decreasing powers, or if\nthe value of the second parameter is True, the polynomial's\nroots (values where the polynomial evaluates to 0).  For example,\n``poly1d([1, 2, 3])`` returns an object that represents\n:math:`x^2 + 2x + 3`, whereas ``poly1d([1, 2, 3], True)`` returns\none that represents :math:`(x-1)(x-2)(x-3) = x^3 - 6x^2 + 11x -6`."
          },
          "r": {
            "type": "bool, optional",
            "description": "If True, `c_or_r` specifies the polynomial's roots; the default\nis False."
          },
          "variable": {
            "type": "str, optional",
            "description": "Changes the variable used when printing `p` from `x` to `variable`\n(see Examples)."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\nConstruct the polynomial :math:`x^2 + 2x + 3`:\n>>> p = np.poly1d([1, 2, 3])\n>>> print(np.poly1d(p))\n2\n1 x + 2 x + 3\nEvaluate the polynomial at :math:`x = 0.5`:\n>>> p(0.5)\n4.25\nFind the roots:\n>>> p.r\narray([-1.+1.41421356j, -1.-1.41421356j])\n>>> p(p.r)\narray([ -4.44089210e-16+0.j,  -4.44089210e-16+0.j]) # may vary\nThese numbers in the previous line represent (0, 0) to machine precision\nShow the coefficients:\n>>> p.c\narray([1, 2, 3])\nDisplay the order (the leading zero-coefficients are removed):\n>>> p.order\n2\nShow the coefficient of the k-th power in the polynomial\n(which is equivalent to ``p.c[-(i+1)]``):\n>>> p[1]\n2\nPolynomials can be added, subtracted, multiplied, and divided\n(returns quotient and remainder):\n>>> p * p\npoly1d([ 1,  4, 10, 12,  9])\n>>> (p**3 + 4) / p\n(poly1d([ 1.,  4., 10., 12.,  9.]), poly1d([4.]))\n``asarray(p)`` gives the coefficient array, so polynomials can be\nused in all functions that accept arrays:\n>>> p**2 # square of polynomial\npoly1d([ 1,  4, 10, 12,  9])\n>>> np.square(p) # square of individual coefficients\narray([1, 4, 9])\nThe variable used in the string representation of `p` can be modified,\nusing the `variable` parameter:\n>>> p = np.poly1d([1,2,3], variable='z')\n>>> print(p)\n2\n1 z + 2 z + 3\nConstruct a polynomial from its roots:\n>>> np.poly1d([1, 2], True)\npoly1d([ 1., -3.,  2.])\nThis is the same polynomial as obtained by:\n>>> np.poly1d([1, -1]) * np.poly1d([1, -2])\npoly1d([ 1, -3,  2])"
      },
      "methods": [
        {
          "name": "deriv",
          "signature": "deriv(self, m=1)",
          "documentation": {
            "description": "Return a derivative of this polynomial.\nRefer to `polyder` for full documentation.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "--------\npolyder : equivalent function",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "integ",
          "signature": "integ(self, m=1, k=0)",
          "documentation": {
            "description": "Return an antiderivative (indefinite integral) of this polynomial.\nRefer to `polyint` for full documentation.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "--------\npolyint : equivalent function",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "vectorize",
      "documentation": {
        "description": "vectorize(pyfunc=np._NoValue, otypes=None, doc=None, excluded=None,\ncache=False, signature=None)",
        "parameters": {
          "pyfunc": {
            "type": "callable, optional",
            "description": "A python function or method.\nCan be omitted to produce a decorator with keyword arguments."
          },
          "otypes": {
            "type": "str or list of dtypes, optional",
            "description": "The output data type. It must be specified as either a string of\ntypecode characters or a list of data type specifiers. There should\nbe one data type specifier for each output."
          },
          "doc": {
            "type": "str, optional",
            "description": "The docstring for the function. If None, the docstring will be the\n``pyfunc.__doc__``."
          },
          "excluded": {
            "type": "set, optional",
            "description": "Set of strings or integers representing the positional or keyword\narguments for which the function will not be vectorized.  These will be\npassed directly to `pyfunc` unmodified.\n.. versionadded:: 1.7.0"
          },
          "cache": {
            "type": "bool, optional",
            "description": "If `True`, then cache the first function call that determines the number\nof outputs if `otypes` is not provided.\n.. versionadded:: 1.7.0"
          },
          "signature": {
            "type": "string, optional",
            "description": "Generalized universal function signature, e.g., ``(m,n),(n)->(m)`` for\nvectorized matrix-vector multiplication. If provided, ``pyfunc`` will\nbe called with (and expected to return) arrays with shapes given by the\nsize of corresponding core dimensions. By default, ``pyfunc`` is\nassumed to take scalars as input and output.\n.. versionadded:: 1.12.0"
          }
        },
        "returns": "Define a vectorized function which takes a nested sequence of objects or\nnumpy arrays as inputs and returns a single numpy array or a tuple of numpy\narrays. The vectorized function evaluates `pyfunc` over successive tuples\nof the input arrays like the python map function, except it uses the\nbroadcasting rules of numpy.\nThe data type of the output of `vectorized` is determined by calling\nthe function with the first element of the input.  This can be avoided\nby specifying the `otypes` argument.\n-------\nout : callable\nA vectorized function if ``pyfunc`` was provided,\na decorator otherwise.",
        "raises": "",
        "see_also": "--------\nfrompyfunc : Takes an arbitrary Python function and returns a ufunc",
        "notes": "-----\nThe `vectorize` function is provided primarily for convenience, not for\nperformance. The implementation is essentially a for loop.\nIf `otypes` is not specified, then a call to the function with the\nfirst argument will be used to determine the number of outputs.  The\nresults of this call will be cached if `cache` is `True` to prevent\ncalling the function twice.  However, to implement the cache, the\noriginal function must be wrapped which will slow down subsequent\ncalls, so only do this if your function is expensive.\nThe new keyword argument interface and `excluded` argument support\nfurther degrades performance.\nReferences\n----------\n.. [1] :doc:`/reference/c-api/generalized-ufuncs`",
        "examples": "--------\n>>> def myfunc(a, b):\n...     \"Return a-b if a>b, otherwise return a+b\"\n...     if a > b:\n...         return a - b\n...     else:\n...         return a + b\n>>> vfunc = np.vectorize(myfunc)\n>>> vfunc([1, 2, 3, 4], 2)\narray([3, 4, 1, 2])\nThe docstring is taken from the input function to `vectorize` unless it\nis specified:\n>>> vfunc.__doc__\n'Return a-b if a>b, otherwise return a+b'\n>>> vfunc = np.vectorize(myfunc, doc='Vectorized `myfunc`')\n>>> vfunc.__doc__\n'Vectorized `myfunc`'\nThe output type is determined by evaluating the first element of the input,\nunless it is specified:\n>>> out = vfunc([1, 2, 3, 4], 2)\n>>> type(out[0])\n<class 'numpy.int64'>\n>>> vfunc = np.vectorize(myfunc, otypes=[float])\n>>> out = vfunc([1, 2, 3, 4], 2)\n>>> type(out[0])\n<class 'numpy.float64'>\nThe `excluded` argument can be used to prevent vectorizing over certain\narguments.  This can be useful for array-like arguments of a fixed length\nsuch as the coefficients for a polynomial as in `polyval`:\n>>> def mypolyval(p, x):\n...     _p = list(p)\n...     res = _p.pop(0)\n...     while _p:\n...         res = res*x + _p.pop(0)\n...     return res\n>>> vpolyval = np.vectorize(mypolyval, excluded=['p'])\n>>> vpolyval(p=[1, 2, 3], x=[0, 1])\narray([3, 6])\nPositional arguments may also be excluded by specifying their position:\n>>> vpolyval.excluded.add(0)\n>>> vpolyval([1, 2, 3], x=[0, 1])\narray([3, 6])\nThe `signature` argument allows for vectorizing functions that act on\nnon-scalar arrays of fixed length. For example, you can use it for a\nvectorized calculation of Pearson correlation coefficient and its p-value:\n>>> import scipy.stats\n>>> pearsonr = np.vectorize(scipy.stats.pearsonr,\n...                 signature='(n),(n)->(),()')\n>>> pearsonr([[0, 1, 2, 3]], [[1, 2, 3, 4], [4, 3, 2, 1]])\n(array([ 1., -1.]), array([ 0.,  0.]))\nOr for a vectorized convolution:\n>>> convolve = np.vectorize(np.convolve, signature='(n),(m)->(k)')\n>>> convolve(np.eye(4), [1, 2, 1])\narray([[1., 2., 1., 0., 0., 0.],\n[0., 1., 2., 1., 0., 0.],\n[0., 0., 1., 2., 1., 0.],\n[0., 0., 0., 1., 2., 1.]])\nDecorator syntax is supported.  The decorator can be called as\na function to provide keyword arguments.\n>>>@np.vectorize\n...def identity(x):\n...    return x\n...\n>>>identity([0, 1, 2])\narray([0, 1, 2])\n>>>@np.vectorize(otypes=[float])\n...def as_float(x):\n...    return x\n...\n>>>as_float([0, 1, 2])\narray([0., 1., 2.])"
      },
      "methods": []
    }
  ]
}