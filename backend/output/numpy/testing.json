{
  "description": "Common test support for all numpy test scripts.\n\nThis single module should provide all the common functionality for numpy tests\nin a single location, so that test scripts can just import it and work right\naway.",
  "functions": [
    {
      "name": "assert_",
      "signature": "assert_(val, msg='')",
      "documentation": {
        "description": "Assert that works in release mode.\n    Accepts callable msg to allow deferring evaluation until failure.\n\n    The Python built-in ``assert`` does not work when executing code in\n    optimized mode (the ``-O`` flag) - no byte-code is generated for it.\n\n    For documentation on usage, refer to the Python documentation.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "assert_allclose",
      "signature": "assert_allclose(actual, desired, rtol=1e-07, atol=0, equal_nan=True, err_msg='', verbose=True)",
      "documentation": {
        "description": "Raises an AssertionError if two objects are not equal up to desired\n    tolerance.\n\n    Given two array_like objects, check that their shapes and all elements\n    are equal (but see the Notes for the special handling of a scalar). An\n    exception is raised if the shapes mismatch or any values conflict. In\n    contrast to the standard usage in numpy, NaNs are compared like numbers,\n    no assertion is raised if both objects have NaNs in the same positions.\n\n    The test is equivalent to ``allclose(actual, desired, rtol, atol)`` (note\n    that ``allclose`` has different default values). It compares the difference\n    between `actual` and `desired` to ``atol + rtol * abs(desired)``.\n\n    .. versionadded:: 1.5.0",
        "parameters": {
          "desired": {
            "type": "array_like",
            "description": "Array desired."
          },
          "rtol": {
            "type": "float",
            "description": "Relative tolerance."
          },
          "atol": {
            "type": "float",
            "description": "Absolute tolerance."
          },
          "equal_nan": {
            "type": "bool",
            "description": ".\n        If True, NaNs will compare equal."
          },
          "err_msg": {
            "type": "str",
            "description": "The error message to be printed in case of failure."
          },
          "verbose": {
            "type": "bool",
            "description": "If True, the conflicting values are appended to the error message."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "assert_almost_equal",
      "signature": "assert_almost_equal(actual, desired, decimal=7, err_msg='', verbose=True)",
      "documentation": {
        "description": "Raises an AssertionError if two items are not equal up to desired\n    precision.\n\n    .. note:: It is recommended to use one of `assert_allclose`,\n              `assert_array_almost_equal_nulp` or `assert_array_max_ulp`\n              instead of this function for more consistent floating point\n              comparisons.\n\n    The test verifies that the elements of `actual` and `desired` satisfy.\n\n        ``abs(desired-actual) < float64(1.5 * 10**(-decimal))``\n\n    That is a looser test than originally documented, but agrees with what the\n    actual implementation in `assert_array_almost_equal` did up to rounding\n    vagaries. An exception is raised at conflicting values. For ndarrays this\n    delegates to assert_array_almost_equal",
        "parameters": {
          "desired": {
            "type": "array_like",
            "description": "The expected object."
          },
          "decimal": {
            "type": "int",
            "description": "Desired precision, default is 7."
          },
          "err_msg": {
            "type": "str",
            "description": "The error message to be printed in case of failure."
          },
          "verbose": {
            "type": "bool",
            "description": "If True, the conflicting values are appended to the error message."
          },
          "AssertionError": {
            "type": "Arrays are not almost equal to 9 decimals",
            "description": "<BLANKLINE>\n    Mismatched elements: 1 / 2 (50%)\n    Max absolute difference: 6.66669964e-09\n    Max relative difference: 2.85715698e-09"
          },
          "ACTUAL": {
            "type": "2.3333333333333",
            "description": ""
          },
          "DESIRED": {
            "type": "2.33333334",
            "description": ">>> assert_almost_equal(np.array([1.0,2.3333333333333]),\n    ...                     np.array([1.0,2.33333334]), decimal=9)\n    Traceback (most recent call last):\n        ..."
          },
          "x": {
            "type": "array([1.",
            "description": ", 2.333333333])"
          },
          "y": {
            "type": "array([1.",
            "description": ", 2.33333334])"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "assert_approx_equal",
      "signature": "assert_approx_equal(actual, desired, significant=7, err_msg='', verbose=True)",
      "documentation": {
        "description": "Raises an AssertionError if two items are not equal up to significant\n    digits.\n\n    .. note:: It is recommended to use one of `assert_allclose`,\n              `assert_array_almost_equal_nulp` or `assert_array_max_ulp`\n              instead of this function for more consistent floating point\n              comparisons.\n\n    Given two numbers, check that they are approximately equal.\n    Approximately equal is defined as the number of significant digits\n    that agree.",
        "parameters": {
          "desired": {
            "type": "scalar",
            "description": "The expected object."
          },
          "significant": {
            "type": "int",
            "description": "Desired precision, default is 7."
          },
          "err_msg": {
            "type": "str",
            "description": "The error message to be printed in case of failure."
          },
          "verbose": {
            "type": "bool",
            "description": "If True, the conflicting values are appended to the error message."
          },
          "AssertionError": {
            "type": "Items are not equal to 8 significant digits:",
            "description": ""
          },
          "ACTUAL": {
            "type": "1.234567e-21",
            "description": ""
          },
          "DESIRED": {
            "type": "1.2345672e-21",
            "description": "the evaluated condition that raises the exception is\n\n    >>> abs(0.12345670e-20/1e-21 - 0.12345672e-20/1e-21) >= 10**-(8-1)\n    True"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "assert_array_almost_equal",
      "signature": "assert_array_almost_equal(x, y, decimal=6, err_msg='', verbose=True)",
      "documentation": {
        "description": "Raises an AssertionError if two objects are not equal up to desired\n    precision.\n\n    .. note:: It is recommended to use one of `assert_allclose`,\n              `assert_array_almost_equal_nulp` or `assert_array_max_ulp`\n              instead of this function for more consistent floating point\n              comparisons.\n\n    The test verifies identical shapes and that the elements of ``actual`` and\n    ``desired`` satisfy.\n\n        ``abs(desired-actual) < 1.5 * 10**(-decimal)``\n\n    That is a looser test than originally documented, but agrees with what the\n    actual implementation did up to rounding vagaries. An exception is raised\n    at shape mismatch or conflicting values. In contrast to the standard usage\n    in numpy, NaNs are compared like numbers, no assertion is raised if both\n    objects have NaNs in the same positions.",
        "parameters": {
          "y": {
            "type": "array([1.",
            "description": ", 2.33333, 5.     ])"
          },
          "decimal": {
            "type": "int",
            "description": "Desired precision, default is 6."
          },
          "err_msg": {
            "type": "str",
            "description": "The error message to be printed in case of failure."
          },
          "verbose": {
            "type": "bool",
            "description": "If True, the conflicting values are appended to the error message."
          },
          "AssertionError": {
            "type": "Arrays are not almost equal to 5 decimals",
            "description": "<BLANKLINE>\n    x and y nan location mismatch:"
          },
          "x": {
            "type": "array([1.",
            "description": ", 2.33333,     nan])"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "assert_array_almost_equal_nulp",
      "signature": "assert_array_almost_equal_nulp(x, y, nulp=1)",
      "documentation": {
        "description": "Compare two arrays relatively to their spacing.\n\n    This is a relatively robust method to compare two arrays whose amplitude\n    is variable.",
        "parameters": {
          "nulp": {
            "type": "int",
            "description": "The maximum number of unit in the last place for tolerance (see Notes).\n        Default is 1."
          },
          "spacing": {
            "type": "Return the distance between x and the nearest adjacent number.",
            "description": ""
          },
          "AssertionError": {
            "type": "X and Y are not equal to 1 ULP (max is 2)",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "assert_array_compare",
      "signature": "assert_array_compare(comparison, x, y, err_msg='', verbose=True, header='', precision=6, equal_nan=True, equal_inf=True, *, strict=False)",
      "documentation": {
        "description": "",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "assert_array_equal",
      "signature": "assert_array_equal(x, y, err_msg='', verbose=True, *, strict=False)",
      "documentation": {
        "description": "Raises an AssertionError if two array_like objects are not equal.\n\n    Given two array_like objects, check that the shape is equal and all\n    elements of these objects are equal (but see the Notes for the special\n    handling of a scalar). An exception is raised at shape mismatch or\n    conflicting values. In contrast to the standard usage in numpy, NaNs\n    are compared like numbers, no assertion is raised if both objects have\n    NaNs in the same positions.\n\n    The usual caution for verifying equality with floating point numbers is\n    advised.",
        "parameters": {
          "y": {
            "type": "array([2.",
            "description": ", 2., 2.], dtype=float32)"
          },
          "err_msg": {
            "type": "str",
            "description": "The error message to be printed in case of failure."
          },
          "verbose": {
            "type": "bool",
            "description": "If True, the conflicting values are appended to the error message."
          },
          "strict": {
            "type": "bool",
            "description": "If True, raise an AssertionError when either the shape or the data\n        type of the array_like objects does not match. The special\n        handling for scalars mentioned in the Notes section is disabled.\n\n        .. versionadded:: 1.24.0"
          },
          "AssertionError": {
            "type": "Arrays are not equal",
            "description": "<BLANKLINE>\n    (dtypes int64, float32 mismatch)"
          },
          "x": {
            "type": "array([2",
            "description": ", 2, 2])"
          },
          "array": {
            "type": ">>> np.testing.assert_array_equal(x",
            "description": ", 3, strict=True)\n    Traceback (most recent call last):\n        ..."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "assert_array_less",
      "signature": "assert_array_less(x, y, err_msg='', verbose=True)",
      "documentation": {
        "description": "Raises an AssertionError if two array_like objects are not ordered by less\n    than.\n\n    Given two array_like objects, check that the shape is equal and all\n    elements of the first object are strictly smaller than those of the\n    second object. An exception is raised at shape mismatch or incorrectly\n    ordered values. Shape mismatch does not raise if an object has zero\n    dimension. In contrast to the standard usage in numpy, NaNs are\n    compared, no assertion is raised if both objects have NaNs in the same\n    positions.",
        "parameters": {
          "y": {
            "type": "array([4])",
            "description": ""
          },
          "err_msg": {
            "type": "string",
            "description": "The error message to be printed in case of failure."
          },
          "verbose": {
            "type": "bool",
            "description": "If True, the conflicting values are appended to the error message."
          },
          "assert_array_almost_equal": {
            "type": "test objects for equality up to precision",
            "description": ""
          },
          "AssertionError": {
            "type": "Arrays are not less-ordered",
            "description": "<BLANKLINE>\n    (shapes (3,), (1,) mismatch)"
          },
          "x": {
            "type": "array([1.",
            "description": ", 2., 3.])"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "assert_array_max_ulp",
      "signature": "assert_array_max_ulp(a, b, maxulp=1, dtype=None)",
      "documentation": {
        "description": "Check that all items of arrays differ in at most N Units in the Last Place.",
        "parameters": {
          "maxulp": {
            "type": "int",
            "description": "The maximum number of units in the last place that elements of `a` and\n        `b` can differ. Default is 1."
          },
          "dtype": {
            "type": "dtype",
            "description": "Data-type to convert `a` and `b` to if given. Default is None."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "assert_equal",
      "signature": "assert_equal(actual, desired, err_msg='', verbose=True)",
      "documentation": {
        "description": "Raises an AssertionError if two objects are not equal.\n\n    Given two objects (scalars, lists, tuples, dictionaries or numpy arrays),\n    check that all elements of these objects are equal. An exception is raised\n    at the first conflicting values.\n\n    When one of `actual` and `desired` is a scalar and the other is array_like,\n    the function checks that each element of the array_like object is equal to\n    the scalar.\n\n    This function handles NaN comparisons as if NaN was a \"normal\" number.\n    That is, AssertionError is not raised if both objects have NaNs in the same\n    positions.  This is in contrast to the IEEE standard on NaNs, which says\n    that NaN compared to anything must return False.",
        "parameters": {
          "desired": {
            "type": "array_like",
            "description": "The expected object."
          },
          "err_msg": {
            "type": "str",
            "description": "The error message to be printed in case of failure."
          },
          "verbose": {
            "type": "bool",
            "description": "If True, the conflicting values are appended to the error message."
          },
          "AssertionError": {
            "type": "Items are not equal:",
            "description": "item=1"
          },
          "ACTUAL": {
            "type": "5",
            "description": ""
          },
          "DESIRED": {
            "type": "6",
            "description": "The following comparison does not raise an exception.  There are NaNs\n    in the inputs, but they are in the same positions.\n\n    >>> np.testing.assert_equal(np.array([1.0, 2.0, np.nan]), [1, 2, np.nan])"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "assert_no_gc_cycles",
      "signature": "assert_no_gc_cycles(*args, **kwargs)",
      "documentation": {
        "description": "Fail if the given callable produces any reference cycles.\n\n    If called with all arguments omitted, may be used as a context manager:\n\n        with assert_no_gc_cycles():\n            do_something()\n\n    .. versionadded:: 1.15.0",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "assert_no_warnings",
      "signature": "assert_no_warnings(*args, **kwargs)",
      "documentation": {
        "description": "Fail if the given callable produces any warnings.\n\n    If called with all arguments omitted, may be used as a context manager:\n\n        with assert_no_warnings():\n            do_something()\n\n    The ability to be used as a context manager is new in NumPy v1.11.0.\n\n    .. versionadded:: 1.7.0",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "assert_raises",
      "signature": "assert_raises(*args, **kwargs)",
      "documentation": {
        "description": "assert_raises(exception_class, callable, *args, **kwargs)\n    assert_raises(exception_class)\n\n    Fail unless an exception of class exception_class is thrown\n    by callable when invoked with arguments args and keyword\n    arguments kwargs. If a different type of exception is\n    thrown, it will not be caught, and the test case will be\n    deemed to have suffered an error, exactly as for an\n    unexpected exception.\n\n    Alternatively, `assert_raises` can be used as a context manager:\n\n    >>> from numpy.testing import assert_raises\n    >>> with assert_raises(ZeroDivisionError):\n    ...     1 / 0\n\n    is equivalent to\n\n    >>> def div(x, y):\n    ...     return x / y\n    >>> assert_raises(ZeroDivisionError, div, 1, 0)",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "assert_raises_regex",
      "signature": "assert_raises_regex(exception_class, expected_regexp, *args, **kwargs)",
      "documentation": {
        "description": "assert_raises_regex(exception_class, expected_regexp, callable, *args,\n                        **kwargs)\n    assert_raises_regex(exception_class, expected_regexp)\n\n    Fail unless an exception of class exception_class and with message that\n    matches expected_regexp is thrown by callable when invoked with arguments\n    args and keyword arguments kwargs.\n\n    Alternatively, can be used as a context manager like `assert_raises`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": ".. versionadded:: 1.9.0",
        "examples": ""
      }
    },
    {
      "name": "assert_string_equal",
      "signature": "assert_string_equal(actual, desired)",
      "documentation": {
        "description": "Test if two strings are equal.\n\n    If the given strings are equal, `assert_string_equal` does nothing.\n    If they are not equal, an AssertionError is raised, and the diff\n    between the strings is shown.",
        "parameters": {
          "desired": {
            "type": "str",
            "description": "The expected string."
          },
          "AssertionError": {
            "type": "Differences in strings:",
            "description": "- abc+ abcd?    +"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "assert_warns",
      "signature": "assert_warns(warning_class, *args, **kwargs)",
      "documentation": {
        "description": "Fail unless the given callable throws the specified warning.\n\n    A warning of class warning_class should be thrown by the callable when\n    invoked with arguments args and keyword arguments kwargs.\n    If a different type of warning is thrown, it will not be caught.\n\n    If called with all arguments other than the warning class omitted, may be\n    used as a context manager:\n\n        with assert_warns(SomeWarning):\n            do_something()\n\n    The ability to be used as a context manager is new in NumPy v1.11.0.\n\n    .. versionadded:: 1.4.0",
        "parameters": {
          "func": {
            "type": "callable",
            "description": "Callable to test\n    *args : Arguments\n        Arguments for `func`.\n    **kwargs : Kwargs\n        Keyword arguments for `func`."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "break_cycles",
      "signature": "break_cycles()",
      "documentation": {
        "description": "Break reference cycles by calling gc.collect\n    Objects can call other objects' methods (for instance, another object's\n     __del__) inside their own __del__. On PyPy, the interpreter only runs\n    between calls to gc.collect, so multiple calls are needed to completely\n    release all cycles.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "build_err_msg",
      "signature": "build_err_msg(arrays, err_msg, header='Items are not equal:', verbose=True, names=('ACTUAL', 'DESIRED'), precision=8)",
      "documentation": {
        "description": "",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "decorate_methods",
      "signature": "decorate_methods(cls, decorator, testmatch=None)",
      "documentation": {
        "description": "Apply a decorator to all methods in a class matching a regular expression.\n\n    The given decorator is applied to all public methods of `cls` that are\n    matched by the regular expression `testmatch`\n    (``testmatch.search(methodname)``). Methods that are private, i.e. start\n    with an underscore, are ignored.",
        "parameters": {
          "decorator": {
            "type": "function",
            "description": "Decorator to apply to methods"
          },
          "testmatch": {
            "type": "compiled regexp or str",
            "description": "The regular expression. Default value is None, in which case the\n        nose default (``re.compile(r'(?:^|[\\b_\\.%s-])[Tt]est' % os.sep)``)\n        is used.\n        If `testmatch` is a string, it is compiled to a regular expression\n        first."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "jiffies",
      "signature": "jiffies(_proc_pid_stat='/proc/124458/stat', _load_time=[])",
      "documentation": {
        "description": "Return number of jiffies elapsed.\n\n        Return number of jiffies (1/100ths of a second) that this\n        process has been scheduled in user mode. See man 5 proc.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "measure",
      "signature": "measure(code_str, times=1, label=None)",
      "documentation": {
        "description": "Return elapsed time for executing code in the namespace of the caller.\n\n    The supplied code string is compiled with the Python builtin ``compile``.\n    The precision of the timing is 10 milli-seconds. If the code will execute\n    fast on this timescale, it can be executed many times to get reasonable\n    timing accuracy.",
        "parameters": {
          "times": {
            "type": "int",
            "description": "The number of times the code is executed. Default is 1. The code is\n        only compiled once."
          },
          "label": {
            "type": "str",
            "description": "A label to identify `code_str` with. This is passed into ``compile``\n        as the second argument (for run-time error messages)."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "memusage",
      "signature": "memusage(_proc_pid_stat='/proc/124458/stat')",
      "documentation": {
        "description": "Return virtual memory size in bytes of the running python.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "print_assert_equal",
      "signature": "print_assert_equal(test_string, actual, desired)",
      "documentation": {
        "description": "Test if two objects are equal, and print an error message if test fails.\n\n    The test is performed with ``actual == desired``.",
        "parameters": {
          "actual": {
            "type": "object",
            "description": "The object to test for equality against `desired`."
          },
          "desired": {
            "type": "object",
            "description": "The expected result."
          },
          "AssertionError": {
            "type": "Test XYZ of func xyz failed",
            "description": ""
          },
          "ACTUAL": {
            "type": "[0",
            "description": ", 1]"
          },
          "DESIRED": {
            "type": "[0",
            "description": ", 2]"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "rundocs",
      "signature": "rundocs(filename=None, raise_on_error=True)",
      "documentation": {
        "description": "Run doctests found in the given file.\n\n    By default `rundocs` raises an AssertionError on failure.",
        "parameters": {
          "raise_on_error": {
            "type": "bool",
            "description": "Whether to raise an AssertionError when a doctest fails. Default is\n        True."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "runstring",
      "signature": "runstring(astr, dict)",
      "documentation": {
        "description": "",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "tempdir",
      "signature": "tempdir(*args, **kwargs)",
      "documentation": {
        "description": "Context manager to provide a temporary test folder.\n\n    All arguments are passed as this to the underlying tempfile.mkdtemp\n    function.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "temppath",
      "signature": "temppath(*args, **kwargs)",
      "documentation": {
        "description": "Context manager for temporary files.\n\n    Context manager that returns the path to a closed temporary file. Its\n    parameters are the same as for tempfile.mkstemp and are passed directly\n    to that function. The underlying file is removed when the context is\n    exited, so it should be closed at that time.\n\n    Windows does not allow a temporary file to be opened if it is already\n    open, so the underlying file must be closed after opening before it\n    can be opened again.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    }
  ],
  "classes": [
    {
      "name": "IgnoreException",
      "documentation": {
        "description": "Ignoring this exception due to disabled feature",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "add_note",
          "signature": "add_note(note)",
          "documentation": {
            "description": "Exception.add_note(note) --\n    add a note to the exception",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_traceback",
          "signature": "with_traceback(tb)",
          "documentation": {
            "description": "Exception.with_traceback(tb) --\n    set self.__traceback__ to tb and return self.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "KnownFailureException",
      "documentation": {
        "description": "Raise this exception to mark a test as a known failing test.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "add_note",
          "signature": "add_note(note)",
          "documentation": {
            "description": "Exception.add_note(note) --\n    add a note to the exception",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_traceback",
          "signature": "with_traceback(tb)",
          "documentation": {
            "description": "Exception.with_traceback(tb) --\n    set self.__traceback__ to tb and return self.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "SkipTest",
      "documentation": {
        "description": "Raise this exception in a test to skip it.\n\n    Usually you can use TestCase.skipTest() or one of the skipping decorators\n    instead of raising this directly.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "add_note",
          "signature": "add_note(note)",
          "documentation": {
            "description": "Exception.add_note(note) --\n    add a note to the exception",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_traceback",
          "signature": "with_traceback(tb)",
          "documentation": {
            "description": "Exception.with_traceback(tb) --\n    set self.__traceback__ to tb and return self.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "TestCase",
      "documentation": {
        "description": "A class whose instances are single test cases.\n\n    By default, the test code itself should be placed in a method named\n    'runTest'.\n\n    If the fixture may be used for many test cases, create as\n    many test methods as are needed. When instantiating such a TestCase\n    subclass, specify in the constructor arguments the name of the test method\n    that the instance is to execute.\n\n    Test authors should subclass TestCase for their own tests. Construction\n    and deconstruction of the test's environment ('fixture') can be\n    implemented by overriding the 'setUp' and 'tearDown' methods respectively.\n\n    If it is necessary to override the __init__ method, the base class\n    __init__ method must always be called. It is important that subclasses\n    should not change the signature of their __init__ method, since instances\n    of the classes are instantiated automatically by parts of the framework\n    in order to be run.\n\n    When subclassing TestCase, you can set these attributes:\n    * failureException: determines which exception will be raised when\n        the instance's assertion methods fail; test methods raising this\n        exception will be deemed to have 'failed' rather than 'errored'.\n    * longMessage: determines whether long messages (including repr of\n        objects used in assert methods) will be printed on failure in *addition*\n        to any explicit message passed.\n    * maxDiff: sets the maximum length of a diff in failure messages\n        by assert methods using difflib. It is looked up as an instance\n        attribute so can be configured by individual tests if required.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "addClassCleanup",
          "signature": "addClassCleanup(function, /, *args, **kwargs)",
          "documentation": {
            "description": "Same as addCleanup, except the cleanup items are called even if\n        setUpClass fails (unlike tearDownClass).",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "addCleanup",
          "signature": "addCleanup(self, function, /, *args, **kwargs)",
          "documentation": {
            "description": "Add a function, with arguments, to be called when the test is\n        completed. Functions added are called on a LIFO basis and are\n        called after tearDown on test failure or success.\n\n        Cleanup items are called even if setUp fails (unlike tearDown).",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "addTypeEqualityFunc",
          "signature": "addTypeEqualityFunc(self, typeobj, function)",
          "documentation": {
            "description": "Add a type specific assertEqual style function to compare a type.\n\n        This method is for use by TestCase subclasses that need to register\n        their own type equality functions to provide nicer error messages.\n\n        Args:\n            typeobj: The data type to call this function on when both values\n                    are of the same type in assertEqual().\n            function: The callable taking two arguments and an optional\n                    msg= argument that raises self.failureException with a\n                    useful error message when the two arguments are not equal.",
            "parameters": {
              "typeobj": {
                "type": "",
                "description": "The data type to call this function on when both values"
              },
              "are": {
                "type": "",
                "description": "of the same type in assertEqual()."
              },
              "function": {
                "type": "",
                "description": "The callable taking two arguments and an optional"
              },
              "msg": {
                "type": "",
                "description": "= argument that raises self.failureException with a"
              },
              "useful": {
                "type": "",
                "description": "error message when the two arguments are not equal."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertAlmostEqual",
          "signature": "assertAlmostEqual(self, first, second, places=None, msg=None, delta=None)",
          "documentation": {
            "description": "Fail if the two objects are unequal as determined by their\n           difference rounded to the given number of decimal places\n           (default 7) and comparing to zero, or by comparing that the\n           difference between the two objects is more than the given\n           delta.\n\n           Note that decimal places (from zero) are usually not the same\n           as significant digits (measured from the most significant digit).\n\n           If the two objects compare equal then they will automatically\n           compare almost equal.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertCountEqual",
          "signature": "assertCountEqual(self, first, second, msg=None)",
          "documentation": {
            "description": "Asserts that two iterables have the same elements, the same number of\n        times, without regard to order.\n\n            self.assertEqual(Counter(list(first)),\n                             Counter(list(second)))\n\n         Example:\n            - [0, 1, 1] and [1, 0, 1] compare equal.\n            - [0, 0, 1] and [0, 1] compare unequal.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertDictEqual",
          "signature": "assertDictEqual(self, d1, d2, msg=None)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertEqual",
          "signature": "assertEqual(self, first, second, msg=None)",
          "documentation": {
            "description": "Fail if the two objects are unequal as determined by the '=='\n           operator.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertFalse",
          "signature": "assertFalse(self, expr, msg=None)",
          "documentation": {
            "description": "Check that the expression is false.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertGreater",
          "signature": "assertGreater(self, a, b, msg=None)",
          "documentation": {
            "description": "Just like self.assertTrue(a > b), but with a nicer default message.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertGreaterEqual",
          "signature": "assertGreaterEqual(self, a, b, msg=None)",
          "documentation": {
            "description": "Just like self.assertTrue(a >= b), but with a nicer default message.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertIn",
          "signature": "assertIn(self, member, container, msg=None)",
          "documentation": {
            "description": "Just like self.assertTrue(a in b), but with a nicer default message.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertIs",
          "signature": "assertIs(self, expr1, expr2, msg=None)",
          "documentation": {
            "description": "Just like self.assertTrue(a is b), but with a nicer default message.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertIsInstance",
          "signature": "assertIsInstance(self, obj, cls, msg=None)",
          "documentation": {
            "description": "Same as self.assertTrue(isinstance(obj, cls)), with a nicer\n        default message.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertIsNone",
          "signature": "assertIsNone(self, obj, msg=None)",
          "documentation": {
            "description": "Same as self.assertTrue(obj is None), with a nicer default message.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertIsNot",
          "signature": "assertIsNot(self, expr1, expr2, msg=None)",
          "documentation": {
            "description": "Just like self.assertTrue(a is not b), but with a nicer default message.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertIsNotNone",
          "signature": "assertIsNotNone(self, obj, msg=None)",
          "documentation": {
            "description": "Included for symmetry with assertIsNone.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertLess",
          "signature": "assertLess(self, a, b, msg=None)",
          "documentation": {
            "description": "Just like self.assertTrue(a < b), but with a nicer default message.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertLessEqual",
          "signature": "assertLessEqual(self, a, b, msg=None)",
          "documentation": {
            "description": "Just like self.assertTrue(a <= b), but with a nicer default message.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertListEqual",
          "signature": "assertListEqual(self, list1, list2, msg=None)",
          "documentation": {
            "description": "A list-specific equality assertion.\n\n        Args:\n            list1: The first list to compare.\n            list2: The second list to compare.\n            msg: Optional message to use on failure instead of a list of\n                    differences.",
            "parameters": {
              "list1": {
                "type": "",
                "description": "The first list to compare."
              },
              "list2": {
                "type": "",
                "description": "The second list to compare."
              },
              "msg": {
                "type": "",
                "description": "Optional message to use on failure instead of a list of"
              },
              "differences": {
                "type": "",
                "description": "."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertLogs",
          "signature": "assertLogs(self, logger=None, level=None)",
          "documentation": {
            "description": "Fail unless a log message of level *level* or higher is emitted\n        on *logger_name* or its children.  If omitted, *level* defaults to\n        INFO and *logger* defaults to the root logger.\n\n        This method must be used as a context manager, and will yield\n        a recording object with two attributes: `output` and `records`.\n        At the end of the context manager, the `output` attribute will\n        be a list of the matching formatted log messages and the\n        `records` attribute will be a list of the corresponding LogRecord\n        objects.\n\n        Example::\n\n            with self.assertLogs('foo', level='INFO') as cm:\n                logging.getLogger('foo').info('first message')\n                logging.getLogger('foo.bar').error('second message')\n            self.assertEqual(cm.output, ['INFO:foo:first message',\n                                         'ERROR:foo.bar:second message'])",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertMultiLineEqual",
          "signature": "assertMultiLineEqual(self, first, second, msg=None)",
          "documentation": {
            "description": "Assert that two multi-line strings are equal.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertNoLogs",
          "signature": "assertNoLogs(self, logger=None, level=None)",
          "documentation": {
            "description": "Fail unless no log messages of level *level* or higher are emitted\n        on *logger_name* or its children.\n\n        This method must be used as a context manager.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertNotAlmostEqual",
          "signature": "assertNotAlmostEqual(self, first, second, places=None, msg=None, delta=None)",
          "documentation": {
            "description": "Fail if the two objects are equal as determined by their\n           difference rounded to the given number of decimal places\n           (default 7) and comparing to zero, or by comparing that the\n           difference between the two objects is less than the given delta.\n\n           Note that decimal places (from zero) are usually not the same\n           as significant digits (measured from the most significant digit).\n\n           Objects that are equal automatically fail.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertNotEqual",
          "signature": "assertNotEqual(self, first, second, msg=None)",
          "documentation": {
            "description": "Fail if the two objects are equal as determined by the '!='\n           operator.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertNotIn",
          "signature": "assertNotIn(self, member, container, msg=None)",
          "documentation": {
            "description": "Just like self.assertTrue(a not in b), but with a nicer default message.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertNotIsInstance",
          "signature": "assertNotIsInstance(self, obj, cls, msg=None)",
          "documentation": {
            "description": "Included for symmetry with assertIsInstance.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertNotRegex",
          "signature": "assertNotRegex(self, text, unexpected_regex, msg=None)",
          "documentation": {
            "description": "Fail the test if the text matches the regular expression.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertRaises",
          "signature": "assertRaises(self, expected_exception, *args, **kwargs)",
          "documentation": {
            "description": "Fail unless an exception of class expected_exception is raised\n           by the callable when invoked with specified positional and\n           keyword arguments. If a different type of exception is\n           raised, it will not be caught, and the test case will be\n           deemed to have suffered an error, exactly as for an\n           unexpected exception.\n\n           If called with the callable and arguments omitted, will return a\n           context object used like this::\n\n                with self.assertRaises(SomeException):\n                    do_something()\n\n           An optional keyword argument 'msg' can be provided when assertRaises\n           is used as a context object.\n\n           The context manager keeps a reference to the exception as\n           the 'exception' attribute. This allows you to inspect the\n           exception after the assertion::\n\n               with self.assertRaises(SomeException) as cm:\n                   do_something()\n               the_exception = cm.exception\n               self.assertEqual(the_exception.error_code, 3)",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertRaisesRegex",
          "signature": "assertRaisesRegex(self, expected_exception, expected_regex, *args, **kwargs)",
          "documentation": {
            "description": "Asserts that the message in a raised exception matches a regex.\n\n        Args:\n            expected_exception: Exception class expected to be raised.\n            expected_regex: Regex (re.Pattern object or string) expected\n                    to be found in error message.\n            args: Function to be called and extra positional args.\n            kwargs: Extra kwargs.\n            msg: Optional message used in case of failure. Can only be used\n                    when assertRaisesRegex is used as a context manager.",
            "parameters": {
              "expected_exception": {
                "type": "",
                "description": "Exception class expected to be raised."
              },
              "expected_regex": {
                "type": "",
                "description": "Regex (re.Pattern object or string) expected"
              },
              "to": {
                "type": "",
                "description": "be found in error message."
              },
              "args": {
                "type": "",
                "description": "Function to be called and extra positional args."
              },
              "kwargs": {
                "type": "",
                "description": "Extra kwargs."
              },
              "msg": {
                "type": "",
                "description": "Optional message used in case of failure. Can only be used"
              },
              "when": {
                "type": "",
                "description": "assertRaisesRegex is used as a context manager."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertRegex",
          "signature": "assertRegex(self, text, expected_regex, msg=None)",
          "documentation": {
            "description": "Fail the test unless the text matches the regular expression.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertSequenceEqual",
          "signature": "assertSequenceEqual(self, seq1, seq2, msg=None, seq_type=None)",
          "documentation": {
            "description": "An equality assertion for ordered sequences (like lists and tuples).\n\n        For the purposes of this function, a valid ordered sequence type is one\n        which can be indexed, has a length, and has an equality operator.\n\n        Args:\n            seq1: The first sequence to compare.\n            seq2: The second sequence to compare.\n            seq_type: The expected datatype of the sequences, or None if no\n                    datatype should be enforced.\n            msg: Optional message to use on failure instead of a list of\n                    differences.",
            "parameters": {
              "seq1": {
                "type": "",
                "description": "The first sequence to compare."
              },
              "seq2": {
                "type": "",
                "description": "The second sequence to compare."
              },
              "seq_type": {
                "type": "",
                "description": "The expected datatype of the sequences, or None if no"
              },
              "datatype": {
                "type": "",
                "description": "should be enforced."
              },
              "msg": {
                "type": "",
                "description": "Optional message to use on failure instead of a list of"
              },
              "differences": {
                "type": "",
                "description": "."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertSetEqual",
          "signature": "assertSetEqual(self, set1, set2, msg=None)",
          "documentation": {
            "description": "A set-specific equality assertion.\n\n        Args:\n            set1: The first set to compare.\n            set2: The second set to compare.\n            msg: Optional message to use on failure instead of a list of\n                    differences.\n\n        assertSetEqual uses ducktyping to support different types of sets, and\n        is optimized for sets specifically (parameters must support a\n        difference method).",
            "parameters": {
              "set1": {
                "type": "",
                "description": "The first set to compare."
              },
              "set2": {
                "type": "",
                "description": "The second set to compare."
              },
              "msg": {
                "type": "",
                "description": "Optional message to use on failure instead of a list of"
              },
              "differences": {
                "type": "",
                "description": "."
              },
              "assertSetEqual": {
                "type": "",
                "description": "uses ducktyping to support different types of sets, and"
              },
              "is": {
                "type": "",
                "description": "optimized for sets specifically (parameters must support a"
              },
              "difference": {
                "type": "",
                "description": "method)."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertTrue",
          "signature": "assertTrue(self, expr, msg=None)",
          "documentation": {
            "description": "Check that the expression is true.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertTupleEqual",
          "signature": "assertTupleEqual(self, tuple1, tuple2, msg=None)",
          "documentation": {
            "description": "A tuple-specific equality assertion.\n\n        Args:\n            tuple1: The first tuple to compare.\n            tuple2: The second tuple to compare.\n            msg: Optional message to use on failure instead of a list of\n                    differences.",
            "parameters": {
              "tuple1": {
                "type": "",
                "description": "The first tuple to compare."
              },
              "tuple2": {
                "type": "",
                "description": "The second tuple to compare."
              },
              "msg": {
                "type": "",
                "description": "Optional message to use on failure instead of a list of"
              },
              "differences": {
                "type": "",
                "description": "."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertWarns",
          "signature": "assertWarns(self, expected_warning, *args, **kwargs)",
          "documentation": {
            "description": "Fail unless a warning of class warnClass is triggered\n           by the callable when invoked with specified positional and\n           keyword arguments.  If a different type of warning is\n           triggered, it will not be handled: depending on the other\n           warning filtering rules in effect, it might be silenced, printed\n           out, or raised as an exception.\n\n           If called with the callable and arguments omitted, will return a\n           context object used like this::\n\n                with self.assertWarns(SomeWarning):\n                    do_something()\n\n           An optional keyword argument 'msg' can be provided when assertWarns\n           is used as a context object.\n\n           The context manager keeps a reference to the first matching\n           warning as the 'warning' attribute; similarly, the 'filename'\n           and 'lineno' attributes give you information about the line\n           of Python code from which the warning was triggered.\n           This allows you to inspect the warning after the assertion::\n\n               with self.assertWarns(SomeWarning) as cm:\n                   do_something()\n               the_warning = cm.warning\n               self.assertEqual(the_warning.some_attribute, 147)",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "assertWarnsRegex",
          "signature": "assertWarnsRegex(self, expected_warning, expected_regex, *args, **kwargs)",
          "documentation": {
            "description": "Asserts that the message in a triggered warning matches a regexp.\n        Basic functioning is similar to assertWarns() with the addition\n        that only warnings whose messages also match the regular expression\n        are considered successful matches.\n\n        Args:\n            expected_warning: Warning class expected to be triggered.\n            expected_regex: Regex (re.Pattern object or string) expected\n                    to be found in error message.\n            args: Function to be called and extra positional args.\n            kwargs: Extra kwargs.\n            msg: Optional message used in case of failure. Can only be used\n                    when assertWarnsRegex is used as a context manager.",
            "parameters": {
              "expected_warning": {
                "type": "",
                "description": "Warning class expected to be triggered."
              },
              "expected_regex": {
                "type": "",
                "description": "Regex (re.Pattern object or string) expected"
              },
              "to": {
                "type": "",
                "description": "be found in error message."
              },
              "args": {
                "type": "",
                "description": "Function to be called and extra positional args."
              },
              "kwargs": {
                "type": "",
                "description": "Extra kwargs."
              },
              "msg": {
                "type": "",
                "description": "Optional message used in case of failure. Can only be used"
              },
              "when": {
                "type": "",
                "description": "assertWarnsRegex is used as a context manager."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "countTestCases",
          "signature": "countTestCases(self)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "debug",
          "signature": "debug(self)",
          "documentation": {
            "description": "Run the test without collecting errors in a TestResult",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "defaultTestResult",
          "signature": "defaultTestResult(self)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "doClassCleanups",
          "signature": "doClassCleanups()",
          "documentation": {
            "description": "Execute all class cleanup functions. Normally called for you after\n        tearDownClass.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "doCleanups",
          "signature": "doCleanups(self)",
          "documentation": {
            "description": "Execute all cleanup functions. Normally called for you after\n        tearDown.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enterClassContext",
          "signature": "enterClassContext(cm)",
          "documentation": {
            "description": "Same as enterContext, but class-wide.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enterContext",
          "signature": "enterContext(self, cm)",
          "documentation": {
            "description": "Enters the supplied context manager.\n\n        If successful, also adds its __exit__ method as a cleanup\n        function and returns the result of the __enter__ method.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fail",
          "signature": "fail(self, msg=None)",
          "documentation": {
            "description": "Fail immediately, with the given message.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "failureException",
          "signature": "AssertionError(...)",
          "documentation": {
            "description": "Assertion failed.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "id",
          "signature": "id(self)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "run",
          "signature": "run(self, result=None)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "setUp",
          "signature": "setUp(self)",
          "documentation": {
            "description": "Hook method for setting up the test fixture before exercising it.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "setUpClass",
          "signature": "setUpClass()",
          "documentation": {
            "description": "Hook method for setting up class fixture before running tests in the class.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "shortDescription",
          "signature": "shortDescription(self)",
          "documentation": {
            "description": "Returns a one-line description of the test, or None if no\n        description has been provided.\n\n        The default implementation of this method returns the first line of\n        the specified test method's docstring.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "skipTest",
          "signature": "skipTest(self, reason)",
          "documentation": {
            "description": "Skip this test.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "subTest",
          "signature": "subTest(self, msg=<object object at 0x7e3a9577a770>, **params)",
          "documentation": {
            "description": "Return a context manager that will return the enclosed block\n        of code in a subtest identified by the optional message and\n        keyword parameters.  A failure in the subtest marks the test\n        case as failed but resumes execution at the end of the enclosed\n        block, allowing further test code to be executed.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "tearDown",
          "signature": "tearDown(self)",
          "documentation": {
            "description": "Hook method for deconstructing the test fixture after testing it.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "tearDownClass",
          "signature": "tearDownClass()",
          "documentation": {
            "description": "Hook method for deconstructing the class fixture after running all tests in the class.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "clear_and_catch_warnings",
      "documentation": {
        "description": "Context manager that resets warning registry for catching warnings\n\n    Warnings can be slippery, because, whenever a warning is triggered, Python\n    adds a ``__warningregistry__`` member to the *calling* module.  This makes\n    it impossible to retrigger the warning in this module, whatever you put in\n    the warnings filters.  This context manager accepts a sequence of `modules`\n    as a keyword argument to its constructor and:\n\n    * stores and removes any ``__warningregistry__`` entries in given `modules`\n      on entry;\n    * resets ``__warningregistry__`` to its previous state on exit.\n\n    This makes it possible to trigger any warning afresh inside the context\n    manager without disturbing the state of warnings outside.\n\n    For compatibility with Python 3.0, please consider all arguments to be\n    keyword-only.",
        "parameters": {
          "modules": {
            "type": "sequence",
            "description": "Sequence of modules for which to reset warnings registry on entry and\n        restore on exit. To work correctly, all 'ignore' filters should\n        filter by one of these modules."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": []
    },
    {
      "name": "suppress_warnings",
      "documentation": {
        "description": "Context manager and decorator doing much the same as\n    ``warnings.catch_warnings``.\n\n    However, it also provides a filter mechanism to work around\n    https://bugs.python.org/issue4180.\n\n    This bug causes Python before 3.4 to not reliably show warnings again\n    after they have been ignored once (even within catch_warnings). It\n    means that no \"ignore\" filter can be used easily, since following\n    tests might need to see the warning. Additionally it allows easier\n    specificity for testing warnings and can be nested.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "filter",
          "signature": "filter(self, category=<class 'Warning'>, message='', module=None)",
          "documentation": {
            "description": "Add a new suppressing filter or apply it if the state is entered.",
            "parameters": {
              "message": {
                "type": "string",
                "description": "Regular expression matching the warning message."
              },
              "module": {
                "type": "module",
                "description": "Module to filter for. Note that the module (and its file)\n            must match exactly and cannot be a submodule. This may make\n            it unreliable for external modules."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "record",
          "signature": "record(self, category=<class 'Warning'>, message='', module=None)",
          "documentation": {
            "description": "Append a new recording filter or apply it if the state is entered.\n\n        All warnings matching will be appended to the ``log`` attribute.",
            "parameters": {
              "message": {
                "type": "string",
                "description": "Regular expression matching the warning message."
              },
              "module": {
                "type": "module",
                "description": "Module to filter for. Note that the module (and its file)\n            must match exactly and cannot be a submodule. This may make\n            it unreliable for external modules."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    }
  ]
}