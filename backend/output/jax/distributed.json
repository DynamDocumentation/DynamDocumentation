{
  "description": "No description available",
  "functions": [
    {
      "name": "initialize",
      "signature": "initialize(coordinator_address: 'str | None' = None, num_processes: 'int | None' = None, process_id: 'int | None' = None, local_device_ids: 'int | Sequence[int] | None' = None, cluster_detection_method: 'str | None' = None, initialization_timeout: 'int' = 300, coordinator_bind_address: 'str | None' = None)",
      "documentation": {
        "description": "Initializes the JAX distributed system.\nCalling :func:`~jax.distributed.initialize` prepares JAX for execution on\nmulti-host GPU and Cloud TPU. :func:`~jax.distributed.initialize` must be\ncalled before performing any JAX computations.\nThe JAX distributed system serves a number of roles:\n* It allows JAX processes to discover each other and share topology information,\n* It performs health checking, ensuring that all processes shut down if any process dies, and\n* It is used for distributed checkpointing.\nIf you are using TPU, Slurm, or Open MPI, all arguments are optional: if omitted, they\nwill be chosen automatically.\nThe ``cluster_detection_method`` may be used to choose a specific method for detecting those\ndistributed arguments. You may pass any of the automatic ``spec_detect_methods`` to this\nargument though it is not necessary in the TPU, Slurm, or Open MPI cases.  For other MPI\ninstallations, if you have a functional ``mpi4py`` installed, you may pass\n``cluster_detection_method=\"mpi4py\"`` to bootstrap the required arguments.\nOtherwise, you must provide the ``coordinator_address``,\n``num_processes``, ``process_id``, and ``local_device_ids`` arguments\nto :func:`~jax.distributed.initialize`. When all four arguments are provided, cluster\nenvironment auto detection will be skipped.\nPlease note: on some systems, particularly HPC clusters that only access external networks\nthrough proxy variables such as HTTP_PROXY, HTTPS_PROXY, etc., the call to\n:func:`~jax.distributed.initialize` may timeout.  You may need to unset these variables\nprior to application launch.\nArgs:\ncoordinator_address: the IP address of process `0` and a port on which that\nprocess should launch a coordinator service. The choice of\nport does not matter, so long as the port is available on the coordinator\nand all processes agree on the port.\nMay be ``None`` only on supported environments, in which case it will be chosen automatically.\nNote that special addresses like ``localhost`` or ``127.0.0.1`` usually mean that the program\nwill bind to a local interface and are not suitable when running in a multi-host environment.\nnum_processes: Number of processes. May be ``None`` only on supported environments, in\nwhich case it will be chosen automatically.\nprocess_id: The ID number of the current process. The ``process_id`` values across\nthe cluster must be a dense range ``0``, ``1``, ..., ``num_processes - 1``.\nMay be ``None`` only on supported environments; if ``None`` it will be chosen automatically.\nlocal_device_ids: Restricts the visible devices of the current process to ``local_device_ids``.\nIf ``None``, defaults to all local devices being visible to the process except when processes\nare launched via Slurm and Open MPI on GPUs. In that case, it will default to a single device per process.\ncluster_detection_method: An optional string to attempt to autodetect the configuration of the distributed\nrun.  Note that \"mpi4py\" method requires you to have a working ``mpi4py`` install in your environment,\nand launch the applicatoin with an MPI-compatible job launcher such as ``mpiexec`` or ``mpirun``.\nLegacy auto-detect options \"ompi\" (OMPI) and \"slurm\" (Slurm) remain enabled. \"deactivate\" bypasses\nautomatic cluster detection.\ninitialization_timeout: Time period (in seconds) for which connection will\nbe retried. If the initialization takes more than the timeout specified,\nthe initialization will error. Defaults to 300 secs i.e. 5 mins.\ncoordinator_bind_address: the address and port to which the coordinator service\non process `0` should bind. If this is not specified, the default is to bind to\nall available addresses on the same port as ``coordinator_address``. On systems\nthat have multiple network interfaces per node it may be insufficient to only\nhave the coordinator service listen on one address/interface.",
        "parameters": {},
        "returns": "",
        "raises": "RuntimeError: If :func:`~jax.distributed.initialize` is called more than once\nor if called after the backend is already initialized.",
        "see_also": "",
        "notes": "",
        "examples": "Suppose there are two GPU processes, and process 0 is the designated coordinator\nwith address ``10.0.0.1:1234``. To initialize the GPU cluster, run the\nfollowing commands before anything else.\nOn process 0:\n>>> jax.distributed.initialize(coordinator_address='10.0.0.1:1234', num_processes=2, process_id=0)  # doctest: +SKIP\nOn process 1:\n>>> jax.distributed.initialize(coordinator_address='10.0.0.1:1234', num_processes=2, process_id=1)  # doctest: +SKIP"
      }
    },
    {
      "name": "is_initialized",
      "signature": "is_initialized() -> 'bool'",
      "documentation": {
        "description": "Check if the JAX distributed system is initialized.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "shutdown",
      "signature": "shutdown()",
      "documentation": {
        "description": "Shuts down the distributed system.\nDoes nothing if the distributed system is not running.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    }
  ],
  "classes": []
}