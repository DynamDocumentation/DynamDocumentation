{
  "description": "No description available",
  "functions": [
    {
      "name": "annotate_function",
      "signature": "annotate_function(func: 'Callable', name: 'str | None' = None, **decorator_kwargs)",
      "documentation": {
        "description": "Decorator that generates a trace event for the execution of a function.\nFor example:\n>>> @jax.profiler.annotate_function\n... def f(x):\n...   return jnp.dot(x, x.T).block_until_ready()\n>>>\n>>> result = f(jnp.ones((1000, 1000)))\nThis will cause an \"f\" event to show up on the trace timeline if the\nfunction execution occurs while the process is being traced by TensorBoard.\nArguments can be passed to the decorator via :py:func:`functools.partial`.\n>>> from functools import partial\n>>> @partial(jax.profiler.annotate_function, name=\"event_name\")\n... def f(x):\n...   return jnp.dot(x, x.T).block_until_ready()\n>>> result = f(jnp.ones((1000, 1000)))",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "device_memory_profile",
      "signature": "device_memory_profile(backend: 'str | None' = None) -> 'bytes'",
      "documentation": {
        "description": "Captures a JAX device memory profile as ``pprof``-format protocol buffer.\nA device memory profile is a snapshot of the state of memory, that describes the JAX\n:class:`~jax.Array` and executable objects present in memory and their\nallocation sites.\nFor more information how to use the device memory profiler, see\n:doc:`/device_memory_profiling`.\nThe profiling system works by instrumenting JAX on-device allocations,\ncapturing a Python stack trace for each allocation. The instrumentation is\nalways enabled; :func:`device_memory_profile` provides an API to capture it.\nThe output of :func:`device_memory_profile` is a binary protocol buffer that\ncan be interpreted and visualized by the `pprof tool\n<https://github.com/google/pprof>`_.\nArgs:\nbackend: optional; the name of the JAX backend for which the device memory\nprofile should be collected.",
        "parameters": {},
        "returns": "A byte string containing a binary `pprof`-format protocol buffer.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "save_device_memory_profile",
      "signature": "save_device_memory_profile(filename, backend: 'str | None' = None) -> 'None'",
      "documentation": {
        "description": "Collects a device memory profile and writes it to a file.\n:func:`save_device_memory_profile` is a convenience wrapper around :func:`device_memory_profile`\nthat saves its output to a ``filename``. See the\n:func:`device_memory_profile` documentation for more information.\nArgs:\nfilename: the filename to which the profile should be written.\nbackend: optional; the name of the JAX backend for which the device memory\nprofile should be collected.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "start_server",
      "signature": "start_server(port: 'int') -> 'xla_client.profiler.ProfilerServer'",
      "documentation": {
        "description": "Starts the profiler server on port `port`.\nUsing the \"TensorFlow profiler\" feature in `TensorBoard\n<https://www.tensorflow.org/tensorboard>`_ 2.2 or newer, you can\nconnect to the profiler server and sample execution traces that show CPU,\nGPU, and/or TPU device activity.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "start_trace",
      "signature": "start_trace(log_dir: 'os.PathLike | str', create_perfetto_link: 'bool' = False, create_perfetto_trace: 'bool' = False) -> 'None'",
      "documentation": {
        "description": "Starts a profiler trace.\nThe trace will capture CPU, GPU, and/or TPU activity, including Python\nfunctions and JAX on-device operations. Use :func:`stop_trace` to end the trace\nand save the results to ``log_dir``.\nThe resulting trace can be viewed with TensorBoard. Note that TensorBoard\ndoesn't need to be running when collecting the trace.\nOnly one trace may be collected at a time. A RuntimeError will be raised if\n:func:`start_trace` is called while another trace is running.\nArgs:\nlog_dir: The directory to save the profiler trace to (usually the\nTensorBoard log directory).\ncreate_perfetto_link: A boolean which, if true, creates and prints link to\nthe Perfetto trace viewer UI (https://ui.perfetto.dev). The program will\nblock until the link is opened and Perfetto loads the trace.\ncreate_perfetto_trace: A boolean which, if true, additionally dumps a\n``perfetto_trace.json.gz`` file that is compatible for upload with the\nPerfetto trace viewer UI (https://ui.perfetto.dev). The file will also be\ngenerated if ``create_perfetto_link`` is true. This could be useful if you\nwant to generate a Perfetto-compatible trace without blocking the\nprocess.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "stop_server",
      "signature": "stop_server()",
      "documentation": {
        "description": "Stops the running profiler server.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "stop_trace",
      "signature": "stop_trace()",
      "documentation": {
        "description": "Stops the currently-running profiler trace.\nThe trace will be saved to the ``log_dir`` passed to the corresponding\n:func:`start_trace` call. Raises a RuntimeError if a trace hasn't been started.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "trace",
      "signature": "trace(log_dir: 'os.PathLike | str', create_perfetto_link=False, create_perfetto_trace=False)",
      "documentation": {
        "description": "Context manager to take a profiler trace.\nThe trace will capture CPU, GPU, and/or TPU activity, including Python\nfunctions and JAX on-device operations.\nThe resulting trace can be viewed with TensorBoard. Note that TensorBoard\ndoesn't need to be running when collecting the trace.\nOnly one trace may be collected at a time. A RuntimeError will be raised if a\ntrace is started while another trace is running.\nArgs:\nlog_dir: The directory to save the profiler trace to (usually the\nTensorBoard log directory).\ncreate_perfetto_link: A boolean which, if true, creates and prints link to\nthe Perfetto trace viewer UI (https://ui.perfetto.dev). The program will\nblock until the link is opened and Perfetto loads the trace.\ncreate_perfetto_trace: A boolean which, if true, additionally dumps a\n``perfetto_trace.json.gz`` file that is compatible for upload with the\nPerfetto trace viewer UI (https://ui.perfetto.dev). The file will also be\ngenerated if ``create_perfetto_link`` is true. This could be useful if you\nwant to generate a Perfetto-compatible trace without blocking the\nprocess.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    }
  ],
  "classes": [
    {
      "name": "StepTraceAnnotation",
      "documentation": {
        "description": "Context manager that generates a step trace event in the profiler.\nThe step trace event spans the duration of the code enclosed by the context.\nThe profiler will provide the performance analysis for each step trace event.\nFor example, it can be used to mark training steps and enable the profiler to\nprovide the performance analysis per step:\n>>> while global_step < NUM_STEPS:                                           # doctest: +SKIP\n...   with jax.profiler.StepTraceAnnotation(\"train\", step_num=global_step):  # doctest: +SKIP\n...     train_step()                                                         # doctest: +SKIP\n...     global_step += 1                                                     # doctest: +SKIP\nThis will cause a \"train xx\" event to show up on the trace timeline if the\nevent occurs while the process is being traced by TensorBoard. In addition,\nif using accelerators, the device trace timeline will also show a \"train xx\"\nevent. Note that \"step_num\" can be set as a keyword argument to pass the\nglobal step number to the profiler.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "is_enabled",
          "signature": "is_enabled(*args, **kwargs)",
          "documentation": {
            "description": "is_enabled() -> bool",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_metadata",
          "signature": "set_metadata(self, **kwargs)",
          "documentation": {
            "description": "set_metadata(self, **kwargs) -> None",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "TraceAnnotation",
      "documentation": {
        "description": "Context manager that generates a trace event in the profiler.\nThe trace event spans the duration of the code enclosed by the context.\nFor example:\n>>> x = jnp.ones((1000, 1000))\n>>> with jax.profiler.TraceAnnotation(\"my_label\"):\n...   result = jnp.dot(x, x.T).block_until_ready()\nThis will cause a \"my_label\" event to show up on the trace timeline if the\nevent occurs while the process is being traced.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "is_enabled",
          "signature": "is_enabled(*args, **kwargs)",
          "documentation": {
            "description": "is_enabled() -> bool",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_metadata",
          "signature": "set_metadata(self, **kwargs)",
          "documentation": {
            "description": "set_metadata(self, **kwargs) -> None",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    }
  ]
}