{
  "description": "The ``distributions`` package contains parameterizable probability distributions\nand sampling functions. This allows the construction of stochastic computation\ngraphs and stochastic gradient estimators for optimization. This package\ngenerally follows the design of the `TensorFlow Distributions`_ package.\n\n.. _`TensorFlow Distributions`:\n    https://arxiv.org/abs/1711.10604\n\nIt is not possible to directly backpropagate through random samples. However,\nthere are two main methods for creating surrogate functions that can be\nbackpropagated through. These are the score function estimator/likelihood ratio\nestimator/REINFORCE and the pathwise derivative estimator. REINFORCE is commonly\nseen as the basis for policy gradient methods in reinforcement learning, and the\npathwise derivative estimator is commonly seen in the reparameterization trick\nin variational autoencoders. Whilst the score function only requires the value\nof samples :math:`f(x)`, the pathwise derivative requires the derivative\n:math:`f'(x)`. The next sections discuss these two in a reinforcement learning\nexample. For more details see\n`Gradient Estimation Using Stochastic Computation Graphs`_ .\n\n.. _`Gradient Estimation Using Stochastic Computation Graphs`:\n     https://arxiv.org/abs/1506.05254\n\nScore function\n^^^^^^^^^^^^^^\n\nWhen the probability density function is differentiable with respect to its\nparameters, we only need :meth:`~torch.distributions.Distribution.sample` and\n:meth:`~torch.distributions.Distribution.log_prob` to implement REINFORCE:\n\n.. math::\n\n    \\Delta\\theta  = \\alpha r \\frac{\\partial\\log p(a|\\pi^\\theta(s))}{\\partial\\theta}\n\nwhere :math:`\\theta` are the parameters, :math:`\\alpha` is the learning rate,\n:math:`r` is the reward and :math:`p(a|\\pi^\\theta(s))` is the probability of\ntaking action :math:`a` in state :math:`s` given policy :math:`\\pi^\\theta`.\n\nIn practice we would sample an action from the output of a network, apply this\naction in an environment, and then use ``log_prob`` to construct an equivalent\nloss function. Note that we use a negative because optimizers use gradient\ndescent, whilst the rule above assumes gradient ascent. With a categorical\npolicy, the code for implementing REINFORCE would be as follows::\n\n    probs = policy_network(state)\n    # Note that this is equivalent to what used to be called multinomial\n    m = Categorical(probs)\n    action = m.sample()\n    next_state, reward = env.step(action)\n    loss = -m.log_prob(action) * reward\n    loss.backward()\n\nPathwise derivative\n^^^^^^^^^^^^^^^^^^^\n\nThe other way to implement these stochastic/policy gradients would be to use the\nreparameterization trick from the\n:meth:`~torch.distributions.Distribution.rsample` method, where the\nparameterized random variable can be constructed via a parameterized\ndeterministic function of a parameter-free random variable. The reparameterized\nsample therefore becomes differentiable. The code for implementing the pathwise\nderivative would be as follows::\n\n    params = policy_network(state)\n    m = Normal(*params)\n    # Any distribution with .has_rsample == True could work based on the application\n    action = m.rsample()\n    next_state, reward = env.step(action)  # Assuming that reward is differentiable\n    loss = -reward\n    loss.backward()",
  "functions": [
    {
      "name": "kl_divergence",
      "signature": "kl_divergence(p: torch.distributions.distribution.Distribution, q: torch.distributions.distribution.Distribution) -> torch.Tensor",
      "documentation": {
        "description": "Compute Kullback-Leibler divergence :math:`KL(p \\| q)` between two distributions.\n\n.. math::\n\n    KL(p \\| q) = \\int p(x) \\log\\frac {p(x)} {q(x)} \\,dx",
        "parameters": {
          "p": {
            "type": "Distribution",
            "description": "A :class:`~torch.distributions.Distribution` object."
          },
          "q": {
            "type": "Distribution",
            "description": "A :class:`~torch.distributions.Distribution` object."
          }
        },
        "returns": "Tensor: A batch of KL divergences of shape `batch_shape`.",
        "raises": "NotImplementedError: If the distribution types have not been registered via\n        :meth:`register_kl`.\nKL divergence is currently implemented for the following distribution pairs:\n    * :class:`~torch.distributions.Bernoulli` and :class:`~torch.distributions.Bernoulli`\n    * :class:`~torch.distributions.Bernoulli` and :class:`~torch.distributions.Poisson`\n    * :class:`~torch.distributions.Beta` and :class:`~torch.distributions.Beta`\n    * :class:`~torch.distributions.Beta` and :class:`~torch.distributions.ContinuousBernoulli`\n    * :class:`~torch.distributions.Beta` and :class:`~torch.distributions.Exponential`\n    * :class:`~torch.distributions.Beta` and :class:`~torch.distributions.Gamma`\n    * :class:`~torch.distributions.Beta` and :class:`~torch.distributions.Normal`\n    * :class:`~torch.distributions.Beta` and :class:`~torch.distributions.Pareto`\n    * :class:`~torch.distributions.Beta` and :class:`~torch.distributions.Uniform`\n    * :class:`~torch.distributions.Binomial` and :class:`~torch.distributions.Binomial`\n    * :class:`~torch.distributions.Categorical` and :class:`~torch.distributions.Categorical`\n    * :class:`~torch.distributions.Cauchy` and :class:`~torch.distributions.Cauchy`\n    * :class:`~torch.distributions.ContinuousBernoulli` and :class:`~torch.distributions.ContinuousBernoulli`\n    * :class:`~torch.distributions.ContinuousBernoulli` and :class:`~torch.distributions.Exponential`\n    * :class:`~torch.distributions.ContinuousBernoulli` and :class:`~torch.distributions.Normal`\n    * :class:`~torch.distributions.ContinuousBernoulli` and :class:`~torch.distributions.Pareto`\n    * :class:`~torch.distributions.ContinuousBernoulli` and :class:`~torch.distributions.Uniform`\n    * :class:`~torch.distributions.Dirichlet` and :class:`~torch.distributions.Dirichlet`\n    * :class:`~torch.distributions.Exponential` and :class:`~torch.distributions.Beta`\n    * :class:`~torch.distributions.Exponential` and :class:`~torch.distributions.ContinuousBernoulli`\n    * :class:`~torch.distributions.Exponential` and :class:`~torch.distributions.Exponential`\n    * :class:`~torch.distributions.Exponential` and :class:`~torch.distributions.Gamma`\n    * :class:`~torch.distributions.Exponential` and :class:`~torch.distributions.Gumbel`\n    * :class:`~torch.distributions.Exponential` and :class:`~torch.distributions.Normal`\n    * :class:`~torch.distributions.Exponential` and :class:`~torch.distributions.Pareto`\n    * :class:`~torch.distributions.Exponential` and :class:`~torch.distributions.Uniform`\n    * :class:`~torch.distributions.ExponentialFamily` and :class:`~torch.distributions.ExponentialFamily`\n    * :class:`~torch.distributions.Gamma` and :class:`~torch.distributions.Beta`\n    * :class:`~torch.distributions.Gamma` and :class:`~torch.distributions.ContinuousBernoulli`\n    * :class:`~torch.distributions.Gamma` and :class:`~torch.distributions.Exponential`\n    * :class:`~torch.distributions.Gamma` and :class:`~torch.distributions.Gamma`\n    * :class:`~torch.distributions.Gamma` and :class:`~torch.distributions.Gumbel`\n    * :class:`~torch.distributions.Gamma` and :class:`~torch.distributions.Normal`\n    * :class:`~torch.distributions.Gamma` and :class:`~torch.distributions.Pareto`\n    * :class:`~torch.distributions.Gamma` and :class:`~torch.distributions.Uniform`\n    * :class:`~torch.distributions.Geometric` and :class:`~torch.distributions.Geometric`\n    * :class:`~torch.distributions.Gumbel` and :class:`~torch.distributions.Beta`\n    * :class:`~torch.distributions.Gumbel` and :class:`~torch.distributions.ContinuousBernoulli`\n    * :class:`~torch.distributions.Gumbel` and :class:`~torch.distributions.Exponential`\n    * :class:`~torch.distributions.Gumbel` and :class:`~torch.distributions.Gamma`\n    * :class:`~torch.distributions.Gumbel` and :class:`~torch.distributions.Gumbel`\n    * :class:`~torch.distributions.Gumbel` and :class:`~torch.distributions.Normal`\n    * :class:`~torch.distributions.Gumbel` and :class:`~torch.distributions.Pareto`\n    * :class:`~torch.distributions.Gumbel` and :class:`~torch.distributions.Uniform`\n    * :class:`~torch.distributions.HalfNormal` and :class:`~torch.distributions.HalfNormal`\n    * :class:`~torch.distributions.Independent` and :class:`~torch.distributions.Independent`\n    * :class:`~torch.distributions.Laplace` and :class:`~torch.distributions.Beta`\n    * :class:`~torch.distributions.Laplace` and :class:`~torch.distributions.ContinuousBernoulli`\n    * :class:`~torch.distributions.Laplace` and :class:`~torch.distributions.Exponential`\n    * :class:`~torch.distributions.Laplace` and :class:`~torch.distributions.Gamma`\n    * :class:`~torch.distributions.Laplace` and :class:`~torch.distributions.Laplace`\n    * :class:`~torch.distributions.Laplace` and :class:`~torch.distributions.Normal`\n    * :class:`~torch.distributions.Laplace` and :class:`~torch.distributions.Pareto`\n    * :class:`~torch.distributions.Laplace` and :class:`~torch.distributions.Uniform`\n    * :class:`~torch.distributions.LowRankMultivariateNormal` and :class:`~torch.distributions.LowRankMultivariateNormal`\n    * :class:`~torch.distributions.LowRankMultivariateNormal` and :class:`~torch.distributions.MultivariateNormal`\n    * :class:`~torch.distributions.MultivariateNormal` and :class:`~torch.distributions.LowRankMultivariateNormal`\n    * :class:`~torch.distributions.MultivariateNormal` and :class:`~torch.distributions.MultivariateNormal`\n    * :class:`~torch.distributions.Normal` and :class:`~torch.distributions.Beta`\n    * :class:`~torch.distributions.Normal` and :class:`~torch.distributions.ContinuousBernoulli`\n    * :class:`~torch.distributions.Normal` and :class:`~torch.distributions.Exponential`\n    * :class:`~torch.distributions.Normal` and :class:`~torch.distributions.Gamma`\n    * :class:`~torch.distributions.Normal` and :class:`~torch.distributions.Gumbel`\n    * :class:`~torch.distributions.Normal` and :class:`~torch.distributions.Laplace`\n    * :class:`~torch.distributions.Normal` and :class:`~torch.distributions.Normal`\n    * :class:`~torch.distributions.Normal` and :class:`~torch.distributions.Pareto`\n    * :class:`~torch.distributions.Normal` and :class:`~torch.distributions.Uniform`\n    * :class:`~torch.distributions.OneHotCategorical` and :class:`~torch.distributions.OneHotCategorical`\n    * :class:`~torch.distributions.Pareto` and :class:`~torch.distributions.Beta`\n    * :class:`~torch.distributions.Pareto` and :class:`~torch.distributions.ContinuousBernoulli`\n    * :class:`~torch.distributions.Pareto` and :class:`~torch.distributions.Exponential`\n    * :class:`~torch.distributions.Pareto` and :class:`~torch.distributions.Gamma`\n    * :class:`~torch.distributions.Pareto` and :class:`~torch.distributions.Normal`\n    * :class:`~torch.distributions.Pareto` and :class:`~torch.distributions.Pareto`\n    * :class:`~torch.distributions.Pareto` and :class:`~torch.distributions.Uniform`\n    * :class:`~torch.distributions.Poisson` and :class:`~torch.distributions.Bernoulli`\n    * :class:`~torch.distributions.Poisson` and :class:`~torch.distributions.Binomial`\n    * :class:`~torch.distributions.Poisson` and :class:`~torch.distributions.Poisson`\n    * :class:`~torch.distributions.TransformedDistribution` and :class:`~torch.distributions.TransformedDistribution`\n    * :class:`~torch.distributions.Uniform` and :class:`~torch.distributions.Beta`\n    * :class:`~torch.distributions.Uniform` and :class:`~torch.distributions.ContinuousBernoulli`\n    * :class:`~torch.distributions.Uniform` and :class:`~torch.distributions.Exponential`\n    * :class:`~torch.distributions.Uniform` and :class:`~torch.distributions.Gamma`\n    * :class:`~torch.distributions.Uniform` and :class:`~torch.distributions.Gumbel`\n    * :class:`~torch.distributions.Uniform` and :class:`~torch.distributions.Normal`\n    * :class:`~torch.distributions.Uniform` and :class:`~torch.distributions.Pareto`\n    * :class:`~torch.distributions.Uniform` and :class:`~torch.distributions.Uniform`",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "register_kl",
      "signature": "register_kl(type_p, type_q)",
      "documentation": {
        "description": "Decorator to register a pairwise function with :meth:`kl_divergence`.\nUsage::\n\n    @register_kl(Normal, Normal)\n    def kl_normal_normal(p, q):\n        # insert implementation here\n\nLookup returns the most specific (type,type) match ordered by subclass. If\nthe match is ambiguous, a `RuntimeWarning` is raised. For example to\nresolve the ambiguous situation::\n\n    @register_kl(BaseP, DerivedQ)\n    def kl_version1(p, q): ...\n    @register_kl(DerivedP, BaseQ)\n    def kl_version2(p, q): ...\n\nyou should register a third most-specific implementation, e.g.::\n\n    register_kl(DerivedP, DerivedQ)(kl_version1)  # Break the tie.",
        "parameters": {
          "type_p": {
            "type": "type",
            "description": "A subclass of :class:`~torch.distributions.Distribution`."
          },
          "type_q": {
            "type": "type",
            "description": "A subclass of :class:`~torch.distributions.Distribution`."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    }
  ],
  "classes": [
    {
      "name": "AbsTransform",
      "documentation": {
        "description": "Transform via the mapping :math:`y = |x|`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "AffineTransform",
      "documentation": {
        "description": "Transform via the pointwise affine mapping :math:`y = \\text{loc} + \\text{scale} \\times x`.",
        "parameters": {
          "loc": {
            "type": "Tensor or float",
            "description": "Location parameter."
          },
          "scale": {
            "type": "Tensor or float",
            "description": "Scale parameter."
          },
          "event_dim": {
            "type": "int",
            "description": "Optional size of `event_shape`. This should be zero"
          },
          "for": {
            "type": "",
            "description": "univariate random variables, 1 for distributions over vectors,"
          },
          "2": {
            "type": "",
            "description": "for distributions over matrices, etc."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Bernoulli",
      "documentation": {
        "description": "Creates a Bernoulli distribution parameterized by :attr:`probs`\nor :attr:`logits` (but not both).\n\nSamples are binary (0 or 1). They take the value `1` with probability `p`\nand `0` with probability `1 - p`.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = Bernoulli(torch.tensor([0.3]))\n    >>> m.sample()  # 30% chance 1; 70% chance 0\n    tensor([ 0.])",
        "parameters": {
          "probs": {
            "type": "Number, Tensor",
            "description": "the probability of sampling `1`"
          },
          "logits": {
            "type": "Number, Tensor",
            "description": "the log-odds of sampling `1`"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Method to compute the entropy using Bregman divergence of the log normalizer.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand=True)",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Beta",
      "documentation": {
        "description": "Beta distribution parameterized by :attr:`concentration1` and :attr:`concentration0`.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = Beta(torch.tensor([0.5]), torch.tensor([0.5]))\n    >>> m.sample()  # Beta distributed with concentration concentration1 and concentration0\n    tensor([ 0.1046])",
        "parameters": {
          "concentration1": {
            "type": "float or Tensor",
            "description": "1st concentration parameter of the distribution\n(often referred to as alpha)"
          },
          "concentration0": {
            "type": "float or Tensor",
            "description": "2nd concentration parameter of the distribution\n(often referred to as beta)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Method to compute the entropy using Bregman divergence of the log normalizer.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = ()) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Binomial",
      "documentation": {
        "description": "Creates a Binomial distribution parameterized by :attr:`total_count` and\neither :attr:`probs` or :attr:`logits` (but not both). :attr:`total_count` must be\nbroadcastable with :attr:`probs`/:attr:`logits`.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = Binomial(100, torch.tensor([0 , .2, .8, 1]))\n    >>> x = m.sample()\n    tensor([   0.,   22.,   71.,  100.])\n\n    >>> m = Binomial(torch.tensor([[5.], [10.]]), torch.tensor([0.5, 0.8]))\n    >>> x = m.sample()\n    tensor([[ 4.,  5.],\n            [ 7.,  6.]])",
        "parameters": {
          "total_count": {
            "type": "int or Tensor",
            "description": "number of Bernoulli trials"
          },
          "probs": {
            "type": "Tensor",
            "description": "Event probabilities"
          },
          "logits": {
            "type": "Tensor",
            "description": "Event log-odds"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand=True)",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "CatTransform",
      "documentation": {
        "description": "Transform functor that applies a sequence of transforms `tseq`\ncomponent-wise to each submatrix at `dim`, of length `lengths[dim]`,\nin a way compatible with :func:`torch.cat`.\n\nExample::\n\n   x0 = torch.cat([torch.range(1, 10), torch.range(1, 10)], dim=0)\n   x = torch.cat([x0, x0], dim=0)\n   t0 = CatTransform([ExpTransform(), identity_transform], dim=0, lengths=[10, 10])\n   t = CatTransform([t0, t0], dim=0, lengths=[20, 20])\n   y = t(x)",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Categorical",
      "documentation": {
        "description": "Creates a categorical distribution parameterized by either :attr:`probs` or\n:attr:`logits` (but not both).\n\n.. note::\n    It is equivalent to the distribution that :func:`torch.multinomial`\n    samples from.\n\nSamples are integers from :math:`\\{0, \\ldots, K-1\\}` where `K` is ``probs.size(-1)``.\n\nIf `probs` is 1-dimensional with length-`K`, each element is the relative probability\nof sampling the class at that index.\n\nIf `probs` is N-dimensional, the first N-1 dimensions are treated as a batch of\nrelative probability vectors.\n\n.. note:: The `probs` argument must be non-negative, finite and have a non-zero sum,\n          and it will be normalized to sum to 1 along the last dimension. :attr:`probs`\n          will return this normalized value.\n          The `logits` argument will be interpreted as unnormalized log probabilities\n          and can therefore be any real number. It will likewise be normalized so that\n          the resulting probabilities sum to 1 along the last dimension. :attr:`logits`\n          will return this normalized value.\n\nSee also: :func:`torch.multinomial`\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = Categorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))\n    >>> m.sample()  # equal probability of 0, 1, 2, 3\n    tensor(3)",
        "parameters": {
          "probs": {
            "type": "Tensor",
            "description": "event probabilities"
          },
          "logits": {
            "type": "Tensor",
            "description": "event log probabilities (unnormalized)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand=True)",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Cauchy",
      "documentation": {
        "description": "Samples from a Cauchy (Lorentz) distribution. The distribution of the ratio of\nindependent normally distributed random variables with means `0` follows a\nCauchy distribution.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = Cauchy(torch.tensor([0.0]), torch.tensor([1.0]))\n    >>> m.sample()  # sample from a Cauchy distribution with loc=0 and scale=1\n    tensor([ 2.3214])",
        "parameters": {
          "loc": {
            "type": "float or Tensor",
            "description": "mode or median of the distribution."
          },
          "scale": {
            "type": "float or Tensor",
            "description": "half width at half maximum."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value)",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Chi2",
      "documentation": {
        "description": "Creates a Chi-squared distribution parameterized by shape parameter :attr:`df`.\nThis is exactly equivalent to ``Gamma(alpha=0.5*df, beta=0.5)``\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = Chi2(torch.tensor([1.0]))\n    >>> m.sample()  # Chi2 distributed with shape df=1\n    tensor([ 0.1046])",
        "parameters": {
          "df": {
            "type": "float or Tensor",
            "description": "shape parameter of the distribution"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Method to compute the entropy using Bregman divergence of the log normalizer.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "ComposeTransform",
      "documentation": {
        "description": "Composes multiple transforms in a chain.\nThe transforms being composed are responsible for caching.",
        "parameters": {
          "parts": {
            "type": "list of :class:`Transform`",
            "description": "A list of transforms to compose."
          },
          "cache_size": {
            "type": "int",
            "description": "Size of cache. If zero, no caching is done. If one,"
          },
          "the": {
            "type": "",
            "description": "latest single value is cached. Only 0 and 1 are supported."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "ContinuousBernoulli",
      "documentation": {
        "description": "Creates a continuous Bernoulli distribution parameterized by :attr:`probs`\nor :attr:`logits` (but not both).\n\nThe distribution is supported in [0, 1] and parameterized by 'probs' (in\n(0,1)) or 'logits' (real-valued). Note that, unlike the Bernoulli, 'probs'\ndoes not correspond to a probability and 'logits' does not correspond to\nlog-odds, but the same names are used due to the similarity with the\nBernoulli. See [1] for more details.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = ContinuousBernoulli(torch.tensor([0.3]))\n    >>> m.sample()\n    tensor([ 0.2538])",
        "parameters": {
          "probs": {
            "type": "Number, Tensor",
            "description": "(0,1) valued parameters"
          },
          "logits": {
            "type": "Number, Tensor",
            "description": "real valued parameters whose sigmoid matches 'probs'\n[1] The continuous Bernoulli: fixing a pervasive error in variational"
          },
          "autoencoders": {
            "type": "",
            "description": ", Loaiza-Ganem G and Cunningham JP, NeurIPS 2019."
          },
          "https": {
            "type": "",
            "description": "//arxiv.org/abs/1907.06845"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Method to compute the entropy using Bregman divergence of the log normalizer.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value)",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "CorrCholeskyTransform",
      "documentation": {
        "description": "Transforms an uncontrained real vector :math:`x` with length :math:`D*(D-1)/2` into the\nCholesky factor of a D-dimension correlation matrix. This Cholesky factor is a lower\ntriangular matrix with positive diagonals and unit Euclidean norm for each row.\nThe transform is processed as follows:\n\n    1. First we convert x into a lower triangular matrix in row order.\n    2. For each row :math:`X_i` of the lower triangular part, we apply a *signed* version of\n       class :class:`StickBreakingTransform` to transform :math:`X_i` into a\n       unit Euclidean length vector using the following steps:\n       - Scales into the interval :math:`(-1, 1)` domain: :math:`r_i = \\tanh(X_i)`.\n       - Transforms into an unsigned domain: :math:`z_i = r_i^2`.\n       - Applies :math:`s_i = StickBreakingTransform(z_i)`.\n       - Transforms back into signed domain: :math:`y_i = sign(r_i) * \\sqrt{s_i}`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y, intermediates=None)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "CumulativeDistributionTransform",
      "documentation": {
        "description": "Transform via the cumulative distribution function of a probability distribution.",
        "parameters": {
          "distribution": {
            "type": "Distribution",
            "description": "Distribution whose cumulative distribution function to use for"
          },
          "the": {
            "type": "",
            "description": "transformation."
          },
          "Example": {
            "type": "",
            "description": ":\n# Construct a Gaussian copula from a multivariate normal."
          },
          "base_dist": {
            "type": "",
            "description": "= MultivariateNormal("
          },
          "loc": {
            "type": "",
            "description": "=torch.zeros(2),"
          },
          "scale_tril": {
            "type": "",
            "description": "=LKJCholesky(2).sample(),\n)"
          },
          "transform": {
            "type": "",
            "description": "= CumulativeDistributionTransform(Normal(0, 1))"
          },
          "copula": {
            "type": "",
            "description": "= TransformedDistribution(base_dist, [transform])"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Dirichlet",
      "documentation": {
        "description": "Creates a Dirichlet distribution parameterized by concentration :attr:`concentration`.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = Dirichlet(torch.tensor([0.5, 0.5]))\n    >>> m.sample()  # Dirichlet distributed with concentration [0.5, 0.5]\n    tensor([ 0.1046,  0.8954])",
        "parameters": {
          "concentration": {
            "type": "Tensor",
            "description": "concentration parameter of the distribution\n(often referred to as alpha)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Method to compute the entropy using Bregman divergence of the log normalizer.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = ()) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Distribution",
      "documentation": {
        "description": "Distribution is the abstract base class for probability distributions.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape: Union[torch.Size, List[int], Tuple[int, ...]], _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "ExpTransform",
      "documentation": {
        "description": "Transform via the mapping :math:`y = \\exp(x)`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Exponential",
      "documentation": {
        "description": "Creates a Exponential distribution parameterized by :attr:`rate`.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = Exponential(torch.tensor([1.0]))\n    >>> m.sample()  # Exponential distributed with rate=1\n    tensor([ 0.1046])",
        "parameters": {
          "rate": {
            "type": "float or Tensor",
            "description": "rate = 1 / scale of the distribution"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Method to compute the entropy using Bregman divergence of the log normalizer.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value)",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "ExponentialFamily",
      "documentation": {
        "description": "ExponentialFamily is the abstract base class for probability distributions belonging to an\nexponential family, whose probability mass/density function has the form is defined below\n\n.. math::\n\n    p_{F}(x; \\theta) = \\exp(\\langle t(x), \\theta\\rangle - F(\\theta) + k(x))\n\nwhere :math:`\\theta` denotes the natural parameters, :math:`t(x)` denotes the sufficient statistic,\n:math:`F(\\theta)` is the log normalizer function for a given family and :math:`k(x)` is the carrier\nmeasure.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "This class is an intermediary between the `Distribution` class and distributions which belong\n    to an exponential family mainly to check the correctness of the `.entropy()` and analytic KL\n    divergence methods. We use this class to compute the entropy and KL divergence using the AD\n    framework and Bregman divergences (courtesy of: Frank Nielsen and Richard Nock, Entropies and\n    Cross-entropies of Exponential Families).",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Method to compute the entropy using Bregman divergence of the log normalizer.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape: Union[torch.Size, List[int], Tuple[int, ...]], _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "FisherSnedecor",
      "documentation": {
        "description": "Creates a Fisher-Snedecor distribution parameterized by :attr:`df1` and :attr:`df2`.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = FisherSnedecor(torch.tensor([1.0]), torch.tensor([2.0]))\n    >>> m.sample()  # Fisher-Snedecor-distributed with df1=1 and df2=2\n    tensor([ 0.2453])",
        "parameters": {
          "df1": {
            "type": "float or Tensor",
            "description": "degrees of freedom parameter 1"
          },
          "df2": {
            "type": "float or Tensor",
            "description": "degrees of freedom parameter 2"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Gamma",
      "documentation": {
        "description": "Creates a Gamma distribution parameterized by shape :attr:`concentration` and :attr:`rate`.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = Gamma(torch.tensor([1.0]), torch.tensor([1.0]))\n    >>> m.sample()  # Gamma distributed with concentration=1 and rate=1\n    tensor([ 0.1046])",
        "parameters": {
          "concentration": {
            "type": "float or Tensor",
            "description": "shape parameter of the distribution\n(often referred to as alpha)"
          },
          "rate": {
            "type": "float or Tensor",
            "description": "rate parameter of the distribution\n(often referred to as beta), rate = 1 / scale"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Method to compute the entropy using Bregman divergence of the log normalizer.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Geometric",
      "documentation": {
        "description": "Creates a Geometric distribution parameterized by :attr:`probs`,\nwhere :attr:`probs` is the probability of success of Bernoulli trials.\n\n.. math::\n\n    P(X=k) = (1-p)^{k} p, k = 0, 1, ...\n\n.. note::\n    :func:`torch.distributions.geometric.Geometric` :math:`(k+1)`-th trial is the first success\n    hence draws samples in :math:`\\{0, 1, \\ldots\\}`, whereas\n    :func:`torch.Tensor.geometric_` `k`-th trial is the first success hence draws samples in :math:`\\{1, 2, \\ldots\\}`.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = Geometric(torch.tensor([0.3]))\n    >>> m.sample()  # underlying Bernoulli has 30% chance 1; 70% chance 0\n    tensor([ 2.])",
        "parameters": {
          "probs": {
            "type": "Number, Tensor",
            "description": "the probability of sampling `1`. Must be in range (0, 1]"
          },
          "logits": {
            "type": "Number, Tensor",
            "description": "the log-odds of sampling `1`."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Gumbel",
      "documentation": {
        "description": "Samples from a Gumbel Distribution.",
        "parameters": {
          "loc": {
            "type": "float or Tensor",
            "description": "Location parameter of the distribution"
          },
          "scale": {
            "type": "float or Tensor",
            "description": "Scale parameter of the distribution"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Computes the cumulative distribution function by inverting the\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value)",
          "documentation": {
            "description": "Computes the inverse cumulative distribution function using\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Scores the sample by inverting the transform(s) and computing the score\nusing the score of the base distribution and the log abs det jacobian.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched. Samples first from base distribution and applies\n`transform()` for every transform in the list.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched. Samples first from\nbase distribution and applies `transform()` for every transform in the\nlist.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "HalfCauchy",
      "documentation": {
        "description": "Creates a half-Cauchy distribution parameterized by `scale` where::\n\n    X ~ Cauchy(0, scale)\n    Y = |X| ~ HalfCauchy(scale)\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = HalfCauchy(torch.tensor([1.0]))\n    >>> m.sample()  # half-cauchy distributed with scale=1\n    tensor([ 2.3214])",
        "parameters": {
          "scale": {
            "type": "float or Tensor",
            "description": "scale of the full Cauchy distribution"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Computes the cumulative distribution function by inverting the\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, prob)",
          "documentation": {
            "description": "Computes the inverse cumulative distribution function using\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Scores the sample by inverting the transform(s) and computing the score\nusing the score of the base distribution and the log abs det jacobian.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched. Samples first from base distribution and applies\n`transform()` for every transform in the list.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched. Samples first from\nbase distribution and applies `transform()` for every transform in the\nlist.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "HalfNormal",
      "documentation": {
        "description": "Creates a half-normal distribution parameterized by `scale` where::\n\n    X ~ Normal(0, scale)\n    Y = |X| ~ HalfNormal(scale)\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = HalfNormal(torch.tensor([1.0]))\n    >>> m.sample()  # half-normal distributed with scale=1\n    tensor([ 0.1046])",
        "parameters": {
          "scale": {
            "type": "float or Tensor",
            "description": "scale of the full Normal distribution"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Computes the cumulative distribution function by inverting the\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, prob)",
          "documentation": {
            "description": "Computes the inverse cumulative distribution function using\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Scores the sample by inverting the transform(s) and computing the score\nusing the score of the base distribution and the log abs det jacobian.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched. Samples first from base distribution and applies\n`transform()` for every transform in the list.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched. Samples first from\nbase distribution and applies `transform()` for every transform in the\nlist.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Independent",
      "documentation": {
        "description": "Reinterprets some of the batch dims of a distribution as event dims.\n\nThis is mainly useful for changing the shape of the result of\n:meth:`log_prob`. For example to create a diagonal Normal distribution with\nthe same shape as a Multivariate Normal distribution (so they are\ninterchangeable), you can::\n\n    >>> from torch.distributions.multivariate_normal import MultivariateNormal\n    >>> from torch.distributions.normal import Normal\n    >>> loc = torch.zeros(3)\n    >>> scale = torch.ones(3)\n    >>> mvn = MultivariateNormal(loc, scale_tril=torch.diag(scale))\n    >>> [mvn.batch_shape, mvn.event_shape]\n    [torch.Size([]), torch.Size([3])]\n    >>> normal = Normal(loc, scale)\n    >>> [normal.batch_shape, normal.event_shape]\n    [torch.Size([3]), torch.Size([])]\n    >>> diagn = Independent(normal, 1)\n    >>> [diagn.batch_shape, diagn.event_shape]\n    [torch.Size([]), torch.Size([3])]",
        "parameters": {
          "base_distribution": {
            "type": "torch.distributions.distribution.Distribution",
            "description": "a"
          },
          "base": {
            "type": "",
            "description": "distribution"
          },
          "reinterpreted_batch_ndims": {
            "type": "int",
            "description": "the number of batch dims to"
          },
          "reinterpret": {
            "type": "",
            "description": "as event dims"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand=True)",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "IndependentTransform",
      "documentation": {
        "description": "Wrapper around another transform to treat\n``reinterpreted_batch_ndims``-many extra of the right most dimensions as\ndependent. This has no effect on the forward or backward transforms, but\ndoes sum out ``reinterpreted_batch_ndims``-many of the rightmost dimensions\nin :meth:`log_abs_det_jacobian`.",
        "parameters": {
          "base_transform": {
            "type": ":class:`Transform`",
            "description": "A base transform."
          },
          "reinterpreted_batch_ndims": {
            "type": "int",
            "description": "The number of extra rightmost"
          },
          "dimensions": {
            "type": "",
            "description": "to treat as dependent."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "InverseGamma",
      "documentation": {
        "description": "Creates an inverse gamma distribution parameterized by :attr:`concentration` and :attr:`rate`\nwhere::\n\n    X ~ Gamma(concentration, rate)\n    Y = 1 / X ~ InverseGamma(concentration, rate)\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterinistic\")\n    >>> m = InverseGamma(torch.tensor([2.0]), torch.tensor([3.0]))\n    >>> m.sample()\n    tensor([ 1.2953])",
        "parameters": {
          "concentration": {
            "type": "float or Tensor",
            "description": "shape parameter of the distribution\n(often referred to as alpha)"
          },
          "rate": {
            "type": "float or Tensor",
            "description": "rate = 1 / scale of the distribution\n(often referred to as beta)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Computes the cumulative distribution function by inverting the\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value)",
          "documentation": {
            "description": "Computes the inverse cumulative distribution function using\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Scores the sample by inverting the transform(s) and computing the score\nusing the score of the base distribution and the log abs det jacobian.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched. Samples first from base distribution and applies\n`transform()` for every transform in the list.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched. Samples first from\nbase distribution and applies `transform()` for every transform in the\nlist.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Kumaraswamy",
      "documentation": {
        "description": "Samples from a Kumaraswamy distribution.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = Kumaraswamy(torch.tensor([1.0]), torch.tensor([1.0]))\n    >>> m.sample()  # sample from a Kumaraswamy distribution with concentration alpha=1 and beta=1\n    tensor([ 0.1729])",
        "parameters": {
          "concentration1": {
            "type": "float or Tensor",
            "description": "1st concentration parameter of the distribution\n(often referred to as alpha)"
          },
          "concentration0": {
            "type": "float or Tensor",
            "description": "2nd concentration parameter of the distribution\n(often referred to as beta)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Computes the cumulative distribution function by inverting the\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value)",
          "documentation": {
            "description": "Computes the inverse cumulative distribution function using\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Scores the sample by inverting the transform(s) and computing the score\nusing the score of the base distribution and the log abs det jacobian.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched. Samples first from base distribution and applies\n`transform()` for every transform in the list.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched. Samples first from\nbase distribution and applies `transform()` for every transform in the\nlist.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "LKJCholesky",
      "documentation": {
        "description": "LKJ distribution for lower Cholesky factor of correlation matrices.\nThe distribution is controlled by ``concentration`` parameter :math:`\\eta`\nto make the probability of the correlation matrix :math:`M` generated from\na Cholesky factor proportional to :math:`\\det(M)^{\\eta - 1}`. Because of that,\nwhen ``concentration == 1``, we have a uniform distribution over Cholesky\nfactors of correlation matrices::\n\n    L ~ LKJCholesky(dim, concentration)\n    X = L @ L' ~ LKJCorr(dim, concentration)\n\nNote that this distribution samples the\nCholesky factor of correlation matrices and not the correlation matrices\nthemselves and thereby differs slightly from the derivations in [1] for\nthe `LKJCorr` distribution. For sampling, this uses the Onion method from\n[1] Section 3.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> l = LKJCholesky(3, 0.5)\n    >>> l.sample()  # l @ l.T is a sample of a correlation 3x3 matrix\n    tensor([[ 1.0000,  0.0000,  0.0000],\n            [ 0.3516,  0.9361,  0.0000],\n            [-0.1899,  0.4748,  0.8593]])",
        "parameters": {
          "dimension": {
            "type": "dim",
            "description": "dimension of the matrices"
          },
          "concentration": {
            "type": "float or Tensor",
            "description": "concentration/shape parameter of the"
          },
          "distribution": {
            "type": "often referred to as eta",
            "description": "**References**\n[1] `Generating random correlation matrices based on vines and extended onion method` (2009),"
          },
          "Daniel": {
            "type": "",
            "description": "Lewandowski, Dorota Kurowicka, Harry Joe."
          },
          "Journal": {
            "type": "",
            "description": "of Multivariate Analysis. 100. 10.1016/j.jmva.2009.04.008"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Laplace",
      "documentation": {
        "description": "Creates a Laplace distribution parameterized by :attr:`loc` and :attr:`scale`.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = Laplace(torch.tensor([0.0]), torch.tensor([1.0]))\n    >>> m.sample()  # Laplace distributed with loc=0, scale=1\n    tensor([ 0.1046])",
        "parameters": {
          "loc": {
            "type": "float or Tensor",
            "description": "mean of the distribution"
          },
          "scale": {
            "type": "float or Tensor",
            "description": "scale of the distribution"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value)",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "LogNormal",
      "documentation": {
        "description": "Creates a log-normal distribution parameterized by\n:attr:`loc` and :attr:`scale` where::\n\n    X ~ Normal(loc, scale)\n    Y = exp(X) ~ LogNormal(loc, scale)\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = LogNormal(torch.tensor([0.0]), torch.tensor([1.0]))\n    >>> m.sample()  # log-normal distributed with mean=0 and stddev=1\n    tensor([ 0.1046])",
        "parameters": {
          "loc": {
            "type": "float or Tensor",
            "description": "mean of log of distribution"
          },
          "scale": {
            "type": "float or Tensor",
            "description": "standard deviation of log of the distribution"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Computes the cumulative distribution function by inverting the\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value)",
          "documentation": {
            "description": "Computes the inverse cumulative distribution function using\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Scores the sample by inverting the transform(s) and computing the score\nusing the score of the base distribution and the log abs det jacobian.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched. Samples first from base distribution and applies\n`transform()` for every transform in the list.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched. Samples first from\nbase distribution and applies `transform()` for every transform in the\nlist.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "LogisticNormal",
      "documentation": {
        "description": "Creates a logistic-normal distribution parameterized by :attr:`loc` and :attr:`scale`\nthat define the base `Normal` distribution transformed with the\n`StickBreakingTransform` such that::\n\n    X ~ LogisticNormal(loc, scale)\n    Y = log(X / (1 - X.cumsum(-1)))[..., :-1] ~ Normal(loc, scale)",
        "parameters": {
          "loc": {
            "type": "float or Tensor",
            "description": "mean of the base distribution"
          },
          "scale": {
            "type": "float or Tensor",
            "description": "standard deviation of the base distribution"
          },
          "Example": {
            "type": "",
            "description": ":\n>>> # logistic-normal distributed with mean=(0, 0, 0) and stddev=(1, 1, 1)\n>>> # of the base Normal distribution\n>>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n>>> m = LogisticNormal(torch.tensor([0.0] * 3), torch.tensor([1.0] * 3))\n>>> m.sample()"
          },
          "tensor": {
            "type": "[ 0.7653,  0.0341,  0.0579,  0.1427]",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Computes the cumulative distribution function by inverting the\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value)",
          "documentation": {
            "description": "Computes the inverse cumulative distribution function using\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Scores the sample by inverting the transform(s) and computing the score\nusing the score of the base distribution and the log abs det jacobian.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched. Samples first from base distribution and applies\n`transform()` for every transform in the list.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched. Samples first from\nbase distribution and applies `transform()` for every transform in the\nlist.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "LowRankMultivariateNormal",
      "documentation": {
        "description": "Creates a multivariate normal distribution with covariance matrix having a low-rank form\nparameterized by :attr:`cov_factor` and :attr:`cov_diag`::\n\n    covariance_matrix = cov_factor @ cov_factor.T + cov_diag\n\nExample:\n    >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_LAPACK)\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = LowRankMultivariateNormal(torch.zeros(2), torch.tensor([[1.], [0.]]), torch.ones(2))\n    >>> m.sample()  # normally distributed with mean=`[0,0]`, cov_factor=`[[1],[0]]`, cov_diag=`[1,1]`\n    tensor([-0.2102, -0.5429])",
        "parameters": {
          "loc": {
            "type": "Tensor",
            "description": "mean of the distribution with shape `batch_shape + event_shape`"
          },
          "cov_factor": {
            "type": "Tensor",
            "description": "factor part of low-rank form of covariance matrix with shape\n`batch_shape + event_shape + (rank,)`"
          },
          "cov_diag": {
            "type": "Tensor",
            "description": "diagonal part of low-rank form of covariance matrix with shape\n`batch_shape + event_shape`"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "The computation for determinant and inverse of covariance matrix is avoided when\n    `cov_factor.shape[1] << cov_factor.shape[0]` thanks to `Woodbury matrix identity\n    <https://en.wikipedia.org/wiki/Woodbury_matrix_identity>`_ and\n    `matrix determinant lemma <https://en.wikipedia.org/wiki/Matrix_determinant_lemma>`_.\n    Thanks to these formulas, we just need to compute the determinant and inverse of\n    the small size \"capacitance\" matrix::\n\n        capacitance = I + cov_factor.T @ inv(cov_diag) @ cov_factor",
        "examples": ">>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_LAPACK)\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = LowRankMultivariateNormal(torch.zeros(2), torch.tensor([[1.], [0.]]), torch.ones(2))\n    >>> m.sample()  # normally distributed with mean=`[0,0]`, cov_factor=`[[1],[0]]`, cov_diag=`[1,1]`\n    tensor([-0.2102, -0.5429])\n\nArgs:\n    loc (Tensor): mean of the distribution with shape `batch_shape + event_shape`\n    cov_factor (Tensor): factor part of low-rank form of covariance matrix with shape\n        `batch_shape + event_shape + (rank,)`\n    cov_diag (Tensor): diagonal part of low-rank form of covariance matrix with shape\n        `batch_shape + event_shape`"
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "LowerCholeskyTransform",
      "documentation": {
        "description": "Transform from unconstrained matrices to lower-triangular matrices with\nnonnegative diagonal entries.\n\nThis is useful for parameterizing positive definite matrices in terms of\ntheir Cholesky factorization.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "MixtureSameFamily",
      "documentation": {
        "description": "The `MixtureSameFamily` distribution implements a (batch of) mixture\ndistribution where all component are from different parameterizations of\nthe same distribution type. It is parameterized by a `Categorical`\n\"selecting distribution\" (over `k` component) and a component\ndistribution, i.e., a `Distribution` with a rightmost batch shape\n(equal to `[k]`) which indexes each (batch of) component.",
        "parameters": {
          "mixture_distribution": {
            "type": "",
            "description": "`torch.distributions.Categorical`-like"
          },
          "instance": {
            "type": "",
            "description": ". Right-most batch dimension indexes component."
          },
          "The": {
            "type": "",
            "description": "number of categories must match the rightmost batch"
          },
          "dimension": {
            "type": "",
            "description": "of the `component_distribution`. Must have either"
          },
          "scalar": {
            "type": "",
            "description": "`batch_shape` or `batch_shape` matching\n`component_distribution.batch_shape[:-1]`"
          },
          "component_distribution": {
            "type": "",
            "description": "`torch.distributions.Distribution`-like"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, x)",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, x)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Multinomial",
      "documentation": {
        "description": "Creates a Multinomial distribution parameterized by :attr:`total_count` and\neither :attr:`probs` or :attr:`logits` (but not both). The innermost dimension of\n:attr:`probs` indexes over categories. All other dimensions index over batches.\n\nNote that :attr:`total_count` need not be specified if only :meth:`log_prob` is\ncalled (see example below)\n\n.. note:: The `probs` argument must be non-negative, finite and have a non-zero sum,\n          and it will be normalized to sum to 1 along the last dimension. :attr:`probs`\n          will return this normalized value.\n          The `logits` argument will be interpreted as unnormalized log probabilities\n          and can therefore be any real number. It will likewise be normalized so that\n          the resulting probabilities sum to 1 along the last dimension. :attr:`logits`\n          will return this normalized value.\n\n-   :meth:`sample` requires a single shared `total_count` for all\n    parameters and samples.\n-   :meth:`log_prob` allows different `total_count` for each parameter and\n    sample.\n\nExample::\n\n    >>> # xdoctest: +SKIP(\"FIXME: found invalid values\")\n    >>> m = Multinomial(100, torch.tensor([ 1., 1., 1., 1.]))\n    >>> x = m.sample()  # equal probability of 0, 1, 2, 3\n    tensor([ 21.,  24.,  30.,  25.])\n\n    >>> Multinomial(probs=torch.tensor([1., 1., 1., 1.])).log_prob(x)\n    tensor([-4.1338])",
        "parameters": {
          "total_count": {
            "type": "int",
            "description": "number of trials"
          },
          "probs": {
            "type": "Tensor",
            "description": "event probabilities"
          },
          "logits": {
            "type": "Tensor",
            "description": "event log probabilities (unnormalized)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "MultivariateNormal",
      "documentation": {
        "description": "Creates a multivariate normal (also called Gaussian) distribution\nparameterized by a mean vector and a covariance matrix.\n\nThe multivariate normal distribution can be parameterized either\nin terms of a positive definite covariance matrix :math:`\\mathbf{\\Sigma}`\nor a positive definite precision matrix :math:`\\mathbf{\\Sigma}^{-1}`\nor a lower-triangular matrix :math:`\\mathbf{L}` with positive-valued\ndiagonal entries, such that\n:math:`\\mathbf{\\Sigma} = \\mathbf{L}\\mathbf{L}^\\top`. This triangular matrix\ncan be obtained via e.g. Cholesky decomposition of the covariance.\n\nExample:\n\n    >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_LAPACK)\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = MultivariateNormal(torch.zeros(2), torch.eye(2))\n    >>> m.sample()  # normally distributed with mean=`[0,0]` and covariance_matrix=`I`\n    tensor([-0.2102, -0.5429])",
        "parameters": {
          "loc": {
            "type": "Tensor",
            "description": "mean of the distribution"
          },
          "covariance_matrix": {
            "type": "Tensor",
            "description": "positive-definite covariance matrix"
          },
          "precision_matrix": {
            "type": "Tensor",
            "description": "positive-definite precision matrix"
          },
          "scale_tril": {
            "type": "Tensor",
            "description": "lower-triangular factor of covariance, with positive-valued diagonal"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "Only one of :attr:`covariance_matrix` or :attr:`precision_matrix` or\n    :attr:`scale_tril` can be specified.\n\n    Using :attr:`scale_tril` will be more efficient: all computations internally\n    are based on :attr:`scale_tril`. If :attr:`covariance_matrix` or\n    :attr:`precision_matrix` is passed instead, it is only used to compute\n    the corresponding lower triangular matrices using a Cholesky decomposition.",
        "examples": ">>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_LAPACK)\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = MultivariateNormal(torch.zeros(2), torch.eye(2))\n    >>> m.sample()  # normally distributed with mean=`[0,0]` and covariance_matrix=`I`\n    tensor([-0.2102, -0.5429])\n\nArgs:\n    loc (Tensor): mean of the distribution\n    covariance_matrix (Tensor): positive-definite covariance matrix\n    precision_matrix (Tensor): positive-definite precision matrix\n    scale_tril (Tensor): lower-triangular factor of covariance, with positive-valued diagonal"
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "NegativeBinomial",
      "documentation": {
        "description": "Creates a Negative Binomial distribution, i.e. distribution\nof the number of successful independent and identical Bernoulli trials\nbefore :attr:`total_count` failures are achieved. The probability\nof success of each Bernoulli trial is :attr:`probs`.",
        "parameters": {
          "total_count": {
            "type": "float or Tensor",
            "description": "non-negative number of negative Bernoulli"
          },
          "trials": {
            "type": "",
            "description": "to stop, although the distribution is still valid for real"
          },
          "valued": {
            "type": "",
            "description": "count"
          },
          "probs": {
            "type": "Tensor",
            "description": "Event probabilities of success in the half open interval [0, 1)"
          },
          "logits": {
            "type": "Tensor",
            "description": "Event log-odds for probabilities of success"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Normal",
      "documentation": {
        "description": "Creates a normal (also called Gaussian) distribution parameterized by\n:attr:`loc` and :attr:`scale`.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n    >>> m.sample()  # normally distributed with loc=0 and scale=1\n    tensor([ 0.1046])",
        "parameters": {
          "loc": {
            "type": "float or Tensor",
            "description": "mean of the distribution (often referred to as mu)"
          },
          "scale": {
            "type": "float or Tensor",
            "description": "standard deviation of the distribution\n(often referred to as sigma)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Method to compute the entropy using Bregman divergence of the log normalizer.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value)",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "OneHotCategorical",
      "documentation": {
        "description": "Creates a one-hot categorical distribution parameterized by :attr:`probs` or\n:attr:`logits`.\n\nSamples are one-hot coded vectors of size ``probs.size(-1)``.\n\n.. note:: The `probs` argument must be non-negative, finite and have a non-zero sum,\n          and it will be normalized to sum to 1 along the last dimension. :attr:`probs`\n          will return this normalized value.\n          The `logits` argument will be interpreted as unnormalized log probabilities\n          and can therefore be any real number. It will likewise be normalized so that\n          the resulting probabilities sum to 1 along the last dimension. :attr:`logits`\n          will return this normalized value.\n\nSee also: :func:`torch.distributions.Categorical` for specifications of\n:attr:`probs` and :attr:`logits`.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = OneHotCategorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))\n    >>> m.sample()  # equal probability of 0, 1, 2, 3\n    tensor([ 0.,  0.,  0.,  1.])",
        "parameters": {
          "probs": {
            "type": "Tensor",
            "description": "event probabilities"
          },
          "logits": {
            "type": "Tensor",
            "description": "event log probabilities (unnormalized)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand=True)",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "OneHotCategoricalStraightThrough",
      "documentation": {
        "description": "Creates a reparameterizable :class:`OneHotCategorical` distribution based on the straight-\nthrough gradient estimator from [1].\n\n[1] Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation\n(Bengio et al., 2013)",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand=True)",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Pareto",
      "documentation": {
        "description": "Samples from a Pareto Type 1 distribution.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = Pareto(torch.tensor([1.0]), torch.tensor([1.0]))\n    >>> m.sample()  # sample from a Pareto distribution with scale=1 and alpha=1\n    tensor([ 1.5623])",
        "parameters": {
          "scale": {
            "type": "float or Tensor",
            "description": "Scale parameter of the distribution"
          },
          "alpha": {
            "type": "float or Tensor",
            "description": "Shape parameter of the distribution"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Computes the cumulative distribution function by inverting the\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value)",
          "documentation": {
            "description": "Computes the inverse cumulative distribution function using\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Scores the sample by inverting the transform(s) and computing the score\nusing the score of the base distribution and the log abs det jacobian.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched. Samples first from base distribution and applies\n`transform()` for every transform in the list.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched. Samples first from\nbase distribution and applies `transform()` for every transform in the\nlist.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Poisson",
      "documentation": {
        "description": "Creates a Poisson distribution parameterized by :attr:`rate`, the rate parameter.\n\nSamples are nonnegative integers, with a pmf given by\n\n.. math::\n  \\mathrm{rate}^k \\frac{e^{-\\mathrm{rate}}}{k!}\n\nExample::\n\n    >>> # xdoctest: +SKIP(\"poisson_cpu not implemented for 'Long'\")\n    >>> m = Poisson(torch.tensor([4]))\n    >>> m.sample()\n    tensor([ 3.])",
        "parameters": {
          "rate": {
            "type": "Number, Tensor",
            "description": "the rate parameter"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Method to compute the entropy using Bregman divergence of the log normalizer.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "PositiveDefiniteTransform",
      "documentation": {
        "description": "Transform from unconstrained matrices to positive-definite matrices.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "PowerTransform",
      "documentation": {
        "description": "Transform via the mapping :math:`y = x^{\\text{exponent}}`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "RelaxedBernoulli",
      "documentation": {
        "description": "Creates a RelaxedBernoulli distribution, parametrized by\n:attr:`temperature`, and either :attr:`probs` or :attr:`logits`\n(but not both). This is a relaxed version of the `Bernoulli` distribution,\nso the values are in (0, 1), and has reparametrizable samples.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = RelaxedBernoulli(torch.tensor([2.2]),\n    ...                      torch.tensor([0.1, 0.2, 0.3, 0.99]))\n    >>> m.sample()\n    tensor([ 0.2951,  0.3442,  0.8918,  0.9021])",
        "parameters": {
          "temperature": {
            "type": "Tensor",
            "description": "relaxation temperature"
          },
          "probs": {
            "type": "Number, Tensor",
            "description": "the probability of sampling `1`"
          },
          "logits": {
            "type": "Number, Tensor",
            "description": "the log-odds of sampling `1`"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Computes the cumulative distribution function by inverting the\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value)",
          "documentation": {
            "description": "Computes the inverse cumulative distribution function using\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Scores the sample by inverting the transform(s) and computing the score\nusing the score of the base distribution and the log abs det jacobian.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched. Samples first from base distribution and applies\n`transform()` for every transform in the list.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched. Samples first from\nbase distribution and applies `transform()` for every transform in the\nlist.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "RelaxedOneHotCategorical",
      "documentation": {
        "description": "Creates a RelaxedOneHotCategorical distribution parametrized by\n:attr:`temperature`, and either :attr:`probs` or :attr:`logits`.\nThis is a relaxed version of the :class:`OneHotCategorical` distribution, so\nits samples are on simplex, and are reparametrizable.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = RelaxedOneHotCategorical(torch.tensor([2.2]),\n    ...                              torch.tensor([0.1, 0.2, 0.3, 0.4]))\n    >>> m.sample()\n    tensor([ 0.1294,  0.2324,  0.3859,  0.2523])",
        "parameters": {
          "temperature": {
            "type": "Tensor",
            "description": "relaxation temperature"
          },
          "probs": {
            "type": "Tensor",
            "description": "event probabilities"
          },
          "logits": {
            "type": "Tensor",
            "description": "unnormalized log probability for each event"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Computes the cumulative distribution function by inverting the\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value)",
          "documentation": {
            "description": "Computes the inverse cumulative distribution function using\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Scores the sample by inverting the transform(s) and computing the score\nusing the score of the base distribution and the log abs det jacobian.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched. Samples first from base distribution and applies\n`transform()` for every transform in the list.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched. Samples first from\nbase distribution and applies `transform()` for every transform in the\nlist.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "ReshapeTransform",
      "documentation": {
        "description": "Unit Jacobian transform to reshape the rightmost part of a tensor.\n\nNote that ``in_shape`` and ``out_shape`` must have the same number of\nelements, just as for :meth:`torch.Tensor.reshape`.",
        "parameters": {
          "in_shape": {
            "type": "torch.Size",
            "description": "The input event shape."
          },
          "out_shape": {
            "type": "torch.Size",
            "description": "The output event shape."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "SigmoidTransform",
      "documentation": {
        "description": "Transform via the mapping :math:`y = \\frac{1}{1 + \\exp(-x)}` and :math:`x = \\text{logit}(y)`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "SoftmaxTransform",
      "documentation": {
        "description": "Transform from unconstrained space to the simplex via :math:`y = \\exp(x)` then\nnormalizing.\n\nThis is not bijective and cannot be used for HMC. However this acts mostly\ncoordinate-wise (except for the final normalization), and thus is\nappropriate for coordinate-wise optimization algorithms.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "SoftplusTransform",
      "documentation": {
        "description": "Transform via the mapping :math:`\\text{Softplus}(x) = \\log(1 + \\exp(x))`.\nThe implementation reverts to the linear function when :math:`x > 20`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "StackTransform",
      "documentation": {
        "description": "Transform functor that applies a sequence of transforms `tseq`\ncomponent-wise to each submatrix at `dim`\nin a way compatible with :func:`torch.stack`.\n\nExample::\n\n   x = torch.stack([torch.range(1, 10), torch.range(1, 10)], dim=1)\n   t = StackTransform([ExpTransform(), identity_transform], dim=1)\n   y = t(x)",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "StickBreakingTransform",
      "documentation": {
        "description": "Transform from unconstrained space to the simplex of one additional\ndimension via a stick-breaking process.\n\nThis transform arises as an iterated sigmoid transform in a stick-breaking\nconstruction of the `Dirichlet` distribution: the first logit is\ntransformed via sigmoid to the first probability and the probability of\neverything else, and then the process recurses.\n\nThis is bijective and appropriate for use in HMC; however it mixes\ncoordinates together and is less appropriate for optimization.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "StudentT",
      "documentation": {
        "description": "Creates a Student's t-distribution parameterized by degree of\nfreedom :attr:`df`, mean :attr:`loc` and scale :attr:`scale`.\n\nExample::\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = StudentT(torch.tensor([2.0]))\n    >>> m.sample()  # Student's t-distributed with degrees of freedom=2\n    tensor([ 0.1046])",
        "parameters": {
          "df": {
            "type": "float or Tensor",
            "description": "degrees of freedom"
          },
          "loc": {
            "type": "float or Tensor",
            "description": "mean of the distribution"
          },
          "scale": {
            "type": "float or Tensor",
            "description": "scale of the distribution"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "TanhTransform",
      "documentation": {
        "description": "Transform via the mapping :math:`y = \\tanh(x)`.\n\nIt is equivalent to\n```\nComposeTransform([AffineTransform(0., 2.), SigmoidTransform(), AffineTransform(-1., 2.)])\n```\nHowever this might not be numerically stable, thus it is recommended to use `TanhTransform`\ninstead.\n\nNote that one should use `cache_size=1` when it comes to `NaN/Inf` values.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Transform",
      "documentation": {
        "description": "Abstract class for invertable transformations with computable log\ndet jacobians. They are primarily used in\n:class:`torch.distributions.TransformedDistribution`.\n\nCaching is useful for transforms whose inverses are either expensive or\nnumerically unstable. Note that care must be taken with memoized values\nsince the autograd graph may be reversed. For example while the following\nworks with or without caching::\n\n    y = t(x)\n    t.log_abs_det_jacobian(x, y).backward()  # x will receive gradients.\n\nHowever the following will error when caching due to dependency reversal::\n\n    y = t(x)\n    z = t.inv(y)\n    grad(z.sum(), [y])  # error because z is x\n\nDerived classes should implement one or both of :meth:`_call` or\n:meth:`_inverse`. Derived classes that set `bijective=True` should also\nimplement :meth:`log_abs_det_jacobian`.",
        "parameters": {
          "cache_size": {
            "type": "int",
            "description": "Size of cache. If zero, no caching is done. If one,"
          },
          "the": {
            "type": "",
            "description": "codomain. Transforms that are not bijective should at least"
          },
          "Attributes": {
            "type": "",
            "description": ""
          },
          "domain": {
            "type": ":class:`~torch.distributions.constraints.Constraint`",
            "description": ""
          },
          "The": {
            "type": "",
            "description": "constraint representing valid outputs to this transform"
          },
          "codomain": {
            "type": ":class:`~torch.distributions.constraints.Constraint`",
            "description": ""
          },
          "which": {
            "type": "",
            "description": "are inputs to the inverse transform."
          },
          "bijective": {
            "type": "bool",
            "description": "Whether this transform is bijective. A transform\n``t`` is bijective iff ``t.inv(t(x)) == x`` and\n``t(t.inv(y)) == y`` for every ``x`` in the domain and ``y`` in"
          },
          "maintain": {
            "type": "",
            "description": "the weaker pseudoinverse properties\n``t(t.inv(t(x)) == t(x)`` and ``t.inv(t(t.inv(y))) == t.inv(y)``."
          },
          "sign": {
            "type": "int or Tensor",
            "description": "For bijective univariate transforms, this"
          },
          "should": {
            "type": "",
            "description": "be +1 or -1 depending on whether transform is monotone"
          },
          "increasing": {
            "type": "",
            "description": "or decreasing."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "forward_shape",
          "signature": "forward_shape(self, shape)",
          "documentation": {
            "description": "Infers the shape of the forward computation, given the input shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_shape",
          "signature": "inverse_shape(self, shape)",
          "documentation": {
            "description": "Infers the shapes of the inverse computation, given the output shape.\nDefaults to preserving shape.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_abs_det_jacobian",
          "signature": "log_abs_det_jacobian(self, x, y)",
          "documentation": {
            "description": "Computes the log det jacobian `log |dy/dx|` given input and output.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_cache",
          "signature": "with_cache(self, cache_size=1)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "TransformedDistribution",
      "documentation": {
        "description": "Extension of the Distribution class, which applies a sequence of Transforms\nto a base distribution.  Let f be the composition of transforms applied::\n\n    X ~ BaseDistribution\n    Y = f(X) ~ TransformedDistribution(BaseDistribution, f)\n    log p(Y) = log p(X) + log |det (dX/dY)|\n\nNote that the ``.event_shape`` of a :class:`TransformedDistribution` is the\nmaximum shape of its base distribution and its transforms, since transforms\ncan introduce correlations among events.\n\nAn example for the usage of :class:`TransformedDistribution` would be::\n\n    # Building a Logistic Distribution\n    # X ~ Uniform(0, 1)\n    # f = a + b * logit(X)\n    # Y ~ f(X) ~ Logistic(a, b)\n    base_distribution = Uniform(0, 1)\n    transforms = [SigmoidTransform().inv, AffineTransform(loc=a, scale=b)]\n    logistic = TransformedDistribution(base_distribution, transforms)\n\nFor more examples, please look at the implementations of\n:class:`~torch.distributions.gumbel.Gumbel`,\n:class:`~torch.distributions.half_cauchy.HalfCauchy`,\n:class:`~torch.distributions.half_normal.HalfNormal`,\n:class:`~torch.distributions.log_normal.LogNormal`,\n:class:`~torch.distributions.pareto.Pareto`,\n:class:`~torch.distributions.weibull.Weibull`,\n:class:`~torch.distributions.relaxed_bernoulli.RelaxedBernoulli` and\n:class:`~torch.distributions.relaxed_categorical.RelaxedOneHotCategorical`",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Computes the cumulative distribution function by inverting the\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value)",
          "documentation": {
            "description": "Computes the inverse cumulative distribution function using\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Scores the sample by inverting the transform(s) and computing the score\nusing the score of the base distribution and the log abs det jacobian.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched. Samples first from base distribution and applies\n`transform()` for every transform in the list.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched. Samples first from\nbase distribution and applies `transform()` for every transform in the\nlist.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Uniform",
      "documentation": {
        "description": "Generates uniformly distributed random samples from the half-open interval\n``[low, high)``.\n\nExample::\n\n    >>> m = Uniform(torch.tensor([0.0]), torch.tensor([5.0]))\n    >>> m.sample()  # uniformly distributed in the range [0.0, 5.0)\n    >>> # xdoctest: +SKIP\n    tensor([ 2.3418])",
        "parameters": {
          "low": {
            "type": "float or Tensor",
            "description": "lower range (inclusive)."
          },
          "high": {
            "type": "float or Tensor",
            "description": "upper range (exclusive)."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value)",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "VonMises",
      "documentation": {
        "description": "A circular von Mises distribution.\n\nThis implementation uses polar coordinates. The ``loc`` and ``value`` args\ncan be any real number (to facilitate unconstrained optimization), but are\ninterpreted as angles modulo 2 pi.\n\nExample::\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = VonMises(torch.tensor([1.0]), torch.tensor([1.0]))\n    >>> m.sample()  # von Mises distributed with loc=1 and concentration=1\n    tensor([1.9777])\n\n:param torch.Tensor loc: an angle in radians.\n:param torch.Tensor concentration: concentration parameter",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "The sampling algorithm for the von Mises distribution is based on the\nfollowing paper: D.J. Best and N.I. Fisher, \"Efficient simulation of the\nvon Mises distribution.\" Applied Statistics (1979): 152-157.\n\nSampling is always done in double precision internally to avoid a hang\nin _rejection_sample() for small values of the concentration, which\nstarts to happen for single precision around 1e-4 (see issue #88443).",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Weibull",
      "documentation": {
        "description": "Samples from a two-parameter Weibull distribution.\n\nExample:\n\n    >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = Weibull(torch.tensor([1.0]), torch.tensor([1.0]))\n    >>> m.sample()  # sample from a Weibull distribution with scale=1, concentration=1\n    tensor([ 0.4784])",
        "parameters": {
          "scale": {
            "type": "float or Tensor",
            "description": "Scale parameter of distribution (lambda)."
          },
          "concentration": {
            "type": "float or Tensor",
            "description": "Concentration parameter of distribution (k/shape)."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ">>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n    >>> m = Weibull(torch.tensor([1.0]), torch.tensor([1.0]))\n    >>> m.sample()  # sample from a Weibull distribution with scale=1, concentration=1\n    tensor([ 0.4784])\n\nArgs:\n    scale (float or Tensor): Scale parameter of distribution (lambda).\n    concentration (float or Tensor): Concentration parameter of distribution (k/shape)."
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value)",
          "documentation": {
            "description": "Computes the cumulative distribution function by inverting the\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Returns entropy of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value)",
          "documentation": {
            "description": "Computes the inverse cumulative distribution function using\ntransform(s) and computing the score of the base distribution.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Scores the sample by inverting the transform(s) and computing the score\nusing the score of the base distribution and the log abs det jacobian.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped reparameterized sample or sample_shape\nshaped batch of reparameterized samples if the distribution parameters\nare batched. Samples first from base distribution and applies\n`transform()` for every transform in the list.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape=torch.Size([]))",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched. Samples first from\nbase distribution and applies `transform()` for every transform in the\nlist.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Wishart",
      "documentation": {
        "description": "Creates a Wishart distribution parameterized by a symmetric positive definite matrix :math:`\\Sigma`,\nor its Cholesky decomposition :math:`\\mathbf{\\Sigma} = \\mathbf{L}\\mathbf{L}^\\top`\n\nExample:\n    >>> # xdoctest: +SKIP(\"FIXME: scale_tril must be at least two-dimensional\")\n    >>> m = Wishart(torch.Tensor([2]), covariance_matrix=torch.eye(2))\n    >>> m.sample()  # Wishart distributed with mean=`df * I` and\n    >>>             # variance(x_ij)=`df` for i != j and variance(x_ij)=`2 * df` for i == j",
        "parameters": {
          "df": {
            "type": "float or Tensor",
            "description": "real-valued parameter larger than the (dimension of Square matrix) - 1"
          },
          "covariance_matrix": {
            "type": "Tensor",
            "description": "positive-definite covariance matrix"
          },
          "precision_matrix": {
            "type": "Tensor",
            "description": "positive-definite precision matrix"
          },
          "scale_tril": {
            "type": "Tensor",
            "description": "lower-triangular factor of covariance, with positive-valued diagonal"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "Only one of :attr:`covariance_matrix` or :attr:`precision_matrix` or\n    :attr:`scale_tril` can be specified.\n    Using :attr:`scale_tril` will be more efficient: all computations internally\n    are based on :attr:`scale_tril`. If :attr:`covariance_matrix` or\n    :attr:`precision_matrix` is passed instead, it is only used to compute\n    the corresponding lower triangular matrices using a Cholesky decomposition.\n    'torch.distributions.LKJCholesky' is a restricted Wishart distribution.[1]\n\n**References**\n\n[1] Wang, Z., Wu, Y. and Chu, H., 2018. `On equivalence of the LKJ distribution and the restricted Wishart distribution`.\n[2] Sawyer, S., 2007. `Wishart Distributions and Inverse-Wishart Sampling`.\n[3] Anderson, T. W., 2003. `An Introduction to Multivariate Statistical Analysis (3rd ed.)`.\n[4] Odell, P. L. & Feiveson, A. H., 1966. `A Numerical Procedure to Generate a SampleCovariance Matrix`. JASA, 61(313):199-203.\n[5] Ku, Y.-C. & Bloomfield, P., 2010. `Generating Random Wishart Matrices with Fractional Degrees of Freedom in OX`.",
        "examples": ">>> # xdoctest: +SKIP(\"FIXME: scale_tril must be at least two-dimensional\")\n    >>> m = Wishart(torch.Tensor([2]), covariance_matrix=torch.eye(2))\n    >>> m.sample()  # Wishart distributed with mean=`df * I` and\n    >>>             # variance(x_ij)=`df` for i != j and variance(x_ij)=`2 * df` for i == j\n\nArgs:\n    df (float or Tensor): real-valued parameter larger than the (dimension of Square matrix) - 1\n    covariance_matrix (Tensor): positive-definite covariance matrix\n    precision_matrix (Tensor): positive-definite precision matrix\n    scale_tril (Tensor): lower-triangular factor of covariance, with positive-valued diagonal"
      },
      "methods": [
        {
          "name": "cdf",
          "signature": "cdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "entropy",
          "signature": "entropy(self)",
          "documentation": {
            "description": "Method to compute the entropy using Bregman divergence of the log normalizer.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "enumerate_support",
          "signature": "enumerate_support(self, expand: bool = True) -> torch.Tensor",
          "documentation": {
            "description": "Returns tensor containing all values supported by a discrete\ndistribution. The result will enumerate over dimension 0, so the shape\nof the result will be `(cardinality,) + batch_shape + event_shape`\n(where `event_shape = ()` for univariate distributions).\n\nNote that this enumerates over all batched tensors in lock-step\n`[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens\nalong dim 0, but with the remaining batch dimensions being\nsingleton dimensions, `[[0], [1], ..`.\n\nTo iterate over the full Cartesian product use\n`itertools.product(m.enumerate_support())`.",
            "parameters": {
              "expand": {
                "type": "bool",
                "description": "whether to expand the support over the"
              },
              "batch": {
                "type": "",
                "description": "dims to match the distribution's `batch_shape`."
              }
            },
            "returns": "Tensor iterating over dimension 0.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "expand",
          "signature": "expand(self, batch_shape, _instance=None)",
          "documentation": {
            "description": "Returns a new distribution instance (or populates an existing instance\nprovided by a derived class) with batch dimensions expanded to\n`batch_shape`. This method calls :class:`~torch.Tensor.expand` on\nthe distribution's parameters. As such, this does not allocate new\nmemory for the expanded distribution instance. Additionally,\nthis does not repeat any args checking or parameter broadcasting in\n`__init__.py`, when an instance is first created.",
            "parameters": {
              "batch_shape": {
                "type": "torch.Size",
                "description": "the desired expanded size."
              },
              "_instance": {
                "type": "",
                "description": "new instance provided by subclasses that"
              },
              "need": {
                "type": "",
                "description": "to override `.expand`."
              }
            },
            "returns": "New distribution instance with batch dimensions expanded to\n    `batch_size`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "icdf",
          "signature": "icdf(self, value: torch.Tensor) -> torch.Tensor",
          "documentation": {
            "description": "Returns the inverse cumulative density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "log_prob",
          "signature": "log_prob(self, value)",
          "documentation": {
            "description": "Returns the log of the probability density/mass function evaluated at\n`value`.",
            "parameters": {
              "value": {
                "type": "Tensor",
                "description": ""
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "perplexity",
          "signature": "perplexity(self) -> torch.Tensor",
          "documentation": {
            "description": "Returns perplexity of distribution, batched over batch_shape.",
            "parameters": {},
            "returns": "Tensor of shape batch_shape.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "rsample",
          "signature": "rsample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([]), max_try_correction=None) -> torch.Tensor",
          "documentation": {
            "description": ".. warning::\n    In some cases, sampling algorithm based on Bartlett decomposition may return singular matrix samples.\n    Several tries to correct singular samples are performed by default, but it may end up returning\n    singular matrix samples. Singular samples may return `-inf` values in `.log_prob()`.\n    In those cases, the user should validate the samples and either fix the value of `df`\n    or adjust `max_try_correction` value for argument in `.rsample` accordingly.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample",
          "signature": "sample(self, sample_shape: Union[torch.Size, List[int], Tuple[int, ...]] = torch.Size([])) -> torch.Tensor",
          "documentation": {
            "description": "Generates a sample_shape shaped sample or sample_shape shaped batch of\nsamples if the distribution parameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "sample_n",
          "signature": "sample_n(self, n: int) -> torch.Tensor",
          "documentation": {
            "description": "Generates n samples or n batches of samples if the distribution\nparameters are batched.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_default_validate_args",
          "signature": "set_default_validate_args(value: bool) -> None",
          "documentation": {
            "description": "Sets whether validation is enabled or disabled.\n\nThe default behavior mimics Python's ``assert`` statement: validation\nis on by default, but is disabled if Python is run in optimized mode\n(via ``python -O``). Validation may be expensive, so you may want to\ndisable it once a model is working.",
            "parameters": {
              "value": {
                "type": "bool",
                "description": "Whether to enable validation."
              }
            },
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    }
  ]
}