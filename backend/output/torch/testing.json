{
  "description": "No description available",
  "functions": [
    {
      "name": "assert_allclose",
      "signature": "assert_allclose(actual: Any, expected: Any, rtol: Optional[float] = None, atol: Optional[float] = None, equal_nan: bool = True, msg: str = '') -> None",
      "documentation": {
        "description": ".. warning::\n\n   :func:`torch.testing.assert_allclose` is deprecated since ``1.12`` and will be removed in a future release.\n   Please use :func:`torch.testing.assert_close` instead. You can find detailed upgrade instructions\n   `here <https://github.com/pytorch/pytorch/issues/61844>`_.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "assert_close",
      "signature": "assert_close(actual: Any, expected: Any, *, allow_subclasses: bool = True, rtol: Optional[float] = None, atol: Optional[float] = None, equal_nan: bool = False, check_device: bool = True, check_dtype: bool = True, check_layout: bool = True, check_stride: bool = False, msg: Union[str, Callable[[str], str], NoneType] = None)",
      "documentation": {
        "description": "Asserts that ``actual`` and ``expected`` are close.\n\nIf ``actual`` and ``expected`` are strided, non-quantized, real-valued, and finite, they are considered close if\n\n.. math::\n\n    \\lvert \\text{actual} - \\text{expected} \\rvert \\le \\texttt{atol} + \\texttt{rtol} \\cdot \\lvert \\text{expected} \\rvert\n\nNon-finite values (``-inf`` and ``inf``) are only considered close if and only if they are equal. ``NaN``'s are\nonly considered equal to each other if ``equal_nan`` is ``True``.\n\nIn addition, they are only considered close if they have the same\n\n- :attr:`~torch.Tensor.device` (if ``check_device`` is ``True``),\n- ``dtype`` (if ``check_dtype`` is ``True``),\n- ``layout`` (if ``check_layout`` is ``True``), and\n- stride (if ``check_stride`` is ``True``).\n\nIf either ``actual`` or ``expected`` is a meta tensor, only the attribute checks will be performed.\n\nIf ``actual`` and ``expected`` are sparse (either having COO, CSR, CSC, BSR, or BSC layout), their strided members are\nchecked individually. Indices, namely ``indices`` for COO, ``crow_indices`` and ``col_indices`` for CSR and BSR,\nor ``ccol_indices``  and ``row_indices`` for CSC and BSC layouts, respectively,\nare always checked for equality whereas the values are checked for closeness according to the definition above.\n\nIf ``actual`` and ``expected`` are quantized, they are considered close if they have the same\n:meth:`~torch.Tensor.qscheme` and the result of :meth:`~torch.Tensor.dequantize` is close according to the\ndefinition above.\n\n``actual`` and ``expected`` can be :class:`~torch.Tensor`'s or any tensor-or-scalar-likes from which\n:class:`torch.Tensor`'s can be constructed with :func:`torch.as_tensor`. Except for Python scalars the input types\nhave to be directly related. In addition, ``actual`` and ``expected`` can be :class:`~collections.abc.Sequence`'s\nor :class:`~collections.abc.Mapping`'s in which case they are considered close if their structure matches and all\ntheir elements are considered close according to the above definition.\n\n.. note::\n\n    Python scalars are an exception to the type relation requirement, because their :func:`type`, i.e.\n    :class:`int`, :class:`float`, and :class:`complex`, is equivalent to the ``dtype`` of a tensor-like. Thus,\n    Python scalars of different types can be checked, but require ``check_dtype=False``.",
        "parameters": {
          "actual": {
            "type": "Any",
            "description": "Actual input."
          },
          "expected": {
            "type": "Any",
            "description": "Expected input."
          },
          "allow_subclasses": {
            "type": "bool",
            "description": "If ``True`` (default) and except for Python scalars, inputs of directly related types"
          },
          "are": {
            "type": "",
            "description": "allowed. Otherwise type equality is required."
          },
          "rtol": {
            "type": "Optional[float]",
            "description": "Relative tolerance. If specified ``atol`` must also be specified. If omitted, default"
          },
          "values": {
            "type": "",
            "description": "based on the :attr:`~torch.Tensor.dtype` are selected with the below table."
          },
          "atol": {
            "type": "Optional[float]",
            "description": "Absolute tolerance. If specified ``rtol`` must also be specified. If omitted, default"
          },
          "equal_nan": {
            "type": "Union[bool, str]",
            "description": "If ``True``, two ``NaN`` values will be considered equal."
          },
          "check_device": {
            "type": "bool",
            "description": "If ``True`` (default), asserts that corresponding tensors are on the same\n:attr:`~torch.Tensor.device`. If this check is disabled, tensors on different\n:attr:`~torch.Tensor.device`'s are moved to the CPU before being compared."
          },
          "check_dtype": {
            "type": "bool",
            "description": "If ``True`` (default), asserts that corresponding tensors have the same ``dtype``. If this"
          },
          "check": {
            "type": "",
            "description": "is disabled, tensors with different ``layout``'s are converted to strided tensors before being"
          },
          "check_layout": {
            "type": "bool",
            "description": "If ``True`` (default), asserts that corresponding tensors have the same ``layout``. If this"
          },
          "compared": {
            "type": "",
            "description": "."
          },
          "check_stride": {
            "type": "bool",
            "description": "If ``True`` and corresponding tensors are strided, asserts that they have the same stride."
          },
          "msg": {
            "type": "Optional[Union[str, Callable[[str], str]]]",
            "description": "Optional error message to use in case a failure occurs during"
          },
          "the": {
            "type": "",
            "description": "comparison. Can also passed as callable in which case it will be called with the generated message and"
          },
          "should": {
            "type": "",
            "description": "return the new message."
          }
        },
        "returns": "",
        "raises": "ValueError: If no :class:`torch.Tensor` can be constructed from an input.\n    ValueError: If only ``rtol`` or ``atol`` is specified.\n    AssertionError: If corresponding inputs are not Python scalars and are not directly related.\n    AssertionError: If ``allow_subclasses`` is ``False``, but corresponding inputs are not Python scalars and have\n        different types.\n    AssertionError: If the inputs are :class:`~collections.abc.Sequence`'s, but their length does not match.\n    AssertionError: If the inputs are :class:`~collections.abc.Mapping`'s, but their set of keys do not match.\n    AssertionError: If corresponding tensors do not have the same :attr:`~torch.Tensor.shape`.\n    AssertionError: If ``check_layout`` is ``True``, but corresponding tensors do not have the same\n        :attr:`~torch.Tensor.layout`.\n    AssertionError: If only one of corresponding tensors is quantized.\n    AssertionError: If corresponding tensors are quantized, but have different :meth:`~torch.Tensor.qscheme`'s.\n    AssertionError: If ``check_device`` is ``True``, but corresponding tensors are not on the same\n        :attr:`~torch.Tensor.device`.\n    AssertionError: If ``check_dtype`` is ``True``, but corresponding tensors do not have the same ``dtype``.\n    AssertionError: If ``check_stride`` is ``True``, but corresponding strided tensors do not have the same stride.\n    AssertionError: If the values of corresponding tensors are not close according to the definition above.\n\nThe following table displays the default ``rtol`` and ``atol`` for different ``dtype``'s. In case of mismatching\n``dtype``'s, the maximum of both tolerances is used.\n\n+---------------------------+------------+----------+\n| ``dtype``                 | ``rtol``   | ``atol`` |\n+===========================+============+==========+\n| :attr:`~torch.float16`    | ``1e-3``   | ``1e-5`` |\n+---------------------------+------------+----------+\n| :attr:`~torch.bfloat16`   | ``1.6e-2`` | ``1e-5`` |\n+---------------------------+------------+----------+\n| :attr:`~torch.float32`    | ``1.3e-6`` | ``1e-5`` |\n+---------------------------+------------+----------+\n| :attr:`~torch.float64`    | ``1e-7``   | ``1e-7`` |\n+---------------------------+------------+----------+\n| :attr:`~torch.complex32`  | ``1e-3``   | ``1e-5`` |\n+---------------------------+------------+----------+\n| :attr:`~torch.complex64`  | ``1.3e-6`` | ``1e-5`` |\n+---------------------------+------------+----------+\n| :attr:`~torch.complex128` | ``1e-7``   | ``1e-7`` |\n+---------------------------+------------+----------+\n| :attr:`~torch.quint8`     | ``1.3e-6`` | ``1e-5`` |\n+---------------------------+------------+----------+\n| :attr:`~torch.quint2x4`   | ``1.3e-6`` | ``1e-5`` |\n+---------------------------+------------+----------+\n| :attr:`~torch.quint4x2`   | ``1.3e-6`` | ``1e-5`` |\n+---------------------------+------------+----------+\n| :attr:`~torch.qint8`      | ``1.3e-6`` | ``1e-5`` |\n+---------------------------+------------+----------+\n| :attr:`~torch.qint32`     | ``1.3e-6`` | ``1e-5`` |\n+---------------------------+------------+----------+\n| other                     | ``0.0``    | ``0.0``  |\n+---------------------------+------------+----------+\n\n.. note::\n\n    :func:`~torch.testing.assert_close` is highly configurable with strict default settings. Users are encouraged\n    to :func:`~functools.partial` it to fit their use case. For example, if an equality check is needed, one might\n    define an ``assert_equal`` that uses zero tolerances for every ``dtype`` by default:\n\n    >>> import functools\n    >>> assert_equal = functools.partial(torch.testing.assert_close, rtol=0, atol=0)\n    >>> assert_equal(1e-9, 1e-10)\n    Traceback (most recent call last):\n    ...\n    AssertionError: Scalars are not equal!\n    <BLANKLINE>\n    Expected 1e-10 but got 1e-09.\n    Absolute difference: 9.000000000000001e-10\n    Relative difference: 9.0",
        "see_also": "",
        "notes": "",
        "examples": ">>> # tensor to tensor comparison\n    >>> expected = torch.tensor([1e0, 1e-1, 1e-2])\n    >>> actual = torch.acos(torch.cos(expected))\n    >>> torch.testing.assert_close(actual, expected)\n\n    >>> # scalar to scalar comparison\n    >>> import math\n    >>> expected = math.sqrt(2.0)\n    >>> actual = 2.0 / math.sqrt(2.0)\n    >>> torch.testing.assert_close(actual, expected)\n\n    >>> # numpy array to numpy array comparison\n    >>> import numpy as np\n    >>> expected = np.array([1e0, 1e-1, 1e-2])\n    >>> actual = np.arccos(np.cos(expected))\n    >>> torch.testing.assert_close(actual, expected)\n\n    >>> # sequence to sequence comparison\n    >>> import numpy as np\n    >>> # The types of the sequences do not have to match. They only have to have the same\n    >>> # length and their elements have to match.\n    >>> expected = [torch.tensor([1.0]), 2.0, np.array(3.0)]\n    >>> actual = tuple(expected)\n    >>> torch.testing.assert_close(actual, expected)\n\n    >>> # mapping to mapping comparison\n    >>> from collections import OrderedDict\n    >>> import numpy as np\n    >>> foo = torch.tensor(1.0)\n    >>> bar = 2.0\n    >>> baz = np.array(3.0)\n    >>> # The types and a possible ordering of mappings do not have to match. They only\n    >>> # have to have the same set of keys and their elements have to match.\n    >>> expected = OrderedDict([(\"foo\", foo), (\"bar\", bar), (\"baz\", baz)])\n    >>> actual = {\"baz\": baz, \"bar\": bar, \"foo\": foo}\n    >>> torch.testing.assert_close(actual, expected)\n\n    >>> expected = torch.tensor([1.0, 2.0, 3.0])\n    >>> actual = expected.clone()\n    >>> # By default, directly related instances can be compared\n    >>> torch.testing.assert_close(torch.nn.Parameter(actual), expected)\n    >>> # This check can be made more strict with allow_subclasses=False\n    >>> torch.testing.assert_close(\n    ...     torch.nn.Parameter(actual), expected, allow_subclasses=False\n    ... )\n    Traceback (most recent call last):\n    ...\n    TypeError: No comparison pair was able to handle inputs of type\n    <class 'torch.nn.parameter.Parameter'> and <class 'torch.Tensor'>.\n    >>> # If the inputs are not directly related, they are never considered close\n    >>> torch.testing.assert_close(actual.numpy(), expected)\n    Traceback (most recent call last):\n    ...\n    TypeError: No comparison pair was able to handle inputs of type <class 'numpy.ndarray'>\n    and <class 'torch.Tensor'>.\n    >>> # Exceptions to these rules are Python scalars. They can be checked regardless of\n    >>> # their type if check_dtype=False.\n    >>> torch.testing.assert_close(1.0, 1, check_dtype=False)\n\n    >>> # NaN != NaN by default.\n    >>> expected = torch.tensor(float(\"Nan\"))\n    >>> actual = expected.clone()\n    >>> torch.testing.assert_close(actual, expected)\n    Traceback (most recent call last):\n    ...\n    AssertionError: Scalars are not close!\n    <BLANKLINE>\n    Expected nan but got nan.\n    Absolute difference: nan (up to 1e-05 allowed)\n    Relative difference: nan (up to 1.3e-06 allowed)\n    >>> torch.testing.assert_close(actual, expected, equal_nan=True)\n\n    >>> expected = torch.tensor([1.0, 2.0, 3.0])\n    >>> actual = torch.tensor([1.0, 4.0, 5.0])\n    >>> # The default error message can be overwritten.\n    >>> torch.testing.assert_close(actual, expected, msg=\"Argh, the tensors are not close!\")\n    Traceback (most recent call last):\n    ...\n    AssertionError: Argh, the tensors are not close!\n    >>> # If msg is a callable, it can be used to augment the generated message with\n    >>> # extra information\n    >>> torch.testing.assert_close(\n    ...     actual, expected, msg=lambda msg: f\"Header\\n\\n{msg}\\n\\nFooter\"\n    ... )\n    Traceback (most recent call last):\n    ...\n    AssertionError: Header\n    <BLANKLINE>\n    Tensor-likes are not close!\n    <BLANKLINE>\n    Mismatched elements: 2 / 3 (66.7%)\n    Greatest absolute difference: 2.0 at index (1,) (up to 1e-05 allowed)\n    Greatest relative difference: 1.0 at index (1,) (up to 1.3e-06 allowed)\n    <BLANKLINE>\n    Footer"
      }
    },
    {
      "name": "make_tensor",
      "signature": "make_tensor(*shape: Union[int, torch.Size, List[int], Tuple[int, ...]], dtype: torch.dtype, device: Union[str, torch.device], low: Optional[float] = None, high: Optional[float] = None, requires_grad: bool = False, noncontiguous: bool = False, exclude_zero: bool = False, memory_format: Optional[torch.memory_format] = None) -> torch.Tensor",
      "documentation": {
        "description": "Creates a tensor with the given :attr:`shape`, :attr:`device`, and :attr:`dtype`, and filled with\nvalues uniformly drawn from ``[low, high)``.\n\nIf :attr:`low` or :attr:`high` are specified and are outside the range of the :attr:`dtype`'s representable\nfinite values then they are clamped to the lowest or highest representable finite value, respectively.\nIf ``None``, then the following table describes the default values for :attr:`low` and :attr:`high`,\nwhich depend on :attr:`dtype`.\n\n+---------------------------+------------+----------+\n| ``dtype``                 | ``low``    | ``high`` |\n+===========================+============+==========+\n| boolean type              | ``0``      | ``2``    |\n+---------------------------+------------+----------+\n| unsigned integral type    | ``0``      | ``10``   |\n+---------------------------+------------+----------+\n| signed integral types     | ``-9``     | ``10``   |\n+---------------------------+------------+----------+\n| floating types            | ``-9``     | ``9``    |\n+---------------------------+------------+----------+\n| complex types             | ``-9``     | ``9``    |\n+---------------------------+------------+----------+",
        "parameters": {
          "shape": {
            "type": "Tuple[int, ...]",
            "description": "Single integer or a sequence of integers defining the shape of the output tensor."
          },
          "dtype": {
            "type": ":class:`torch.dtype`",
            "description": "The data type of the returned tensor."
          },
          "device": {
            "type": "Union[str, torch.device]",
            "description": "The device of the returned tensor."
          },
          "low": {
            "type": "Optional[Number]",
            "description": "Sets the lower limit (inclusive) of the given range. If a number is provided it is"
          },
          "clamped": {
            "type": "",
            "description": "to the greatest representable finite value of the given dtype. When ``None`` (default) this value"
          },
          "this": {
            "type": "",
            "description": "value is determined based on the :attr:`dtype` (see the table above). Default: ``None``."
          },
          "high": {
            "type": "Optional[Number]",
            "description": "Sets the upper limit (exclusive) of the given range. If a number is provided it is"
          },
          "is": {
            "type": "",
            "description": "determined based on the :attr:`dtype` (see the table above). Default: ``None``.\n.. deprecated:: 2.1"
          },
          "Passing": {
            "type": "",
            "description": "``low==high`` to :func:`~torch.testing.make_tensor` for floating or complex types is deprecated"
          },
          "since": {
            "type": "",
            "description": "2.1 and will be removed in 2.3. Use :func:`torch.full` instead."
          },
          "requires_grad": {
            "type": "Optional[bool]",
            "description": "If autograd should record operations on the returned tensor. Default: ``False``."
          },
          "noncontiguous": {
            "type": "Optional[bool]",
            "description": "If `True`, the returned tensor will be noncontiguous. This argument is"
          },
          "ignored": {
            "type": "",
            "description": "if the constructed tensor has fewer than two elements. Mutually exclusive with ``memory_format``."
          },
          "exclude_zero": {
            "type": "Optional[bool]",
            "description": "If ``True`` then zeros are replaced with the dtype's small positive value"
          },
          "depending": {
            "type": "",
            "description": "on the :attr:`dtype`. For bool and integer types zero is replaced with one. For floating"
          },
          "point": {
            "type": "",
            "description": "types it is replaced with the dtype's smallest positive normal number (the \"tiny\" value of the\n:attr:`dtype`'s :func:`~torch.finfo` object), and for complex types it is replaced with a complex number"
          },
          "whose": {
            "type": "",
            "description": "real and imaginary parts are both the smallest positive normal number representable by the complex"
          },
          "type": {
            "type": "",
            "description": ". Default ``False``."
          },
          "memory_format": {
            "type": "Optional[torch.memory_format]",
            "description": "The memory format of the returned tensor. Mutually exclusive"
          },
          "with": {
            "type": "",
            "description": "``noncontiguous``."
          }
        },
        "returns": "",
        "raises": "ValueError: If ``requires_grad=True`` is passed for integral `dtype`\n    ValueError: If ``low >= high``.\n    ValueError: If either :attr:`low` or :attr:`high` is ``nan``.\n    ValueError: If both :attr:`noncontiguous` and :attr:`memory_format` are passed.\n    TypeError: If :attr:`dtype` isn't supported by this function.",
        "see_also": "",
        "notes": "",
        "examples": ">>> # xdoctest: +SKIP\n    >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA)\n    >>> from torch.testing import make_tensor\n    >>> # Creates a float tensor with values in [-1, 1)\n    >>> make_tensor((3,), device='cpu', dtype=torch.float32, low=-1, high=1)\n    >>> # xdoctest: +SKIP\n    tensor([ 0.1205, 0.2282, -0.6380])\n    >>> # Creates a bool tensor on CUDA\n    >>> make_tensor((2, 2), device='cuda', dtype=torch.bool)\n    tensor([[False, False],\n            [False, True]], device='cuda:0')"
      }
    }
  ],
  "classes": [
    {
      "name": "FileCheck",
      "documentation": {
        "description": "",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "check",
          "signature": "check(self: torch._C.FileCheck, arg0: str)",
          "documentation": {
            "description": "check(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "check_count",
          "signature": "check_count(*args, **kwargs)",
          "documentation": {
            "description": "check_count(*args, **kwargs)\nOverloaded function.\n\n1. check_count(self: torch._C.FileCheck, arg0: str, arg1: int, arg2: bool) -> torch._C.FileCheck\n\n2. check_count(self: torch._C.FileCheck, str: str, count: int, exactly: bool = False) -> torch._C.FileCheck\n\nCheck Count",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "check_dag",
          "signature": "check_dag(self: torch._C.FileCheck, arg0: str)",
          "documentation": {
            "description": "check_dag(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "check_next",
          "signature": "check_next(self: torch._C.FileCheck, arg0: str)",
          "documentation": {
            "description": "check_next(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "check_not",
          "signature": "check_not(self: torch._C.FileCheck, arg0: str)",
          "documentation": {
            "description": "check_not(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "check_regex",
          "signature": "check_regex(self: torch._C.FileCheck, arg0: str)",
          "documentation": {
            "description": "check_regex(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "check_same",
          "signature": "check_same(self: torch._C.FileCheck, arg0: str)",
          "documentation": {
            "description": "check_same(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "check_source_highlighted",
          "signature": "check_source_highlighted(self: torch._C.FileCheck, arg0: str)",
          "documentation": {
            "description": "check_source_highlighted(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "run",
          "signature": "run(*args, **kwargs)",
          "documentation": {
            "description": "run(*args, **kwargs)\nOverloaded function.\n\n1. run(self: torch._C.FileCheck, arg0: str) -> None\n\n2. run(self: torch._C.FileCheck, arg0: torch._C.Graph) -> None\n\n3. run(self: torch._C.FileCheck, checks_file: str, test_file: str) -> None\n\nRun\n\n4. run(self: torch._C.FileCheck, checks_file: str, graph: torch._C.Graph) -> None\n\nRun",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    }
  ]
}