{
  "description": "Python implementation of ``__torch_function__``\n\nWhile most of the torch API and handling for ``__torch_function__`` happens\nat the C++ level, some of the torch API is written in Python so we need\npython-level handling for ``__torch_function__`` overrides as well. The main\ndeveloper-facing functionality in this file are handle_torch_function and\nhas_torch_function. See torch/functional.py and test/test_overrides.py\nfor usage examples.\n\nNote\n----\nheavily inspired by NumPy's ``__array_function__`` (see:\nhttps://github.com/pytorch/pytorch/issues/24015 and\nhttps://www.numpy.org/neps/nep-0018-array-function-protocol.html\n)\n\nIf changing this file in a way that can affect ``__torch_function__`` overhead,\nplease report the benchmarks in ``benchmarks/overrides_benchmark``. See the\ninstructions in the ``README.md`` in that directory.",
  "functions": [
    {
      "name": "Callable",
      "signature": "Callable(*args, **kwargs)",
      "documentation": {
        "description": "Deprecated alias to collections.abc.Callable.\n\nCallable[[int], str] signifies a function that takes a single\nparameter of type int and returns a str.\n\nThe subscription syntax must always be used with exactly two\nvalues: the argument list and the return type.\nThe argument list must be a list of types, a ParamSpec,\nConcatenate or ellipsis. The return type must be a single type.\n\nThere is no syntax to indicate optional or keyword arguments;\nsuch function types are rarely used as callback types.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "Dict",
      "signature": "Dict(*args, **kwargs)",
      "documentation": {
        "description": "A generic version of dict.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "Iterable",
      "signature": "Iterable(*args, **kwargs)",
      "documentation": {
        "description": "A generic version of collections.abc.Iterable.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "List",
      "signature": "List(*args, **kwargs)",
      "documentation": {
        "description": "A generic version of list.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "Optional",
      "signature": "Optional(*args, **kwds)",
      "documentation": {
        "description": "Optional[X] is equivalent to Union[X, None].",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "Set",
      "signature": "Set(*args, **kwargs)",
      "documentation": {
        "description": "A generic version of set.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "Tuple",
      "signature": "Tuple(*args, **kwargs)",
      "documentation": {
        "description": "Deprecated alias to builtins.tuple.\n\nTuple[X, Y] is the cross-product type of X and Y.\n\nExample: Tuple[T1, T2] is a tuple of two elements corresponding\nto type variables T1 and T2.  Tuple[int, float, str] is a tuple\nof an int, a float and a string.\n\nTo specify a variable-length tuple of homogeneous type, use Tuple[T, ...].",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "Type",
      "signature": "Type(*args, **kwargs)",
      "documentation": {
        "description": "Deprecated alias to builtins.type.\n\nbuiltins.type or typing.Type can be used to annotate class objects.\nFor example, suppose we have the following classes::\n\n    class User: ...  # Abstract base for User classes\n    class BasicUser(User): ...\n    class ProUser(User): ...\n    class TeamUser(User): ...\n\nAnd a function that takes a class argument that's a subclass of\nUser and returns an instance of the corresponding class::\n\n    def new_user[U](user_class: Type[U]) -> U:\n        user = user_class()\n        # (Here we could write the user object to a database)\n        return user\n\n    joe = new_user(BasicUser)\n\nAt this point the type checker knows that joe has type BasicUser.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "enable_reentrant_dispatch",
      "signature": "enable_reentrant_dispatch()",
      "documentation": {
        "description": "",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "get_default_nowrap_functions",
      "signature": "get_default_nowrap_functions() -> Set[Callable]",
      "documentation": {
        "description": "Return public functions that do not wrap in a subclass when invoked by\nthe default ``Tensor.__torch_function__`` that preserves subclasses.  Typically,\nthese functions represent field accesses (i.e., retrieving a Tensor that\nis stored somewhere on the Tensor) as opposed to computation.  Users of\nthese functions expect object identity to be preserved over multiple accesses\n(e.g., ``a.grad is a.grad``) which cannot be upheld if we're wrapping on\nthe fly every time (furthermore, the tensor stored here might already be\nthe subclass, in which case wrapping really ought not to happen).\n\nNot ALL property accessors have this property; for example ``Tensor.T`` actually\njust creates a new transposed tensor on the fly, and so we SHOULD interpose on\nthese calls (you need to check the implementation of the function to see if\nthis is the case or not).  Additionally, if a property accessor doesn't return a Tensor,\nit doesn't have to be on this list (though it is harmless if it is).",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "get_ignored_functions",
      "signature": "get_ignored_functions() -> Set[Callable]",
      "documentation": {
        "description": "Return public functions that cannot be overridden by ``__torch_function__``.\n\nReturns\n-------\nSet[Callable]\n    A tuple of functions that are publicly available in the torch API but cannot\n    be overridden with ``__torch_function__``. Mostly this is because none of the\n    arguments of these functions are tensors or tensor-likes.\n\nExamples\n--------\n>>> torch.Tensor.as_subclass in torch.overrides.get_ignored_functions()\nTrue\n>>> torch.add in torch.overrides.get_ignored_functions()\nFalse",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "get_overridable_functions",
      "signature": "get_overridable_functions() -> Dict[Any, List[Callable]]",
      "documentation": {
        "description": "List functions that are overridable via __torch_function__\n\nReturns\n-------\nDict[Any, List[Callable]]\n    A dictionary that maps namespaces that contain overridable functions\n    to functions in that namespace that can be overridden.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "get_testing_overrides",
      "signature": "get_testing_overrides() -> Dict[Callable, Callable]",
      "documentation": {
        "description": "Return a dict containing dummy overrides for all overridable functions\n\nReturns\n-------\nDict[Callable, Callable]\n    A dictionary that maps overridable functions in the PyTorch API to\n    lambda functions that have the same signature as the real function\n    and unconditionally return -1. These lambda functions are useful\n    for testing API coverage for a type that defines ``__torch_function__``.\n\nExamples\n--------\n>>> import inspect\n>>> my_add = torch.overrides.get_testing_overrides()[torch.add]\n>>> inspect.signature(my_add)\n<Signature (input, other, out=None)>",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "handle_torch_function",
      "signature": "handle_torch_function(public_api: Callable, relevant_args: Iterable[Any], *args, **kwargs) -> Any",
      "documentation": {
        "description": "Implement a function with checks for ``__torch_function__`` overrides.\n\nSee torch::autograd::handle_torch_function for the equivalent of this\nfunction in the C++ implementation.\n\nArguments\n---------\npublic_api : function\n    Function exposed by the public torch API originally called like\n    ``public_api(*args, **kwargs)`` on which arguments are now being\n    checked.\nrelevant_args : iterable\n    Iterable of arguments to check for __torch_function__ methods.\nargs : tuple\n    Arbitrary positional arguments originally passed into ``public_api``.\nkwargs : tuple\n    Arbitrary keyword arguments originally passed into ``public_api``.\n\nReturns\n-------\nobject\n    Result from calling ``implementation`` or an ``__torch_function__``\n    method, as appropriate.\n\nRaises\n------\nTypeError : if no implementation is found.\n\nExample\n-------\n>>> def func(a):\n...     if has_torch_function_unary(a):\n...         return handle_torch_function(func, (a,), a)\n...     return a + 0",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "has_torch_function",
      "signature": "_has_torch_function(...)",
      "documentation": {
        "description": "Check for __torch_function__ implementations in the elements of an iterable\nor if a __torch_function__ mode is enabled.  Considers exact ``Tensor`` s\nand ``Parameter`` s non-dispatchable.  Use this to guard a call to\n:func:`handle_torch_function`; don't use it to test if something\nis Tensor-like, use :func:`is_tensor_like` instead.\nArguments\n---------\nrelevant_args : iterable\n    Iterable or arguments to check for __torch_function__ methods.\nReturns\n-------\nbool\n    True if any of the elements of relevant_args have __torch_function__\n    implementations, False otherwise.\nSee Also\n________\ntorch.is_tensor_like\n    Checks if something is a Tensor-like, including an exact ``Tensor``.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "has_torch_function_unary",
      "signature": "_has_torch_function_unary(...)",
      "documentation": {
        "description": "Special case of `has_torch_function` for single inputs.\nInstead of:\n  `has_torch_function((t,))`\ncall:\n  `has_torch_function_unary(t)`\nwhich skips unnecessary packing and unpacking work.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "has_torch_function_variadic",
      "signature": "_has_torch_function_variadic(...)",
      "documentation": {
        "description": "Special case of `has_torch_function` that skips tuple creation.\n\nThis uses the METH_FASTCALL protocol introduced in Python 3.7\n\nInstead of:\n  `has_torch_function((a, b))`\ncall:\n  `has_torch_function_variadic(a, b)`\nwhich skips unnecessary packing and unpacking work.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "is_tensor_like",
      "signature": "is_tensor_like(inp)",
      "documentation": {
        "description": "Returns ``True`` if the passed-in input is a Tensor-like.\n\nCurrently, this occurs whenever there's a ``__torch_function__``\nattribute on the type of the input.\n\nExamples\n--------\nA subclass of tensor is generally a Tensor-like.\n\n>>> class SubTensor(torch.Tensor): ...\n>>> is_tensor_like(SubTensor([0]))\nTrue\n\nBuilt-in or user types aren't usually Tensor-like.\n\n>>> is_tensor_like(6)\nFalse\n>>> is_tensor_like(None)\nFalse\n>>> class NotATensor: ...\n>>> is_tensor_like(NotATensor())\nFalse\n\nBut, they can be made Tensor-like by implementing __torch_function__.\n\n>>> class TensorLike:\n...     @classmethod\n...     def __torch_function__(cls, func, types, args, kwargs):\n...         return -1\n>>> is_tensor_like(TensorLike())\nTrue",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "is_tensor_method_or_property",
      "signature": "is_tensor_method_or_property(func: Callable) -> bool",
      "documentation": {
        "description": "Returns True if the function passed in is a handler for a\nmethod or property belonging to ``torch.Tensor``, as passed\ninto ``__torch_function__``.\n\n.. note::\n   For properties, their ``__get__`` method must be passed in.\n\nThis may be needed, in particular, for the following reasons:\n\n1. Methods/properties sometimes don't contain a `__module__` slot.\n2. They require that the first passed-in argument is an instance\n   of ``torch.Tensor``.\n\nExamples\n--------\n>>> is_tensor_method_or_property(torch.Tensor.add)\nTrue\n>>> is_tensor_method_or_property(torch.add)\nFalse",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "resolve_name",
      "signature": "resolve_name(f)",
      "documentation": {
        "description": "Get a human readable string name for a function passed to\n__torch_function__\n\nArguments\n---------\nf : Callable\n    Function to resolve the name of.\n\nReturns\n-------\nstr\n    Name of the function; if eval'ed it should give back the input\n    function.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "wrap_torch_function",
      "signature": "wrap_torch_function(dispatcher: Callable)",
      "documentation": {
        "description": "Wraps a given function with ``__torch_function__`` -related functionality.\n\nParameters\n----------\ndispatcher: Callable\n    A callable that returns an iterable of Tensor-likes passed into the function.\n\nNote\n----\nThis decorator may reduce the performance of your code. Generally, it's enough to express\nyour code as a series of functions that, themselves, support __torch_function__. If you\nfind yourself in the rare situation where this is not the case, e.g. if you're wrapping a\nlow-level library and you also need it to work for Tensor-likes, then this function is available.\n\nExamples\n--------\n>>> def dispatcher(a):  # Must have the same signature as func\n...     return (a,)\n>>> @torch.overrides.wrap_torch_function(dispatcher)\n>>> def func(a):  # This will make func dispatchable by __torch_function__\n...     return a + 0",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "wraps",
      "signature": "wraps(wrapped, assigned=('__module__', '__name__', '__qualname__', '__doc__', '__annotations__', '__type_params__'), updated=('__dict__',))",
      "documentation": {
        "description": "Decorator factory to apply update_wrapper() to a wrapper function\n\nReturns a decorator that invokes update_wrapper() with the decorated\nfunction as the wrapper argument and the arguments to wraps() as the\nremaining arguments. Default arguments are as for update_wrapper().\nThis is a convenience function to simplify applying partial() to\nupdate_wrapper().",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    }
  ],
  "classes": [
    {
      "name": "Any",
      "documentation": {
        "description": "Special type indicating an unconstrained type.\n\n- Any is compatible with every type.\n- Any assumed to have all methods.\n- All values assumed to be instances of Any.\n\nNote that all the above statements are true from the point of view of\nstatic type checkers. At runtime, Any should not be used with instance\nchecks.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": []
    },
    {
      "name": "BaseTorchFunctionMode",
      "documentation": {
        "description": "A ``TorchFunctionMode`` allows you to override the meaning of all\n``__torch_function__`` overrideable functions within a dynamic scope,\nwithout having to actually create a tensor subclass or manually\nmonkey-patch functions in the PyTorch API.  Some common situations\nwhere you should use a mode:\n\n    * You want to override the meaning of factory functions, or other\n      functions that do not otherwise take a tensor as an argument\n      (these cannot be overridden with tensor subclasses).\n\n    * You want to override the behavior of all functions without needing\n      to wrap your inputs in tensor subclasses; e.g., if you are just\n      interested in logging intermediate computations.\n\n    * You want to control the order of execution of various tensor\n      subclasses explicitly, rather than implicitly via the return of\n      ``NotImplemented``.\n\nIndependent subclasses of :class:`TorchFunctionMode` are compositional:\nmodes can be pushed onto a stack using ``with MyMode():``.\nWhen you call functions in the PyTorch API inside your\n``__torch_function__`` implementation, by default, they will forward on to\nthe next mode on the mode stack.  If you want recursively call back into\nyour current ``__torch_function__`` implementation, either explicitly\ninvoke ``self.__torch_function__(...)``, or use the context manager\n``enable_torch_function_mode(self, replace=self.inner)`` to make PyTorch\nAPI self-referential (beware of infinite loops, in this case!)",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "push",
          "signature": "push(*args, **kwargs)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "TorchFunctionMode",
      "documentation": {
        "description": "A ``TorchFunctionMode`` allows you to override the meaning of all\n``__torch_function__`` overrideable functions within a dynamic scope,\nwithout having to actually create a tensor subclass or manually\nmonkey-patch functions in the PyTorch API.  Some common situations\nwhere you should use a mode:\n\n    * You want to override the meaning of factory functions, or other\n      functions that do not otherwise take a tensor as an argument\n      (these cannot be overridden with tensor subclasses).\n\n    * You want to override the behavior of all functions without needing\n      to wrap your inputs in tensor subclasses; e.g., if you are just\n      interested in logging intermediate computations.\n\n    * You want to control the order of execution of various tensor\n      subclasses explicitly, rather than implicitly via the return of\n      ``NotImplemented``.\n\nIndependent subclasses of :class:`TorchFunctionMode` are compositional:\nmodes can be pushed onto a stack using ``with MyMode():``.\nWhen you call functions in the PyTorch API inside your\n``__torch_function__`` implementation, by default, they will forward on to\nthe next mode on the mode stack.  If you want recursively call back into\nyour current ``__torch_function__`` implementation, either explicitly\ninvoke ``self.__torch_function__(...)``, or use the context manager\n``enable_torch_function_mode(self, replace=self.inner)`` to make PyTorch\nAPI self-referential (beware of infinite loops, in this case!)",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "push",
          "signature": "push(*args, **kwargs)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    }
  ]
}