{
  "description": "This package introduces support for the current :ref:`accelerator<accelerators>` in python.",
  "functions": [
    {
      "name": "current_accelerator",
      "signature": "current_accelerator() -> torch.device",
      "documentation": {
        "description": "Return the device of the current :ref:`accelerator<accelerators>`.",
        "parameters": {},
        "returns": "torch.device: return the current accelerator as :class:`torch.device`.\n\n.. note:: The index of the returned :class:`torch.device` will be ``None``, please use\n    :func:`torch.accelerator.current_device_index` to know the current index being used.\n    And ensure to use :func:`torch.accelerator.is_available` to check if there is an available\n    accelerator. If there is no available accelerator, this function will raise an exception.\n\nExample::\n\n    >>> # xdoctest:\n    >>> if torch.accelerator.is_available():\n    >>>     current_device = torch.accelerator.current_accelerator()\n    >>> else:\n    >>>     current_device = torch.device(\"cpu\")\n    >>> if current_device.type == 'cuda':\n    >>>     is_half_supported = torch.cuda.has_half\n    >>> elif current_device.type == 'xpu':\n    >>>     is_half_supported = torch.xpu.get_device_properties().has_fp16\n    >>> elif current_device.type == 'cpu':\n    >>>     is_half_supported = True",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "current_device_idx",
      "signature": "current_device_index() -> int",
      "documentation": {
        "description": "Return the index of a currently selected device for the current :ref:`accelerator<accelerators>`.",
        "parameters": {},
        "returns": "int: the index of a currently selected device.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "current_device_index",
      "signature": "current_device_index() -> int",
      "documentation": {
        "description": "Return the index of a currently selected device for the current :ref:`accelerator<accelerators>`.",
        "parameters": {},
        "returns": "int: the index of a currently selected device.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "current_stream",
      "signature": "current_stream(device: Union[torch.device, str, int, NoneType] = None, /) -> torch.Stream",
      "documentation": {
        "description": "Return the currently selected stream for a given device.",
        "parameters": {
          "device": {
            "type": ":class:`torch.device`, str, int, optional",
            "description": "a given device that must match the current\n:ref:`accelerator<accelerators>` device type. If not given,"
          },
          "use": {
            "type": "",
            "description": "func:`torch.accelerator.current_device_index` by default."
          }
        },
        "returns": "torch.Stream: the currently selected stream for a given device.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "device_count",
      "signature": "device_count() -> int",
      "documentation": {
        "description": "Return the number of current :ref:`accelerator<accelerators>` available.",
        "parameters": {},
        "returns": "int: the number of the current :ref:`accelerator<accelerators>` available.\n        If there is no available accelerators, return 0.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "is_available",
      "signature": "is_available() -> bool",
      "documentation": {
        "description": "Check if there is an available :ref:`accelerator<accelerators>`.",
        "parameters": {},
        "returns": "bool: A boolean indicating if there is an available :ref:`accelerator<accelerators>`.\n\nExample::\n\n    >>> assert torch.accelerator.is_available() \"No available accelerators detected.\"",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "set_device_idx",
      "signature": "set_device_index(device: Union[torch.device, str, int, NoneType], /) -> None",
      "documentation": {
        "description": "Set the current device index to a given device.",
        "parameters": {
          "device": {
            "type": ":class:`torch.device`, str, int",
            "description": "a given device that must match the current\n:ref:`accelerator<accelerators>` device type.\n.. note:: This function is a no-op if this device index is negative."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "set_device_index",
      "signature": "set_device_index(device: Union[torch.device, str, int, NoneType], /) -> None",
      "documentation": {
        "description": "Set the current device index to a given device.",
        "parameters": {
          "device": {
            "type": ":class:`torch.device`, str, int",
            "description": "a given device that must match the current\n:ref:`accelerator<accelerators>` device type.\n.. note:: This function is a no-op if this device index is negative."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "set_stream",
      "signature": "set_stream(stream: torch.Stream) -> None",
      "documentation": {
        "description": "Set the current stream to a given stream.",
        "parameters": {
          "stream": {
            "type": "torch.Stream",
            "description": "a given stream that must match the current :ref:`accelerator<accelerators>` device type.\n.. note:: This function will set the current device index to the device index of the given stream."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "synchronize",
      "signature": "synchronize(device: Union[torch.device, str, int, NoneType] = None, /) -> None",
      "documentation": {
        "description": "Wait for all kernels in all streams on the given device to complete.",
        "parameters": {
          "device": {
            "type": ":class:`torch.device`, str, int, optional",
            "description": "device for which to synchronize. It must match"
          },
          "the": {
            "type": "",
            "description": "current :ref:`accelerator<accelerators>` device type. If not given,"
          },
          "use": {
            "type": "",
            "description": "func:`torch.accelerator.current_device_index` by default.\n.. note:: This function is a no-op if the current :ref:`accelerator<accelerators>` is not initialized."
          },
          "Example": {
            "type": "",
            "description": ":\n>>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA)\n>>> assert torch.accelerator.is_available() \"No available accelerators detected.\"\n>>> start_event = torch.Event(enable_timing=True)\n>>> end_event = torch.Event(enable_timing=True)\n>>> start_event.record()\n>>> tensor = torch.randn(100, device=torch.accelerator.current_accelerator())\n>>> sum = torch.sum(tensor)\n>>> end_event.record()\n>>> torch.accelerator.synchronize()\n>>> elapsed_time_ms = start_event.elapsed_time(end_event)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    }
  ],
  "classes": [
    {
      "name": "deprecated",
      "documentation": {
        "description": "Indicate that a class, function or overload is deprecated.\n\nWhen this decorator is applied to an object, the type checker\nwill generate a diagnostic on usage of the deprecated object.\n\nUsage:\n\n    @deprecated(\"Use B instead\")\n    class A:\n        pass\n\n    @deprecated(\"Use g instead\")\n    def f():\n        pass\n\n    @overload\n    @deprecated(\"int support is deprecated\")\n    def g(x: int) -> int: ...\n    @overload\n    def g(x: str) -> int: ...\n\nThe warning specified by *category* will be emitted at runtime\non use of deprecated objects. For functions, that happens on calls;\nfor classes, on instantiation and on creation of subclasses.\nIf the *category* is ``None``, no warning is emitted at runtime.\nThe *stacklevel* determines where the\nwarning is emitted. If it is ``1`` (the default), the warning\nis emitted at the direct caller of the deprecated object; if it\nis higher, it is emitted further up the stack.\nStatic type checker behavior is not affected by the *category*\nand *stacklevel* arguments.\n\nThe deprecation message passed to the decorator is saved in the\n``__deprecated__`` attribute on the decorated object.\nIf applied to an overload, the decorator\nmust be after the ``@overload`` decorator for the attribute to\nexist on the overload as returned by ``get_overloads()``.\n\nSee PEP 702 for details.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": []
    }
  ]
}