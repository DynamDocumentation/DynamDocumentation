{
  "description": "Random projection transformers.\n\nRandom projections are a simple and computationally efficient way to\nreduce the dimensionality of the data by trading a controlled amount\nof accuracy (as additional variance) for faster processing times and\nsmaller model sizes.\n\nThe dimensions and distribution of random projections matrices are\ncontrolled so as to preserve the pairwise distances between any two\nsamples of the dataset.\n\nThe main theoretical result behind the efficiency of random projection is the\n`Johnson-Lindenstrauss lemma (quoting Wikipedia)\n<https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma>`_:\n\n  In mathematics, the Johnson-Lindenstrauss lemma is a result\n  concerning low-distortion embeddings of points from high-dimensional\n  into low-dimensional Euclidean space. The lemma states that a small set\n  of points in a high-dimensional space can be embedded into a space of\n  much lower dimension in such a way that distances between the points are\n  nearly preserved. The map used for the embedding is at least Lipschitz,\n  and can even be taken to be an orthogonal projection.",
  "functions": [
    {
      "name": "abstractmethod",
      "signature": "abstractmethod(funcobj)",
      "documentation": {
        "description": "A decorator indicating abstract methods.\n\n    Requires that the metaclass is ABCMeta or derived from it.  A\n    class that has a metaclass derived from ABCMeta cannot be\n    instantiated unless all of its abstract methods are overridden.\n    The abstract methods can be called using any of the normal\n    'super' call mechanisms.  abstractmethod() may be used to declare\n    abstract methods for properties and descriptors.\n\n    Usage:\n\n        class C(metaclass=ABCMeta):\n            @abstractmethod\n            def my_abstract_method(self, arg1, arg2, argN):\n                ...",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "check_array",
      "signature": "check_array(array, accept_sparse=False, *, accept_large_sparse=True, dtype='numeric', order=None, copy=False, force_writeable=False, force_all_finite='deprecated', ensure_all_finite=None, ensure_non_negative=False, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, estimator=None, input_name='')",
      "documentation": {
        "description": "Input validation on an array, list, sparse matrix or similar.\n\n    By default, the input is checked to be a non-empty 2D array containing\n    only finite values. If the dtype of the array is object, attempt\n    converting to float, raising on failure.\n\n    Parameters\n    ----------\n    array : object\n        Input object to check / convert.\n\n    accept_sparse : str, bool or list/tuple of str, default=False\n        String[s] representing allowed sparse matrix formats, such as 'csc',\n        'csr', etc. If the input is sparse but not in the allowed format,\n        it will be converted to the first listed format. True allows the input\n        to be any format. False means that a sparse matrix input will\n        raise an error.\n\n    accept_large_sparse : bool, default=True\n        If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by\n        accept_sparse, accept_large_sparse=False will cause it to be accepted\n        only if its indices are stored with a 32-bit dtype.\n\n        .. versionadded:: 0.20\n\n    dtype : 'numeric', type, list of type or None, default='numeric'\n        Data type of result. If None, the dtype of the input is preserved.\n        If \"numeric\", dtype is preserved unless array.dtype is object.\n        If dtype is a list of types, conversion on the first type is only\n        performed if the dtype of the input is not in the list.\n\n    order : {'F', 'C'} or None, default=None\n        Whether an array will be forced to be fortran or c-style.\n        When order is None (default), then if copy=False, nothing is ensured\n        about the memory layout of the output array; otherwise (copy=True)\n        the memory layout of the returned array is kept as close as possible\n        to the original array.\n\n    copy : bool, default=False\n        Whether a forced copy will be triggered. If copy=False, a copy might\n        be triggered by a conversion.\n\n    force_writeable : bool, default=False\n        Whether to force the output array to be writeable. If True, the returned array\n        is guaranteed to be writeable, which may require a copy. Otherwise the\n        writeability of the input array is preserved.\n\n        .. versionadded:: 1.6\n\n    force_all_finite : bool or 'allow-nan', default=True\n        Whether to raise an error on np.inf, np.nan, pd.NA in array. The\n        possibilities are:\n\n        - True: Force all values of array to be finite.\n        - False: accepts np.inf, np.nan, pd.NA in array.\n        - 'allow-nan': accepts only np.nan and pd.NA values in array. Values\n          cannot be infinite.\n\n        .. versionadded:: 0.20\n           ``force_all_finite`` accepts the string ``'allow-nan'``.\n\n        .. versionchanged:: 0.23\n           Accepts `pd.NA` and converts it into `np.nan`\n\n        .. deprecated:: 1.6\n           `force_all_finite` was renamed to `ensure_all_finite` and will be removed\n           in 1.8.\n\n    ensure_all_finite : bool or 'allow-nan', default=True\n        Whether to raise an error on np.inf, np.nan, pd.NA in array. The\n        possibilities are:\n\n        - True: Force all values of array to be finite.\n        - False: accepts np.inf, np.nan, pd.NA in array.\n        - 'allow-nan': accepts only np.nan and pd.NA values in array. Values\n          cannot be infinite.\n\n        .. versionadded:: 1.6\n           `force_all_finite` was renamed to `ensure_all_finite`.\n\n    ensure_non_negative : bool, default=False\n        Make sure the array has only non-negative values. If True, an array that\n        contains negative values will raise a ValueError.\n\n        .. versionadded:: 1.6\n\n    ensure_2d : bool, default=True\n        Whether to raise a value error if array is not 2D.\n\n    allow_nd : bool, default=False\n        Whether to allow array.ndim > 2.\n\n    ensure_min_samples : int, default=1\n        Make sure that the array has a minimum number of samples in its first\n        axis (rows for a 2D array). Setting to 0 disables this check.\n\n    ensure_min_features : int, default=1\n        Make sure that the 2D array has some minimum number of features\n        (columns). The default value of 1 rejects empty datasets.\n        This check is only enforced when the input data has effectively 2\n        dimensions or is originally 1D and ``ensure_2d`` is True. Setting to 0\n        disables this check.\n\n    estimator : str or estimator instance, default=None\n        If passed, include the name of the estimator in warning messages.\n\n    input_name : str, default=\"\"\n        The data name used to construct the error message. In particular\n        if `input_name` is \"X\" and the data has NaN values and\n        allow_nan is False, the error message will link to the imputer\n        documentation.\n\n        .. versionadded:: 1.1.0\n\n    Returns\n    -------\n    array_converted : object\n        The converted and validated array.",
        "parameters": {
          "array": {
            "type": "[[1, 2, 3], [4, 5, 6]]",
            "description": ""
          },
          "Input": {
            "type": "object to check / convert.",
            "description": ""
          },
          "accept_sparse": {
            "type": "str, bool or list/tuple of str, default=False",
            "description": "String[s] representing allowed sparse matrix formats, such as 'csc',\n'csr', etc. If the input is sparse but not in the allowed format,"
          },
          "it": {
            "type": "will be converted to the first listed format. True allows the input",
            "description": ""
          },
          "to": {
            "type": "the original array.",
            "description": ""
          },
          "raise": {
            "type": "an error.",
            "description": ""
          },
          "accept_large_sparse": {
            "type": "bool, default=True",
            "description": ""
          },
          "If": {
            "type": "passed, include the name of the estimator in warning messages.",
            "description": ""
          },
          "only": {
            "type": "if its indices are stored with a 32-bit dtype.",
            "description": ".. versionadded:: 0.20"
          },
          "dtype": {
            "type": "'numeric', type, list of type or None, default='numeric'",
            "description": ""
          },
          "Data": {
            "type": "type of result. If None, the dtype of the input is preserved.",
            "description": ""
          },
          "performed": {
            "type": "if the dtype of the input is not in the list.",
            "description": ""
          },
          "order": {
            "type": "{'F', 'C'} or None, default=None",
            "description": ""
          },
          "Whether": {
            "type": "to allow array.ndim > 2.",
            "description": ""
          },
          "When": {
            "type": "order is None (default), then if copy=False, nothing is ensured",
            "description": ""
          },
          "about": {
            "type": "the memory layout of the output array; otherwise (copy=True)",
            "description": ""
          },
          "the": {
            "type": "memory layout of the returned array is kept as close as possible",
            "description": ""
          },
          "copy": {
            "type": "bool, default=False",
            "description": ""
          },
          "be": {
            "type": "triggered by a conversion.",
            "description": ""
          },
          "force_writeable": {
            "type": "bool, default=False",
            "description": ""
          },
          "is": {
            "type": "guaranteed to be writeable, which may require a copy. Otherwise the",
            "description": ""
          },
          "writeability": {
            "type": "of the input array is preserved.",
            "description": ".. versionadded:: 1.6"
          },
          "force_all_finite": {
            "type": "bool or 'allow",
            "description": "nan', default=True"
          },
          "possibilities": {
            "type": "are:",
            "description": "- True: Force all values of array to be finite.\n- False: accepts np.inf, np.nan, pd.NA in array.\n- 'allow-nan': accepts only np.nan and pd.NA values in array. Values"
          },
          "cannot": {
            "type": "be infinite.",
            "description": ".. versionadded:: 1.6\n`force_all_finite` was renamed to `ensure_all_finite`."
          },
          "Accepts": {
            "type": "`pd.NA` and converts it into `np.nan`",
            "description": ".. deprecated:: 1.6\n`force_all_finite` was renamed to `ensure_all_finite` and will be removed"
          },
          "in": {
            "type": "1.8.",
            "description": ""
          },
          "ensure_all_finite": {
            "type": "bool or 'allow",
            "description": "nan', default=True"
          },
          "ensure_non_negative": {
            "type": "bool, default=False",
            "description": ""
          },
          "Make": {
            "type": "sure that the 2D array has some minimum number of features",
            "description": "(columns). The default value of 1 rejects empty datasets."
          },
          "contains": {
            "type": "negative values will raise a ValueError.",
            "description": ".. versionadded:: 1.6"
          },
          "ensure_2d": {
            "type": "bool, default=True",
            "description": ""
          },
          "allow_nd": {
            "type": "bool, default=False",
            "description": ""
          },
          "ensure_min_samples": {
            "type": "int, default=1",
            "description": ""
          },
          "axis": {
            "type": "rows for a 2D array",
            "description": ". Setting to 0 disables this check."
          },
          "ensure_min_features": {
            "type": "int, default=1",
            "description": ""
          },
          "This": {
            "type": "check is only enforced when the input data has effectively 2",
            "description": ""
          },
          "dimensions": {
            "type": "or is originally 1D and ``ensure_2d`` is True. Setting to 0",
            "description": ""
          },
          "disables": {
            "type": "this check.",
            "description": ""
          },
          "estimator": {
            "type": "str or estimator instance, default=None",
            "description": ""
          },
          "input_name": {
            "type": "str, default=\"\"",
            "description": ""
          },
          "The": {
            "type": "converted and validated array.",
            "description": "Examples\n--------\n>>> from sklearn.utils.validation import check_array\n>>> X = [[1, 2, 3], [4, 5, 6]]\n>>> X_checked = check_array(X)\n>>> X_checked"
          },
          "if": {
            "type": "`input_name` is \"X\" and the data has NaN values and",
            "description": ""
          },
          "allow_nan": {
            "type": "is False, the error message will link to the imputer",
            "description": "documentation.\n.. versionadded:: 1.1.0\nReturns\n-------"
          },
          "array_converted": {
            "type": "object",
            "description": ""
          }
        },
        "returns": "-------\n    array_converted : object\n        The converted and validated array.\n\n    Examples\n    --------\n    >>> from sklearn.utils.validation import check_array\n    >>> X = [[1, 2, 3], [4, 5, 6]]\n    >>> X_checked = check_array(X)\n    >>> X_checked\n    array([[1, 2, 3], [4, 5, 6]])",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils.validation import check_array\n    >>> X = [[1, 2, 3], [4, 5, 6]]\n    >>> X_checked = check_array(X)\n    >>> X_checked\n    array([[1, 2, 3], [4, 5, 6]])"
      }
    },
    {
      "name": "check_is_fitted",
      "signature": "check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=<built-in function all>)",
      "documentation": {
        "description": "Perform is_fitted validation for estimator.\n\n    Checks if the estimator is fitted by verifying the presence of\n    fitted attributes (ending with a trailing underscore) and otherwise\n    raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n\n    If an estimator does not set any attributes with a trailing underscore, it\n    can define a ``__sklearn_is_fitted__`` method returning a boolean to\n    specify if the estimator is fitted or not. See\n    :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n    for an example on how to use the API.\n\n    If no `attributes` are passed, this fuction will pass if an estimator is stateless.\n    An estimator can indicate it's stateless by setting the `requires_fit` tag. See\n    :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n    is ignored if `attributes` are passed.\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        Estimator instance for which the check is performed.\n\n    attributes : str, list or tuple of str, default=None\n        Attribute name(s) given as string or a list/tuple of strings\n        Eg.: ``[\"coef_\", \"estimator_\", ...], \"coef_\"``\n\n        If `None`, `estimator` is considered fitted if there exist an\n        attribute that ends with a underscore and does not start with double\n        underscore.\n\n    msg : str, default=None\n        The default error message is, \"This %(name)s instance is not fitted\n        yet. Call 'fit' with appropriate arguments before using this\n        estimator.\"\n\n        For custom messages if \"%(name)s\" is present in the message string,\n        it is substituted for the estimator name.\n\n        Eg. : \"Estimator, %(name)s, must be fitted before sparsifying\".\n\n    all_or_any : callable, {all, any}, default=all\n        Specify whether all or any of the given attributes must exist.\n\n    Raises\n    ------\n    TypeError\n        If the estimator is a class or not an estimator instance\n\n    NotFittedError\n        If the attributes are not found.",
        "parameters": {
          "estimator": {
            "type": "estimator instance",
            "description": ""
          },
          "Estimator": {
            "type": "instance for which the check is performed.",
            "description": ""
          },
          "attributes": {
            "type": "str, list or tuple of str, default=None",
            "description": ""
          },
          "Attribute": {
            "type": "name(s) given as string or a list/tuple of strings",
            "description": "Eg.: ``[\"coef_\", \"estimator_\", ...], \"coef_\"``"
          },
          "If": {
            "type": "the attributes are not found.",
            "description": "Examples\n--------\n>>> from sklearn.linear_model import LogisticRegression\n>>> from sklearn.utils.validation import check_is_fitted\n>>> from sklearn.exceptions import NotFittedError\n>>> lr = LogisticRegression()\n>>> try:\n...     check_is_fitted(lr)\n... except NotFittedError as exc:\n...     print(f\"Model is not fitted yet.\")"
          },
          "attribute": {
            "type": "that ends with a underscore and does not start with double",
            "description": "underscore."
          },
          "msg": {
            "type": "str, default=None",
            "description": ""
          },
          "The": {
            "type": "default error message is, \"This %(name)s instance is not fitted",
            "description": "yet. Call 'fit' with appropriate arguments before using this\nestimator.\""
          },
          "For": {
            "type": "custom messages if \"%(name)s\" is present in the message string,",
            "description": ""
          },
          "it": {
            "type": "is substituted for the estimator name.",
            "description": "Eg. : \"Estimator, %(name)s, must be fitted before sparsifying\"."
          },
          "all_or_any": {
            "type": "callable, {all, any}, default=all",
            "description": ""
          },
          "Specify": {
            "type": "whether all or any of the given attributes must exist.",
            "description": "Raises\n------\nTypeError"
          },
          "Model": {
            "type": "is not fitted yet.",
            "description": ">>> lr.fit([[1, 2], [1, 3]], [1, 0])"
          },
          "LogisticRegression": {
            "type": "",
            "description": ">>> check_is_fitted(lr)"
          }
        },
        "returns": "",
        "raises": "a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n\n    If an estimator does not set any attributes with a trailing underscore, it\n    can define a ``__sklearn_is_fitted__`` method returning a boolean to\n    specify if the estimator is fitted or not. See\n    :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n    for an example on how to use the API.\n\n    If no `attributes` are passed, this fuction will pass if an estimator is stateless.\n    An estimator can indicate it's stateless by setting the `requires_fit` tag. See\n    :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n    is ignored if `attributes` are passed.\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        Estimator instance for which the check is performed.\n\n    attributes : str, list or tuple of str, default=None\n        Attribute name(s) given as string or a list/tuple of strings\n        Eg.: ``[\"coef_\", \"estimator_\", ...], \"coef_\"``\n\n        If `None`, `estimator` is considered fitted if there exist an\n        attribute that ends with a underscore and does not start with double\n        underscore.\n\n    msg : str, default=None\n        The default error message is, \"This %(name)s instance is not fitted\n        yet. Call 'fit' with appropriate arguments before using this\n        estimator.\"\n\n        For custom messages if \"%(name)s\" is present in the message string,\n        it is substituted for the estimator name.\n\n        Eg. : \"Estimator, %(name)s, must be fitted before sparsifying\".\n\n    all_or_any : callable, {all, any}, default=all\n        Specify whether all or any of the given attributes must exist.",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> from sklearn.utils.validation import check_is_fitted\n    >>> from sklearn.exceptions import NotFittedError\n    >>> lr = LogisticRegression()\n    >>> try:\n    ...     check_is_fitted(lr)\n    ... except NotFittedError as exc:\n    ...     print(f\"Model is not fitted yet.\")\n    Model is not fitted yet.\n    >>> lr.fit([[1, 2], [1, 3]], [1, 0])\n    LogisticRegression()\n    >>> check_is_fitted(lr)"
      }
    },
    {
      "name": "check_random_state",
      "signature": "check_random_state(seed)",
      "documentation": {
        "description": "Turn seed into a np.random.RandomState instance.\n\n    Parameters\n    ----------\n    seed : None, int or instance of RandomState\n        If seed is None, return the RandomState singleton used by np.random.\n        If seed is an int, return a new RandomState instance seeded with seed.\n        If seed is already a RandomState instance, return it.\n        Otherwise raise ValueError.\n\n    Returns\n    -------\n    :class:`numpy:numpy.random.RandomState`\n        The random state object based on `seed` parameter.",
        "parameters": {
          "seed": {
            "type": "None, int or instance of RandomState",
            "description": ""
          },
          "If": {
            "type": "seed is already a RandomState instance, return it.",
            "description": ""
          },
          "Otherwise": {
            "type": "raise ValueError.",
            "description": "Returns\n-------\n:class:`numpy:numpy.random.RandomState`"
          },
          "The": {
            "type": "random state object based on `seed` parameter.",
            "description": "Examples\n--------\n>>> from sklearn.utils.validation import check_random_state\n>>> check_random_state(42)"
          },
          "RandomState": {
            "type": "MT19937",
            "description": "at 0x..."
          }
        },
        "returns": "-------\n    :class:`numpy:numpy.random.RandomState`\n        The random state object based on `seed` parameter.\n\n    Examples\n    --------\n    >>> from sklearn.utils.validation import check_random_state\n    >>> check_random_state(42)\n    RandomState(MT19937) at 0x...",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils.validation import check_random_state\n    >>> check_random_state(42)\n    RandomState(MT19937) at 0x..."
      }
    },
    {
      "name": "johnson_lindenstrauss_min_dim",
      "signature": "johnson_lindenstrauss_min_dim(n_samples, *, eps=0.1)",
      "documentation": {
        "description": "Find a 'safe' number of components to randomly project to.\n\n    The distortion introduced by a random projection `p` only changes the\n    distance between two points by a factor (1 +- eps) in a euclidean space\n    with good probability. The projection `p` is an eps-embedding as defined\n    by:\n\n    .. code-block:: text\n\n      (1 - eps) ||u - v||^2 < ||p(u) - p(v)||^2 < (1 + eps) ||u - v||^2\n\n    Where u and v are any rows taken from a dataset of shape (n_samples,\n    n_features), eps is in ]0, 1[ and p is a projection by a random Gaussian\n    N(0, 1) matrix of shape (n_components, n_features) (or a sparse\n    Achlioptas matrix).\n\n    The minimum number of components to guarantee the eps-embedding is\n    given by:\n\n    .. code-block:: text\n\n      n_components >= 4 log(n_samples) / (eps^2 / 2 - eps^3 / 3)\n\n    Note that the number of dimensions is independent of the original\n    number of features but instead depends on the size of the dataset:\n    the larger the dataset, the higher is the minimal dimensionality of\n    an eps-embedding.\n\n    Read more in the :ref:`User Guide <johnson_lindenstrauss>`.\n\n    Parameters\n    ----------\n    n_samples : int or array-like of int\n        Number of samples that should be an integer greater than 0. If an array\n        is given, it will compute a safe number of components array-wise.\n\n    eps : float or array-like of shape (n_components,), dtype=float,             default=0.1\n        Maximum distortion rate in the range (0, 1) as defined by the\n        Johnson-Lindenstrauss lemma. If an array is given, it will compute a\n        safe number of components array-wise.\n\n    Returns\n    -------\n    n_components : int or ndarray of int\n        The minimal number of components to guarantee with good probability\n        an eps-embedding with n_samples.\n\n    References\n    ----------\n\n    .. [1] https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma\n\n    .. [2] `Sanjoy Dasgupta and Anupam Gupta, 1999,\n           \"An elementary proof of the Johnson-Lindenstrauss Lemma.\"\n           <https://citeseerx.ist.psu.edu/doc_view/pid/95cd464d27c25c9c8690b378b894d337cdf021f9>`_",
        "parameters": {
          "n_samples": {
            "type": "int or array",
            "description": "like of int"
          },
          "Number": {
            "type": "of samples that should be an integer greater than 0. If an array",
            "description": ""
          },
          "is": {
            "type": "given, it will compute a safe number of components array-wise.",
            "description": ""
          },
          "eps": {
            "type": "float or array",
            "description": "like of shape (n_components,), dtype=float,             default=0.1"
          },
          "Maximum": {
            "type": "distortion rate in the range (0, 1) as defined by the",
            "description": "Johnson-Lindenstrauss lemma. If an array is given, it will compute a"
          },
          "safe": {
            "type": "number of components array-wise.",
            "description": "Returns\n-------"
          },
          "n_components": {
            "type": "int or ndarray of int",
            "description": ""
          },
          "The": {
            "type": "minimal number of components to guarantee with good probability",
            "description": ""
          },
          "an": {
            "type": "eps-embedding with n_samples.",
            "description": "References\n----------\n.. [1] https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma\n.. [2] `Sanjoy Dasgupta and Anupam Gupta, 1999,\n\"An elementary proof of the Johnson-Lindenstrauss Lemma.\"\n<https://citeseerx.ist.psu.edu/doc_view/pid/95cd464d27c25c9c8690b378b894d337cdf021f9>`_\nExamples\n--------\n>>> from sklearn.random_projection import johnson_lindenstrauss_min_dim\n>>> johnson_lindenstrauss_min_dim(1e6, eps=0.5)\nnp.int64(663)\n>>> johnson_lindenstrauss_min_dim(1e6, eps=[0.5, 0.1, 0.01])"
          },
          "array": {
            "type": "[ 7894,  9868, 11841]",
            "description": ""
          }
        },
        "returns": "-------\n    n_components : int or ndarray of int\n        The minimal number of components to guarantee with good probability\n        an eps-embedding with n_samples.\n\n    References\n    ----------\n\n    .. [1] https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma\n\n    .. [2] `Sanjoy Dasgupta and Anupam Gupta, 1999,\n           \"An elementary proof of the Johnson-Lindenstrauss Lemma.\"\n           <https://citeseerx.ist.psu.edu/doc_view/pid/95cd464d27c25c9c8690b378b894d337cdf021f9>`_\n\n    Examples\n    --------\n    >>> from sklearn.random_projection import johnson_lindenstrauss_min_dim\n    >>> johnson_lindenstrauss_min_dim(1e6, eps=0.5)\n    np.int64(663)\n\n    >>> johnson_lindenstrauss_min_dim(1e6, eps=[0.5, 0.1, 0.01])\n    array([    663,   11841, 1112658])\n\n    >>> johnson_lindenstrauss_min_dim([1e4, 1e5, 1e6], eps=0.1)\n    array([ 7894,  9868, 11841])",
        "raises": "",
        "see_also": "",
        "notes": "that the number of dimensions is independent of the original\n    number of features but instead depends on the size of the dataset:\n    the larger the dataset, the higher is the minimal dimensionality of\n    an eps-embedding.\n\n    Read more in the :ref:`User Guide <johnson_lindenstrauss>`.\n\n    Parameters\n    ----------\n    n_samples : int or array-like of int\n        Number of samples that should be an integer greater than 0. If an array\n        is given, it will compute a safe number of components array-wise.\n\n    eps : float or array-like of shape (n_components,), dtype=float,             default=0.1\n        Maximum distortion rate in the range (0, 1) as defined by the\n        Johnson-Lindenstrauss lemma. If an array is given, it will compute a\n        safe number of components array-wise.\n\n    Returns\n    -------\n    n_components : int or ndarray of int\n        The minimal number of components to guarantee with good probability\n        an eps-embedding with n_samples.\n\n    References\n    ----------\n\n    .. [1] https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma\n\n    .. [2] `Sanjoy Dasgupta and Anupam Gupta, 1999,\n           \"An elementary proof of the Johnson-Lindenstrauss Lemma.\"\n           <https://citeseerx.ist.psu.edu/doc_view/pid/95cd464d27c25c9c8690b378b894d337cdf021f9>`_\n\n    Examples\n    --------\n    >>> from sklearn.random_projection import johnson_lindenstrauss_min_dim\n    >>> johnson_lindenstrauss_min_dim(1e6, eps=0.5)\n    np.int64(663)\n\n    >>> johnson_lindenstrauss_min_dim(1e6, eps=[0.5, 0.1, 0.01])\n    array([    663,   11841, 1112658])\n\n    >>> johnson_lindenstrauss_min_dim([1e4, 1e5, 1e6], eps=0.1)\n    array([ 7894,  9868, 11841])",
        "examples": "--------\n    >>> from sklearn.random_projection import johnson_lindenstrauss_min_dim\n    >>> johnson_lindenstrauss_min_dim(1e6, eps=0.5)\n    np.int64(663)\n\n    >>> johnson_lindenstrauss_min_dim(1e6, eps=[0.5, 0.1, 0.01])\n    array([    663,   11841, 1112658])\n\n    >>> johnson_lindenstrauss_min_dim([1e4, 1e5, 1e6], eps=0.1)\n    array([ 7894,  9868, 11841])"
      }
    },
    {
      "name": "safe_sparse_dot",
      "signature": "safe_sparse_dot(a, b, *, dense_output=False)",
      "documentation": {
        "description": "Dot product that handle the sparse matrix case correctly.\n\n    Parameters\n    ----------\n    a : {ndarray, sparse matrix}\n    b : {ndarray, sparse matrix}\n    dense_output : bool, default=False\n        When False, ``a`` and ``b`` both being sparse will yield sparse output.\n        When True, output will always be a dense array.\n\n    Returns\n    -------\n    dot_product : {ndarray, sparse matrix}\n        Sparse if ``a`` and ``b`` are sparse and ``dense_output=False``.",
        "parameters": {
          "a": {
            "type": "{ndarray, sparse matrix}",
            "description": ""
          },
          "b": {
            "type": "{ndarray, sparse matrix}",
            "description": ""
          },
          "dense_output": {
            "type": "bool, default=False",
            "description": ""
          },
          "When": {
            "type": "True, output will always be a dense array.",
            "description": "Returns\n-------"
          },
          "dot_product": {
            "type": "{ndarray, sparse matrix}",
            "description": ""
          },
          "Sparse": {
            "type": "if ``a`` and ``b`` are sparse and ``dense_output=False``.",
            "description": "Examples\n--------\n>>> from scipy.sparse import csr_matrix\n>>> from sklearn.utils.extmath import safe_sparse_dot\n>>> X = csr_matrix([[1, 2], [3, 4], [5, 6]])\n>>> dot_product = safe_sparse_dot(X, X.T)\n>>> dot_product.toarray()\narray([[ 5, 11, 17],\n[11, 25, 39],\n[17, 39, 61]])"
          }
        },
        "returns": "-------\n    dot_product : {ndarray, sparse matrix}\n        Sparse if ``a`` and ``b`` are sparse and ``dense_output=False``.\n\n    Examples\n    --------\n    >>> from scipy.sparse import csr_matrix\n    >>> from sklearn.utils.extmath import safe_sparse_dot\n    >>> X = csr_matrix([[1, 2], [3, 4], [5, 6]])\n    >>> dot_product = safe_sparse_dot(X, X.T)\n    >>> dot_product.toarray()\n    array([[ 5, 11, 17],\n           [11, 25, 39],\n           [17, 39, 61]])",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from scipy.sparse import csr_matrix\n    >>> from sklearn.utils.extmath import safe_sparse_dot\n    >>> X = csr_matrix([[1, 2], [3, 4], [5, 6]])\n    >>> dot_product = safe_sparse_dot(X, X.T)\n    >>> dot_product.toarray()\n    array([[ 5, 11, 17],\n           [11, 25, 39],\n           [17, 39, 61]])"
      }
    },
    {
      "name": "sample_without_replacement",
      "signature": "sample_without_replacement(n_population, n_samples, method='auto', random_state=None)",
      "documentation": {
        "description": "Sample integers without replacement.\n\n    Select n_samples integers from the set [0, n_population) without\n    replacement.\n\n\n    Parameters\n    ----------\n    n_population : int\n        The size of the set to sample from.\n\n    n_samples : int\n        The number of integer to sample.\n\n    random_state : int, RandomState instance or None, default=None\n        If int, random_state is the seed used by the random number generator;\n        If RandomState instance, random_state is the random number generator;\n        If None, the random number generator is the RandomState instance used\n        by `np.random`.\n\n    method : {\"auto\", \"tracking_selection\", \"reservoir_sampling\", \"pool\"},             default='auto'\n        If method == \"auto\", the ratio of n_samples / n_population is used\n        to determine which algorithm to use:\n        If ratio is between 0 and 0.01, tracking selection is used.\n        If ratio is between 0.01 and 0.99, numpy.random.permutation is used.\n        If ratio is greater than 0.99, reservoir sampling is used.\n        The order of the selected integers is undefined. If a random order is\n        desired, the selected subset should be shuffled.\n\n        If method ==\"tracking_selection\", a set based implementation is used\n        which is suitable for `n_samples` <<< `n_population`.\n\n        If method == \"reservoir_sampling\", a reservoir sampling algorithm is\n        used which is suitable for high memory constraint or when\n        O(`n_samples`) ~ O(`n_population`).\n        The order of the selected integers is undefined. If a random order is\n        desired, the selected subset should be shuffled.\n\n        If method == \"pool\", a pool based algorithm is particularly fast, even\n        faster than the tracking selection method. However, a vector containing\n        the entire population has to be initialized.\n        If n_samples ~ n_population, the reservoir sampling method is faster.\n\n    Returns\n    -------\n    out : ndarray of shape (n_samples,)\n        The sampled subsets of integer. The subset of selected integer might\n        not be randomized, see the method argument.",
        "parameters": {
          "n_population": {
            "type": "int",
            "description": ""
          },
          "The": {
            "type": "sampled subsets of integer. The subset of selected integer might",
            "description": ""
          },
          "n_samples": {
            "type": "int",
            "description": ""
          },
          "random_state": {
            "type": "int, RandomState instance or None, default=None",
            "description": ""
          },
          "If": {
            "type": "n_samples ~ n_population, the reservoir sampling method is faster.",
            "description": "Returns\n-------"
          },
          "by": {
            "type": "`np.random`.",
            "description": ""
          },
          "method": {
            "type": "{\"auto\", \"tracking_selection\", \"reservoir_sampling\", \"pool\"},             default='auto'",
            "description": ""
          },
          "to": {
            "type": "determine which algorithm to use:",
            "description": ""
          },
          "which": {
            "type": "is suitable for `n_samples` <<< `n_population`.",
            "description": ""
          },
          "used": {
            "type": "which is suitable for high memory constraint or when",
            "description": ""
          },
          "O": {
            "type": "`n_samples`",
            "description": "~ O(`n_population`)."
          },
          "faster": {
            "type": "than the tracking selection method. However, a vector containing",
            "description": ""
          },
          "the": {
            "type": "entire population has to be initialized.",
            "description": ""
          },
          "out": {
            "type": "ndarray of shape (n_samples,)",
            "description": ""
          },
          "not": {
            "type": "be randomized, see the method argument.",
            "description": "Examples\n--------\n>>> from sklearn.utils.random import sample_without_replacement\n>>> sample_without_replacement(10, 5, random_state=42)"
          },
          "array": {
            "type": "[8, 1, 5, 0, 7]",
            "description": ""
          }
        },
        "returns": "-------\n    out : ndarray of shape (n_samples,)\n        The sampled subsets of integer. The subset of selected integer might\n        not be randomized, see the method argument.\n\n    Examples\n    --------\n    >>> from sklearn.utils.random import sample_without_replacement\n    >>> sample_without_replacement(10, 5, random_state=42)\n    array([8, 1, 5, 0, 7])",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils.random import sample_without_replacement\n    >>> sample_without_replacement(10, 5, random_state=42)\n    array([8, 1, 5, 0, 7])"
      }
    },
    {
      "name": "validate_data",
      "signature": "validate_data(_estimator, /, X='no_validation', y='no_validation', reset=True, validate_separately=False, skip_check_array=False, **check_params)",
      "documentation": {
        "description": "Validate input data and set or check feature names and counts of the input.\n\n    This helper function should be used in an estimator that requires input\n    validation. This mutates the estimator and sets the `n_features_in_` and\n    `feature_names_in_` attributes if `reset=True`.\n\n    .. versionadded:: 1.6\n\n    Parameters\n    ----------\n    _estimator : estimator instance\n        The estimator to validate the input for.\n\n    X : {array-like, sparse matrix, dataframe} of shape             (n_samples, n_features), default='no validation'\n        The input samples.\n        If `'no_validation'`, no validation is performed on `X`. This is\n        useful for meta-estimator which can delegate input validation to\n        their underlying estimator(s). In that case `y` must be passed and\n        the only accepted `check_params` are `multi_output` and\n        `y_numeric`.\n\n    y : array-like of shape (n_samples,), default='no_validation'\n        The targets.\n\n        - If `None`, :func:`~sklearn.utils.check_array` is called on `X`. If\n          the estimator's `requires_y` tag is True, then an error will be raised.\n        - If `'no_validation'`, :func:`~sklearn.utils.check_array` is called\n          on `X` and the estimator's `requires_y` tag is ignored. This is a default\n          placeholder and is never meant to be explicitly set. In that case `X` must be\n          passed.\n        - Otherwise, only `y` with `_check_y` or both `X` and `y` are checked with\n          either :func:`~sklearn.utils.check_array` or\n          :func:`~sklearn.utils.check_X_y` depending on `validate_separately`.\n\n    reset : bool, default=True\n        Whether to reset the `n_features_in_` attribute.\n        If False, the input will be checked for consistency with data\n        provided when reset was last True.\n\n        .. note::\n\n           It is recommended to call `reset=True` in `fit` and in the first\n           call to `partial_fit`. All other methods that validate `X`\n           should set `reset=False`.\n\n    validate_separately : False or tuple of dicts, default=False\n        Only used if `y` is not `None`.\n        If `False`, call :func:`~sklearn.utils.check_X_y`. Else, it must be a tuple of\n        kwargs to be used for calling :func:`~sklearn.utils.check_array` on `X` and `y`\n        respectively.\n\n        `estimator=self` is automatically added to these dicts to generate\n        more informative error message in case of invalid input data.\n\n    skip_check_array : bool, default=False\n        If `True`, `X` and `y` are unchanged and only `feature_names_in_` and\n        `n_features_in_` are checked. Otherwise, :func:`~sklearn.utils.check_array`\n        is called on `X` and `y`.\n\n    **check_params : kwargs\n        Parameters passed to :func:`~sklearn.utils.check_array` or\n        :func:`~sklearn.utils.check_X_y`. Ignored if validate_separately\n        is not False.\n\n        `estimator=self` is automatically added to these params to generate\n        more informative error message in case of invalid input data.",
        "parameters": {
          "_estimator": {
            "type": "estimator instance",
            "description": ""
          },
          "The": {
            "type": "targets.",
            "description": "- If `None`, :func:`~sklearn.utils.check_array` is called on `X`. If"
          },
          "X": {
            "type": "{array",
            "description": "like, sparse matrix, dataframe} of shape             (n_samples, n_features), default='no validation'"
          },
          "If": {
            "type": "`True`, `X` and `y` are unchanged and only `feature_names_in_` and",
            "description": "`n_features_in_` are checked. Otherwise, :func:`~sklearn.utils.check_array`"
          },
          "useful": {
            "type": "for meta-estimator which can delegate input validation to",
            "description": ""
          },
          "their": {
            "type": "underlying estimator(s). In that case `y` must be passed and",
            "description": ""
          },
          "the": {
            "type": "estimator's `requires_y` tag is True, then an error will be raised.",
            "description": "- If `'no_validation'`, :func:`~sklearn.utils.check_array` is called"
          },
          "y": {
            "type": "array",
            "description": "like of shape (n_samples,), default='no_validation'"
          },
          "on": {
            "type": "`X` and the estimator's `requires_y` tag is ignored. This is a default",
            "description": ""
          },
          "placeholder": {
            "type": "and is never meant to be explicitly set. In that case `X` must be",
            "description": "passed.\n- Otherwise, only `y` with `_check_y` or both `X` and `y` are checked with"
          },
          "either": {
            "type": "func:`~sklearn.utils.check_array` or",
            "description": ":func:`~sklearn.utils.check_X_y` depending on `validate_separately`."
          },
          "reset": {
            "type": "bool, default=True",
            "description": ""
          },
          "Whether": {
            "type": "to reset the `n_features_in_` attribute.",
            "description": ""
          },
          "provided": {
            "type": "when reset was last True.",
            "description": ".. note::"
          },
          "It": {
            "type": "is recommended to call `reset=True` in `fit` and in the first",
            "description": ""
          },
          "call": {
            "type": "to `partial_fit`. All other methods that validate `X`",
            "description": ""
          },
          "should": {
            "type": "set `reset=False`.",
            "description": ""
          },
          "validate_separately": {
            "type": "False or tuple of dicts, default=False",
            "description": ""
          },
          "Only": {
            "type": "used if `y` is not `None`.",
            "description": ""
          },
          "kwargs": {
            "type": "to be used for calling :func:`~sklearn.utils.check_array` on `X` and `y`",
            "description": "respectively.\n`estimator=self` is automatically added to these dicts to generate"
          },
          "more": {
            "type": "informative error message in case of invalid input data.",
            "description": ""
          },
          "skip_check_array": {
            "type": "bool, default=False",
            "description": ""
          },
          "is": {
            "type": "called on `X` and `y`.",
            "description": "**check_params : kwargs"
          }
        },
        "returns": "-------\n    out : {ndarray, sparse matrix} or tuple of these\n        The validated input. A tuple is returned if both `X` and `y` are\n        validated.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "validate_params",
      "signature": "validate_params(parameter_constraints, *, prefer_skip_nested_validation)",
      "documentation": {
        "description": "Decorator to validate types and values of functions and methods.\n\n    Parameters\n    ----------\n    parameter_constraints : dict\n        A dictionary `param_name: list of constraints`. See the docstring of\n        `validate_parameter_constraints` for a description of the accepted constraints.",
        "parameters": {
          "parameter_constraints": {
            "type": "dict",
            "description": ""
          },
          "A": {
            "type": "dictionary `param_name: list of constraints`. See the docstring of",
            "description": "`validate_parameter_constraints` for a description of the accepted constraints."
          },
          "Note": {
            "type": "that the *args and **kwargs parameters are not validated and must not be",
            "description": ""
          },
          "present": {
            "type": "in the parameter_constraints dictionary.",
            "description": ""
          },
          "prefer_skip_nested_validation": {
            "type": "bool",
            "description": ""
          },
          "If": {
            "type": "True, the validation of parameters of inner estimators or functions",
            "description": ""
          },
          "called": {
            "type": "by the decorated function will be skipped.",
            "description": ""
          },
          "This": {
            "type": "is useful to avoid validating many times the parameters passed by the",
            "description": ""
          },
          "user": {
            "type": "from the public facing API. It's also useful to avoid validating",
            "description": ""
          }
        },
        "returns": "-------\n    decorated_function : function or method\n        The decorated function.",
        "raises": "",
        "see_also": "",
        "notes": "that the *args and **kwargs parameters are not validated and must not be\n        present in the parameter_constraints dictionary.\n\n    prefer_skip_nested_validation : bool\n        If True, the validation of parameters of inner estimators or functions\n        called by the decorated function will be skipped.\n\n        This is useful to avoid validating many times the parameters passed by the\n        user from the public facing API. It's also useful to avoid validating\n        parameters that we pass internally to inner functions that are guaranteed to\n        be valid by the test suite.\n\n        It should be set to True for most functions, except for those that receive\n        non-validated objects as parameters or that are just wrappers around classes\n        because they only perform a partial validation.\n\n    Returns\n    -------\n    decorated_function : function or method\n        The decorated function.",
        "examples": ""
      }
    }
  ],
  "classes": [
    {
      "name": "ABCMeta",
      "documentation": {
        "description": "Metaclass for defining Abstract Base Classes (ABCs).\n\n        Use this metaclass to create an ABC.  An ABC can be subclassed\n        directly, and then acts as a mix-in class.  You can also register\n        unrelated concrete classes (even built-in classes) and unrelated\n        ABCs as 'virtual subclasses' -- these and their descendants will\n        be considered subclasses of the registering ABC by the built-in\n        issubclass() function, but the registering ABC won't show up in\n        their MRO (Method Resolution Order) nor will method\n        implementations defined by the registering ABC be callable (not\n        even via super()).",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "mro",
          "signature": "mro(self, /)",
          "documentation": {
            "description": "Return a type's method resolution order.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "register",
          "signature": "register(cls, subclass)",
          "documentation": {
            "description": "Register a virtual subclass of an ABC.",
            "parameters": {},
            "returns": "the subclass, to allow usage as a class decorator.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "BaseEstimator",
      "documentation": {
        "description": "Base class for all estimators in scikit-learn.\n\n    Inheriting from this class provides default implementations of:\n\n    - setting and getting parameters used by `GridSearchCV` and friends;\n    - textual and HTML representation displayed in terminals and IDEs;\n    - estimator serialization;\n    - parameters validation;\n    - data validation;\n    - feature names validation.\n\n    Read more in the :ref:`User Guide <rolling_your_own_estimator>`.\n\n\n    Notes\n    -----\n    All estimators should specify all the parameters that can be set\n    at the class level in their ``__init__`` as explicit keyword\n    arguments (no ``*args`` or ``**kwargs``).",
        "parameters": {
          "array": {
            "type": "[3, 3, 3]",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "-----\n    All estimators should specify all the parameters that can be set\n    at the class level in their ``__init__`` as explicit keyword\n    arguments (no ``*args`` or ``**kwargs``).\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.base import BaseEstimator\n    >>> class MyEstimator(BaseEstimator):\n    ...     def __init__(self, *, param=1):\n    ...         self.param = param\n    ...     def fit(self, X, y=None):\n    ...         self.is_fitted_ = True\n    ...         return self\n    ...     def predict(self, X):\n    ...         return np.full(shape=X.shape[0], fill_value=self.param)\n    >>> estimator = MyEstimator(param=2)\n    >>> estimator.get_params()\n    {'param': 2}\n    >>> X = np.array([[1, 2], [2, 3], [3, 4]])\n    >>> y = np.array([1, 0, 1])\n    >>> estimator.fit(X, y).predict(X)\n    array([2, 2, 2])\n    >>> estimator.set_params(param=3).fit(X, y).predict(X)\n    array([3, 3, 3])",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.base import BaseEstimator\n    >>> class MyEstimator(BaseEstimator):\n    ...     def __init__(self, *, param=1):\n    ...         self.param = param\n    ...     def fit(self, X, y=None):\n    ...         self.is_fitted_ = True\n    ...         return self\n    ...     def predict(self, X):\n    ...         return np.full(shape=X.shape[0], fill_value=self.param)\n    >>> estimator = MyEstimator(param=2)\n    >>> estimator.get_params()\n    {'param': 2}\n    >>> X = np.array([[1, 2], [2, 3], [3, 4]])\n    >>> y = np.array([1, 0, 1])\n    >>> estimator.fit(X, y).predict(X)\n    array([2, 2, 2])\n    >>> estimator.set_params(param=3).fit(X, y).predict(X)\n    array([3, 3, 3])"
      },
      "methods": [
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "BaseRandomProjection",
      "documentation": {
        "description": "Base class for random projections.\n\n    Warning: This class should not be used directly.\n    Use derived classes instead.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, X, y=None)",
          "documentation": {
            "description": "Generate a sparse random projection matrix.\n\n        Parameters\n        ----------\n        X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n            Training set: only the shape is used to find optimal random\n            matrix dimensions based on the theory referenced in the\n            afore mentioned papers.\n\n        y : Ignored\n            Not used, present here for API consistency by convention.",
            "parameters": {
              "X": {
                "type": "{ndarray, sparse matrix} of shape (n_samples, n_features)",
                "description": ""
              },
              "Training": {
                "type": "set: only the shape is used to find optimal random",
                "description": ""
              },
              "matrix": {
                "type": "dimensions based on the theory referenced in the",
                "description": ""
              },
              "afore": {
                "type": "mentioned papers.",
                "description": ""
              },
              "y": {
                "type": "Ignored",
                "description": ""
              },
              "Not": {
                "type": "used, present here for API consistency by convention.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "BaseRandomProjection": {
                "type": "class instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object\n            BaseRandomProjection class instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit to data, then transform it.\n\n        Fits transformer to `X` and `y` with optional parameters `fit_params`\n        and returns a transformed version of `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input samples.\n\n        y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n            Target values (None for unsupervised transformations).\n\n        **fit_params : dict\n            Additional fit parameters.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
              },
              "Target": {
                "type": "values (None for unsupervised transformations).",
                "description": "**fit_params : dict"
              },
              "Additional": {
                "type": "fit parameters.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray array of shape (n_samples, n_features_new)",
                "description": ""
              },
              "Transformed": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray array of shape (n_samples, n_features_new)\n            Transformed array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Get output feature names for transformation.\n\n        The feature names out will prefixed by the lowercased class name. For\n        example, if the transformer outputs 3 features, then the feature names\n        out are: `[\"class_name0\", \"class_name1\", \"class_name2\"]`.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Only used to validate feature names with the names seen in `fit`.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Only": {
                "type": "used to validate feature names with the names seen in `fit`.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Transformed": {
                "type": "feature names.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_transform",
          "signature": "inverse_transform(self, X)",
          "documentation": {
            "description": "Project data back to its original space.",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like, sparse matrix} of shape (n_samples, n_components)"
              },
              "Data": {
                "type": "to be transformed back.",
                "description": "Returns\n-------"
              },
              "X_original": {
                "type": "ndarray of shape (n_samples, n_features)",
                "description": ""
              },
              "Reconstructed": {
                "type": "data.",
                "description": ""
              }
            },
            "returns": "an array X_original whose transform would be X. Note that even\n        if X is sparse, X_original is dense: this may use a lot of RAM.\n\n        If `compute_inverse_components` is False, the inverse of the components is\n        computed during each call to `inverse_transform` which can be costly.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_components)\n            Data to be transformed back.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "ClassNamePrefixFeaturesOutMixin",
      "documentation": {
        "description": "Mixin class for transformers that generate their own names by prefixing.\n\n    This mixin is useful when the transformer needs to generate its own feature\n    names out, such as :class:`~sklearn.decomposition.PCA`. For example, if\n    :class:`~sklearn.decomposition.PCA` outputs 3 features, then the generated feature\n    names out are: `[\"pca0\", \"pca1\", \"pca2\"]`.\n\n    This mixin assumes that a `_n_features_out` attribute is defined when the\n    transformer is fitted. `_n_features_out` is the number of output features\n    that the transformer will return in `transform` of `fit_transform`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.base import ClassNamePrefixFeaturesOutMixin, BaseEstimator\n    >>> class MyEstimator(ClassNamePrefixFeaturesOutMixin, BaseEstimator):\n    ...     def fit(self, X, y=None):\n    ...         self._n_features_out = X.shape[1]\n    ...         return self\n    >>> X = np.array([[1, 2], [3, 4]])\n    >>> MyEstimator().fit(X).get_feature_names_out()\n    array(['myestimator0', 'myestimator1'], dtype=object)"
      },
      "methods": [
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Get output feature names for transformation.\n\n        The feature names out will prefixed by the lowercased class name. For\n        example, if the transformer outputs 3 features, then the feature names\n        out are: `[\"class_name0\", \"class_name1\", \"class_name2\"]`.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Only used to validate feature names with the names seen in `fit`.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Only": {
                "type": "used to validate feature names with the names seen in `fit`.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Transformed": {
                "type": "feature names.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "DataDimensionalityWarning",
      "documentation": {
        "description": "Custom warning to notify potential issues with data dimensionality.\n\n    For example, in random projection, this warning is raised when the\n    number of components, which quantifies the dimensionality of the target\n    projection space, is higher than the number of features, which quantifies\n    the dimensionality of the original source space, to imply that the\n    dimensionality of the problem will not be reduced.\n\n    .. versionchanged:: 0.18\n       Moved from sklearn.utils.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "add_note",
          "signature": "add_note(note)",
          "documentation": {
            "description": "Exception.add_note(note) --\n    add a note to the exception",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_traceback",
          "signature": "with_traceback(tb)",
          "documentation": {
            "description": "Exception.with_traceback(tb) --\n    set self.__traceback__ to tb and return self.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "GaussianRandomProjection",
      "documentation": {
        "description": "Reduce dimensionality through Gaussian random projection.\n\n    The components of the random matrix are drawn from N(0, 1 / n_components).\n\n    Read more in the :ref:`User Guide <gaussian_random_matrix>`.\n\n    .. versionadded:: 0.13\n\n    Parameters\n    ----------\n    n_components : int or 'auto', default='auto'\n        Dimensionality of the target projection space.\n\n        n_components can be automatically adjusted according to the\n        number of samples in the dataset and the bound given by the\n        Johnson-Lindenstrauss lemma. In that case the quality of the\n        embedding is controlled by the ``eps`` parameter.\n\n        It should be noted that Johnson-Lindenstrauss lemma can yield\n        very conservative estimated of the required number of components\n        as it makes no assumption on the structure of the dataset.\n\n    eps : float, default=0.1\n        Parameter to control the quality of the embedding according to\n        the Johnson-Lindenstrauss lemma when `n_components` is set to\n        'auto'. The value should be strictly positive.\n\n        Smaller values lead to better embedding and higher number of\n        dimensions (n_components) in the target projection space.\n\n    compute_inverse_components : bool, default=False\n        Learn the inverse transform by computing the pseudo-inverse of the\n        components during fit. Note that computing the pseudo-inverse does not\n        scale well to large matrices.\n\n    random_state : int, RandomState instance or None, default=None\n        Controls the pseudo random number generator used to generate the\n        projection matrix at fit time.\n        Pass an int for reproducible output across multiple function calls.\n        See :term:`Glossary <random_state>`.\n\n    Attributes\n    ----------\n    n_components_ : int\n        Concrete number of components computed when n_components=\"auto\".\n\n    components_ : ndarray of shape (n_components, n_features)\n        Random matrix used for the projection.\n\n    inverse_components_ : ndarray of shape (n_features, n_components)\n        Pseudo-inverse of the components, only computed if\n        `compute_inverse_components` is True.\n\n        .. versionadded:: 1.1\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    SparseRandomProjection : Reduce dimensionality through sparse\n        random projection.",
        "parameters": {
          "n_components": {
            "type": "can be automatically adjusted according to the",
            "description": ""
          },
          "Dimensionality": {
            "type": "of the target projection space.",
            "description": ""
          },
          "number": {
            "type": "of samples in the dataset and the bound given by the",
            "description": "Johnson-Lindenstrauss lemma. In that case the quality of the"
          },
          "embedding": {
            "type": "is controlled by the ``eps`` parameter.",
            "description": ""
          },
          "It": {
            "type": "should be noted that Johnson-Lindenstrauss lemma can yield",
            "description": ""
          },
          "very": {
            "type": "conservative estimated of the required number of components",
            "description": ""
          },
          "as": {
            "type": "it makes no assumption on the structure of the dataset.",
            "description": ""
          },
          "eps": {
            "type": "float, default=0.1",
            "description": ""
          },
          "Parameter": {
            "type": "to control the quality of the embedding according to",
            "description": ""
          },
          "the": {
            "type": "Johnson-Lindenstrauss lemma when `n_components` is set to",
            "description": "'auto'. The value should be strictly positive."
          },
          "Smaller": {
            "type": "values lead to better embedding and higher number of",
            "description": ""
          },
          "dimensions": {
            "type": "n_components",
            "description": "in the target projection space."
          },
          "compute_inverse_components": {
            "type": "bool, default=False",
            "description": ""
          },
          "Learn": {
            "type": "the inverse transform by computing the pseudo-inverse of the",
            "description": ""
          },
          "components": {
            "type": "during fit. Note that computing the pseudo-inverse does not",
            "description": ""
          },
          "scale": {
            "type": "well to large matrices.",
            "description": ""
          },
          "random_state": {
            "type": "int, RandomState instance or None, default=None",
            "description": ""
          },
          "Controls": {
            "type": "the pseudo random number generator used to generate the",
            "description": ""
          },
          "projection": {
            "type": "matrix at fit time.",
            "description": ""
          },
          "Pass": {
            "type": "an int for reproducible output across multiple function calls.",
            "description": ""
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "n_components_": {
            "type": "int",
            "description": ""
          },
          "Concrete": {
            "type": "number of components computed when n_components=\"auto\".",
            "description": ""
          },
          "components_": {
            "type": "ndarray of shape (n_components, n_features)",
            "description": ""
          },
          "Random": {
            "type": "matrix used for the projection.",
            "description": ""
          },
          "inverse_components_": {
            "type": "ndarray of shape (n_features, n_components)",
            "description": "Pseudo-inverse of the components, only computed if\n`compute_inverse_components` is True.\n.. versionadded:: 1.1"
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "Number": {
            "type": "of features seen during :term:`fit`.",
            "description": ".. versionadded:: 0.24"
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "SparseRandomProjection": {
            "type": "Reduce dimensionality through sparse",
            "description": ""
          },
          "random": {
            "type": "projection.",
            "description": "Examples\n--------\n>>> import numpy as np\n>>> from sklearn.random_projection import GaussianRandomProjection\n>>> rng = np.random.RandomState(42)\n>>> X = rng.rand(25, 3000)\n>>> transformer = GaussianRandomProjection(random_state=rng)\n>>> X_new = transformer.fit_transform(X)\n>>> X_new.shape\n(25, 2759)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    SparseRandomProjection : Reduce dimensionality through sparse\n        random projection.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.random_projection import GaussianRandomProjection\n    >>> rng = np.random.RandomState(42)\n    >>> X = rng.rand(25, 3000)\n    >>> transformer = GaussianRandomProjection(random_state=rng)\n    >>> X_new = transformer.fit_transform(X)\n    >>> X_new.shape\n    (25, 2759)",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.random_projection import GaussianRandomProjection\n    >>> rng = np.random.RandomState(42)\n    >>> X = rng.rand(25, 3000)\n    >>> transformer = GaussianRandomProjection(random_state=rng)\n    >>> X_new = transformer.fit_transform(X)\n    >>> X_new.shape\n    (25, 2759)"
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, X, y=None)",
          "documentation": {
            "description": "Generate a sparse random projection matrix.\n\n        Parameters\n        ----------\n        X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n            Training set: only the shape is used to find optimal random\n            matrix dimensions based on the theory referenced in the\n            afore mentioned papers.\n\n        y : Ignored\n            Not used, present here for API consistency by convention.",
            "parameters": {
              "X": {
                "type": "{ndarray, sparse matrix} of shape (n_samples, n_features)",
                "description": ""
              },
              "Training": {
                "type": "set: only the shape is used to find optimal random",
                "description": ""
              },
              "matrix": {
                "type": "dimensions based on the theory referenced in the",
                "description": ""
              },
              "afore": {
                "type": "mentioned papers.",
                "description": ""
              },
              "y": {
                "type": "Ignored",
                "description": ""
              },
              "Not": {
                "type": "used, present here for API consistency by convention.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "BaseRandomProjection": {
                "type": "class instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object\n            BaseRandomProjection class instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit to data, then transform it.\n\n        Fits transformer to `X` and `y` with optional parameters `fit_params`\n        and returns a transformed version of `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input samples.\n\n        y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n            Target values (None for unsupervised transformations).\n\n        **fit_params : dict\n            Additional fit parameters.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
              },
              "Target": {
                "type": "values (None for unsupervised transformations).",
                "description": "**fit_params : dict"
              },
              "Additional": {
                "type": "fit parameters.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray array of shape (n_samples, n_features_new)",
                "description": ""
              },
              "Transformed": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray array of shape (n_samples, n_features_new)\n            Transformed array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Get output feature names for transformation.\n\n        The feature names out will prefixed by the lowercased class name. For\n        example, if the transformer outputs 3 features, then the feature names\n        out are: `[\"class_name0\", \"class_name1\", \"class_name2\"]`.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Only used to validate feature names with the names seen in `fit`.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Only": {
                "type": "used to validate feature names with the names seen in `fit`.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Transformed": {
                "type": "feature names.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_transform",
          "signature": "inverse_transform(self, X)",
          "documentation": {
            "description": "Project data back to its original space.",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like, sparse matrix} of shape (n_samples, n_components)"
              },
              "Data": {
                "type": "to be transformed back.",
                "description": "Returns\n-------"
              },
              "X_original": {
                "type": "ndarray of shape (n_samples, n_features)",
                "description": ""
              },
              "Reconstructed": {
                "type": "data.",
                "description": ""
              }
            },
            "returns": "an array X_original whose transform would be X. Note that even\n        if X is sparse, X_original is dense: this may use a lot of RAM.\n\n        If `compute_inverse_components` is False, the inverse of the components is\n        computed during each call to `inverse_transform` which can be costly.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_components)\n            Data to be transformed back.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "transform",
          "signature": "transform(self, X)",
          "documentation": {
            "description": "Project the data by using matrix product with the random matrix.\n\n        Parameters\n        ----------\n        X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n            The input data to project into a smaller dimensional space.",
            "parameters": {
              "X": {
                "type": "{ndarray, sparse matrix} of shape (n_samples, n_features)",
                "description": ""
              },
              "The": {
                "type": "input data to project into a smaller dimensional space.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray of shape (n_samples, n_components)",
                "description": ""
              },
              "Projected": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray of shape (n_samples, n_components)\n            Projected array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Integral",
      "documentation": {
        "description": "Integral adds methods that work on integral numbers.\n\n    In short, these are conversion to int, pow with modulus, and the\n    bit-string operations.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "conjugate",
          "signature": "conjugate(self)",
          "documentation": {
            "description": "Conjugate is a no-op for Reals.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Interval",
      "documentation": {
        "description": "Constraint representing a typed interval.\n\n    Parameters\n    ----------\n    type : {numbers.Integral, numbers.Real, RealNotInt}\n        The set of numbers in which to set the interval.\n\n        If RealNotInt, only reals that don't have the integer type\n        are allowed. For example 1.0 is allowed but 1 is not.\n\n    left : float or int or None\n        The left bound of the interval. None means left bound is -.\n\n    right : float, int or None\n        The right bound of the interval. None means right bound is +.\n\n    closed : {\"left\", \"right\", \"both\", \"neither\"}\n        Whether the interval is open or closed. Possible choices are:\n\n        - `\"left\"`: the interval is closed on the left and open on the right.\n          It is equivalent to the interval `[ left, right )`.\n        - `\"right\"`: the interval is closed on the right and open on the left.\n          It is equivalent to the interval `( left, right ]`.\n        - `\"both\"`: the interval is closed.\n          It is equivalent to the interval `[ left, right ]`.\n        - `\"neither\"`: the interval is open.\n          It is equivalent to the interval `( left, right )`.",
        "parameters": {
          "type": {
            "type": "{numbers.Integral, numbers.Real, RealNotInt}",
            "description": ""
          },
          "The": {
            "type": "right bound of the interval. None means right bound is +.",
            "description": ""
          },
          "If": {
            "type": "RealNotInt, only reals that don't have the integer type",
            "description": ""
          },
          "are": {
            "type": "allowed. For example 1.0 is allowed but 1 is not.",
            "description": ""
          },
          "left": {
            "type": "float or int or None",
            "description": ""
          },
          "right": {
            "type": "float, int or None",
            "description": ""
          },
          "closed": {
            "type": "{\"left\", \"right\", \"both\", \"neither\"}",
            "description": ""
          },
          "Whether": {
            "type": "the interval is open or closed. Possible choices are:",
            "description": "- `\"left\"`: the interval is closed on the left and open on the right."
          },
          "It": {
            "type": "is equivalent to the interval `( left, right )`.",
            "description": "Notes\n-----"
          },
          "Setting": {
            "type": "a bound to `None` and setting the interval closed is valid. For instance,",
            "description": ""
          },
          "strictly": {
            "type": "speaking, `Interval(Real, 0, None, closed=\"both\")` corresponds to",
            "description": "`[0, +) U {+}`."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "-----\n    Setting a bound to `None` and setting the interval closed is valid. For instance,\n    strictly speaking, `Interval(Real, 0, None, closed=\"both\")` corresponds to\n    `[0, +) U {+}`.",
        "examples": ""
      },
      "methods": [
        {
          "name": "is_satisfied_by",
          "signature": "is_satisfied_by(self, val)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Real",
      "documentation": {
        "description": "To Complex, Real adds the operations that work on real numbers.\n\n    In short, those are: a conversion to float, trunc(), divmod,\n    %, <, <=, >, and >=.\n\n    Real also provides defaults for the derived operations.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "conjugate",
          "signature": "conjugate(self)",
          "documentation": {
            "description": "Conjugate is a no-op for Reals.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "SparseRandomProjection",
      "documentation": {
        "description": "Reduce dimensionality through sparse random projection.\n\n    Sparse random matrix is an alternative to dense random\n    projection matrix that guarantees similar embedding quality while being\n    much more memory efficient and allowing faster computation of the\n    projected data.\n\n    If we note `s = 1 / density` the components of the random matrix are\n    drawn from:\n\n    .. code-block:: text\n\n      -sqrt(s) / sqrt(n_components)   with probability 1 / 2s\n       0                              with probability 1 - 1 / s\n      +sqrt(s) / sqrt(n_components)   with probability 1 / 2s\n\n    Read more in the :ref:`User Guide <sparse_random_matrix>`.\n\n    .. versionadded:: 0.13\n\n    Parameters\n    ----------\n    n_components : int or 'auto', default='auto'\n        Dimensionality of the target projection space.\n\n        n_components can be automatically adjusted according to the\n        number of samples in the dataset and the bound given by the\n        Johnson-Lindenstrauss lemma. In that case the quality of the\n        embedding is controlled by the ``eps`` parameter.\n\n        It should be noted that Johnson-Lindenstrauss lemma can yield\n        very conservative estimated of the required number of components\n        as it makes no assumption on the structure of the dataset.\n\n    density : float or 'auto', default='auto'\n        Ratio in the range (0, 1] of non-zero component in the random\n        projection matrix.\n\n        If density = 'auto', the value is set to the minimum density\n        as recommended by Ping Li et al.: 1 / sqrt(n_features).\n\n        Use density = 1 / 3.0 if you want to reproduce the results from\n        Achlioptas, 2001.\n\n    eps : float, default=0.1\n        Parameter to control the quality of the embedding according to\n        the Johnson-Lindenstrauss lemma when n_components is set to\n        'auto'. This value should be strictly positive.\n\n        Smaller values lead to better embedding and higher number of\n        dimensions (n_components) in the target projection space.\n\n    dense_output : bool, default=False\n        If True, ensure that the output of the random projection is a\n        dense numpy array even if the input and random projection matrix\n        are both sparse. In practice, if the number of components is\n        small the number of zero components in the projected data will\n        be very small and it will be more CPU and memory efficient to\n        use a dense representation.\n\n        If False, the projected data uses a sparse representation if\n        the input is sparse.\n\n    compute_inverse_components : bool, default=False\n        Learn the inverse transform by computing the pseudo-inverse of the\n        components during fit. Note that the pseudo-inverse is always a dense\n        array, even if the training data was sparse. This means that it might be\n        necessary to call `inverse_transform` on a small batch of samples at a\n        time to avoid exhausting the available memory on the host. Moreover,\n        computing the pseudo-inverse does not scale well to large matrices.\n\n    random_state : int, RandomState instance or None, default=None\n        Controls the pseudo random number generator used to generate the\n        projection matrix at fit time.\n        Pass an int for reproducible output across multiple function calls.\n        See :term:`Glossary <random_state>`.\n\n    Attributes\n    ----------\n    n_components_ : int\n        Concrete number of components computed when n_components=\"auto\".\n\n    components_ : sparse matrix of shape (n_components, n_features)\n        Random matrix used for the projection. Sparse matrix will be of CSR\n        format.\n\n    inverse_components_ : ndarray of shape (n_features, n_components)\n        Pseudo-inverse of the components, only computed if\n        `compute_inverse_components` is True.\n\n        .. versionadded:: 1.1\n\n    density_ : float in range 0.0 - 1.0\n        Concrete density computed from when density = \"auto\".\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    GaussianRandomProjection : Reduce dimensionality through Gaussian\n        random projection.\n\n    References\n    ----------\n\n    .. [1] Ping Li, T. Hastie and K. W. Church, 2006,\n           \"Very Sparse Random Projections\".\n           https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf\n\n    .. [2] D. Achlioptas, 2001, \"Database-friendly random projections\",\n           https://cgi.di.uoa.gr/~optas/papers/jl.pdf",
        "parameters": {
          "n_components": {
            "type": "can be automatically adjusted according to the",
            "description": ""
          },
          "Dimensionality": {
            "type": "of the target projection space.",
            "description": ""
          },
          "number": {
            "type": "of samples in the dataset and the bound given by the",
            "description": "Johnson-Lindenstrauss lemma. In that case the quality of the"
          },
          "embedding": {
            "type": "is controlled by the ``eps`` parameter.",
            "description": ""
          },
          "It": {
            "type": "should be noted that Johnson-Lindenstrauss lemma can yield",
            "description": ""
          },
          "very": {
            "type": "conservative estimated of the required number of components",
            "description": ""
          },
          "as": {
            "type": "recommended by Ping Li et al.: 1 / sqrt(n_features).",
            "description": ""
          },
          "density": {
            "type": "float or 'auto', default='auto'",
            "description": ""
          },
          "Ratio": {
            "type": "in the range (0, 1] of non-zero component in the random",
            "description": ""
          },
          "projection": {
            "type": "matrix at fit time.",
            "description": ""
          },
          "If": {
            "type": "False, the projected data uses a sparse representation if",
            "description": ""
          },
          "Use": {
            "type": "density = 1 / 3.0 if you want to reproduce the results from",
            "description": "Achlioptas, 2001."
          },
          "eps": {
            "type": "float, default=0.1",
            "description": ""
          },
          "Parameter": {
            "type": "to control the quality of the embedding according to",
            "description": ""
          },
          "the": {
            "type": "input is sparse.",
            "description": ""
          },
          "Smaller": {
            "type": "values lead to better embedding and higher number of",
            "description": ""
          },
          "dimensions": {
            "type": "n_components",
            "description": "in the target projection space."
          },
          "dense_output": {
            "type": "bool, default=False",
            "description": ""
          },
          "dense": {
            "type": "numpy array even if the input and random projection matrix",
            "description": ""
          },
          "are": {
            "type": "both sparse. In practice, if the number of components is",
            "description": ""
          },
          "small": {
            "type": "the number of zero components in the projected data will",
            "description": ""
          },
          "be": {
            "type": "very small and it will be more CPU and memory efficient to",
            "description": ""
          },
          "use": {
            "type": "a dense representation.",
            "description": ""
          },
          "compute_inverse_components": {
            "type": "bool, default=False",
            "description": ""
          },
          "Learn": {
            "type": "the inverse transform by computing the pseudo-inverse of the",
            "description": ""
          },
          "components": {
            "type": "during fit. Note that the pseudo-inverse is always a dense",
            "description": "array, even if the training data was sparse. This means that it might be"
          },
          "necessary": {
            "type": "to call `inverse_transform` on a small batch of samples at a",
            "description": ""
          },
          "time": {
            "type": "to avoid exhausting the available memory on the host. Moreover,",
            "description": ""
          },
          "computing": {
            "type": "the pseudo-inverse does not scale well to large matrices.",
            "description": ""
          },
          "random_state": {
            "type": "int, RandomState instance or None, default=None",
            "description": ""
          },
          "Controls": {
            "type": "the pseudo random number generator used to generate the",
            "description": ""
          },
          "Pass": {
            "type": "an int for reproducible output across multiple function calls.",
            "description": ""
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "n_components_": {
            "type": "int",
            "description": ""
          },
          "Concrete": {
            "type": "density computed from when density = \"auto\".",
            "description": ""
          },
          "components_": {
            "type": "sparse matrix of shape (n_components, n_features)",
            "description": ""
          },
          "Random": {
            "type": "matrix used for the projection. Sparse matrix will be of CSR",
            "description": "format."
          },
          "inverse_components_": {
            "type": "ndarray of shape (n_features, n_components)",
            "description": "Pseudo-inverse of the components, only computed if\n`compute_inverse_components` is True.\n.. versionadded:: 1.1"
          },
          "density_": {
            "type": "float in range 0.0",
            "description": "1.0"
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "Number": {
            "type": "of features seen during :term:`fit`.",
            "description": ".. versionadded:: 0.24"
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "GaussianRandomProjection": {
            "type": "Reduce dimensionality through Gaussian",
            "description": ""
          },
          "random": {
            "type": "projection.",
            "description": "References\n----------\n.. [1] Ping Li, T. Hastie and K. W. Church, 2006,\n\"Very Sparse Random Projections\"."
          },
          "https": {
            "type": "//cgi.di.uoa.gr/~optas/papers/jl.pdf",
            "description": "Examples\n--------\n>>> import numpy as np\n>>> from sklearn.random_projection import SparseRandomProjection\n>>> rng = np.random.RandomState(42)\n>>> X = rng.rand(25, 3000)\n>>> transformer = SparseRandomProjection(random_state=rng)\n>>> X_new = transformer.fit_transform(X)\n>>> X_new.shape\n(25, 2759)\n>>> # very few components are non-zero\n>>> np.mean(transformer.components_ != 0)\nnp.float64(0.0182...)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    GaussianRandomProjection : Reduce dimensionality through Gaussian\n        random projection.\n\n    References\n    ----------\n\n    .. [1] Ping Li, T. Hastie and K. W. Church, 2006,\n           \"Very Sparse Random Projections\".\n           https://web.stanford.edu/~hastie/Papers/Ping/KDD06_rp.pdf\n\n    .. [2] D. Achlioptas, 2001, \"Database-friendly random projections\",\n           https://cgi.di.uoa.gr/~optas/papers/jl.pdf\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.random_projection import SparseRandomProjection\n    >>> rng = np.random.RandomState(42)\n    >>> X = rng.rand(25, 3000)\n    >>> transformer = SparseRandomProjection(random_state=rng)\n    >>> X_new = transformer.fit_transform(X)\n    >>> X_new.shape\n    (25, 2759)\n    >>> # very few components are non-zero\n    >>> np.mean(transformer.components_ != 0)\n    np.float64(0.0182...)",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.random_projection import SparseRandomProjection\n    >>> rng = np.random.RandomState(42)\n    >>> X = rng.rand(25, 3000)\n    >>> transformer = SparseRandomProjection(random_state=rng)\n    >>> X_new = transformer.fit_transform(X)\n    >>> X_new.shape\n    (25, 2759)\n    >>> # very few components are non-zero\n    >>> np.mean(transformer.components_ != 0)\n    np.float64(0.0182...)"
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, X, y=None)",
          "documentation": {
            "description": "Generate a sparse random projection matrix.\n\n        Parameters\n        ----------\n        X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n            Training set: only the shape is used to find optimal random\n            matrix dimensions based on the theory referenced in the\n            afore mentioned papers.\n\n        y : Ignored\n            Not used, present here for API consistency by convention.",
            "parameters": {
              "X": {
                "type": "{ndarray, sparse matrix} of shape (n_samples, n_features)",
                "description": ""
              },
              "Training": {
                "type": "set: only the shape is used to find optimal random",
                "description": ""
              },
              "matrix": {
                "type": "dimensions based on the theory referenced in the",
                "description": ""
              },
              "afore": {
                "type": "mentioned papers.",
                "description": ""
              },
              "y": {
                "type": "Ignored",
                "description": ""
              },
              "Not": {
                "type": "used, present here for API consistency by convention.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "BaseRandomProjection": {
                "type": "class instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object\n            BaseRandomProjection class instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit to data, then transform it.\n\n        Fits transformer to `X` and `y` with optional parameters `fit_params`\n        and returns a transformed version of `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input samples.\n\n        y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n            Target values (None for unsupervised transformations).\n\n        **fit_params : dict\n            Additional fit parameters.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
              },
              "Target": {
                "type": "values (None for unsupervised transformations).",
                "description": "**fit_params : dict"
              },
              "Additional": {
                "type": "fit parameters.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray array of shape (n_samples, n_features_new)",
                "description": ""
              },
              "Transformed": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray array of shape (n_samples, n_features_new)\n            Transformed array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Get output feature names for transformation.\n\n        The feature names out will prefixed by the lowercased class name. For\n        example, if the transformer outputs 3 features, then the feature names\n        out are: `[\"class_name0\", \"class_name1\", \"class_name2\"]`.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Only used to validate feature names with the names seen in `fit`.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Only": {
                "type": "used to validate feature names with the names seen in `fit`.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Transformed": {
                "type": "feature names.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_transform",
          "signature": "inverse_transform(self, X)",
          "documentation": {
            "description": "Project data back to its original space.",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like, sparse matrix} of shape (n_samples, n_components)"
              },
              "Data": {
                "type": "to be transformed back.",
                "description": "Returns\n-------"
              },
              "X_original": {
                "type": "ndarray of shape (n_samples, n_features)",
                "description": ""
              },
              "Reconstructed": {
                "type": "data.",
                "description": ""
              }
            },
            "returns": "an array X_original whose transform would be X. Note that even\n        if X is sparse, X_original is dense: this may use a lot of RAM.\n\n        If `compute_inverse_components` is False, the inverse of the components is\n        computed during each call to `inverse_transform` which can be costly.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_components)\n            Data to be transformed back.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "transform",
          "signature": "transform(self, X)",
          "documentation": {
            "description": "Project the data by using matrix product with the random matrix.\n\n        Parameters\n        ----------\n        X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n            The input data to project into a smaller dimensional space.",
            "parameters": {
              "X": {
                "type": "{ndarray, sparse matrix} of shape (n_samples, n_features)",
                "description": ""
              },
              "The": {
                "type": "input data to project into a smaller dimensional space.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "{ndarray, sparse matrix} of shape (n_samples, n_components)",
                "description": ""
              },
              "Projected": {
                "type": "array. It is a sparse matrix only when the input is sparse and",
                "description": "`dense_output = False`."
              }
            },
            "returns": "-------\n        X_new : {ndarray, sparse matrix} of shape (n_samples, n_components)\n            Projected array. It is a sparse matrix only when the input is sparse and\n            `dense_output = False`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "StrOptions",
      "documentation": {
        "description": "Constraint representing a finite set of strings.",
        "parameters": {
          "options": {
            "type": "set of str",
            "description": ""
          },
          "The": {
            "type": "set of valid strings.",
            "description": ""
          },
          "deprecated": {
            "type": "set of str or None, default=None",
            "description": ""
          },
          "A": {
            "type": "subset of the `options` to mark as deprecated in the string",
            "description": ""
          },
          "representation": {
            "type": "of the constraint.",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "is_satisfied_by",
          "signature": "is_satisfied_by(self, val)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "TransformerMixin",
      "documentation": {
        "description": "Mixin class for all transformers in scikit-learn.\n\n    This mixin defines the following functionality:\n\n    - a `fit_transform` method that delegates to `fit` and `transform`;\n    - a `set_output` method to output `X` as a specific container type.\n\n    If :term:`get_feature_names_out` is defined, then :class:`BaseEstimator` will\n    automatically wrap `transform` and `fit_transform` to follow the `set_output`\n    API. See the :ref:`developer_api_set_output` for details.\n\n    :class:`OneToOneFeatureMixin` and\n    :class:`ClassNamePrefixFeaturesOutMixin` are helpful mixins for\n    defining :term:`get_feature_names_out`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.base import BaseEstimator, TransformerMixin\n    >>> class MyTransformer(TransformerMixin, BaseEstimator):\n    ...     def __init__(self, *, param=1):\n    ...         self.param = param\n    ...     def fit(self, X, y=None):\n    ...         return self\n    ...     def transform(self, X):\n    ...         return np.full(shape=len(X), fill_value=self.param)\n    >>> transformer = MyTransformer()\n    >>> X = [[1, 2], [2, 3], [3, 4]]\n    >>> transformer.fit_transform(X)\n    array([1, 1, 1])"
      },
      "methods": [
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit to data, then transform it.\n\n        Fits transformer to `X` and `y` with optional parameters `fit_params`\n        and returns a transformed version of `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input samples.\n\n        y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n            Target values (None for unsupervised transformations).\n\n        **fit_params : dict\n            Additional fit parameters.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
              },
              "Target": {
                "type": "values (None for unsupervised transformations).",
                "description": "**fit_params : dict"
              },
              "Additional": {
                "type": "fit parameters.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray array of shape (n_samples, n_features_new)",
                "description": ""
              },
              "Transformed": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray array of shape (n_samples, n_features_new)\n            Transformed array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    }
  ]
}