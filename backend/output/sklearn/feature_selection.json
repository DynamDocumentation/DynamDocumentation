{
  "description": "Feature selection algorithms.\n\nThese include univariate filter selection methods and the recursive feature elimination\nalgorithm.",
  "functions": [
    {
      "name": "chi2",
      "signature": "chi2(X, y)",
      "documentation": {
        "description": "Compute chi-squared stats between each non-negative feature and class.\n\n    This score can be used to select the `n_features` features with the\n    highest values for the test chi-squared statistic from X, which must\n    contain only **non-negative integer feature values** such as booleans or frequencies\n    (e.g., term counts in document classification), relative to the classes.\n\n    If some of your features are continuous, you need to bin them, for",
        "parameters": {
          "X": {
            "type": "{array",
            "description": "like, sparse matrix} of shape (n_samples, n_features)"
          },
          "Sample": {
            "type": "vectors.",
            "description": ""
          },
          "y": {
            "type": "array",
            "description": "like of shape (n_samples,)"
          },
          "Target": {
            "type": "vector (class labels).",
            "description": "Returns\n-------"
          },
          "chi2": {
            "type": "ndarray of shape (n_features,)",
            "description": ""
          },
          "Chi2": {
            "type": "statistics for each feature.",
            "description": ""
          },
          "p_values": {
            "type": "ndarray of shape (n_features,)",
            "description": "P-values for each feature."
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "f_classif": {
            "type": "ANOVA F",
            "description": "value between label/feature for classification tasks."
          },
          "f_regression": {
            "type": "F",
            "description": "value between label/feature for regression tasks.\nNotes\n-----"
          },
          "Complexity": {
            "type": "of this algorithm is O(n_classes * n_features).",
            "description": "Examples\n--------\n>>> import numpy as np\n>>> from sklearn.feature_selection import chi2\n>>> X = np.array([[1, 1, 3],\n...               [0, 1, 5],\n...               [5, 4, 1],\n...               [6, 6, 2],\n...               [1, 4, 0],\n...               [0, 0, 0]])\n>>> y = np.array([1, 1, 0, 0, 2, 2])\n>>> chi2_stats, p_values = chi2(X, y)\n>>> chi2_stats"
          },
          "array": {
            "type": "[0.0004..., 0.0387..., 0.0116... ]",
            "description": ""
          }
        },
        "returns": "-------\n    chi2 : ndarray of shape (n_features,)\n        Chi2 statistics for each feature.\n\n    p_values : ndarray of shape (n_features,)\n        P-values for each feature.\n\n    See Also\n    --------\n    f_classif : ANOVA F-value between label/feature for classification tasks.\n    f_regression : F-value between label/feature for regression tasks.\n\n    Notes\n    -----\n    Complexity of this algorithm is O(n_classes * n_features).\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.feature_selection import chi2\n    >>> X = np.array([[1, 1, 3],\n    ...               [0, 1, 5],\n    ...               [5, 4, 1],\n    ...               [6, 6, 2],\n    ...               [1, 4, 0],\n    ...               [0, 0, 0]])\n    >>> y = np.array([1, 1, 0, 0, 2, 2])\n    >>> chi2_stats, p_values = chi2(X, y)\n    >>> chi2_stats\n    array([15.3...,  6.5       ,  8.9...])\n    >>> p_values\n    array([0.0004..., 0.0387..., 0.0116... ])",
        "raises": "",
        "see_also": "--------\n    f_classif : ANOVA F-value between label/feature for classification tasks.\n    f_regression : F-value between label/feature for regression tasks.\n\n    Notes\n    -----\n    Complexity of this algorithm is O(n_classes * n_features).\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.feature_selection import chi2\n    >>> X = np.array([[1, 1, 3],\n    ...               [0, 1, 5],\n    ...               [5, 4, 1],\n    ...               [6, 6, 2],\n    ...               [1, 4, 0],\n    ...               [0, 0, 0]])\n    >>> y = np.array([1, 1, 0, 0, 2, 2])\n    >>> chi2_stats, p_values = chi2(X, y)\n    >>> chi2_stats\n    array([15.3...,  6.5       ,  8.9...])\n    >>> p_values\n    array([0.0004..., 0.0387..., 0.0116... ])",
        "notes": "-----\n    Complexity of this algorithm is O(n_classes * n_features).\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.feature_selection import chi2\n    >>> X = np.array([[1, 1, 3],\n    ...               [0, 1, 5],\n    ...               [5, 4, 1],\n    ...               [6, 6, 2],\n    ...               [1, 4, 0],\n    ...               [0, 0, 0]])\n    >>> y = np.array([1, 1, 0, 0, 2, 2])\n    >>> chi2_stats, p_values = chi2(X, y)\n    >>> chi2_stats\n    array([15.3...,  6.5       ,  8.9...])\n    >>> p_values\n    array([0.0004..., 0.0387..., 0.0116... ])",
        "examples": "by using :class:`~sklearn.preprocessing.KBinsDiscretizer`.\n\n    Recall that the chi-square test measures dependence between stochastic\n    variables, so using this function \"weeds out\" the features that are the\n    most likely to be independent of class and therefore irrelevant for\n    classification.\n\n    Read more in the :ref:`User Guide <univariate_feature_selection>`.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        Sample vectors.\n\n    y : array-like of shape (n_samples,)\n        Target vector (class labels).\n\n    Returns\n    -------\n    chi2 : ndarray of shape (n_features,)\n        Chi2 statistics for each feature.\n\n    p_values : ndarray of shape (n_features,)\n        P-values for each feature.\n\n    See Also\n    --------\n    f_classif : ANOVA F-value between label/feature for classification tasks.\n    f_regression : F-value between label/feature for regression tasks.\n\n    Notes\n    -----\n    Complexity of this algorithm is O(n_classes * n_features).\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.feature_selection import chi2\n    >>> X = np.array([[1, 1, 3],\n    ...               [0, 1, 5],\n    ...               [5, 4, 1],\n    ...               [6, 6, 2],\n    ...               [1, 4, 0],\n    ...               [0, 0, 0]])\n    >>> y = np.array([1, 1, 0, 0, 2, 2])\n    >>> chi2_stats, p_values = chi2(X, y)\n    >>> chi2_stats\n    array([15.3...,  6.5       ,  8.9...])\n    >>> p_values\n    array([0.0004..., 0.0387..., 0.0116... ])"
      }
    },
    {
      "name": "f_classif",
      "signature": "f_classif(X, y)",
      "documentation": {
        "description": "Compute the ANOVA F-value for the provided sample.\n\n    Read more in the :ref:`User Guide <univariate_feature_selection>`.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The set of regressors that will be tested sequentially.\n\n    y : array-like of shape (n_samples,)\n        The target vector.\n\n    Returns\n    -------\n    f_statistic : ndarray of shape (n_features,)\n        F-statistic for each feature.\n\n    p_values : ndarray of shape (n_features,)\n        P-values associated with the F-statistic.\n\n    See Also\n    --------\n    chi2 : Chi-squared stats of non-negative features for classification tasks.\n    f_regression : F-value between label/feature for regression tasks.",
        "parameters": {
          "X": {
            "type": "{array",
            "description": "like, sparse matrix} of shape (n_samples, n_features)"
          },
          "The": {
            "type": "target vector.",
            "description": "Returns\n-------"
          },
          "y": {
            "type": "array",
            "description": "like of shape (n_samples,)"
          },
          "f_statistic": {
            "type": "ndarray of shape (n_features,)",
            "description": "F-statistic for each feature."
          },
          "p_values": {
            "type": "ndarray of shape (n_features,)",
            "description": "P-values associated with the F-statistic."
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "chi2": {
            "type": "Chi",
            "description": "squared stats of non-negative features for classification tasks."
          },
          "f_regression": {
            "type": "F",
            "description": "value between label/feature for regression tasks.\nExamples\n--------\n>>> from sklearn.datasets import make_classification\n>>> from sklearn.feature_selection import f_classif\n>>> X, y = make_classification(\n...     n_samples=100, n_features=10, n_informative=2, n_clusters_per_class=1,\n...     shuffle=False, random_state=42\n... )\n>>> f_statistic, p_values = f_classif(X, y)\n>>> f_statistic\narray([2.2...e+02, 7.0...e-01, 1.6...e+00, 9.3...e-01,\n5.4...e+00, 3.2...e-01, 4.7...e-02, 5.7...e-01,\n7.5...e-01, 8.9...e-02])\n>>> p_values\narray([7.1...e-27, 4.0...e-01, 1.9...e-01, 3.3...e-01,\n2.2...e-02, 5.7...e-01, 8.2...e-01, 4.5...e-01,\n3.8...e-01, 7.6...e-01])"
          }
        },
        "returns": "-------\n    f_statistic : ndarray of shape (n_features,)\n        F-statistic for each feature.\n\n    p_values : ndarray of shape (n_features,)\n        P-values associated with the F-statistic.\n\n    See Also\n    --------\n    chi2 : Chi-squared stats of non-negative features for classification tasks.\n    f_regression : F-value between label/feature for regression tasks.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import make_classification\n    >>> from sklearn.feature_selection import f_classif\n    >>> X, y = make_classification(\n    ...     n_samples=100, n_features=10, n_informative=2, n_clusters_per_class=1,\n    ...     shuffle=False, random_state=42\n    ... )\n    >>> f_statistic, p_values = f_classif(X, y)\n    >>> f_statistic\n    array([2.2...e+02, 7.0...e-01, 1.6...e+00, 9.3...e-01,\n           5.4...e+00, 3.2...e-01, 4.7...e-02, 5.7...e-01,\n           7.5...e-01, 8.9...e-02])\n    >>> p_values\n    array([7.1...e-27, 4.0...e-01, 1.9...e-01, 3.3...e-01,\n           2.2...e-02, 5.7...e-01, 8.2...e-01, 4.5...e-01,\n           3.8...e-01, 7.6...e-01])",
        "raises": "",
        "see_also": "--------\n    chi2 : Chi-squared stats of non-negative features for classification tasks.\n    f_regression : F-value between label/feature for regression tasks.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import make_classification\n    >>> from sklearn.feature_selection import f_classif\n    >>> X, y = make_classification(\n    ...     n_samples=100, n_features=10, n_informative=2, n_clusters_per_class=1,\n    ...     shuffle=False, random_state=42\n    ... )\n    >>> f_statistic, p_values = f_classif(X, y)\n    >>> f_statistic\n    array([2.2...e+02, 7.0...e-01, 1.6...e+00, 9.3...e-01,\n           5.4...e+00, 3.2...e-01, 4.7...e-02, 5.7...e-01,\n           7.5...e-01, 8.9...e-02])\n    >>> p_values\n    array([7.1...e-27, 4.0...e-01, 1.9...e-01, 3.3...e-01,\n           2.2...e-02, 5.7...e-01, 8.2...e-01, 4.5...e-01,\n           3.8...e-01, 7.6...e-01])",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.datasets import make_classification\n    >>> from sklearn.feature_selection import f_classif\n    >>> X, y = make_classification(\n    ...     n_samples=100, n_features=10, n_informative=2, n_clusters_per_class=1,\n    ...     shuffle=False, random_state=42\n    ... )\n    >>> f_statistic, p_values = f_classif(X, y)\n    >>> f_statistic\n    array([2.2...e+02, 7.0...e-01, 1.6...e+00, 9.3...e-01,\n           5.4...e+00, 3.2...e-01, 4.7...e-02, 5.7...e-01,\n           7.5...e-01, 8.9...e-02])\n    >>> p_values\n    array([7.1...e-27, 4.0...e-01, 1.9...e-01, 3.3...e-01,\n           2.2...e-02, 5.7...e-01, 8.2...e-01, 4.5...e-01,\n           3.8...e-01, 7.6...e-01])"
      }
    },
    {
      "name": "f_oneway",
      "signature": "f_oneway(*args)",
      "documentation": {
        "description": "Perform a 1-way ANOVA.\n\n    The one-way ANOVA tests the null hypothesis that 2 or more groups have\n    the same population mean. The test is applied to samples from two or\n    more groups, possibly with differing sizes.\n\n    Read more in the :ref:`User Guide <univariate_feature_selection>`.\n\n    Parameters\n    ----------\n    *args : {array-like, sparse matrix}\n        Sample1, sample2... The sample measurements should be given as\n        arguments.\n\n    Returns\n    -------\n    f_statistic : float\n        The computed F-value of the test.\n    p_value : float\n        The associated p-value from the F-distribution.",
        "parameters": {
          "f_statistic": {
            "type": "float",
            "description": ""
          },
          "The": {
            "type": "algorithm is from Heiman[2], pp.394-7.",
            "description": ""
          },
          "p_value": {
            "type": "float",
            "description": ""
          },
          "for": {
            "type": "the associated p-value to be valid.",
            "description": "1. The samples are independent\n2. Each sample is from a normally distributed population\n3. The population standard deviations of the groups are all equal. This"
          },
          "property": {
            "type": "is known as homoscedasticity.",
            "description": ""
          },
          "If": {
            "type": "these assumptions are not true for a given set of data, it may still be",
            "description": ""
          },
          "possible": {
            "type": "to use the Kruskal-Wallis H-test (`scipy.stats.kruskal`_) although",
            "description": ""
          },
          "with": {
            "type": "some loss of power.",
            "description": ""
          },
          "See": {
            "type": "``scipy.stats.f_oneway`` that should give the same results while",
            "description": ""
          },
          "being": {
            "type": "less efficient.",
            "description": "References\n----------\n.. [1] Lowry, Richard.  \"Concepts and Applications of Inferential\nStatistics\". Chapter 14."
          },
          "http": {
            "type": "//vassarstats.net/textbook",
            "description": ".. [2] Heiman, G.W.  Research Methods in Statistics. 2002."
          }
        },
        "returns": "-------\n    f_statistic : float\n        The computed F-value of the test.\n    p_value : float\n        The associated p-value from the F-distribution.\n\n    Notes\n    -----\n    The ANOVA test has important assumptions that must be satisfied in order\n    for the associated p-value to be valid.\n\n    1. The samples are independent\n    2. Each sample is from a normally distributed population\n    3. The population standard deviations of the groups are all equal. This\n       property is known as homoscedasticity.\n\n    If these assumptions are not true for a given set of data, it may still be\n    possible to use the Kruskal-Wallis H-test (`scipy.stats.kruskal`_) although\n    with some loss of power.\n\n    The algorithm is from Heiman[2], pp.394-7.\n\n    See ``scipy.stats.f_oneway`` that should give the same results while\n    being less efficient.\n\n    References\n    ----------\n    .. [1] Lowry, Richard.  \"Concepts and Applications of Inferential\n           Statistics\". Chapter 14.\n           http://vassarstats.net/textbook\n\n    .. [2] Heiman, G.W.  Research Methods in Statistics. 2002.",
        "raises": "",
        "see_also": "",
        "notes": "-----\n    The ANOVA test has important assumptions that must be satisfied in order\n    for the associated p-value to be valid.\n\n    1. The samples are independent\n    2. Each sample is from a normally distributed population\n    3. The population standard deviations of the groups are all equal. This\n       property is known as homoscedasticity.\n\n    If these assumptions are not true for a given set of data, it may still be\n    possible to use the Kruskal-Wallis H-test (`scipy.stats.kruskal`_) although\n    with some loss of power.\n\n    The algorithm is from Heiman[2], pp.394-7.\n\n    See ``scipy.stats.f_oneway`` that should give the same results while\n    being less efficient.\n\n    References\n    ----------\n    .. [1] Lowry, Richard.  \"Concepts and Applications of Inferential\n           Statistics\". Chapter 14.\n           http://vassarstats.net/textbook\n\n    .. [2] Heiman, G.W.  Research Methods in Statistics. 2002.",
        "examples": ""
      }
    },
    {
      "name": "f_regression",
      "signature": "f_regression(X, y, *, center=True, force_finite=True)",
      "documentation": {
        "description": "Univariate linear regression tests returning F-statistic and p-values.\n\n    Quick linear model for testing the effect of a single regressor,\n    sequentially for many regressors.\n\n    This is done in 2 steps:\n\n    1. The cross correlation between each regressor and the target is computed\n       using :func:`r_regression` as::\n\n           E[(X[:, i] - mean(X[:, i])) * (y - mean(y))] / (std(X[:, i]) * std(y))\n\n    2. It is converted to an F score and then to a p-value.\n\n    :func:`f_regression` is derived from :func:`r_regression` and will rank\n    features in the same order if all the features are positively correlated\n    with the target.\n\n    Note however that contrary to :func:`f_regression`, :func:`r_regression`\n    values lie in [-1, 1] and can thus be negative. :func:`f_regression` is\n    therefore recommended as a feature selection criterion to identify\n    potentially predictive feature for a downstream classifier, irrespective of\n    the sign of the association with the target variable.\n\n    Furthermore :func:`f_regression` returns p-values while\n    :func:`r_regression` does not.\n\n    Read more in the :ref:`User Guide <univariate_feature_selection>`.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The data matrix.\n\n    y : array-like of shape (n_samples,)\n        The target vector.\n\n    center : bool, default=True\n        Whether or not to center the data matrix `X` and the target vector `y`.\n        By default, `X` and `y` will be centered.\n\n    force_finite : bool, default=True\n        Whether or not to force the F-statistics and associated p-values to\n        be finite. There are two cases where the F-statistic is expected to not\n        be finite:\n\n        - when the target `y` or some features in `X` are constant. In this\n          case, the Pearson's R correlation is not defined leading to obtain\n          `np.nan` values in the F-statistic and p-value. When\n          `force_finite=True`, the F-statistic is set to `0.0` and the\n          associated p-value is set to `1.0`.\n        - when a feature in `X` is perfectly correlated (or\n          anti-correlated) with the target `y`. In this case, the F-statistic\n          is expected to be `np.inf`. When `force_finite=True`, the F-statistic\n          is set to `np.finfo(dtype).max` and the associated p-value is set to\n          `0.0`.\n\n        .. versionadded:: 1.1\n\n    Returns\n    -------\n    f_statistic : ndarray of shape (n_features,)\n        F-statistic for each feature.\n\n    p_values : ndarray of shape (n_features,)\n        P-values associated with the F-statistic.\n\n    See Also\n    --------\n    r_regression: Pearson's R between label/feature for regression tasks.\n    f_classif: ANOVA F-value between label/feature for classification tasks.\n    chi2: Chi-squared stats of non-negative features for classification tasks.\n    SelectKBest: Select features based on the k highest scores.\n    SelectFpr: Select features based on a false positive rate test.\n    SelectFdr: Select features based on an estimated false discovery rate.\n    SelectFwe: Select features based on family-wise error rate.\n    SelectPercentile: Select features based on percentile of the highest\n        scores.",
        "parameters": {
          "X": {
            "type": "{array",
            "description": "like, sparse matrix} of shape (n_samples, n_features)"
          },
          "The": {
            "type": "target vector.",
            "description": ""
          },
          "y": {
            "type": "array",
            "description": "like of shape (n_samples,)"
          },
          "center": {
            "type": "bool, default=True",
            "description": ""
          },
          "Whether": {
            "type": "or not to force the F-statistics and associated p-values to",
            "description": ""
          },
          "By": {
            "type": "default, `X` and `y` will be centered.",
            "description": ""
          },
          "force_finite": {
            "type": "bool, default=True",
            "description": ""
          },
          "be": {
            "type": "finite:",
            "description": "- when the target `y` or some features in `X` are constant. In this\ncase, the Pearson's R correlation is not defined leading to obtain\n`np.nan` values in the F-statistic and p-value. When\n`force_finite=True`, the F-statistic is set to `0.0` and the"
          },
          "associated": {
            "type": "p-value is set to `1.0`.",
            "description": "- when a feature in `X` is perfectly correlated (or\nanti-correlated) with the target `y`. In this case, the F-statistic"
          },
          "is": {
            "type": "set to `np.finfo(dtype).max` and the associated p-value is set to",
            "description": "`0.0`.\n.. versionadded:: 1.1\nReturns\n-------"
          },
          "f_statistic": {
            "type": "ndarray of shape (n_features,)",
            "description": "F-statistic for each feature."
          },
          "p_values": {
            "type": "ndarray of shape (n_features,)",
            "description": "P-values associated with the F-statistic."
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "r_regression": {
            "type": "Pearson's R between label/feature for regression tasks.",
            "description": ""
          },
          "f_classif": {
            "type": "ANOVA F",
            "description": "value between label/feature for classification tasks."
          },
          "chi2": {
            "type": "Chi",
            "description": "squared stats of non-negative features for classification tasks."
          },
          "SelectKBest": {
            "type": "Select features based on the k highest scores.",
            "description": ""
          },
          "SelectFpr": {
            "type": "Select features based on a false positive rate test.",
            "description": ""
          },
          "SelectFdr": {
            "type": "Select features based on an estimated false discovery rate.",
            "description": ""
          },
          "SelectFwe": {
            "type": "Select features based on family",
            "description": "wise error rate."
          },
          "SelectPercentile": {
            "type": "Select features based on percentile of the highest",
            "description": "scores.\nExamples\n--------\n>>> from sklearn.datasets import make_regression\n>>> from sklearn.feature_selection import f_regression\n>>> X, y = make_regression(\n...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42\n... )\n>>> f_statistic, p_values = f_regression(X, y)\n>>> f_statistic"
          },
          "array": {
            "type": "[2.7..., 1.5..., 1.0...]",
            "description": ""
          }
        },
        "returns": "-------\n    f_statistic : ndarray of shape (n_features,)\n        F-statistic for each feature.\n\n    p_values : ndarray of shape (n_features,)\n        P-values associated with the F-statistic.\n\n    See Also\n    --------\n    r_regression: Pearson's R between label/feature for regression tasks.\n    f_classif: ANOVA F-value between label/feature for classification tasks.\n    chi2: Chi-squared stats of non-negative features for classification tasks.\n    SelectKBest: Select features based on the k highest scores.\n    SelectFpr: Select features based on a false positive rate test.\n    SelectFdr: Select features based on an estimated false discovery rate.\n    SelectFwe: Select features based on family-wise error rate.\n    SelectPercentile: Select features based on percentile of the highest\n        scores.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import make_regression\n    >>> from sklearn.feature_selection import f_regression\n    >>> X, y = make_regression(\n    ...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42\n    ... )\n    >>> f_statistic, p_values = f_regression(X, y)\n    >>> f_statistic\n    array([1.2...+00, 2.6...+13, 2.6...+00])\n    >>> p_values\n    array([2.7..., 1.5..., 1.0...])",
        "raises": "",
        "see_also": "--------\n    r_regression: Pearson's R between label/feature for regression tasks.\n    f_classif: ANOVA F-value between label/feature for classification tasks.\n    chi2: Chi-squared stats of non-negative features for classification tasks.\n    SelectKBest: Select features based on the k highest scores.\n    SelectFpr: Select features based on a false positive rate test.\n    SelectFdr: Select features based on an estimated false discovery rate.\n    SelectFwe: Select features based on family-wise error rate.\n    SelectPercentile: Select features based on percentile of the highest\n        scores.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import make_regression\n    >>> from sklearn.feature_selection import f_regression\n    >>> X, y = make_regression(\n    ...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42\n    ... )\n    >>> f_statistic, p_values = f_regression(X, y)\n    >>> f_statistic\n    array([1.2...+00, 2.6...+13, 2.6...+00])\n    >>> p_values\n    array([2.7..., 1.5..., 1.0...])",
        "notes": "however that contrary to :func:`f_regression`, :func:`r_regression`\n    values lie in [-1, 1] and can thus be negative. :func:`f_regression` is\n    therefore recommended as a feature selection criterion to identify\n    potentially predictive feature for a downstream classifier, irrespective of\n    the sign of the association with the target variable.\n\n    Furthermore :func:`f_regression` returns p-values while\n    :func:`r_regression` does not.\n\n    Read more in the :ref:`User Guide <univariate_feature_selection>`.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The data matrix.\n\n    y : array-like of shape (n_samples,)\n        The target vector.\n\n    center : bool, default=True\n        Whether or not to center the data matrix `X` and the target vector `y`.\n        By default, `X` and `y` will be centered.\n\n    force_finite : bool, default=True\n        Whether or not to force the F-statistics and associated p-values to\n        be finite. There are two cases where the F-statistic is expected to not\n        be finite:\n\n        - when the target `y` or some features in `X` are constant. In this\n          case, the Pearson's R correlation is not defined leading to obtain\n          `np.nan` values in the F-statistic and p-value. When\n          `force_finite=True`, the F-statistic is set to `0.0` and the\n          associated p-value is set to `1.0`.\n        - when a feature in `X` is perfectly correlated (or\n          anti-correlated) with the target `y`. In this case, the F-statistic\n          is expected to be `np.inf`. When `force_finite=True`, the F-statistic\n          is set to `np.finfo(dtype).max` and the associated p-value is set to\n          `0.0`.\n\n        .. versionadded:: 1.1\n\n    Returns\n    -------\n    f_statistic : ndarray of shape (n_features,)\n        F-statistic for each feature.\n\n    p_values : ndarray of shape (n_features,)\n        P-values associated with the F-statistic.\n\n    See Also\n    --------\n    r_regression: Pearson's R between label/feature for regression tasks.\n    f_classif: ANOVA F-value between label/feature for classification tasks.\n    chi2: Chi-squared stats of non-negative features for classification tasks.\n    SelectKBest: Select features based on the k highest scores.\n    SelectFpr: Select features based on a false positive rate test.\n    SelectFdr: Select features based on an estimated false discovery rate.\n    SelectFwe: Select features based on family-wise error rate.\n    SelectPercentile: Select features based on percentile of the highest\n        scores.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import make_regression\n    >>> from sklearn.feature_selection import f_regression\n    >>> X, y = make_regression(\n    ...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42\n    ... )\n    >>> f_statistic, p_values = f_regression(X, y)\n    >>> f_statistic\n    array([1.2...+00, 2.6...+13, 2.6...+00])\n    >>> p_values\n    array([2.7..., 1.5..., 1.0...])",
        "examples": "--------\n    >>> from sklearn.datasets import make_regression\n    >>> from sklearn.feature_selection import f_regression\n    >>> X, y = make_regression(\n    ...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42\n    ... )\n    >>> f_statistic, p_values = f_regression(X, y)\n    >>> f_statistic\n    array([1.2...+00, 2.6...+13, 2.6...+00])\n    >>> p_values\n    array([2.7..., 1.5..., 1.0...])"
      }
    },
    {
      "name": "mutual_info_classif",
      "signature": "mutual_info_classif(X, y, *, discrete_features='auto', n_neighbors=3, copy=True, random_state=None, n_jobs=None)",
      "documentation": {
        "description": "Estimate mutual information for a discrete target variable.\n\n    Mutual information (MI) [1]_ between two random variables is a non-negative\n    value, which measures the dependency between the variables. It is equal\n    to zero if and only if two random variables are independent, and higher\n    values mean higher dependency.\n\n    The function relies on nonparametric methods based on entropy estimation\n    from k-nearest neighbors distances as described in [2]_ and [3]_. Both\n    methods are based on the idea originally proposed in [4]_.\n\n    It can be used for univariate features selection, read more in the\n    :ref:`User Guide <univariate_feature_selection>`.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        Feature matrix.\n\n    y : array-like of shape (n_samples,)\n        Target vector.\n\n    discrete_features : 'auto', bool or array-like, default='auto'\n        If bool, then determines whether to consider all features discrete\n        or continuous. If array, then it should be either a boolean mask\n        with shape (n_features,) or array with indices of discrete features.\n        If 'auto', it is assigned to False for dense `X` and to True for\n        sparse `X`.\n\n    n_neighbors : int, default=3\n        Number of neighbors to use for MI estimation for continuous variables,\n        see [2]_ and [3]_. Higher values reduce variance of the estimation, but\n        could introduce a bias.\n\n    copy : bool, default=True\n        Whether to make a copy of the given data. If set to False, the initial\n        data will be overwritten.\n\n    random_state : int, RandomState instance or None, default=None\n        Determines random number generation for adding small noise to\n        continuous variables in order to remove repeated values.\n        Pass an int for reproducible results across multiple function calls.\n        See :term:`Glossary <random_state>`.\n\n    n_jobs : int, default=None\n        The number of jobs to use for computing the mutual information.\n        The parallelization is done on the columns of `X`.\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n        .. versionadded:: 1.5\n\n    Returns\n    -------\n    mi : ndarray, shape (n_features,)\n        Estimated mutual information between each feature and the target in\n        nat units.\n\n    Notes\n    -----\n    1. The term \"discrete features\" is used instead of naming them\n       \"categorical\", because it describes the essence more accurately.\n       For example, pixel intensities of an image are discrete features\n       (but hardly categorical) and you will get better results if mark them\n       as such. Also note, that treating a continuous variable as discrete and\n       vice versa will usually give incorrect results, so be attentive about\n       that.\n    2. True mutual information can't be negative. If its estimate turns out\n       to be negative, it is replaced by zero.\n\n    References\n    ----------\n    .. [1] `Mutual Information\n           <https://en.wikipedia.org/wiki/Mutual_information>`_\n           on Wikipedia.\n    .. [2] A. Kraskov, H. Stogbauer and P. Grassberger, \"Estimating mutual\n           information\". Phys. Rev. E 69, 2004.\n    .. [3] B. C. Ross \"Mutual Information between Discrete and Continuous\n           Data Sets\". PLoS ONE 9(2), 2014.\n    .. [4] L. F. Kozachenko, N. N. Leonenko, \"Sample Estimate of the Entropy\n           of a Random Vector:, Probl. Peredachi Inf., 23:2 (1987), 9-16",
        "parameters": {
          "X": {
            "type": "{array",
            "description": "like, sparse matrix} of shape (n_samples, n_features)"
          },
          "Feature": {
            "type": "matrix.",
            "description": ""
          },
          "y": {
            "type": "array",
            "description": "like of shape (n_samples,)"
          },
          "Target": {
            "type": "vector.",
            "description": ""
          },
          "discrete_features": {
            "type": "'auto', bool or array",
            "description": "like, default='auto'"
          },
          "If": {
            "type": "'auto', it is assigned to False for dense `X` and to True for",
            "description": ""
          },
          "or": {
            "type": "continuous. If array, then it should be either a boolean mask",
            "description": ""
          },
          "with": {
            "type": "shape (n_features,) or array with indices of discrete features.",
            "description": ""
          },
          "sparse": {
            "type": "`X`.",
            "description": ""
          },
          "n_neighbors": {
            "type": "int, default=3",
            "description": ""
          },
          "Number": {
            "type": "of neighbors to use for MI estimation for continuous variables,",
            "description": ""
          },
          "see": {
            "type": "[2]_ and [3]_. Higher values reduce variance of the estimation, but",
            "description": ""
          },
          "could": {
            "type": "introduce a bias.",
            "description": ""
          },
          "copy": {
            "type": "bool, default=True",
            "description": ""
          },
          "Whether": {
            "type": "to make a copy of the given data. If set to False, the initial",
            "description": ""
          },
          "data": {
            "type": "will be overwritten.",
            "description": ""
          },
          "random_state": {
            "type": "int, RandomState instance or None, default=None",
            "description": ""
          },
          "Determines": {
            "type": "random number generation for adding small noise to",
            "description": ""
          },
          "continuous": {
            "type": "variables in order to remove repeated values.",
            "description": ""
          },
          "Pass": {
            "type": "an int for reproducible results across multiple function calls.",
            "description": ""
          },
          "See": {
            "type": "term:`Glossary <random_state>`.",
            "description": ""
          },
          "n_jobs": {
            "type": "int, default=None",
            "description": ""
          },
          "The": {
            "type": "parallelization is done on the columns of `X`.",
            "description": "``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n``-1`` means using all processors. See :term:`Glossary <n_jobs>`"
          },
          "for": {
            "type": "more details.",
            "description": ".. versionadded:: 1.5\nReturns\n-------"
          },
          "mi": {
            "type": "ndarray, shape (n_features,)",
            "description": ""
          },
          "Estimated": {
            "type": "mutual information between each feature and the target in",
            "description": ""
          },
          "nat": {
            "type": "units.",
            "description": "Notes\n-----\n1. The term \"discrete features\" is used instead of naming them\n\"categorical\", because it describes the essence more accurately."
          },
          "For": {
            "type": "example, pixel intensities of an image are discrete features",
            "description": "(but hardly categorical) and you will get better results if mark them"
          },
          "as": {
            "type": "such. Also note, that treating a continuous variable as discrete and",
            "description": ""
          },
          "vice": {
            "type": "versa will usually give incorrect results, so be attentive about",
            "description": "that.\n2. True mutual information can't be negative. If its estimate turns out"
          },
          "to": {
            "type": "be negative, it is replaced by zero.",
            "description": "References\n----------\n.. [1] `Mutual Information\n<https://en.wikipedia.org/wiki/Mutual_information>`_"
          },
          "on": {
            "type": "Wikipedia.",
            "description": ".. [2] A. Kraskov, H. Stogbauer and P. Grassberger, \"Estimating mutual\ninformation\". Phys. Rev. E 69, 2004.\n.. [3] B. C. Ross \"Mutual Information between Discrete and Continuous"
          },
          "Data": {
            "type": "Sets\". PLoS ONE 9(2), 2014.",
            "description": ".. [4] L. F. Kozachenko, N. N. Leonenko, \"Sample Estimate of the Entropy"
          },
          "of": {
            "type": "a Random Vector:, Probl. Peredachi Inf., 23:2 (1987), 9-16",
            "description": "Examples\n--------\n>>> from sklearn.datasets import make_classification\n>>> from sklearn.feature_selection import mutual_info_classif\n>>> X, y = make_classification(\n...     n_samples=100, n_features=10, n_informative=2, n_clusters_per_class=1,\n...     shuffle=False, random_state=42\n... )\n>>> mutual_info_classif(X, y)\narray([0.58..., 0.10..., 0.19..., 0.09... , 0.        ,\n0.     , 0.     , 0.     , 0.      , 0.        ])"
          }
        },
        "returns": "-------\n    mi : ndarray, shape (n_features,)\n        Estimated mutual information between each feature and the target in\n        nat units.\n\n    Notes\n    -----\n    1. The term \"discrete features\" is used instead of naming them\n       \"categorical\", because it describes the essence more accurately.\n       For example, pixel intensities of an image are discrete features\n       (but hardly categorical) and you will get better results if mark them\n       as such. Also note, that treating a continuous variable as discrete and\n       vice versa will usually give incorrect results, so be attentive about\n       that.\n    2. True mutual information can't be negative. If its estimate turns out\n       to be negative, it is replaced by zero.\n\n    References\n    ----------\n    .. [1] `Mutual Information\n           <https://en.wikipedia.org/wiki/Mutual_information>`_\n           on Wikipedia.\n    .. [2] A. Kraskov, H. Stogbauer and P. Grassberger, \"Estimating mutual\n           information\". Phys. Rev. E 69, 2004.\n    .. [3] B. C. Ross \"Mutual Information between Discrete and Continuous\n           Data Sets\". PLoS ONE 9(2), 2014.\n    .. [4] L. F. Kozachenko, N. N. Leonenko, \"Sample Estimate of the Entropy\n           of a Random Vector:, Probl. Peredachi Inf., 23:2 (1987), 9-16\n\n    Examples\n    --------\n    >>> from sklearn.datasets import make_classification\n    >>> from sklearn.feature_selection import mutual_info_classif\n    >>> X, y = make_classification(\n    ...     n_samples=100, n_features=10, n_informative=2, n_clusters_per_class=1,\n    ...     shuffle=False, random_state=42\n    ... )\n    >>> mutual_info_classif(X, y)\n    array([0.58..., 0.10..., 0.19..., 0.09... , 0.        ,\n           0.     , 0.     , 0.     , 0.      , 0.        ])",
        "raises": "",
        "see_also": "",
        "notes": "-----\n    1. The term \"discrete features\" is used instead of naming them\n       \"categorical\", because it describes the essence more accurately.\n       For example, pixel intensities of an image are discrete features\n       (but hardly categorical) and you will get better results if mark them\n       as such. Also note, that treating a continuous variable as discrete and\n       vice versa will usually give incorrect results, so be attentive about\n       that.\n    2. True mutual information can't be negative. If its estimate turns out\n       to be negative, it is replaced by zero.\n\n    References\n    ----------\n    .. [1] `Mutual Information\n           <https://en.wikipedia.org/wiki/Mutual_information>`_\n           on Wikipedia.\n    .. [2] A. Kraskov, H. Stogbauer and P. Grassberger, \"Estimating mutual\n           information\". Phys. Rev. E 69, 2004.\n    .. [3] B. C. Ross \"Mutual Information between Discrete and Continuous\n           Data Sets\". PLoS ONE 9(2), 2014.\n    .. [4] L. F. Kozachenko, N. N. Leonenko, \"Sample Estimate of the Entropy\n           of a Random Vector:, Probl. Peredachi Inf., 23:2 (1987), 9-16\n\n    Examples\n    --------\n    >>> from sklearn.datasets import make_classification\n    >>> from sklearn.feature_selection import mutual_info_classif\n    >>> X, y = make_classification(\n    ...     n_samples=100, n_features=10, n_informative=2, n_clusters_per_class=1,\n    ...     shuffle=False, random_state=42\n    ... )\n    >>> mutual_info_classif(X, y)\n    array([0.58..., 0.10..., 0.19..., 0.09... , 0.        ,\n           0.     , 0.     , 0.     , 0.      , 0.        ])",
        "examples": "--------\n    >>> from sklearn.datasets import make_classification\n    >>> from sklearn.feature_selection import mutual_info_classif\n    >>> X, y = make_classification(\n    ...     n_samples=100, n_features=10, n_informative=2, n_clusters_per_class=1,\n    ...     shuffle=False, random_state=42\n    ... )\n    >>> mutual_info_classif(X, y)\n    array([0.58..., 0.10..., 0.19..., 0.09... , 0.        ,\n           0.     , 0.     , 0.     , 0.      , 0.        ])"
      }
    },
    {
      "name": "mutual_info_regression",
      "signature": "mutual_info_regression(X, y, *, discrete_features='auto', n_neighbors=3, copy=True, random_state=None, n_jobs=None)",
      "documentation": {
        "description": "Estimate mutual information for a continuous target variable.\n\n    Mutual information (MI) [1]_ between two random variables is a non-negative\n    value, which measures the dependency between the variables. It is equal\n    to zero if and only if two random variables are independent, and higher\n    values mean higher dependency.\n\n    The function relies on nonparametric methods based on entropy estimation\n    from k-nearest neighbors distances as described in [2]_ and [3]_. Both\n    methods are based on the idea originally proposed in [4]_.\n\n    It can be used for univariate features selection, read more in the\n    :ref:`User Guide <univariate_feature_selection>`.\n\n    Parameters\n    ----------\n    X : array-like or sparse matrix, shape (n_samples, n_features)\n        Feature matrix.\n\n    y : array-like of shape (n_samples,)\n        Target vector.\n\n    discrete_features : {'auto', bool, array-like}, default='auto'\n        If bool, then determines whether to consider all features discrete\n        or continuous. If array, then it should be either a boolean mask\n        with shape (n_features,) or array with indices of discrete features.\n        If 'auto', it is assigned to False for dense `X` and to True for\n        sparse `X`.\n\n    n_neighbors : int, default=3\n        Number of neighbors to use for MI estimation for continuous variables,\n        see [2]_ and [3]_. Higher values reduce variance of the estimation, but\n        could introduce a bias.\n\n    copy : bool, default=True\n        Whether to make a copy of the given data. If set to False, the initial\n        data will be overwritten.\n\n    random_state : int, RandomState instance or None, default=None\n        Determines random number generation for adding small noise to\n        continuous variables in order to remove repeated values.\n        Pass an int for reproducible results across multiple function calls.\n        See :term:`Glossary <random_state>`.\n\n    n_jobs : int, default=None\n        The number of jobs to use for computing the mutual information.\n        The parallelization is done on the columns of `X`.\n\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n        .. versionadded:: 1.5\n\n    Returns\n    -------\n    mi : ndarray, shape (n_features,)\n        Estimated mutual information between each feature and the target in\n        nat units.\n\n    Notes\n    -----\n    1. The term \"discrete features\" is used instead of naming them\n       \"categorical\", because it describes the essence more accurately.\n       For example, pixel intensities of an image are discrete features\n       (but hardly categorical) and you will get better results if mark them\n       as such. Also note, that treating a continuous variable as discrete and\n       vice versa will usually give incorrect results, so be attentive about\n       that.\n    2. True mutual information can't be negative. If its estimate turns out\n       to be negative, it is replaced by zero.\n\n    References\n    ----------\n    .. [1] `Mutual Information\n           <https://en.wikipedia.org/wiki/Mutual_information>`_\n           on Wikipedia.\n    .. [2] A. Kraskov, H. Stogbauer and P. Grassberger, \"Estimating mutual\n           information\". Phys. Rev. E 69, 2004.\n    .. [3] B. C. Ross \"Mutual Information between Discrete and Continuous\n           Data Sets\". PLoS ONE 9(2), 2014.\n    .. [4] L. F. Kozachenko, N. N. Leonenko, \"Sample Estimate of the Entropy\n           of a Random Vector\", Probl. Peredachi Inf., 23:2 (1987), 9-16",
        "parameters": {
          "X": {
            "type": "array",
            "description": "like or sparse matrix, shape (n_samples, n_features)"
          },
          "Feature": {
            "type": "matrix.",
            "description": ""
          },
          "y": {
            "type": "array",
            "description": "like of shape (n_samples,)"
          },
          "Target": {
            "type": "vector.",
            "description": ""
          },
          "discrete_features": {
            "type": "{'auto', bool, array",
            "description": "like}, default='auto'"
          },
          "If": {
            "type": "'auto', it is assigned to False for dense `X` and to True for",
            "description": ""
          },
          "or": {
            "type": "continuous. If array, then it should be either a boolean mask",
            "description": ""
          },
          "with": {
            "type": "shape (n_features,) or array with indices of discrete features.",
            "description": ""
          },
          "sparse": {
            "type": "`X`.",
            "description": ""
          },
          "n_neighbors": {
            "type": "int, default=3",
            "description": ""
          },
          "Number": {
            "type": "of neighbors to use for MI estimation for continuous variables,",
            "description": ""
          },
          "see": {
            "type": "[2]_ and [3]_. Higher values reduce variance of the estimation, but",
            "description": ""
          },
          "could": {
            "type": "introduce a bias.",
            "description": ""
          },
          "copy": {
            "type": "bool, default=True",
            "description": ""
          },
          "Whether": {
            "type": "to make a copy of the given data. If set to False, the initial",
            "description": ""
          },
          "data": {
            "type": "will be overwritten.",
            "description": ""
          },
          "random_state": {
            "type": "int, RandomState instance or None, default=None",
            "description": ""
          },
          "Determines": {
            "type": "random number generation for adding small noise to",
            "description": ""
          },
          "continuous": {
            "type": "variables in order to remove repeated values.",
            "description": ""
          },
          "Pass": {
            "type": "an int for reproducible results across multiple function calls.",
            "description": ""
          },
          "See": {
            "type": "term:`Glossary <random_state>`.",
            "description": ""
          },
          "n_jobs": {
            "type": "int, default=None",
            "description": ""
          },
          "The": {
            "type": "parallelization is done on the columns of `X`.",
            "description": "``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n``-1`` means using all processors. See :term:`Glossary <n_jobs>`"
          },
          "for": {
            "type": "more details.",
            "description": ".. versionadded:: 1.5\nReturns\n-------"
          },
          "mi": {
            "type": "ndarray, shape (n_features,)",
            "description": ""
          },
          "Estimated": {
            "type": "mutual information between each feature and the target in",
            "description": ""
          },
          "nat": {
            "type": "units.",
            "description": "Notes\n-----\n1. The term \"discrete features\" is used instead of naming them\n\"categorical\", because it describes the essence more accurately."
          },
          "For": {
            "type": "example, pixel intensities of an image are discrete features",
            "description": "(but hardly categorical) and you will get better results if mark them"
          },
          "as": {
            "type": "such. Also note, that treating a continuous variable as discrete and",
            "description": ""
          },
          "vice": {
            "type": "versa will usually give incorrect results, so be attentive about",
            "description": "that.\n2. True mutual information can't be negative. If its estimate turns out"
          },
          "to": {
            "type": "be negative, it is replaced by zero.",
            "description": "References\n----------\n.. [1] `Mutual Information\n<https://en.wikipedia.org/wiki/Mutual_information>`_"
          },
          "on": {
            "type": "Wikipedia.",
            "description": ".. [2] A. Kraskov, H. Stogbauer and P. Grassberger, \"Estimating mutual\ninformation\". Phys. Rev. E 69, 2004.\n.. [3] B. C. Ross \"Mutual Information between Discrete and Continuous"
          },
          "Data": {
            "type": "Sets\". PLoS ONE 9(2), 2014.",
            "description": ".. [4] L. F. Kozachenko, N. N. Leonenko, \"Sample Estimate of the Entropy"
          },
          "of": {
            "type": "a Random Vector\", Probl. Peredachi Inf., 23:2 (1987), 9-16",
            "description": "Examples\n--------\n>>> from sklearn.datasets import make_regression\n>>> from sklearn.feature_selection import mutual_info_regression\n>>> X, y = make_regression(\n...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42\n... )\n>>> mutual_info_regression(X, y)"
          },
          "array": {
            "type": "[0.1..., 2.6...  , 0.0...]",
            "description": ""
          }
        },
        "returns": "-------\n    mi : ndarray, shape (n_features,)\n        Estimated mutual information between each feature and the target in\n        nat units.\n\n    Notes\n    -----\n    1. The term \"discrete features\" is used instead of naming them\n       \"categorical\", because it describes the essence more accurately.\n       For example, pixel intensities of an image are discrete features\n       (but hardly categorical) and you will get better results if mark them\n       as such. Also note, that treating a continuous variable as discrete and\n       vice versa will usually give incorrect results, so be attentive about\n       that.\n    2. True mutual information can't be negative. If its estimate turns out\n       to be negative, it is replaced by zero.\n\n    References\n    ----------\n    .. [1] `Mutual Information\n           <https://en.wikipedia.org/wiki/Mutual_information>`_\n           on Wikipedia.\n    .. [2] A. Kraskov, H. Stogbauer and P. Grassberger, \"Estimating mutual\n           information\". Phys. Rev. E 69, 2004.\n    .. [3] B. C. Ross \"Mutual Information between Discrete and Continuous\n           Data Sets\". PLoS ONE 9(2), 2014.\n    .. [4] L. F. Kozachenko, N. N. Leonenko, \"Sample Estimate of the Entropy\n           of a Random Vector\", Probl. Peredachi Inf., 23:2 (1987), 9-16\n\n    Examples\n    --------\n    >>> from sklearn.datasets import make_regression\n    >>> from sklearn.feature_selection import mutual_info_regression\n    >>> X, y = make_regression(\n    ...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42\n    ... )\n    >>> mutual_info_regression(X, y)\n    array([0.1..., 2.6...  , 0.0...])",
        "raises": "",
        "see_also": "",
        "notes": "-----\n    1. The term \"discrete features\" is used instead of naming them\n       \"categorical\", because it describes the essence more accurately.\n       For example, pixel intensities of an image are discrete features\n       (but hardly categorical) and you will get better results if mark them\n       as such. Also note, that treating a continuous variable as discrete and\n       vice versa will usually give incorrect results, so be attentive about\n       that.\n    2. True mutual information can't be negative. If its estimate turns out\n       to be negative, it is replaced by zero.\n\n    References\n    ----------\n    .. [1] `Mutual Information\n           <https://en.wikipedia.org/wiki/Mutual_information>`_\n           on Wikipedia.\n    .. [2] A. Kraskov, H. Stogbauer and P. Grassberger, \"Estimating mutual\n           information\". Phys. Rev. E 69, 2004.\n    .. [3] B. C. Ross \"Mutual Information between Discrete and Continuous\n           Data Sets\". PLoS ONE 9(2), 2014.\n    .. [4] L. F. Kozachenko, N. N. Leonenko, \"Sample Estimate of the Entropy\n           of a Random Vector\", Probl. Peredachi Inf., 23:2 (1987), 9-16\n\n    Examples\n    --------\n    >>> from sklearn.datasets import make_regression\n    >>> from sklearn.feature_selection import mutual_info_regression\n    >>> X, y = make_regression(\n    ...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42\n    ... )\n    >>> mutual_info_regression(X, y)\n    array([0.1..., 2.6...  , 0.0...])",
        "examples": "--------\n    >>> from sklearn.datasets import make_regression\n    >>> from sklearn.feature_selection import mutual_info_regression\n    >>> X, y = make_regression(\n    ...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42\n    ... )\n    >>> mutual_info_regression(X, y)\n    array([0.1..., 2.6...  , 0.0...])"
      }
    },
    {
      "name": "r_regression",
      "signature": "r_regression(X, y, *, center=True, force_finite=True)",
      "documentation": {
        "description": "Compute Pearson's r for each features and the target.\n\n    Pearson's r is also known as the Pearson correlation coefficient.\n\n    Linear model for testing the individual effect of each of many regressors.\n    This is a scoring function to be used in a feature selection procedure, not\n    a free standing feature selection procedure.\n\n    The cross correlation between each regressor and the target is computed\n    as::\n\n        E[(X[:, i] - mean(X[:, i])) * (y - mean(y))] / (std(X[:, i]) * std(y))\n\n    For more on usage see the :ref:`User Guide <univariate_feature_selection>`.\n\n    .. versionadded:: 1.0\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The data matrix.\n\n    y : array-like of shape (n_samples,)\n        The target vector.\n\n    center : bool, default=True\n        Whether or not to center the data matrix `X` and the target vector `y`.\n        By default, `X` and `y` will be centered.\n\n    force_finite : bool, default=True\n        Whether or not to force the Pearson's R correlation to be finite.\n        In the particular case where some features in `X` or the target `y`\n        are constant, the Pearson's R correlation is not defined. When\n        `force_finite=False`, a correlation of `np.nan` is returned to\n        acknowledge this case. When `force_finite=True`, this value will be\n        forced to a minimal correlation of `0.0`.\n\n        .. versionadded:: 1.1\n\n    Returns\n    -------\n    correlation_coefficient : ndarray of shape (n_features,)\n        Pearson's R correlation coefficients of features.\n\n    See Also\n    --------\n    f_regression: Univariate linear regression tests returning f-statistic\n        and p-values.\n    mutual_info_regression: Mutual information for a continuous target.\n    f_classif: ANOVA F-value between label/feature for classification tasks.\n    chi2: Chi-squared stats of non-negative features for classification tasks.",
        "parameters": {
          "X": {
            "type": "{array",
            "description": "like, sparse matrix} of shape (n_samples, n_features)"
          },
          "The": {
            "type": "target vector.",
            "description": ""
          },
          "y": {
            "type": "array",
            "description": "like of shape (n_samples,)"
          },
          "center": {
            "type": "bool, default=True",
            "description": ""
          },
          "Whether": {
            "type": "or not to force the Pearson's R correlation to be finite.",
            "description": ""
          },
          "By": {
            "type": "default, `X` and `y` will be centered.",
            "description": ""
          },
          "force_finite": {
            "type": "bool, default=True",
            "description": ""
          },
          "In": {
            "type": "the particular case where some features in `X` or the target `y`",
            "description": ""
          },
          "are": {
            "type": "constant, the Pearson's R correlation is not defined. When",
            "description": "`force_finite=False`, a correlation of `np.nan` is returned to"
          },
          "acknowledge": {
            "type": "this case. When `force_finite=True`, this value will be",
            "description": ""
          },
          "forced": {
            "type": "to a minimal correlation of `0.0`.",
            "description": ".. versionadded:: 1.1\nReturns\n-------"
          },
          "correlation_coefficient": {
            "type": "ndarray of shape (n_features,)",
            "description": "Pearson's R correlation coefficients of features."
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "f_regression": {
            "type": "Univariate linear regression tests returning f",
            "description": "statistic"
          },
          "and": {
            "type": "p-values.",
            "description": ""
          },
          "mutual_info_regression": {
            "type": "Mutual information for a continuous target.",
            "description": ""
          },
          "f_classif": {
            "type": "ANOVA F",
            "description": "value between label/feature for classification tasks."
          },
          "chi2": {
            "type": "Chi",
            "description": "squared stats of non-negative features for classification tasks.\nExamples\n--------\n>>> from sklearn.datasets import make_regression\n>>> from sklearn.feature_selection import r_regression\n>>> X, y = make_regression(\n...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42\n... )\n>>> r_regression(X, y)"
          },
          "array": {
            "type": "[-0.15...,  1.        , -0.22...]",
            "description": ""
          }
        },
        "returns": "-------\n    correlation_coefficient : ndarray of shape (n_features,)\n        Pearson's R correlation coefficients of features.\n\n    See Also\n    --------\n    f_regression: Univariate linear regression tests returning f-statistic\n        and p-values.\n    mutual_info_regression: Mutual information for a continuous target.\n    f_classif: ANOVA F-value between label/feature for classification tasks.\n    chi2: Chi-squared stats of non-negative features for classification tasks.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import make_regression\n    >>> from sklearn.feature_selection import r_regression\n    >>> X, y = make_regression(\n    ...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42\n    ... )\n    >>> r_regression(X, y)\n    array([-0.15...,  1.        , -0.22...])",
        "raises": "",
        "see_also": "--------\n    f_regression: Univariate linear regression tests returning f-statistic\n        and p-values.\n    mutual_info_regression: Mutual information for a continuous target.\n    f_classif: ANOVA F-value between label/feature for classification tasks.\n    chi2: Chi-squared stats of non-negative features for classification tasks.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import make_regression\n    >>> from sklearn.feature_selection import r_regression\n    >>> X, y = make_regression(\n    ...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42\n    ... )\n    >>> r_regression(X, y)\n    array([-0.15...,  1.        , -0.22...])",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.datasets import make_regression\n    >>> from sklearn.feature_selection import r_regression\n    >>> X, y = make_regression(\n    ...     n_samples=50, n_features=3, n_informative=1, noise=1e-4, random_state=42\n    ... )\n    >>> r_regression(X, y)\n    array([-0.15...,  1.        , -0.22...])"
      }
    }
  ],
  "classes": [
    {
      "name": "GenericUnivariateSelect",
      "documentation": {
        "description": "Univariate feature selector with configurable strategy.\n\n    Read more in the :ref:`User Guide <univariate_feature_selection>`.\n\n    Parameters\n    ----------\n    score_func : callable, default=f_classif\n        Function taking two arrays X and y, and returning a pair of arrays\n        (scores, pvalues). For modes 'percentile' or 'kbest' it can return\n        a single array scores.\n\n    mode : {'percentile', 'k_best', 'fpr', 'fdr', 'fwe'}, default='percentile'\n        Feature selection mode. Note that the `'percentile'` and `'kbest'`\n        modes are supporting unsupervised feature selection (when `y` is `None`).\n\n    param : \"all\", float or int, default=1e-5\n        Parameter of the corresponding mode.\n\n    Attributes\n    ----------\n    scores_ : array-like of shape (n_features,)\n        Scores of features.\n\n    pvalues_ : array-like of shape (n_features,)\n        p-values of feature scores, None if `score_func` returned scores only.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    f_classif : ANOVA F-value between label/feature for classification tasks.\n    mutual_info_classif : Mutual information for a discrete target.\n    chi2 : Chi-squared stats of non-negative features for classification tasks.\n    f_regression : F-value between label/feature for regression tasks.\n    mutual_info_regression : Mutual information for a continuous target.\n    SelectPercentile : Select features based on percentile of the highest\n        scores.\n    SelectKBest : Select features based on the k highest scores.\n    SelectFpr : Select features based on a false positive rate test.\n    SelectFdr : Select features based on an estimated false discovery rate.\n    SelectFwe : Select features based on family-wise error rate.",
        "parameters": {
          "score_func": {
            "type": "callable, default=f_classif",
            "description": ""
          },
          "Function": {
            "type": "taking two arrays X and y, and returning a pair of arrays",
            "description": "(scores, pvalues). For modes 'percentile' or 'kbest' it can return"
          },
          "a": {
            "type": "single array scores.",
            "description": ""
          },
          "mode": {
            "type": "{'percentile', 'k_best', 'fpr', 'fdr', 'fwe'}, default='percentile'",
            "description": ""
          },
          "Feature": {
            "type": "selection mode. Note that the `'percentile'` and `'kbest'`",
            "description": ""
          },
          "modes": {
            "type": "are supporting unsupervised feature selection (when `y` is `None`).",
            "description": ""
          },
          "param": {
            "type": "\"all\", float or int, default=1e",
            "description": "5"
          },
          "Parameter": {
            "type": "of the corresponding mode.",
            "description": "Attributes\n----------"
          },
          "scores_": {
            "type": "array",
            "description": "like of shape (n_features,)"
          },
          "Scores": {
            "type": "of features.",
            "description": ""
          },
          "pvalues_": {
            "type": "array",
            "description": "like of shape (n_features,)\np-values of feature scores, None if `score_func` returned scores only."
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "Number": {
            "type": "of features seen during :term:`fit`.",
            "description": ".. versionadded:: 0.24"
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "f_classif": {
            "type": "ANOVA F",
            "description": "value between label/feature for classification tasks."
          },
          "mutual_info_classif": {
            "type": "Mutual information for a discrete target.",
            "description": ""
          },
          "chi2": {
            "type": "Chi",
            "description": "squared stats of non-negative features for classification tasks."
          },
          "f_regression": {
            "type": "F",
            "description": "value between label/feature for regression tasks."
          },
          "mutual_info_regression": {
            "type": "Mutual information for a continuous target.",
            "description": ""
          },
          "SelectPercentile": {
            "type": "Select features based on percentile of the highest",
            "description": "scores."
          },
          "SelectKBest": {
            "type": "Select features based on the k highest scores.",
            "description": ""
          },
          "SelectFpr": {
            "type": "Select features based on a false positive rate test.",
            "description": ""
          },
          "SelectFdr": {
            "type": "Select features based on an estimated false discovery rate.",
            "description": ""
          },
          "SelectFwe": {
            "type": "Select features based on family",
            "description": "wise error rate.\nExamples\n--------\n>>> from sklearn.datasets import load_breast_cancer\n>>> from sklearn.feature_selection import GenericUnivariateSelect, chi2\n>>> X, y = load_breast_cancer(return_X_y=True)\n>>> X.shape\n(569, 30)\n>>> transformer = GenericUnivariateSelect(chi2, mode='k_best', param=20)\n>>> X_new = transformer.fit_transform(X, y)\n>>> X_new.shape\n(569, 20)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    f_classif : ANOVA F-value between label/feature for classification tasks.\n    mutual_info_classif : Mutual information for a discrete target.\n    chi2 : Chi-squared stats of non-negative features for classification tasks.\n    f_regression : F-value between label/feature for regression tasks.\n    mutual_info_regression : Mutual information for a continuous target.\n    SelectPercentile : Select features based on percentile of the highest\n        scores.\n    SelectKBest : Select features based on the k highest scores.\n    SelectFpr : Select features based on a false positive rate test.\n    SelectFdr : Select features based on an estimated false discovery rate.\n    SelectFwe : Select features based on family-wise error rate.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.feature_selection import GenericUnivariateSelect, chi2\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> X.shape\n    (569, 30)\n    >>> transformer = GenericUnivariateSelect(chi2, mode='k_best', param=20)\n    >>> X_new = transformer.fit_transform(X, y)\n    >>> X_new.shape\n    (569, 20)",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.feature_selection import GenericUnivariateSelect, chi2\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> X.shape\n    (569, 30)\n    >>> transformer = GenericUnivariateSelect(chi2, mode='k_best', param=20)\n    >>> X_new = transformer.fit_transform(X, y)\n    >>> X_new.shape\n    (569, 20)"
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, X, y=None)",
          "documentation": {
            "description": "Run score function on (X, y) and get the appropriate features.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The training input samples.\n\n        y : array-like of shape (n_samples,) or None\n            The target values (class labels in classification, real numbers in\n            regression). If the selector is unsupervised then `y` can be set to `None`.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "target values (class labels in classification, real numbers in",
                "description": "regression). If the selector is unsupervised then `y` can be set to `None`.\nReturns\n-------"
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or None"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit to data, then transform it.\n\n        Fits transformer to `X` and `y` with optional parameters `fit_params`\n        and returns a transformed version of `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input samples.\n\n        y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n            Target values (None for unsupervised transformations).\n\n        **fit_params : dict\n            Additional fit parameters.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
              },
              "Target": {
                "type": "values (None for unsupervised transformations).",
                "description": "**fit_params : dict"
              },
              "Additional": {
                "type": "fit parameters.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray array of shape (n_samples, n_features_new)",
                "description": ""
              },
              "Transformed": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray array of shape (n_samples, n_features_new)\n            Transformed array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Mask feature names according to selected features.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Input features.\n\n            - If `input_features` is `None`, then `feature_names_in_` is\n              used as feature names in. If `feature_names_in_` is not defined,\n              then the following input feature names are generated:\n              `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n            - If `input_features` is an array-like, then `input_features` must\n              match `feature_names_in_` if `feature_names_in_` is defined.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Input": {
                "type": "features.",
                "description": "- If `input_features` is `None`, then `feature_names_in_` is"
              },
              "used": {
                "type": "as feature names in. If `feature_names_in_` is not defined,",
                "description": ""
              },
              "then": {
                "type": "the following input feature names are generated:",
                "description": "`[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n- If `input_features` is an array-like, then `input_features` must"
              },
              "match": {
                "type": "`feature_names_in_` if `feature_names_in_` is defined.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Transformed": {
                "type": "feature names.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_support",
          "signature": "get_support(self, indices=False)",
          "documentation": {
            "description": "Get a mask, or integer index, of the features selected.\n\n        Parameters\n        ----------\n        indices : bool, default=False\n            If True, the return value will be an array of integers, rather\n            than a boolean mask.",
            "parameters": {
              "indices": {
                "type": "bool, default=False",
                "description": ""
              },
              "If": {
                "type": "`indices` is False, this is a boolean array of shape",
                "description": "[# input features], in which an element is True iff its"
              },
              "than": {
                "type": "a boolean mask.",
                "description": "Returns\n-------"
              },
              "support": {
                "type": "array",
                "description": ""
              },
              "An": {
                "type": "index that selects the retained features from a feature vector.",
                "description": ""
              },
              "corresponding": {
                "type": "feature is selected for retention. If `indices` is",
                "description": "True, this is an integer array of shape [# output features] whose"
              },
              "values": {
                "type": "are indices into the input feature vector.",
                "description": ""
              }
            },
            "returns": "-------\n        support : array\n            An index that selects the retained features from a feature vector.\n            If `indices` is False, this is a boolean array of shape\n            [# input features], in which an element is True iff its\n            corresponding feature is selected for retention. If `indices` is\n            True, this is an integer array of shape [# output features] whose\n            values are indices into the input feature vector.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_transform",
          "signature": "inverse_transform(self, X)",
          "documentation": {
            "description": "Reverse the transformation operation.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_selected_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "X_r": {
                "type": "array of shape [n_samples, n_original_features]",
                "description": "`X` with columns of zeros inserted where features would have"
              },
              "been": {
                "type": "removed by :meth:`transform`.",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_original_features]\n            `X` with columns of zeros inserted where features would have\n            been removed by :meth:`transform`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "transform",
          "signature": "transform(self, X)",
          "documentation": {
            "description": "Reduce X to the selected features.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_features]",
                "description": ""
              },
              "The": {
                "type": "input samples with only the selected features.",
                "description": ""
              },
              "X_r": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_selected_features]\n            The input samples with only the selected features.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "RFE",
      "documentation": {
        "description": "Feature ranking with recursive feature elimination.\n\n    Given an external estimator that assigns weights to features (e.g., the\n    coefficients of a linear model), the goal of recursive feature elimination\n    (RFE) is to select features by recursively considering smaller and smaller\n    sets of features. First, the estimator is trained on the initial set of\n    features and the importance of each feature is obtained either through\n    any specific attribute or callable.\n    Then, the least important features are pruned from current set of features.\n    That procedure is recursively repeated on the pruned set until the desired\n    number of features to select is eventually reached.\n\n    Read more in the :ref:`User Guide <rfe>`.\n\n    Parameters\n    ----------\n    estimator : ``Estimator`` instance\n        A supervised learning estimator with a ``fit`` method that provides\n        information about feature importance\n        (e.g. `coef_`, `feature_importances_`).\n\n    n_features_to_select : int or float, default=None\n        The number of features to select. If `None`, half of the features are\n        selected. If integer, the parameter is the absolute number of features\n        to select. If float between 0 and 1, it is the fraction of features to\n        select.\n\n        .. versionchanged:: 0.24\n           Added float values for fractions.\n\n    step : int or float, default=1\n        If greater than or equal to 1, then ``step`` corresponds to the\n        (integer) number of features to remove at each iteration.\n        If within (0.0, 1.0), then ``step`` corresponds to the percentage\n        (rounded down) of features to remove at each iteration.\n\n    verbose : int, default=0\n        Controls verbosity of output.\n\n    importance_getter : str or callable, default='auto'\n        If 'auto', uses the feature importance either through a `coef_`\n        or `feature_importances_` attributes of estimator.\n\n        Also accepts a string that specifies an attribute name/path\n        for extracting feature importance (implemented with `attrgetter`).\n        For example, give `regressor_.coef_` in case of\n        :class:`~sklearn.compose.TransformedTargetRegressor`  or\n        `named_steps.clf.feature_importances_` in case of\n        class:`~sklearn.pipeline.Pipeline` with its last step named `clf`.\n\n        If `callable`, overrides the default feature importance getter.\n        The callable is passed with the fitted estimator and it should\n        return importance for each feature.\n\n        .. versionadded:: 0.24\n\n    Attributes\n    ----------\n    classes_ : ndarray of shape (n_classes,)\n        The classes labels. Only available when `estimator` is a classifier.\n\n    estimator_ : ``Estimator`` instance\n        The fitted estimator used to select features.\n\n    n_features_ : int\n        The number of selected features.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`. Only defined if the\n        underlying estimator exposes such an attribute when fit.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    ranking_ : ndarray of shape (n_features,)\n        The feature ranking, such that ``ranking_[i]`` corresponds to the\n        ranking position of the i-th feature. Selected (i.e., estimated\n        best) features are assigned rank 1.\n\n    support_ : ndarray of shape (n_features,)\n        The mask of selected features.\n\n    See Also\n    --------\n    RFECV : Recursive feature elimination with built-in cross-validated\n        selection of the best number of features.\n    SelectFromModel : Feature selection based on thresholds of importance\n        weights.\n    SequentialFeatureSelector : Sequential cross-validation based feature\n        selection. Does not rely on importance weights.\n\n    Notes\n    -----\n    Allows NaN/Inf in the input if the underlying estimator does as well.\n\n    References\n    ----------\n\n    .. [1] Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., \"Gene selection\n           for cancer classification using support vector machines\",\n           Mach. Learn., 46(1-3), 389--422, 2002.",
        "parameters": {
          "estimator": {
            "type": "``Estimator`` instance",
            "description": ""
          },
          "A": {
            "type": "supervised learning estimator with a ``fit`` method that provides",
            "description": ""
          },
          "information": {
            "type": "about feature importance",
            "description": "(e.g. `coef_`, `feature_importances_`)."
          },
          "n_features_to_select": {
            "type": "int or float, default=None",
            "description": ""
          },
          "The": {
            "type": "following example shows how to retrieve the 5 most informative",
            "description": ""
          },
          "to": {
            "type": "select. If float between 0 and 1, it is the fraction of features to",
            "description": "select.\n.. versionchanged:: 0.24"
          },
          "Added": {
            "type": "float values for fractions.",
            "description": ""
          },
          "step": {
            "type": "int or float, default=1",
            "description": ""
          },
          "If": {
            "type": "`callable`, overrides the default feature importance getter.",
            "description": ""
          },
          "verbose": {
            "type": "int, default=0",
            "description": ""
          },
          "Controls": {
            "type": "verbosity of output.",
            "description": ""
          },
          "importance_getter": {
            "type": "str or callable, default='auto'",
            "description": ""
          },
          "or": {
            "type": "`feature_importances_` attributes of estimator.",
            "description": ""
          },
          "Also": {
            "type": "accepts a string that specifies an attribute name/path",
            "description": ""
          },
          "for": {
            "type": "cancer classification using support vector machines\",",
            "description": "Mach. Learn., 46(1-3), 389--422, 2002.\nExamples\n--------"
          },
          "For": {
            "type": "example, give `regressor_.coef_` in case of",
            "description": ":class:`~sklearn.compose.TransformedTargetRegressor`  or\n`named_steps.clf.feature_importances_` in case of"
          },
          "class": {
            "type": "`~sklearn.pipeline.Pipeline` with its last step named `clf`.",
            "description": ""
          },
          "return": {
            "type": "importance for each feature.",
            "description": ".. versionadded:: 0.24\nAttributes\n----------"
          },
          "classes_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "estimator_": {
            "type": "``Estimator`` instance",
            "description": ""
          },
          "n_features_": {
            "type": "int",
            "description": ""
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "Number": {
            "type": "of features seen during :term:`fit`. Only defined if the",
            "description": ""
          },
          "underlying": {
            "type": "estimator exposes such an attribute when fit.",
            "description": ".. versionadded:: 0.24"
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "ranking_": {
            "type": "ndarray of shape (n_features,)",
            "description": ""
          },
          "ranking": {
            "type": "position of the i-th feature. Selected (i.e., estimated",
            "description": "best) features are assigned rank 1."
          },
          "support_": {
            "type": "ndarray of shape (n_features,)",
            "description": ""
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "RFECV": {
            "type": "Recursive feature elimination with built",
            "description": "in cross-validated"
          },
          "selection": {
            "type": "of the best number of features.",
            "description": ""
          },
          "SelectFromModel": {
            "type": "Feature selection based on thresholds of importance",
            "description": "weights."
          },
          "SequentialFeatureSelector": {
            "type": "Sequential cross",
            "description": "validation based feature\nselection. Does not rely on importance weights.\nNotes\n-----"
          },
          "Allows": {
            "type": "NaN/Inf in the input if the underlying estimator does as well.",
            "description": "References\n----------\n.. [1] Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., \"Gene selection"
          },
          "features": {
            "type": "in the Friedman #1 dataset.",
            "description": ">>> from sklearn.datasets import make_friedman1\n>>> from sklearn.feature_selection import RFE\n>>> from sklearn.svm import SVR\n>>> X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n>>> estimator = SVR(kernel=\"linear\")\n>>> selector = RFE(estimator, n_features_to_select=5, step=1)\n>>> selector = selector.fit(X, y)\n>>> selector.support_\narray([ True,  True,  True,  True,  True, False, False, False, False,\nFalse])\n>>> selector.ranking_"
          },
          "array": {
            "type": "[1, 1, 1, 1, 1, 6, 4, 3, 2, 5]",
            "description": ""
          }
        },
        "returns": "importance for each feature.\n\n        .. versionadded:: 0.24\n\n    Attributes\n    ----------\n    classes_ : ndarray of shape (n_classes,)\n        The classes labels. Only available when `estimator` is a classifier.\n\n    estimator_ : ``Estimator`` instance\n        The fitted estimator used to select features.\n\n    n_features_ : int\n        The number of selected features.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`. Only defined if the\n        underlying estimator exposes such an attribute when fit.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    ranking_ : ndarray of shape (n_features,)\n        The feature ranking, such that ``ranking_[i]`` corresponds to the\n        ranking position of the i-th feature. Selected (i.e., estimated\n        best) features are assigned rank 1.\n\n    support_ : ndarray of shape (n_features,)\n        The mask of selected features.\n\n    See Also\n    --------\n    RFECV : Recursive feature elimination with built-in cross-validated\n        selection of the best number of features.\n    SelectFromModel : Feature selection based on thresholds of importance\n        weights.\n    SequentialFeatureSelector : Sequential cross-validation based feature\n        selection. Does not rely on importance weights.\n\n    Notes\n    -----\n    Allows NaN/Inf in the input if the underlying estimator does as well.\n\n    References\n    ----------\n\n    .. [1] Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., \"Gene selection\n           for cancer classification using support vector machines\",\n           Mach. Learn., 46(1-3), 389--422, 2002.\n\n    Examples\n    --------\n    The following example shows how to retrieve the 5 most informative\n    features in the Friedman #1 dataset.\n\n    >>> from sklearn.datasets import make_friedman1\n    >>> from sklearn.feature_selection import RFE\n    >>> from sklearn.svm import SVR\n    >>> X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n    >>> estimator = SVR(kernel=\"linear\")\n    >>> selector = RFE(estimator, n_features_to_select=5, step=1)\n    >>> selector = selector.fit(X, y)\n    >>> selector.support_\n    array([ True,  True,  True,  True,  True, False, False, False, False,\n           False])\n    >>> selector.ranking_\n    array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])",
        "raises": "",
        "see_also": "--------\n    RFECV : Recursive feature elimination with built-in cross-validated\n        selection of the best number of features.\n    SelectFromModel : Feature selection based on thresholds of importance\n        weights.\n    SequentialFeatureSelector : Sequential cross-validation based feature\n        selection. Does not rely on importance weights.\n\n    Notes\n    -----\n    Allows NaN/Inf in the input if the underlying estimator does as well.\n\n    References\n    ----------\n\n    .. [1] Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., \"Gene selection\n           for cancer classification using support vector machines\",\n           Mach. Learn., 46(1-3), 389--422, 2002.\n\n    Examples\n    --------\n    The following example shows how to retrieve the 5 most informative\n    features in the Friedman #1 dataset.\n\n    >>> from sklearn.datasets import make_friedman1\n    >>> from sklearn.feature_selection import RFE\n    >>> from sklearn.svm import SVR\n    >>> X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n    >>> estimator = SVR(kernel=\"linear\")\n    >>> selector = RFE(estimator, n_features_to_select=5, step=1)\n    >>> selector = selector.fit(X, y)\n    >>> selector.support_\n    array([ True,  True,  True,  True,  True, False, False, False, False,\n           False])\n    >>> selector.ranking_\n    array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])",
        "notes": "-----\n    Allows NaN/Inf in the input if the underlying estimator does as well.\n\n    References\n    ----------\n\n    .. [1] Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., \"Gene selection\n           for cancer classification using support vector machines\",\n           Mach. Learn., 46(1-3), 389--422, 2002.\n\n    Examples\n    --------\n    The following example shows how to retrieve the 5 most informative\n    features in the Friedman #1 dataset.\n\n    >>> from sklearn.datasets import make_friedman1\n    >>> from sklearn.feature_selection import RFE\n    >>> from sklearn.svm import SVR\n    >>> X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n    >>> estimator = SVR(kernel=\"linear\")\n    >>> selector = RFE(estimator, n_features_to_select=5, step=1)\n    >>> selector = selector.fit(X, y)\n    >>> selector.support_\n    array([ True,  True,  True,  True,  True, False, False, False, False,\n           False])\n    >>> selector.ranking_\n    array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])",
        "examples": "--------\n    The following example shows how to retrieve the 5 most informative\n    features in the Friedman #1 dataset.\n\n    >>> from sklearn.datasets import make_friedman1\n    >>> from sklearn.feature_selection import RFE\n    >>> from sklearn.svm import SVR\n    >>> X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n    >>> estimator = SVR(kernel=\"linear\")\n    >>> selector = RFE(estimator, n_features_to_select=5, step=1)\n    >>> selector = selector.fit(X, y)\n    >>> selector.support_\n    array([ True,  True,  True,  True,  True, False, False, False, False,\n           False])\n    >>> selector.ranking_\n    array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])"
      },
      "methods": [
        {
          "name": "decision_function",
          "signature": "decision_function(self, X)",
          "documentation": {
            "description": "Compute the decision function of ``X``.\n\n        Parameters\n        ----------\n        X : {array-like or sparse matrix} of shape (n_samples, n_features)\n            The input samples. Internally, it will be converted to\n            ``dtype=np.float32`` and if a sparse matrix is provided\n            to a sparse ``csr_matrix``.",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like or sparse matrix} of shape (n_samples, n_features)"
              },
              "The": {
                "type": "decision function of the input samples. The order of the",
                "description": ""
              },
              "to": {
                "type": "a sparse ``csr_matrix``.",
                "description": "Returns\n-------"
              },
              "score": {
                "type": "array, shape = [n_samples, n_classes] or [n_samples]",
                "description": ""
              },
              "classes": {
                "type": "corresponds to that in the attribute :term:`classes_`.",
                "description": ""
              },
              "Regression": {
                "type": "and binary classification produce an array of shape",
                "description": "[n_samples]."
              }
            },
            "returns": "-------\n        score : array, shape = [n_samples, n_classes] or [n_samples]\n            The decision function of the input samples. The order of the\n            classes corresponds to that in the attribute :term:`classes_`.\n            Regression and binary classification produce an array of shape\n            [n_samples].",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fit",
          "signature": "fit(self, X, y, **fit_params)",
          "documentation": {
            "description": "Fit the RFE model and then the underlying estimator on the selected features.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The training input samples.\n\n        y : array-like of shape (n_samples,)\n            The target values.\n\n        **fit_params : dict\n            - If `enable_metadata_routing=False` (default): Parameters directly passed\n              to the ``fit`` method of the underlying estimator.\n\n            - If `enable_metadata_routing=True`: Parameters safely routed to the ``fit``\n              method of the underlying estimator.\n\n            .. versionchanged:: 1.6\n                See :ref:`Metadata Routing User Guide <metadata_routing>`\n                for more details.",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like, sparse matrix} of shape (n_samples, n_features)"
              },
              "The": {
                "type": "target values.",
                "description": "**fit_params : dict\n- If `enable_metadata_routing=False` (default): Parameters directly passed"
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,)"
              },
              "to": {
                "type": "the ``fit`` method of the underlying estimator.",
                "description": "- If `enable_metadata_routing=True`: Parameters safely routed to the ``fit``"
              },
              "method": {
                "type": "of the underlying estimator.",
                "description": ".. versionchanged:: 1.6"
              },
              "See": {
                "type": "ref:`Metadata Routing User Guide <metadata_routing>`",
                "description": ""
              },
              "for": {
                "type": "more details.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Fitted": {
                "type": "estimator.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object\n            Fitted estimator.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit to data, then transform it.\n\n        Fits transformer to `X` and `y` with optional parameters `fit_params`\n        and returns a transformed version of `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input samples.\n\n        y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n            Target values (None for unsupervised transformations).\n\n        **fit_params : dict\n            Additional fit parameters.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
              },
              "Target": {
                "type": "values (None for unsupervised transformations).",
                "description": "**fit_params : dict"
              },
              "Additional": {
                "type": "fit parameters.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray array of shape (n_samples, n_features_new)",
                "description": ""
              },
              "Transformed": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray array of shape (n_samples, n_features_new)\n            Transformed array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Mask feature names according to selected features.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Input features.\n\n            - If `input_features` is `None`, then `feature_names_in_` is\n              used as feature names in. If `feature_names_in_` is not defined,\n              then the following input feature names are generated:\n              `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n            - If `input_features` is an array-like, then `input_features` must\n              match `feature_names_in_` if `feature_names_in_` is defined.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Input": {
                "type": "features.",
                "description": "- If `input_features` is `None`, then `feature_names_in_` is"
              },
              "used": {
                "type": "as feature names in. If `feature_names_in_` is not defined,",
                "description": ""
              },
              "then": {
                "type": "the following input feature names are generated:",
                "description": "`[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n- If `input_features` is an array-like, then `input_features` must"
              },
              "match": {
                "type": "`feature_names_in_` if `feature_names_in_` is defined.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Transformed": {
                "type": "feature names.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        .. versionadded:: 1.6",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRouter\n            A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_support",
          "signature": "get_support(self, indices=False)",
          "documentation": {
            "description": "Get a mask, or integer index, of the features selected.\n\n        Parameters\n        ----------\n        indices : bool, default=False\n            If True, the return value will be an array of integers, rather\n            than a boolean mask.",
            "parameters": {
              "indices": {
                "type": "bool, default=False",
                "description": ""
              },
              "If": {
                "type": "`indices` is False, this is a boolean array of shape",
                "description": "[# input features], in which an element is True iff its"
              },
              "than": {
                "type": "a boolean mask.",
                "description": "Returns\n-------"
              },
              "support": {
                "type": "array",
                "description": ""
              },
              "An": {
                "type": "index that selects the retained features from a feature vector.",
                "description": ""
              },
              "corresponding": {
                "type": "feature is selected for retention. If `indices` is",
                "description": "True, this is an integer array of shape [# output features] whose"
              },
              "values": {
                "type": "are indices into the input feature vector.",
                "description": ""
              }
            },
            "returns": "-------\n        support : array\n            An index that selects the retained features from a feature vector.\n            If `indices` is False, this is a boolean array of shape\n            [# input features], in which an element is True iff its\n            corresponding feature is selected for retention. If `indices` is\n            True, this is an integer array of shape [# output features] whose\n            values are indices into the input feature vector.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_transform",
          "signature": "inverse_transform(self, X)",
          "documentation": {
            "description": "Reverse the transformation operation.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_selected_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "X_r": {
                "type": "array of shape [n_samples, n_original_features]",
                "description": "`X` with columns of zeros inserted where features would have"
              },
              "been": {
                "type": "removed by :meth:`transform`.",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_original_features]\n            `X` with columns of zeros inserted where features would have\n            been removed by :meth:`transform`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict",
          "signature": "predict(self, X, **predict_params)",
          "documentation": {
            "description": "Reduce X to the selected features and predict using the estimator.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_features]\n            The input samples.\n\n        **predict_params : dict\n            Parameters to route to the ``predict`` method of the\n            underlying estimator.\n\n            .. versionadded:: 1.6\n                Only available if `enable_metadata_routing=True`,\n                which can be set by using\n                ``sklearn.set_config(enable_metadata_routing=True)``.\n                See :ref:`Metadata Routing User Guide <metadata_routing>`\n                for more details.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_features]",
                "description": ""
              },
              "The": {
                "type": "input samples.",
                "description": "**predict_params : dict"
              }
            },
            "returns": "-------\n        y : array of shape [n_samples]\n            The predicted target values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_log_proba",
          "signature": "predict_log_proba(self, X)",
          "documentation": {
            "description": "Predict class log-probabilities for X.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_features]",
                "description": ""
              },
              "The": {
                "type": "class log-probabilities of the input samples. The order of the",
                "description": ""
              },
              "p": {
                "type": "array of shape (n_samples, n_classes)",
                "description": ""
              },
              "classes": {
                "type": "corresponds to that in the attribute :term:`classes_`.",
                "description": ""
              }
            },
            "returns": "-------\n        p : array of shape (n_samples, n_classes)\n            The class log-probabilities of the input samples. The order of the\n            classes corresponds to that in the attribute :term:`classes_`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_proba",
          "signature": "predict_proba(self, X)",
          "documentation": {
            "description": "Predict class probabilities for X.\n\n        Parameters\n        ----------\n        X : {array-like or sparse matrix} of shape (n_samples, n_features)\n            The input samples. Internally, it will be converted to\n            ``dtype=np.float32`` and if a sparse matrix is provided\n            to a sparse ``csr_matrix``.",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like or sparse matrix} of shape (n_samples, n_features)"
              },
              "The": {
                "type": "class probabilities of the input samples. The order of the",
                "description": ""
              },
              "to": {
                "type": "a sparse ``csr_matrix``.",
                "description": "Returns\n-------"
              },
              "p": {
                "type": "array of shape (n_samples, n_classes)",
                "description": ""
              },
              "classes": {
                "type": "corresponds to that in the attribute :term:`classes_`.",
                "description": ""
              }
            },
            "returns": "-------\n        p : array of shape (n_samples, n_classes)\n            The class probabilities of the input samples. The order of the\n            classes corresponds to that in the attribute :term:`classes_`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "score",
          "signature": "score(self, X, y, **score_params)",
          "documentation": {
            "description": "Reduce X to the selected features and return the score of the estimator.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_features]\n            The input samples.\n\n        y : array of shape [n_samples]\n            The target values.\n\n        **score_params : dict\n            - If `enable_metadata_routing=False` (default): Parameters directly passed\n              to the ``score`` method of the underlying estimator.\n\n            - If `enable_metadata_routing=True`: Parameters safely routed to the `score`\n              method of the underlying estimator.\n\n            .. versionadded:: 1.0\n\n            .. versionchanged:: 1.6\n                See :ref:`Metadata Routing User Guide <metadata_routing>`\n                for more details.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_features]",
                "description": ""
              },
              "The": {
                "type": "target values.",
                "description": "**score_params : dict\n- If `enable_metadata_routing=False` (default): Parameters directly passed"
              },
              "y": {
                "type": "array of shape [n_samples]",
                "description": ""
              },
              "to": {
                "type": "the ``score`` method of the underlying estimator.",
                "description": "- If `enable_metadata_routing=True`: Parameters safely routed to the `score`"
              },
              "method": {
                "type": "of the underlying estimator.",
                "description": ".. versionadded:: 1.0\n.. versionchanged:: 1.6"
              },
              "See": {
                "type": "ref:`Metadata Routing User Guide <metadata_routing>`",
                "description": ""
              },
              "for": {
                "type": "more details.",
                "description": "Returns\n-------"
              },
              "score": {
                "type": "float",
                "description": ""
              },
              "Score": {
                "type": "of the underlying base estimator computed with the selected",
                "description": ""
              },
              "features": {
                "type": "returned by `rfe.transform(X)` and `y`.",
                "description": ""
              }
            },
            "returns": "-------\n        score : float\n            Score of the underlying base estimator computed with the selected\n            features returned by `rfe.transform(X)` and `y`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "transform",
          "signature": "transform(self, X)",
          "documentation": {
            "description": "Reduce X to the selected features.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_features]",
                "description": ""
              },
              "The": {
                "type": "input samples with only the selected features.",
                "description": ""
              },
              "X_r": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_selected_features]\n            The input samples with only the selected features.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "RFECV",
      "documentation": {
        "description": "Recursive feature elimination with cross-validation to select features.\n\n    The number of features selected is tuned automatically by fitting an :class:`RFE`\n    selector on the different cross-validation splits (provided by the `cv` parameter).\n    The performance of the :class:`RFE` selector are evaluated using `scorer` for\n    different number of selected features and aggregated together. Finally, the scores\n    are averaged across folds and the number of features selected is set to the number\n    of features that maximize the cross-validation score.\n    See glossary entry for :term:`cross-validation estimator`.\n\n    Read more in the :ref:`User Guide <rfe>`.\n\n    Parameters\n    ----------\n    estimator : ``Estimator`` instance\n        A supervised learning estimator with a ``fit`` method that provides\n        information about feature importance either through a ``coef_``\n        attribute or through a ``feature_importances_`` attribute.\n\n    step : int or float, default=1\n        If greater than or equal to 1, then ``step`` corresponds to the\n        (integer) number of features to remove at each iteration.\n        If within (0.0, 1.0), then ``step`` corresponds to the percentage\n        (rounded down) of features to remove at each iteration.\n        Note that the last iteration may remove fewer than ``step`` features in\n        order to reach ``min_features_to_select``.\n\n    min_features_to_select : int, default=1\n        The minimum number of features to be selected. This number of features\n        will always be scored, even if the difference between the original\n        feature count and ``min_features_to_select`` isn't divisible by\n        ``step``.\n\n        .. versionadded:: 0.20\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the default 5-fold cross-validation,\n        - integer, to specify the number of folds.\n        - :term:`CV splitter`,\n        - An iterable yielding (train, test) splits as arrays of indices.\n\n        For integer/None inputs, if ``y`` is binary or multiclass,\n        :class:`~sklearn.model_selection.StratifiedKFold` is used. If the\n        estimator is not a classifier or if ``y`` is neither binary nor multiclass,\n        :class:`~sklearn.model_selection.KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n        .. versionchanged:: 0.22\n            ``cv`` default value of None changed from 3-fold to 5-fold.\n\n    scoring : str, callable or None, default=None\n        A string (see :ref:`scoring_parameter`) or\n        a scorer callable object / function with signature\n        ``scorer(estimator, X, y)``.\n\n    verbose : int, default=0\n        Controls verbosity of output.\n\n    n_jobs : int or None, default=None\n        Number of cores to run in parallel while fitting across folds.\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n        .. versionadded:: 0.18\n\n    importance_getter : str or callable, default='auto'\n        If 'auto', uses the feature importance either through a `coef_`\n        or `feature_importances_` attributes of estimator.\n\n        Also accepts a string that specifies an attribute name/path\n        for extracting feature importance.\n        For example, give `regressor_.coef_` in case of\n        :class:`~sklearn.compose.TransformedTargetRegressor`  or\n        `named_steps.clf.feature_importances_` in case of\n        :class:`~sklearn.pipeline.Pipeline` with its last step named `clf`.\n\n        If `callable`, overrides the default feature importance getter.\n        The callable is passed with the fitted estimator and it should\n        return importance for each feature.\n\n        .. versionadded:: 0.24\n\n    Attributes\n    ----------\n    classes_ : ndarray of shape (n_classes,)\n        The classes labels. Only available when `estimator` is a classifier.\n\n    estimator_ : ``Estimator`` instance\n        The fitted estimator used to select features.\n\n    cv_results_ : dict of ndarrays\n        All arrays (values of the dictionary) are sorted in ascending order\n        by the number of features used (i.e., the first element of the array\n        represents the models that used the least number of features, while the\n        last element represents the models that used all available features).\n\n        .. versionadded:: 1.0\n\n        This dictionary contains the following keys:\n\n        split(k)_test_score : ndarray of shape (n_subsets_of_features,)\n            The cross-validation scores across (k)th fold.\n\n        mean_test_score : ndarray of shape (n_subsets_of_features,)\n            Mean of scores over the folds.\n\n        std_test_score : ndarray of shape (n_subsets_of_features,)\n            Standard deviation of scores over the folds.\n\n        n_features : ndarray of shape (n_subsets_of_features,)\n            Number of features used at each step.\n\n            .. versionadded:: 1.5\n\n    n_features_ : int\n        The number of selected features with cross-validation.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`. Only defined if the\n        underlying estimator exposes such an attribute when fit.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    ranking_ : narray of shape (n_features,)\n        The feature ranking, such that `ranking_[i]`\n        corresponds to the ranking\n        position of the i-th feature.\n        Selected (i.e., estimated best)\n        features are assigned rank 1.\n\n    support_ : ndarray of shape (n_features,)\n        The mask of selected features.\n\n    See Also\n    --------\n    RFE : Recursive feature elimination.\n\n    Notes\n    -----\n    The size of all values in ``cv_results_`` is equal to\n    ``ceil((n_features - min_features_to_select) / step) + 1``,\n    where step is the number of features removed at each iteration.\n\n    Allows NaN/Inf in the input if the underlying estimator does as well.\n\n    References\n    ----------\n\n    .. [1] Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., \"Gene selection\n           for cancer classification using support vector machines\",\n           Mach. Learn., 46(1-3), 389--422, 2002.",
        "parameters": {
          "estimator": {
            "type": "is not a classifier or if ``y`` is neither binary nor multiclass,",
            "description": ":class:`~sklearn.model_selection.KFold` is used."
          },
          "A": {
            "type": "string (see :ref:`scoring_parameter`) or",
            "description": ""
          },
          "information": {
            "type": "about feature importance either through a ``coef_``",
            "description": ""
          },
          "attribute": {
            "type": "or through a ``feature_importances_`` attribute.",
            "description": ""
          },
          "step": {
            "type": "int or float, default=1",
            "description": ""
          },
          "If": {
            "type": "`callable`, overrides the default feature importance getter.",
            "description": ""
          },
          "Note": {
            "type": "that the last iteration may remove fewer than ``step`` features in",
            "description": ""
          },
          "order": {
            "type": "to reach ``min_features_to_select``.",
            "description": ""
          },
          "min_features_to_select": {
            "type": "int, default=1",
            "description": ""
          },
          "The": {
            "type": "following example shows how to retrieve the a-priori not known 5",
            "description": ""
          },
          "will": {
            "type": "always be scored, even if the difference between the original",
            "description": ""
          },
          "feature": {
            "type": "count and ``min_features_to_select`` isn't divisible by",
            "description": "``step``.\n.. versionadded:: 0.20"
          },
          "cv": {
            "type": "int, cross",
            "description": "validation generator or an iterable, default=None"
          },
          "Determines": {
            "type": "the cross-validation splitting strategy.",
            "description": ""
          },
          "Possible": {
            "type": "inputs for cv are:",
            "description": "- None, to use the default 5-fold cross-validation,\n- integer, to specify the number of folds.\n- :term:`CV splitter`,\n- An iterable yielding (train, test) splits as arrays of indices."
          },
          "For": {
            "type": "example, give `regressor_.coef_` in case of",
            "description": ":class:`~sklearn.compose.TransformedTargetRegressor`  or\n`named_steps.clf.feature_importances_` in case of\n:class:`~sklearn.pipeline.Pipeline` with its last step named `clf`."
          },
          "Refer": {
            "type": "ref:`User Guide <cross_validation>` for the various",
            "description": "cross-validation strategies that can be used here.\n.. versionchanged:: 0.22\n``cv`` default value of None changed from 3-fold to 5-fold."
          },
          "scoring": {
            "type": "str, callable or None, default=None",
            "description": ""
          },
          "a": {
            "type": "scorer callable object / function with signature",
            "description": "``scorer(estimator, X, y)``."
          },
          "verbose": {
            "type": "int, default=0",
            "description": ""
          },
          "Controls": {
            "type": "verbosity of output.",
            "description": ""
          },
          "n_jobs": {
            "type": "int or None, default=None",
            "description": ""
          },
          "Number": {
            "type": "of features seen during :term:`fit`. Only defined if the",
            "description": ""
          },
          "for": {
            "type": "cancer classification using support vector machines\",",
            "description": "Mach. Learn., 46(1-3), 389--422, 2002.\nExamples\n--------"
          },
          "importance_getter": {
            "type": "str or callable, default='auto'",
            "description": ""
          },
          "or": {
            "type": "`feature_importances_` attributes of estimator.",
            "description": ""
          },
          "Also": {
            "type": "accepts a string that specifies an attribute name/path",
            "description": ""
          },
          "return": {
            "type": "importance for each feature.",
            "description": ".. versionadded:: 0.24\nAttributes\n----------"
          },
          "classes_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "estimator_": {
            "type": "``Estimator`` instance",
            "description": ""
          },
          "cv_results_": {
            "type": "dict of ndarrays",
            "description": ""
          },
          "All": {
            "type": "arrays (values of the dictionary) are sorted in ascending order",
            "description": ""
          },
          "by": {
            "type": "the number of features used (i.e., the first element of the array",
            "description": ""
          },
          "represents": {
            "type": "the models that used the least number of features, while the",
            "description": ""
          },
          "last": {
            "type": "element represents the models that used all available features).",
            "description": ".. versionadded:: 1.0"
          },
          "This": {
            "type": "dictionary contains the following keys:",
            "description": ""
          },
          "split": {
            "type": "k",
            "description": "_test_score : ndarray of shape (n_subsets_of_features,)"
          },
          "mean_test_score": {
            "type": "ndarray of shape (n_subsets_of_features,)",
            "description": ""
          },
          "Mean": {
            "type": "of scores over the folds.",
            "description": ""
          },
          "std_test_score": {
            "type": "ndarray of shape (n_subsets_of_features,)",
            "description": ""
          },
          "Standard": {
            "type": "deviation of scores over the folds.",
            "description": ""
          },
          "n_features": {
            "type": "ndarray of shape (n_subsets_of_features,)",
            "description": ""
          },
          "n_features_": {
            "type": "int",
            "description": ""
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "underlying": {
            "type": "estimator exposes such an attribute when fit.",
            "description": ".. versionadded:: 0.24"
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "ranking_": {
            "type": "narray of shape (n_features,)",
            "description": ""
          },
          "corresponds": {
            "type": "to the ranking",
            "description": ""
          },
          "position": {
            "type": "of the i-th feature.",
            "description": ""
          },
          "Selected": {
            "type": "i.e., estimated best",
            "description": ""
          },
          "features": {
            "type": "are assigned rank 1.",
            "description": ""
          },
          "support_": {
            "type": "ndarray of shape (n_features,)",
            "description": ""
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "RFE": {
            "type": "Recursive feature elimination.",
            "description": "Notes\n-----"
          },
          "where": {
            "type": "step is the number of features removed at each iteration.",
            "description": ""
          },
          "Allows": {
            "type": "NaN/Inf in the input if the underlying estimator does as well.",
            "description": "References\n----------\n.. [1] Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., \"Gene selection"
          },
          "informative": {
            "type": "features in the Friedman #1 dataset.",
            "description": ">>> from sklearn.datasets import make_friedman1\n>>> from sklearn.feature_selection import RFECV\n>>> from sklearn.svm import SVR\n>>> X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n>>> estimator = SVR(kernel=\"linear\")\n>>> selector = RFECV(estimator, step=1, cv=5)\n>>> selector = selector.fit(X, y)\n>>> selector.support_\narray([ True,  True,  True,  True,  True, False, False, False, False,\nFalse])\n>>> selector.ranking_"
          },
          "array": {
            "type": "[1, 1, 1, 1, 1, 6, 4, 3, 2, 5]",
            "description": ""
          }
        },
        "returns": "importance for each feature.\n\n        .. versionadded:: 0.24\n\n    Attributes\n    ----------\n    classes_ : ndarray of shape (n_classes,)\n        The classes labels. Only available when `estimator` is a classifier.\n\n    estimator_ : ``Estimator`` instance\n        The fitted estimator used to select features.\n\n    cv_results_ : dict of ndarrays\n        All arrays (values of the dictionary) are sorted in ascending order\n        by the number of features used (i.e., the first element of the array\n        represents the models that used the least number of features, while the\n        last element represents the models that used all available features).\n\n        .. versionadded:: 1.0\n\n        This dictionary contains the following keys:\n\n        split(k)_test_score : ndarray of shape (n_subsets_of_features,)\n            The cross-validation scores across (k)th fold.\n\n        mean_test_score : ndarray of shape (n_subsets_of_features,)\n            Mean of scores over the folds.\n\n        std_test_score : ndarray of shape (n_subsets_of_features,)\n            Standard deviation of scores over the folds.\n\n        n_features : ndarray of shape (n_subsets_of_features,)\n            Number of features used at each step.\n\n            .. versionadded:: 1.5\n\n    n_features_ : int\n        The number of selected features with cross-validation.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`. Only defined if the\n        underlying estimator exposes such an attribute when fit.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    ranking_ : narray of shape (n_features,)\n        The feature ranking, such that `ranking_[i]`\n        corresponds to the ranking\n        position of the i-th feature.\n        Selected (i.e., estimated best)\n        features are assigned rank 1.\n\n    support_ : ndarray of shape (n_features,)\n        The mask of selected features.\n\n    See Also\n    --------\n    RFE : Recursive feature elimination.\n\n    Notes\n    -----\n    The size of all values in ``cv_results_`` is equal to\n    ``ceil((n_features - min_features_to_select) / step) + 1``,\n    where step is the number of features removed at each iteration.\n\n    Allows NaN/Inf in the input if the underlying estimator does as well.\n\n    References\n    ----------\n\n    .. [1] Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., \"Gene selection\n           for cancer classification using support vector machines\",\n           Mach. Learn., 46(1-3), 389--422, 2002.\n\n    Examples\n    --------\n    The following example shows how to retrieve the a-priori not known 5\n    informative features in the Friedman #1 dataset.\n\n    >>> from sklearn.datasets import make_friedman1\n    >>> from sklearn.feature_selection import RFECV\n    >>> from sklearn.svm import SVR\n    >>> X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n    >>> estimator = SVR(kernel=\"linear\")\n    >>> selector = RFECV(estimator, step=1, cv=5)\n    >>> selector = selector.fit(X, y)\n    >>> selector.support_\n    array([ True,  True,  True,  True,  True, False, False, False, False,\n           False])\n    >>> selector.ranking_\n    array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])",
        "raises": "",
        "see_also": "--------\n    RFE : Recursive feature elimination.\n\n    Notes\n    -----\n    The size of all values in ``cv_results_`` is equal to\n    ``ceil((n_features - min_features_to_select) / step) + 1``,\n    where step is the number of features removed at each iteration.\n\n    Allows NaN/Inf in the input if the underlying estimator does as well.\n\n    References\n    ----------\n\n    .. [1] Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., \"Gene selection\n           for cancer classification using support vector machines\",\n           Mach. Learn., 46(1-3), 389--422, 2002.\n\n    Examples\n    --------\n    The following example shows how to retrieve the a-priori not known 5\n    informative features in the Friedman #1 dataset.\n\n    >>> from sklearn.datasets import make_friedman1\n    >>> from sklearn.feature_selection import RFECV\n    >>> from sklearn.svm import SVR\n    >>> X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n    >>> estimator = SVR(kernel=\"linear\")\n    >>> selector = RFECV(estimator, step=1, cv=5)\n    >>> selector = selector.fit(X, y)\n    >>> selector.support_\n    array([ True,  True,  True,  True,  True, False, False, False, False,\n           False])\n    >>> selector.ranking_\n    array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])",
        "notes": "that the last iteration may remove fewer than ``step`` features in\n        order to reach ``min_features_to_select``.\n\n    min_features_to_select : int, default=1\n        The minimum number of features to be selected. This number of features\n        will always be scored, even if the difference between the original\n        feature count and ``min_features_to_select`` isn't divisible by\n        ``step``.\n\n        .. versionadded:: 0.20\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the default 5-fold cross-validation,\n        - integer, to specify the number of folds.\n        - :term:`CV splitter`,\n        - An iterable yielding (train, test) splits as arrays of indices.\n\n        For integer/None inputs, if ``y`` is binary or multiclass,\n        :class:`~sklearn.model_selection.StratifiedKFold` is used. If the\n        estimator is not a classifier or if ``y`` is neither binary nor multiclass,\n        :class:`~sklearn.model_selection.KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n        .. versionchanged:: 0.22\n            ``cv`` default value of None changed from 3-fold to 5-fold.\n\n    scoring : str, callable or None, default=None\n        A string (see :ref:`scoring_parameter`) or\n        a scorer callable object / function with signature\n        ``scorer(estimator, X, y)``.\n\n    verbose : int, default=0\n        Controls verbosity of output.\n\n    n_jobs : int or None, default=None\n        Number of cores to run in parallel while fitting across folds.\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n        .. versionadded:: 0.18\n\n    importance_getter : str or callable, default='auto'\n        If 'auto', uses the feature importance either through a `coef_`\n        or `feature_importances_` attributes of estimator.\n\n        Also accepts a string that specifies an attribute name/path\n        for extracting feature importance.\n        For example, give `regressor_.coef_` in case of\n        :class:`~sklearn.compose.TransformedTargetRegressor`  or\n        `named_steps.clf.feature_importances_` in case of\n        :class:`~sklearn.pipeline.Pipeline` with its last step named `clf`.\n\n        If `callable`, overrides the default feature importance getter.\n        The callable is passed with the fitted estimator and it should\n        return importance for each feature.\n\n        .. versionadded:: 0.24\n\n    Attributes\n    ----------\n    classes_ : ndarray of shape (n_classes,)\n        The classes labels. Only available when `estimator` is a classifier.\n\n    estimator_ : ``Estimator`` instance\n        The fitted estimator used to select features.\n\n    cv_results_ : dict of ndarrays\n        All arrays (values of the dictionary) are sorted in ascending order\n        by the number of features used (i.e., the first element of the array\n        represents the models that used the least number of features, while the\n        last element represents the models that used all available features).\n\n        .. versionadded:: 1.0\n\n        This dictionary contains the following keys:\n\n        split(k)_test_score : ndarray of shape (n_subsets_of_features,)\n            The cross-validation scores across (k)th fold.\n\n        mean_test_score : ndarray of shape (n_subsets_of_features,)\n            Mean of scores over the folds.\n\n        std_test_score : ndarray of shape (n_subsets_of_features,)\n            Standard deviation of scores over the folds.\n\n        n_features : ndarray of shape (n_subsets_of_features,)\n            Number of features used at each step.\n\n            .. versionadded:: 1.5\n\n    n_features_ : int\n        The number of selected features with cross-validation.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`. Only defined if the\n        underlying estimator exposes such an attribute when fit.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    ranking_ : narray of shape (n_features,)\n        The feature ranking, such that `ranking_[i]`\n        corresponds to the ranking\n        position of the i-th feature.\n        Selected (i.e., estimated best)\n        features are assigned rank 1.\n\n    support_ : ndarray of shape (n_features,)\n        The mask of selected features.\n\n    See Also\n    --------\n    RFE : Recursive feature elimination.\n\n    Notes\n    -----\n    The size of all values in ``cv_results_`` is equal to\n    ``ceil((n_features - min_features_to_select) / step) + 1``,\n    where step is the number of features removed at each iteration.\n\n    Allows NaN/Inf in the input if the underlying estimator does as well.\n\n    References\n    ----------\n\n    .. [1] Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., \"Gene selection\n           for cancer classification using support vector machines\",\n           Mach. Learn., 46(1-3), 389--422, 2002.\n\n    Examples\n    --------\n    The following example shows how to retrieve the a-priori not known 5\n    informative features in the Friedman #1 dataset.\n\n    >>> from sklearn.datasets import make_friedman1\n    >>> from sklearn.feature_selection import RFECV\n    >>> from sklearn.svm import SVR\n    >>> X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n    >>> estimator = SVR(kernel=\"linear\")\n    >>> selector = RFECV(estimator, step=1, cv=5)\n    >>> selector = selector.fit(X, y)\n    >>> selector.support_\n    array([ True,  True,  True,  True,  True, False, False, False, False,\n           False])\n    >>> selector.ranking_\n    array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])",
        "examples": "--------\n    The following example shows how to retrieve the a-priori not known 5\n    informative features in the Friedman #1 dataset.\n\n    >>> from sklearn.datasets import make_friedman1\n    >>> from sklearn.feature_selection import RFECV\n    >>> from sklearn.svm import SVR\n    >>> X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n    >>> estimator = SVR(kernel=\"linear\")\n    >>> selector = RFECV(estimator, step=1, cv=5)\n    >>> selector = selector.fit(X, y)\n    >>> selector.support_\n    array([ True,  True,  True,  True,  True, False, False, False, False,\n           False])\n    >>> selector.ranking_\n    array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])"
      },
      "methods": [
        {
          "name": "decision_function",
          "signature": "decision_function(self, X)",
          "documentation": {
            "description": "Compute the decision function of ``X``.\n\n        Parameters\n        ----------\n        X : {array-like or sparse matrix} of shape (n_samples, n_features)\n            The input samples. Internally, it will be converted to\n            ``dtype=np.float32`` and if a sparse matrix is provided\n            to a sparse ``csr_matrix``.",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like or sparse matrix} of shape (n_samples, n_features)"
              },
              "The": {
                "type": "decision function of the input samples. The order of the",
                "description": ""
              },
              "to": {
                "type": "a sparse ``csr_matrix``.",
                "description": "Returns\n-------"
              },
              "score": {
                "type": "array, shape = [n_samples, n_classes] or [n_samples]",
                "description": ""
              },
              "classes": {
                "type": "corresponds to that in the attribute :term:`classes_`.",
                "description": ""
              },
              "Regression": {
                "type": "and binary classification produce an array of shape",
                "description": "[n_samples]."
              }
            },
            "returns": "-------\n        score : array, shape = [n_samples, n_classes] or [n_samples]\n            The decision function of the input samples. The order of the\n            classes corresponds to that in the attribute :term:`classes_`.\n            Regression and binary classification produce an array of shape\n            [n_samples].",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fit",
          "signature": "fit(self, X, y, *, groups=None, **params)",
          "documentation": {
            "description": "Fit the RFE model and automatically tune the number of selected features.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training vector, where `n_samples` is the number of samples and\n            `n_features` is the total number of features.\n\n        y : array-like of shape (n_samples,)\n            Target values (integers for classification, real numbers for\n            regression).\n\n        groups : array-like of shape (n_samples,) or None, default=None\n            Group labels for the samples used while splitting the dataset into\n            train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n            instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n\n            .. versionadded:: 0.20\n\n        **params : dict of str -> object\n            Parameters passed to the ``fit`` method of the estimator,\n            the scorer, and the CV splitter.\n\n            .. versionadded:: 1.6\n                Only available if `enable_metadata_routing=True`,\n                which can be set by using\n                ``sklearn.set_config(enable_metadata_routing=True)``.\n                See :ref:`Metadata Routing User Guide <metadata_routing>`\n                for more details.",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like, sparse matrix} of shape (n_samples, n_features)"
              },
              "Training": {
                "type": "vector, where `n_samples` is the number of samples and",
                "description": "`n_features` is the total number of features."
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,)"
              },
              "Target": {
                "type": "values (integers for classification, real numbers for",
                "description": "regression)."
              },
              "groups": {
                "type": "array",
                "description": "like of shape (n_samples,) or None, default=None"
              },
              "Group": {
                "type": "labels for the samples used while splitting the dataset into",
                "description": "train/test set. Only used in conjunction with a \"Group\" :term:`cv`"
              },
              "instance": {
                "type": "e.g., :class:`~sklearn.model_selection.GroupKFold`",
                "description": ".\n.. versionadded:: 0.20\n**params : dict of str -> object"
              }
            },
            "returns": "-------\n        self : object\n            Fitted estimator.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit to data, then transform it.\n\n        Fits transformer to `X` and `y` with optional parameters `fit_params`\n        and returns a transformed version of `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input samples.\n\n        y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n            Target values (None for unsupervised transformations).\n\n        **fit_params : dict\n            Additional fit parameters.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
              },
              "Target": {
                "type": "values (None for unsupervised transformations).",
                "description": "**fit_params : dict"
              },
              "Additional": {
                "type": "fit parameters.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray array of shape (n_samples, n_features_new)",
                "description": ""
              },
              "Transformed": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray array of shape (n_samples, n_features_new)\n            Transformed array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Mask feature names according to selected features.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Input features.\n\n            - If `input_features` is `None`, then `feature_names_in_` is\n              used as feature names in. If `feature_names_in_` is not defined,\n              then the following input feature names are generated:\n              `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n            - If `input_features` is an array-like, then `input_features` must\n              match `feature_names_in_` if `feature_names_in_` is defined.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Input": {
                "type": "features.",
                "description": "- If `input_features` is `None`, then `feature_names_in_` is"
              },
              "used": {
                "type": "as feature names in. If `feature_names_in_` is not defined,",
                "description": ""
              },
              "then": {
                "type": "the following input feature names are generated:",
                "description": "`[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n- If `input_features` is an array-like, then `input_features` must"
              },
              "match": {
                "type": "`feature_names_in_` if `feature_names_in_` is defined.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Transformed": {
                "type": "feature names.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        .. versionadded:: 1.6",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRouter\n            A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_support",
          "signature": "get_support(self, indices=False)",
          "documentation": {
            "description": "Get a mask, or integer index, of the features selected.\n\n        Parameters\n        ----------\n        indices : bool, default=False\n            If True, the return value will be an array of integers, rather\n            than a boolean mask.",
            "parameters": {
              "indices": {
                "type": "bool, default=False",
                "description": ""
              },
              "If": {
                "type": "`indices` is False, this is a boolean array of shape",
                "description": "[# input features], in which an element is True iff its"
              },
              "than": {
                "type": "a boolean mask.",
                "description": "Returns\n-------"
              },
              "support": {
                "type": "array",
                "description": ""
              },
              "An": {
                "type": "index that selects the retained features from a feature vector.",
                "description": ""
              },
              "corresponding": {
                "type": "feature is selected for retention. If `indices` is",
                "description": "True, this is an integer array of shape [# output features] whose"
              },
              "values": {
                "type": "are indices into the input feature vector.",
                "description": ""
              }
            },
            "returns": "-------\n        support : array\n            An index that selects the retained features from a feature vector.\n            If `indices` is False, this is a boolean array of shape\n            [# input features], in which an element is True iff its\n            corresponding feature is selected for retention. If `indices` is\n            True, this is an integer array of shape [# output features] whose\n            values are indices into the input feature vector.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_transform",
          "signature": "inverse_transform(self, X)",
          "documentation": {
            "description": "Reverse the transformation operation.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_selected_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "X_r": {
                "type": "array of shape [n_samples, n_original_features]",
                "description": "`X` with columns of zeros inserted where features would have"
              },
              "been": {
                "type": "removed by :meth:`transform`.",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_original_features]\n            `X` with columns of zeros inserted where features would have\n            been removed by :meth:`transform`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict",
          "signature": "predict(self, X, **predict_params)",
          "documentation": {
            "description": "Reduce X to the selected features and predict using the estimator.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_features]\n            The input samples.\n\n        **predict_params : dict\n            Parameters to route to the ``predict`` method of the\n            underlying estimator.\n\n            .. versionadded:: 1.6\n                Only available if `enable_metadata_routing=True`,\n                which can be set by using\n                ``sklearn.set_config(enable_metadata_routing=True)``.\n                See :ref:`Metadata Routing User Guide <metadata_routing>`\n                for more details.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_features]",
                "description": ""
              },
              "The": {
                "type": "input samples.",
                "description": "**predict_params : dict"
              }
            },
            "returns": "-------\n        y : array of shape [n_samples]\n            The predicted target values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_log_proba",
          "signature": "predict_log_proba(self, X)",
          "documentation": {
            "description": "Predict class log-probabilities for X.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_features]",
                "description": ""
              },
              "The": {
                "type": "class log-probabilities of the input samples. The order of the",
                "description": ""
              },
              "p": {
                "type": "array of shape (n_samples, n_classes)",
                "description": ""
              },
              "classes": {
                "type": "corresponds to that in the attribute :term:`classes_`.",
                "description": ""
              }
            },
            "returns": "-------\n        p : array of shape (n_samples, n_classes)\n            The class log-probabilities of the input samples. The order of the\n            classes corresponds to that in the attribute :term:`classes_`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_proba",
          "signature": "predict_proba(self, X)",
          "documentation": {
            "description": "Predict class probabilities for X.\n\n        Parameters\n        ----------\n        X : {array-like or sparse matrix} of shape (n_samples, n_features)\n            The input samples. Internally, it will be converted to\n            ``dtype=np.float32`` and if a sparse matrix is provided\n            to a sparse ``csr_matrix``.",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like or sparse matrix} of shape (n_samples, n_features)"
              },
              "The": {
                "type": "class probabilities of the input samples. The order of the",
                "description": ""
              },
              "to": {
                "type": "a sparse ``csr_matrix``.",
                "description": "Returns\n-------"
              },
              "p": {
                "type": "array of shape (n_samples, n_classes)",
                "description": ""
              },
              "classes": {
                "type": "corresponds to that in the attribute :term:`classes_`.",
                "description": ""
              }
            },
            "returns": "-------\n        p : array of shape (n_samples, n_classes)\n            The class probabilities of the input samples. The order of the\n            classes corresponds to that in the attribute :term:`classes_`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "score",
          "signature": "score(self, X, y, **score_params)",
          "documentation": {
            "description": "Score using the `scoring` option on the given test data and labels.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Test samples.\n\n        y : array-like of shape (n_samples,)\n            True labels for X.\n\n        **score_params : dict\n            Parameters to pass to the `score` method of the underlying scorer.\n\n            .. versionadded:: 1.6\n                Only available if `enable_metadata_routing=True`,\n                which can be set by using\n                ``sklearn.set_config(enable_metadata_routing=True)``.\n                See :ref:`Metadata Routing User Guide <metadata_routing>`\n                for more details.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Test": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,)"
              },
              "True": {
                "type": "labels for X.",
                "description": "**score_params : dict"
              }
            },
            "returns": "-------\n        score : float\n            Score of self.predict(X) w.r.t. y defined by `scoring`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "transform",
          "signature": "transform(self, X)",
          "documentation": {
            "description": "Reduce X to the selected features.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_features]",
                "description": ""
              },
              "The": {
                "type": "input samples with only the selected features.",
                "description": ""
              },
              "X_r": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_selected_features]\n            The input samples with only the selected features.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "SelectFdr",
      "documentation": {
        "description": "Filter: Select the p-values for an estimated false discovery rate.\n\n    This uses the Benjamini-Hochberg procedure. ``alpha`` is an upper bound\n    on the expected false discovery rate.\n\n    Read more in the :ref:`User Guide <univariate_feature_selection>`.\n\n    Parameters\n    ----------\n    score_func : callable, default=f_classif\n        Function taking two arrays X and y, and returning a pair of arrays\n        (scores, pvalues).\n        Default is f_classif (see below \"See Also\"). The default function only\n        works with classification tasks.\n\n    alpha : float, default=5e-2\n        The highest uncorrected p-value for features to keep.\n\n    Attributes\n    ----------\n    scores_ : array-like of shape (n_features,)\n        Scores of features.\n\n    pvalues_ : array-like of shape (n_features,)\n        p-values of feature scores.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    f_classif : ANOVA F-value between label/feature for classification tasks.\n    mutual_info_classif : Mutual information for a discrete target.\n    chi2 : Chi-squared stats of non-negative features for classification tasks.\n    f_regression : F-value between label/feature for regression tasks.\n    mutual_info_regression : Mutual information for a continuous target.\n    SelectPercentile : Select features based on percentile of the highest\n        scores.\n    SelectKBest : Select features based on the k highest scores.\n    SelectFpr : Select features based on a false positive rate test.\n    SelectFwe : Select features based on family-wise error rate.\n    GenericUnivariateSelect : Univariate feature selector with configurable\n        mode.\n\n    References\n    ----------\n    https://en.wikipedia.org/wiki/False_discovery_rate",
        "parameters": {
          "score_func": {
            "type": "callable, default=f_classif",
            "description": ""
          },
          "Function": {
            "type": "taking two arrays X and y, and returning a pair of arrays",
            "description": "(scores, pvalues)."
          },
          "Default": {
            "type": "is f_classif (see below \"See Also\"). The default function only",
            "description": ""
          },
          "works": {
            "type": "with classification tasks.",
            "description": ""
          },
          "alpha": {
            "type": "float, default=5e",
            "description": "2"
          },
          "The": {
            "type": "highest uncorrected p-value for features to keep.",
            "description": "Attributes\n----------"
          },
          "scores_": {
            "type": "array",
            "description": "like of shape (n_features,)"
          },
          "Scores": {
            "type": "of features.",
            "description": ""
          },
          "pvalues_": {
            "type": "array",
            "description": "like of shape (n_features,)\np-values of feature scores."
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "Number": {
            "type": "of features seen during :term:`fit`.",
            "description": ".. versionadded:: 0.24"
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "f_classif": {
            "type": "ANOVA F",
            "description": "value between label/feature for classification tasks."
          },
          "mutual_info_classif": {
            "type": "Mutual information for a discrete target.",
            "description": ""
          },
          "chi2": {
            "type": "Chi",
            "description": "squared stats of non-negative features for classification tasks."
          },
          "f_regression": {
            "type": "F",
            "description": "value between label/feature for regression tasks."
          },
          "mutual_info_regression": {
            "type": "Mutual information for a continuous target.",
            "description": ""
          },
          "SelectPercentile": {
            "type": "Select features based on percentile of the highest",
            "description": "scores."
          },
          "SelectKBest": {
            "type": "Select features based on the k highest scores.",
            "description": ""
          },
          "SelectFpr": {
            "type": "Select features based on a false positive rate test.",
            "description": ""
          },
          "SelectFwe": {
            "type": "Select features based on family",
            "description": "wise error rate."
          },
          "GenericUnivariateSelect": {
            "type": "Univariate feature selector with configurable",
            "description": "mode.\nReferences\n----------"
          },
          "https": {
            "type": "//en.wikipedia.org/wiki/False_discovery_rate",
            "description": "Examples\n--------\n>>> from sklearn.datasets import load_breast_cancer\n>>> from sklearn.feature_selection import SelectFdr, chi2\n>>> X, y = load_breast_cancer(return_X_y=True)\n>>> X.shape\n(569, 30)\n>>> X_new = SelectFdr(chi2, alpha=0.01).fit_transform(X, y)\n>>> X_new.shape\n(569, 16)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    f_classif : ANOVA F-value between label/feature for classification tasks.\n    mutual_info_classif : Mutual information for a discrete target.\n    chi2 : Chi-squared stats of non-negative features for classification tasks.\n    f_regression : F-value between label/feature for regression tasks.\n    mutual_info_regression : Mutual information for a continuous target.\n    SelectPercentile : Select features based on percentile of the highest\n        scores.\n    SelectKBest : Select features based on the k highest scores.\n    SelectFpr : Select features based on a false positive rate test.\n    SelectFwe : Select features based on family-wise error rate.\n    GenericUnivariateSelect : Univariate feature selector with configurable\n        mode.\n\n    References\n    ----------\n    https://en.wikipedia.org/wiki/False_discovery_rate\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.feature_selection import SelectFdr, chi2\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> X.shape\n    (569, 30)\n    >>> X_new = SelectFdr(chi2, alpha=0.01).fit_transform(X, y)\n    >>> X_new.shape\n    (569, 16)",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.feature_selection import SelectFdr, chi2\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> X.shape\n    (569, 30)\n    >>> X_new = SelectFdr(chi2, alpha=0.01).fit_transform(X, y)\n    >>> X_new.shape\n    (569, 16)"
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, X, y=None)",
          "documentation": {
            "description": "Run score function on (X, y) and get the appropriate features.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The training input samples.\n\n        y : array-like of shape (n_samples,) or None\n            The target values (class labels in classification, real numbers in\n            regression). If the selector is unsupervised then `y` can be set to `None`.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "target values (class labels in classification, real numbers in",
                "description": "regression). If the selector is unsupervised then `y` can be set to `None`.\nReturns\n-------"
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or None"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit to data, then transform it.\n\n        Fits transformer to `X` and `y` with optional parameters `fit_params`\n        and returns a transformed version of `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input samples.\n\n        y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n            Target values (None for unsupervised transformations).\n\n        **fit_params : dict\n            Additional fit parameters.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
              },
              "Target": {
                "type": "values (None for unsupervised transformations).",
                "description": "**fit_params : dict"
              },
              "Additional": {
                "type": "fit parameters.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray array of shape (n_samples, n_features_new)",
                "description": ""
              },
              "Transformed": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray array of shape (n_samples, n_features_new)\n            Transformed array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Mask feature names according to selected features.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Input features.\n\n            - If `input_features` is `None`, then `feature_names_in_` is\n              used as feature names in. If `feature_names_in_` is not defined,\n              then the following input feature names are generated:\n              `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n            - If `input_features` is an array-like, then `input_features` must\n              match `feature_names_in_` if `feature_names_in_` is defined.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Input": {
                "type": "features.",
                "description": "- If `input_features` is `None`, then `feature_names_in_` is"
              },
              "used": {
                "type": "as feature names in. If `feature_names_in_` is not defined,",
                "description": ""
              },
              "then": {
                "type": "the following input feature names are generated:",
                "description": "`[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n- If `input_features` is an array-like, then `input_features` must"
              },
              "match": {
                "type": "`feature_names_in_` if `feature_names_in_` is defined.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Transformed": {
                "type": "feature names.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_support",
          "signature": "get_support(self, indices=False)",
          "documentation": {
            "description": "Get a mask, or integer index, of the features selected.\n\n        Parameters\n        ----------\n        indices : bool, default=False\n            If True, the return value will be an array of integers, rather\n            than a boolean mask.",
            "parameters": {
              "indices": {
                "type": "bool, default=False",
                "description": ""
              },
              "If": {
                "type": "`indices` is False, this is a boolean array of shape",
                "description": "[# input features], in which an element is True iff its"
              },
              "than": {
                "type": "a boolean mask.",
                "description": "Returns\n-------"
              },
              "support": {
                "type": "array",
                "description": ""
              },
              "An": {
                "type": "index that selects the retained features from a feature vector.",
                "description": ""
              },
              "corresponding": {
                "type": "feature is selected for retention. If `indices` is",
                "description": "True, this is an integer array of shape [# output features] whose"
              },
              "values": {
                "type": "are indices into the input feature vector.",
                "description": ""
              }
            },
            "returns": "-------\n        support : array\n            An index that selects the retained features from a feature vector.\n            If `indices` is False, this is a boolean array of shape\n            [# input features], in which an element is True iff its\n            corresponding feature is selected for retention. If `indices` is\n            True, this is an integer array of shape [# output features] whose\n            values are indices into the input feature vector.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_transform",
          "signature": "inverse_transform(self, X)",
          "documentation": {
            "description": "Reverse the transformation operation.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_selected_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "X_r": {
                "type": "array of shape [n_samples, n_original_features]",
                "description": "`X` with columns of zeros inserted where features would have"
              },
              "been": {
                "type": "removed by :meth:`transform`.",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_original_features]\n            `X` with columns of zeros inserted where features would have\n            been removed by :meth:`transform`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "transform",
          "signature": "transform(self, X)",
          "documentation": {
            "description": "Reduce X to the selected features.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_features]",
                "description": ""
              },
              "The": {
                "type": "input samples with only the selected features.",
                "description": ""
              },
              "X_r": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_selected_features]\n            The input samples with only the selected features.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "SelectFpr",
      "documentation": {
        "description": "Filter: Select the pvalues below alpha based on a FPR test.\n\n    FPR test stands for False Positive Rate test. It controls the total\n    amount of false detections.\n\n    Read more in the :ref:`User Guide <univariate_feature_selection>`.\n\n    Parameters\n    ----------\n    score_func : callable, default=f_classif\n        Function taking two arrays X and y, and returning a pair of arrays\n        (scores, pvalues).\n        Default is f_classif (see below \"See Also\"). The default function only\n        works with classification tasks.\n\n    alpha : float, default=5e-2\n        Features with p-values less than `alpha` are selected.\n\n    Attributes\n    ----------\n    scores_ : array-like of shape (n_features,)\n        Scores of features.\n\n    pvalues_ : array-like of shape (n_features,)\n        p-values of feature scores.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    f_classif : ANOVA F-value between label/feature for classification tasks.\n    chi2 : Chi-squared stats of non-negative features for classification tasks.\n    mutual_info_classif: Mutual information for a discrete target.\n    f_regression : F-value between label/feature for regression tasks.\n    mutual_info_regression : Mutual information for a continuous target.\n    SelectPercentile : Select features based on percentile of the highest\n        scores.\n    SelectKBest : Select features based on the k highest scores.\n    SelectFdr : Select features based on an estimated false discovery rate.\n    SelectFwe : Select features based on family-wise error rate.\n    GenericUnivariateSelect : Univariate feature selector with configurable\n        mode.",
        "parameters": {
          "score_func": {
            "type": "callable, default=f_classif",
            "description": ""
          },
          "Function": {
            "type": "taking two arrays X and y, and returning a pair of arrays",
            "description": "(scores, pvalues)."
          },
          "Default": {
            "type": "is f_classif (see below \"See Also\"). The default function only",
            "description": ""
          },
          "works": {
            "type": "with classification tasks.",
            "description": ""
          },
          "alpha": {
            "type": "float, default=5e",
            "description": "2"
          },
          "Features": {
            "type": "with p-values less than `alpha` are selected.",
            "description": "Attributes\n----------"
          },
          "scores_": {
            "type": "array",
            "description": "like of shape (n_features,)"
          },
          "Scores": {
            "type": "of features.",
            "description": ""
          },
          "pvalues_": {
            "type": "array",
            "description": "like of shape (n_features,)\np-values of feature scores."
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "Number": {
            "type": "of features seen during :term:`fit`.",
            "description": ".. versionadded:: 0.24"
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "f_classif": {
            "type": "ANOVA F",
            "description": "value between label/feature for classification tasks."
          },
          "chi2": {
            "type": "Chi",
            "description": "squared stats of non-negative features for classification tasks."
          },
          "mutual_info_classif": {
            "type": "Mutual information for a discrete target.",
            "description": ""
          },
          "f_regression": {
            "type": "F",
            "description": "value between label/feature for regression tasks."
          },
          "mutual_info_regression": {
            "type": "Mutual information for a continuous target.",
            "description": ""
          },
          "SelectPercentile": {
            "type": "Select features based on percentile of the highest",
            "description": "scores."
          },
          "SelectKBest": {
            "type": "Select features based on the k highest scores.",
            "description": ""
          },
          "SelectFdr": {
            "type": "Select features based on an estimated false discovery rate.",
            "description": ""
          },
          "SelectFwe": {
            "type": "Select features based on family",
            "description": "wise error rate."
          },
          "GenericUnivariateSelect": {
            "type": "Univariate feature selector with configurable",
            "description": "mode.\nExamples\n--------\n>>> from sklearn.datasets import load_breast_cancer\n>>> from sklearn.feature_selection import SelectFpr, chi2\n>>> X, y = load_breast_cancer(return_X_y=True)\n>>> X.shape\n(569, 30)\n>>> X_new = SelectFpr(chi2, alpha=0.01).fit_transform(X, y)\n>>> X_new.shape\n(569, 16)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    f_classif : ANOVA F-value between label/feature for classification tasks.\n    chi2 : Chi-squared stats of non-negative features for classification tasks.\n    mutual_info_classif: Mutual information for a discrete target.\n    f_regression : F-value between label/feature for regression tasks.\n    mutual_info_regression : Mutual information for a continuous target.\n    SelectPercentile : Select features based on percentile of the highest\n        scores.\n    SelectKBest : Select features based on the k highest scores.\n    SelectFdr : Select features based on an estimated false discovery rate.\n    SelectFwe : Select features based on family-wise error rate.\n    GenericUnivariateSelect : Univariate feature selector with configurable\n        mode.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.feature_selection import SelectFpr, chi2\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> X.shape\n    (569, 30)\n    >>> X_new = SelectFpr(chi2, alpha=0.01).fit_transform(X, y)\n    >>> X_new.shape\n    (569, 16)",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.feature_selection import SelectFpr, chi2\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> X.shape\n    (569, 30)\n    >>> X_new = SelectFpr(chi2, alpha=0.01).fit_transform(X, y)\n    >>> X_new.shape\n    (569, 16)"
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, X, y=None)",
          "documentation": {
            "description": "Run score function on (X, y) and get the appropriate features.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The training input samples.\n\n        y : array-like of shape (n_samples,) or None\n            The target values (class labels in classification, real numbers in\n            regression). If the selector is unsupervised then `y` can be set to `None`.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "target values (class labels in classification, real numbers in",
                "description": "regression). If the selector is unsupervised then `y` can be set to `None`.\nReturns\n-------"
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or None"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit to data, then transform it.\n\n        Fits transformer to `X` and `y` with optional parameters `fit_params`\n        and returns a transformed version of `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input samples.\n\n        y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n            Target values (None for unsupervised transformations).\n\n        **fit_params : dict\n            Additional fit parameters.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
              },
              "Target": {
                "type": "values (None for unsupervised transformations).",
                "description": "**fit_params : dict"
              },
              "Additional": {
                "type": "fit parameters.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray array of shape (n_samples, n_features_new)",
                "description": ""
              },
              "Transformed": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray array of shape (n_samples, n_features_new)\n            Transformed array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Mask feature names according to selected features.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Input features.\n\n            - If `input_features` is `None`, then `feature_names_in_` is\n              used as feature names in. If `feature_names_in_` is not defined,\n              then the following input feature names are generated:\n              `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n            - If `input_features` is an array-like, then `input_features` must\n              match `feature_names_in_` if `feature_names_in_` is defined.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Input": {
                "type": "features.",
                "description": "- If `input_features` is `None`, then `feature_names_in_` is"
              },
              "used": {
                "type": "as feature names in. If `feature_names_in_` is not defined,",
                "description": ""
              },
              "then": {
                "type": "the following input feature names are generated:",
                "description": "`[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n- If `input_features` is an array-like, then `input_features` must"
              },
              "match": {
                "type": "`feature_names_in_` if `feature_names_in_` is defined.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Transformed": {
                "type": "feature names.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_support",
          "signature": "get_support(self, indices=False)",
          "documentation": {
            "description": "Get a mask, or integer index, of the features selected.\n\n        Parameters\n        ----------\n        indices : bool, default=False\n            If True, the return value will be an array of integers, rather\n            than a boolean mask.",
            "parameters": {
              "indices": {
                "type": "bool, default=False",
                "description": ""
              },
              "If": {
                "type": "`indices` is False, this is a boolean array of shape",
                "description": "[# input features], in which an element is True iff its"
              },
              "than": {
                "type": "a boolean mask.",
                "description": "Returns\n-------"
              },
              "support": {
                "type": "array",
                "description": ""
              },
              "An": {
                "type": "index that selects the retained features from a feature vector.",
                "description": ""
              },
              "corresponding": {
                "type": "feature is selected for retention. If `indices` is",
                "description": "True, this is an integer array of shape [# output features] whose"
              },
              "values": {
                "type": "are indices into the input feature vector.",
                "description": ""
              }
            },
            "returns": "-------\n        support : array\n            An index that selects the retained features from a feature vector.\n            If `indices` is False, this is a boolean array of shape\n            [# input features], in which an element is True iff its\n            corresponding feature is selected for retention. If `indices` is\n            True, this is an integer array of shape [# output features] whose\n            values are indices into the input feature vector.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_transform",
          "signature": "inverse_transform(self, X)",
          "documentation": {
            "description": "Reverse the transformation operation.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_selected_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "X_r": {
                "type": "array of shape [n_samples, n_original_features]",
                "description": "`X` with columns of zeros inserted where features would have"
              },
              "been": {
                "type": "removed by :meth:`transform`.",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_original_features]\n            `X` with columns of zeros inserted where features would have\n            been removed by :meth:`transform`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "transform",
          "signature": "transform(self, X)",
          "documentation": {
            "description": "Reduce X to the selected features.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_features]",
                "description": ""
              },
              "The": {
                "type": "input samples with only the selected features.",
                "description": ""
              },
              "X_r": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_selected_features]\n            The input samples with only the selected features.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "SelectFromModel",
      "documentation": {
        "description": "Meta-transformer for selecting features based on importance weights.\n\n    .. versionadded:: 0.17\n\n    Read more in the :ref:`User Guide <select_from_model>`.\n\n    Parameters\n    ----------\n    estimator : object\n        The base estimator from which the transformer is built.\n        This can be both a fitted (if ``prefit`` is set to True)\n        or a non-fitted estimator. The estimator should have a\n        ``feature_importances_`` or ``coef_`` attribute after fitting.\n        Otherwise, the ``importance_getter`` parameter should be used.\n\n    threshold : str or float, default=None\n        The threshold value to use for feature selection. Features whose\n        absolute importance value is greater or equal are kept while the others\n        are discarded. If \"median\" (resp. \"mean\"), then the ``threshold`` value\n        is the median (resp. the mean) of the feature importances. A scaling\n        factor (e.g., \"1.25*mean\") may also be used. If None and if the\n        estimator has a parameter penalty set to l1, either explicitly\n        or implicitly (e.g, Lasso), the threshold used is 1e-5.\n        Otherwise, \"mean\" is used by default.\n\n    prefit : bool, default=False\n        Whether a prefit model is expected to be passed into the constructor\n        directly or not.\n        If `True`, `estimator` must be a fitted estimator.\n        If `False`, `estimator` is fitted and updated by calling\n        `fit` and `partial_fit`, respectively.\n\n    norm_order : non-zero int, inf, -inf, default=1\n        Order of the norm used to filter the vectors of coefficients below\n        ``threshold`` in the case where the ``coef_`` attribute of the\n        estimator is of dimension 2.\n\n    max_features : int, callable, default=None\n        The maximum number of features to select.\n\n        - If an integer, then it specifies the maximum number of features to\n          allow.\n        - If a callable, then it specifies how to calculate the maximum number of\n          features allowed by using the output of `max_features(X)`.\n        - If `None`, then all features are kept.\n\n        To only select based on ``max_features``, set ``threshold=-np.inf``.\n\n        .. versionadded:: 0.20\n        .. versionchanged:: 1.1\n           `max_features` accepts a callable.\n\n    importance_getter : str or callable, default='auto'\n        If 'auto', uses the feature importance either through a ``coef_``\n        attribute or ``feature_importances_`` attribute of estimator.\n\n        Also accepts a string that specifies an attribute name/path\n        for extracting feature importance (implemented with `attrgetter`).\n        For example, give `regressor_.coef_` in case of\n        :class:`~sklearn.compose.TransformedTargetRegressor`  or\n        `named_steps.clf.feature_importances_` in case of\n        :class:`~sklearn.pipeline.Pipeline` with its last step named `clf`.\n\n        If `callable`, overrides the default feature importance getter.\n        The callable is passed with the fitted estimator and it should\n        return importance for each feature.\n\n        .. versionadded:: 0.24\n\n    Attributes\n    ----------\n    estimator_ : estimator\n        The base estimator from which the transformer is built. This attribute\n        exist only when `fit` has been called.\n\n        - If `prefit=True`, it is a deep copy of `estimator`.\n        - If `prefit=False`, it is a clone of `estimator` and fit on the data\n          passed to `fit` or `partial_fit`.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`. Only defined if the\n        underlying estimator exposes such an attribute when fit.\n\n        .. versionadded:: 0.24\n\n    max_features_ : int\n        Maximum number of features calculated during :term:`fit`. Only defined\n        if the ``max_features`` is not `None`.\n\n        - If `max_features` is an `int`, then `max_features_ = max_features`.\n        - If `max_features` is a callable, then `max_features_ = max_features(X)`.\n\n        .. versionadded:: 1.1\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    threshold_ : float\n        The threshold value used for feature selection.\n\n    See Also\n    --------\n    RFE : Recursive feature elimination based on importance weights.\n    RFECV : Recursive feature elimination with built-in cross-validated\n        selection of the best number of features.\n    SequentialFeatureSelector : Sequential cross-validation based feature\n        selection. Does not rely on importance weights.\n\n    Notes\n    -----\n    Allows NaN/Inf in the input if the underlying estimator does as well.",
        "parameters": {
          "estimator": {
            "type": "is of dimension 2.",
            "description": ""
          },
          "The": {
            "type": "threshold value used for feature selection.",
            "description": ""
          },
          "This": {
            "type": "can be both a fitted (if ``prefit`` is set to True)",
            "description": ""
          },
          "or": {
            "type": "implicitly (e.g, Lasso), the threshold used is 1e-5.",
            "description": "Otherwise, \"mean\" is used by default."
          },
          "threshold": {
            "type": "str or float, default=None",
            "description": ""
          },
          "absolute": {
            "type": "importance value is greater or equal are kept while the others",
            "description": ""
          },
          "are": {
            "type": "discarded. If \"median\" (resp. \"mean\"), then the ``threshold`` value",
            "description": ""
          },
          "is": {
            "type": "the median (resp. the mean) of the feature importances. A scaling",
            "description": ""
          },
          "factor": {
            "type": "e.g., \"1.25*mean\"",
            "description": "may also be used. If None and if the"
          },
          "prefit": {
            "type": "bool, default=False",
            "description": ""
          },
          "Whether": {
            "type": "a prefit model is expected to be passed into the constructor",
            "description": ""
          },
          "directly": {
            "type": "or not.",
            "description": ""
          },
          "If": {
            "type": "`callable`, overrides the default feature importance getter.",
            "description": ""
          },
          "norm_order": {
            "type": "non",
            "description": "zero int, inf, -inf, default=1"
          },
          "Order": {
            "type": "of the norm used to filter the vectors of coefficients below",
            "description": "``threshold`` in the case where the ``coef_`` attribute of the"
          },
          "max_features": {
            "type": "int, callable, default=None",
            "description": ""
          },
          "features": {
            "type": "allowed by using the output of `max_features(X)`.",
            "description": "- If `None`, then all features are kept."
          },
          "To": {
            "type": "only select based on ``max_features``, set ``threshold=-np.inf``.",
            "description": ".. versionadded:: 0.20\n.. versionchanged:: 1.1\n`max_features` accepts a callable."
          },
          "importance_getter": {
            "type": "str or callable, default='auto'",
            "description": ""
          },
          "attribute": {
            "type": "or ``feature_importances_`` attribute of estimator.",
            "description": ""
          },
          "Also": {
            "type": "accepts a string that specifies an attribute name/path",
            "description": ""
          },
          "for": {
            "type": "extracting feature importance (implemented with `attrgetter`).",
            "description": ""
          },
          "For": {
            "type": "example, give `regressor_.coef_` in case of",
            "description": ":class:`~sklearn.compose.TransformedTargetRegressor`  or\n`named_steps.clf.feature_importances_` in case of\n:class:`~sklearn.pipeline.Pipeline` with its last step named `clf`."
          },
          "return": {
            "type": "importance for each feature.",
            "description": ".. versionadded:: 0.24\nAttributes\n----------"
          },
          "estimator_": {
            "type": "estimator",
            "description": ""
          },
          "exist": {
            "type": "only when `fit` has been called.",
            "description": "- If `prefit=True`, it is a deep copy of `estimator`.\n- If `prefit=False`, it is a clone of `estimator` and fit on the data"
          },
          "passed": {
            "type": "to `fit` or `partial_fit`.",
            "description": ""
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "Number": {
            "type": "of features seen during :term:`fit`. Only defined if the",
            "description": ""
          },
          "underlying": {
            "type": "estimator exposes such an attribute when fit.",
            "description": ".. versionadded:: 0.24"
          },
          "max_features_": {
            "type": "int",
            "description": ""
          },
          "Maximum": {
            "type": "number of features calculated during :term:`fit`. Only defined",
            "description": ""
          },
          "if": {
            "type": "the ``max_features`` is not `None`.",
            "description": "- If `max_features` is an `int`, then `max_features_ = max_features`.\n- If `max_features` is a callable, then `max_features_ = max_features(X)`.\n.. versionadded:: 1.1"
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "threshold_": {
            "type": "float",
            "description": ""
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "RFE": {
            "type": "Recursive feature elimination based on importance weights.",
            "description": ""
          },
          "RFECV": {
            "type": "Recursive feature elimination with built",
            "description": "in cross-validated"
          },
          "selection": {
            "type": "of the best number of features.",
            "description": ""
          },
          "SequentialFeatureSelector": {
            "type": "Sequential cross",
            "description": "validation based feature\nselection. Does not rely on importance weights.\nNotes\n-----"
          },
          "Allows": {
            "type": "NaN/Inf in the input if the underlying estimator does as well.",
            "description": "Examples\n--------\n>>> from sklearn.feature_selection import SelectFromModel\n>>> from sklearn.linear_model import LogisticRegression\n>>> X = [[ 0.87, -1.34,  0.31 ],\n...      [-2.79, -0.02, -0.85 ],\n...      [-1.34, -0.48, -2.55 ],\n...      [ 1.92,  1.48,  0.65 ]]\n>>> y = [0, 1, 0, 1]\n>>> selector = SelectFromModel(estimator=LogisticRegression()).fit(X, y)\n>>> selector.estimator_.coef_"
          },
          "array": {
            "type": "[False,  True, False]",
            "description": ">>> selector.transform(X)\narray([[-1.34],\n[-0.02],\n[-0.48],\n[ 1.48]])"
          },
          "Using": {
            "type": "a callable to create a selector that can use no more than half",
            "description": ""
          },
          "of": {
            "type": "the input features.",
            "description": ">>> def half_callable(X):\n...     return round(len(X[0]) / 2)\n>>> half_selector = SelectFromModel(estimator=LogisticRegression(),\n...                                 max_features=half_callable)\n>>> _ = half_selector.fit(X, y)\n>>> half_selector.max_features_\n2"
          }
        },
        "returns": "importance for each feature.\n\n        .. versionadded:: 0.24\n\n    Attributes\n    ----------\n    estimator_ : estimator\n        The base estimator from which the transformer is built. This attribute\n        exist only when `fit` has been called.\n\n        - If `prefit=True`, it is a deep copy of `estimator`.\n        - If `prefit=False`, it is a clone of `estimator` and fit on the data\n          passed to `fit` or `partial_fit`.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`. Only defined if the\n        underlying estimator exposes such an attribute when fit.\n\n        .. versionadded:: 0.24\n\n    max_features_ : int\n        Maximum number of features calculated during :term:`fit`. Only defined\n        if the ``max_features`` is not `None`.\n\n        - If `max_features` is an `int`, then `max_features_ = max_features`.\n        - If `max_features` is a callable, then `max_features_ = max_features(X)`.\n\n        .. versionadded:: 1.1\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    threshold_ : float\n        The threshold value used for feature selection.\n\n    See Also\n    --------\n    RFE : Recursive feature elimination based on importance weights.\n    RFECV : Recursive feature elimination with built-in cross-validated\n        selection of the best number of features.\n    SequentialFeatureSelector : Sequential cross-validation based feature\n        selection. Does not rely on importance weights.\n\n    Notes\n    -----\n    Allows NaN/Inf in the input if the underlying estimator does as well.\n\n    Examples\n    --------\n    >>> from sklearn.feature_selection import SelectFromModel\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> X = [[ 0.87, -1.34,  0.31 ],\n    ...      [-2.79, -0.02, -0.85 ],\n    ...      [-1.34, -0.48, -2.55 ],\n    ...      [ 1.92,  1.48,  0.65 ]]\n    >>> y = [0, 1, 0, 1]\n    >>> selector = SelectFromModel(estimator=LogisticRegression()).fit(X, y)\n    >>> selector.estimator_.coef_\n    array([[-0.3252...,  0.8345...,  0.4976...]])\n    >>> selector.threshold_\n    np.float64(0.55249...)\n    >>> selector.get_support()\n    array([False,  True, False])\n    >>> selector.transform(X)\n    array([[-1.34],\n           [-0.02],\n           [-0.48],\n           [ 1.48]])\n\n    Using a callable to create a selector that can use no more than half\n    of the input features.\n\n    >>> def half_callable(X):\n    ...     return round(len(X[0]) / 2)\n    >>> half_selector = SelectFromModel(estimator=LogisticRegression(),\n    ...                                 max_features=half_callable)\n    >>> _ = half_selector.fit(X, y)\n    >>> half_selector.max_features_\n    2",
        "raises": "",
        "see_also": "--------\n    RFE : Recursive feature elimination based on importance weights.\n    RFECV : Recursive feature elimination with built-in cross-validated\n        selection of the best number of features.\n    SequentialFeatureSelector : Sequential cross-validation based feature\n        selection. Does not rely on importance weights.\n\n    Notes\n    -----\n    Allows NaN/Inf in the input if the underlying estimator does as well.\n\n    Examples\n    --------\n    >>> from sklearn.feature_selection import SelectFromModel\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> X = [[ 0.87, -1.34,  0.31 ],\n    ...      [-2.79, -0.02, -0.85 ],\n    ...      [-1.34, -0.48, -2.55 ],\n    ...      [ 1.92,  1.48,  0.65 ]]\n    >>> y = [0, 1, 0, 1]\n    >>> selector = SelectFromModel(estimator=LogisticRegression()).fit(X, y)\n    >>> selector.estimator_.coef_\n    array([[-0.3252...,  0.8345...,  0.4976...]])\n    >>> selector.threshold_\n    np.float64(0.55249...)\n    >>> selector.get_support()\n    array([False,  True, False])\n    >>> selector.transform(X)\n    array([[-1.34],\n           [-0.02],\n           [-0.48],\n           [ 1.48]])\n\n    Using a callable to create a selector that can use no more than half\n    of the input features.\n\n    >>> def half_callable(X):\n    ...     return round(len(X[0]) / 2)\n    >>> half_selector = SelectFromModel(estimator=LogisticRegression(),\n    ...                                 max_features=half_callable)\n    >>> _ = half_selector.fit(X, y)\n    >>> half_selector.max_features_\n    2",
        "notes": "-----\n    Allows NaN/Inf in the input if the underlying estimator does as well.\n\n    Examples\n    --------\n    >>> from sklearn.feature_selection import SelectFromModel\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> X = [[ 0.87, -1.34,  0.31 ],\n    ...      [-2.79, -0.02, -0.85 ],\n    ...      [-1.34, -0.48, -2.55 ],\n    ...      [ 1.92,  1.48,  0.65 ]]\n    >>> y = [0, 1, 0, 1]\n    >>> selector = SelectFromModel(estimator=LogisticRegression()).fit(X, y)\n    >>> selector.estimator_.coef_\n    array([[-0.3252...,  0.8345...,  0.4976...]])\n    >>> selector.threshold_\n    np.float64(0.55249...)\n    >>> selector.get_support()\n    array([False,  True, False])\n    >>> selector.transform(X)\n    array([[-1.34],\n           [-0.02],\n           [-0.48],\n           [ 1.48]])\n\n    Using a callable to create a selector that can use no more than half\n    of the input features.\n\n    >>> def half_callable(X):\n    ...     return round(len(X[0]) / 2)\n    >>> half_selector = SelectFromModel(estimator=LogisticRegression(),\n    ...                                 max_features=half_callable)\n    >>> _ = half_selector.fit(X, y)\n    >>> half_selector.max_features_\n    2",
        "examples": "--------\n    >>> from sklearn.feature_selection import SelectFromModel\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> X = [[ 0.87, -1.34,  0.31 ],\n    ...      [-2.79, -0.02, -0.85 ],\n    ...      [-1.34, -0.48, -2.55 ],\n    ...      [ 1.92,  1.48,  0.65 ]]\n    >>> y = [0, 1, 0, 1]\n    >>> selector = SelectFromModel(estimator=LogisticRegression()).fit(X, y)\n    >>> selector.estimator_.coef_\n    array([[-0.3252...,  0.8345...,  0.4976...]])\n    >>> selector.threshold_\n    np.float64(0.55249...)\n    >>> selector.get_support()\n    array([False,  True, False])\n    >>> selector.transform(X)\n    array([[-1.34],\n           [-0.02],\n           [-0.48],\n           [ 1.48]])\n\n    Using a callable to create a selector that can use no more than half\n    of the input features.\n\n    >>> def half_callable(X):\n    ...     return round(len(X[0]) / 2)\n    >>> half_selector = SelectFromModel(estimator=LogisticRegression(),\n    ...                                 max_features=half_callable)\n    >>> _ = half_selector.fit(X, y)\n    >>> half_selector.max_features_\n    2"
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit the SelectFromModel meta-transformer.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The training input samples.\n\n        y : array-like of shape (n_samples,), default=None\n            The target values (integers that correspond to classes in\n            classification, real numbers in regression).\n\n        **fit_params : dict\n            - If `enable_metadata_routing=False` (default): Parameters directly passed\n              to the `fit` method of the sub-estimator. They are ignored if\n              `prefit=True`.\n\n            - If `enable_metadata_routing=True`: Parameters safely routed to the `fit`\n              method of the sub-estimator. They are ignored if `prefit=True`.\n\n            .. versionchanged:: 1.4\n                See :ref:`Metadata Routing User Guide <metadata_routing>` for\n                more details.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "target values (integers that correspond to classes in",
                "description": "classification, real numbers in regression).\n**fit_params : dict\n- If `enable_metadata_routing=False` (default): Parameters directly passed"
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "to": {
                "type": "the `fit` method of the sub-estimator. They are ignored if",
                "description": "`prefit=True`.\n- If `enable_metadata_routing=True`: Parameters safely routed to the `fit`"
              },
              "method": {
                "type": "of the sub-estimator. They are ignored if `prefit=True`.",
                "description": ".. versionchanged:: 1.4"
              },
              "See": {
                "type": "ref:`Metadata Routing User Guide <metadata_routing>` for",
                "description": ""
              },
              "more": {
                "type": "details.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Fitted": {
                "type": "estimator.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object\n            Fitted estimator.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit to data, then transform it.\n\n        Fits transformer to `X` and `y` with optional parameters `fit_params`\n        and returns a transformed version of `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input samples.\n\n        y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n            Target values (None for unsupervised transformations).\n\n        **fit_params : dict\n            Additional fit parameters.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
              },
              "Target": {
                "type": "values (None for unsupervised transformations).",
                "description": "**fit_params : dict"
              },
              "Additional": {
                "type": "fit parameters.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray array of shape (n_samples, n_features_new)",
                "description": ""
              },
              "Transformed": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray array of shape (n_samples, n_features_new)\n            Transformed array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Mask feature names according to selected features.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Input features.\n\n            - If `input_features` is `None`, then `feature_names_in_` is\n              used as feature names in. If `feature_names_in_` is not defined,\n              then the following input feature names are generated:\n              `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n            - If `input_features` is an array-like, then `input_features` must\n              match `feature_names_in_` if `feature_names_in_` is defined.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Input": {
                "type": "features.",
                "description": "- If `input_features` is `None`, then `feature_names_in_` is"
              },
              "used": {
                "type": "as feature names in. If `feature_names_in_` is not defined,",
                "description": ""
              },
              "then": {
                "type": "the following input feature names are generated:",
                "description": "`[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n- If `input_features` is an array-like, then `input_features` must"
              },
              "match": {
                "type": "`feature_names_in_` if `feature_names_in_` is defined.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Transformed": {
                "type": "feature names.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        .. versionadded:: 1.4",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRouter\n            A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_support",
          "signature": "get_support(self, indices=False)",
          "documentation": {
            "description": "Get a mask, or integer index, of the features selected.\n\n        Parameters\n        ----------\n        indices : bool, default=False\n            If True, the return value will be an array of integers, rather\n            than a boolean mask.",
            "parameters": {
              "indices": {
                "type": "bool, default=False",
                "description": ""
              },
              "If": {
                "type": "`indices` is False, this is a boolean array of shape",
                "description": "[# input features], in which an element is True iff its"
              },
              "than": {
                "type": "a boolean mask.",
                "description": "Returns\n-------"
              },
              "support": {
                "type": "array",
                "description": ""
              },
              "An": {
                "type": "index that selects the retained features from a feature vector.",
                "description": ""
              },
              "corresponding": {
                "type": "feature is selected for retention. If `indices` is",
                "description": "True, this is an integer array of shape [# output features] whose"
              },
              "values": {
                "type": "are indices into the input feature vector.",
                "description": ""
              }
            },
            "returns": "-------\n        support : array\n            An index that selects the retained features from a feature vector.\n            If `indices` is False, this is a boolean array of shape\n            [# input features], in which an element is True iff its\n            corresponding feature is selected for retention. If `indices` is\n            True, this is an integer array of shape [# output features] whose\n            values are indices into the input feature vector.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_transform",
          "signature": "inverse_transform(self, X)",
          "documentation": {
            "description": "Reverse the transformation operation.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_selected_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "X_r": {
                "type": "array of shape [n_samples, n_original_features]",
                "description": "`X` with columns of zeros inserted where features would have"
              },
              "been": {
                "type": "removed by :meth:`transform`.",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_original_features]\n            `X` with columns of zeros inserted where features would have\n            been removed by :meth:`transform`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "partial_fit",
          "signature": "partial_fit(self, X, y=None, **partial_fit_params)",
          "documentation": {
            "description": "Fit the SelectFromModel meta-transformer only once.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The training input samples.\n\n        y : array-like of shape (n_samples,), default=None\n            The target values (integers that correspond to classes in\n            classification, real numbers in regression).\n\n        **partial_fit_params : dict\n            - If `enable_metadata_routing=False` (default): Parameters directly passed\n              to the `partial_fit` method of the sub-estimator.\n\n            - If `enable_metadata_routing=True`: Parameters passed to the `partial_fit`\n              method of the sub-estimator. They are ignored if `prefit=True`.\n\n            .. versionchanged:: 1.4\n\n                `**partial_fit_params` are routed to the sub-estimator, if\n                `enable_metadata_routing=True` is set via\n                :func:`~sklearn.set_config`, which allows for aliasing.\n\n                See :ref:`Metadata Routing User Guide <metadata_routing>` for\n                more details.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "target values (integers that correspond to classes in",
                "description": "classification, real numbers in regression).\n**partial_fit_params : dict\n- If `enable_metadata_routing=False` (default): Parameters directly passed"
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "to": {
                "type": "the `partial_fit` method of the sub-estimator.",
                "description": "- If `enable_metadata_routing=True`: Parameters passed to the `partial_fit`"
              },
              "method": {
                "type": "of the sub-estimator. They are ignored if `prefit=True`.",
                "description": ".. versionchanged:: 1.4\n`**partial_fit_params` are routed to the sub-estimator, if\n`enable_metadata_routing=True` is set via\n:func:`~sklearn.set_config`, which allows for aliasing."
              },
              "See": {
                "type": "ref:`Metadata Routing User Guide <metadata_routing>` for",
                "description": ""
              },
              "more": {
                "type": "details.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Fitted": {
                "type": "estimator.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object\n            Fitted estimator.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "transform",
          "signature": "transform(self, X)",
          "documentation": {
            "description": "Reduce X to the selected features.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_features]",
                "description": ""
              },
              "The": {
                "type": "input samples with only the selected features.",
                "description": ""
              },
              "X_r": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_selected_features]\n            The input samples with only the selected features.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "SelectFwe",
      "documentation": {
        "description": "Filter: Select the p-values corresponding to Family-wise error rate.\n\n    Read more in the :ref:`User Guide <univariate_feature_selection>`.\n\n    Parameters\n    ----------\n    score_func : callable, default=f_classif\n        Function taking two arrays X and y, and returning a pair of arrays\n        (scores, pvalues).\n        Default is f_classif (see below \"See Also\"). The default function only\n        works with classification tasks.\n\n    alpha : float, default=5e-2\n        The highest uncorrected p-value for features to keep.\n\n    Attributes\n    ----------\n    scores_ : array-like of shape (n_features,)\n        Scores of features.\n\n    pvalues_ : array-like of shape (n_features,)\n        p-values of feature scores.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    f_classif : ANOVA F-value between label/feature for classification tasks.\n    chi2 : Chi-squared stats of non-negative features for classification tasks.\n    f_regression : F-value between label/feature for regression tasks.\n    SelectPercentile : Select features based on percentile of the highest\n        scores.\n    SelectKBest : Select features based on the k highest scores.\n    SelectFpr : Select features based on a false positive rate test.\n    SelectFdr : Select features based on an estimated false discovery rate.\n    GenericUnivariateSelect : Univariate feature selector with configurable\n        mode.",
        "parameters": {
          "score_func": {
            "type": "callable, default=f_classif",
            "description": ""
          },
          "Function": {
            "type": "taking two arrays X and y, and returning a pair of arrays",
            "description": "(scores, pvalues)."
          },
          "Default": {
            "type": "is f_classif (see below \"See Also\"). The default function only",
            "description": ""
          },
          "works": {
            "type": "with classification tasks.",
            "description": ""
          },
          "alpha": {
            "type": "float, default=5e",
            "description": "2"
          },
          "The": {
            "type": "highest uncorrected p-value for features to keep.",
            "description": "Attributes\n----------"
          },
          "scores_": {
            "type": "array",
            "description": "like of shape (n_features,)"
          },
          "Scores": {
            "type": "of features.",
            "description": ""
          },
          "pvalues_": {
            "type": "array",
            "description": "like of shape (n_features,)\np-values of feature scores."
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "Number": {
            "type": "of features seen during :term:`fit`.",
            "description": ".. versionadded:: 0.24"
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "f_classif": {
            "type": "ANOVA F",
            "description": "value between label/feature for classification tasks."
          },
          "chi2": {
            "type": "Chi",
            "description": "squared stats of non-negative features for classification tasks."
          },
          "f_regression": {
            "type": "F",
            "description": "value between label/feature for regression tasks."
          },
          "SelectPercentile": {
            "type": "Select features based on percentile of the highest",
            "description": "scores."
          },
          "SelectKBest": {
            "type": "Select features based on the k highest scores.",
            "description": ""
          },
          "SelectFpr": {
            "type": "Select features based on a false positive rate test.",
            "description": ""
          },
          "SelectFdr": {
            "type": "Select features based on an estimated false discovery rate.",
            "description": ""
          },
          "GenericUnivariateSelect": {
            "type": "Univariate feature selector with configurable",
            "description": "mode.\nExamples\n--------\n>>> from sklearn.datasets import load_breast_cancer\n>>> from sklearn.feature_selection import SelectFwe, chi2\n>>> X, y = load_breast_cancer(return_X_y=True)\n>>> X.shape\n(569, 30)\n>>> X_new = SelectFwe(chi2, alpha=0.01).fit_transform(X, y)\n>>> X_new.shape\n(569, 15)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    f_classif : ANOVA F-value between label/feature for classification tasks.\n    chi2 : Chi-squared stats of non-negative features for classification tasks.\n    f_regression : F-value between label/feature for regression tasks.\n    SelectPercentile : Select features based on percentile of the highest\n        scores.\n    SelectKBest : Select features based on the k highest scores.\n    SelectFpr : Select features based on a false positive rate test.\n    SelectFdr : Select features based on an estimated false discovery rate.\n    GenericUnivariateSelect : Univariate feature selector with configurable\n        mode.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.feature_selection import SelectFwe, chi2\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> X.shape\n    (569, 30)\n    >>> X_new = SelectFwe(chi2, alpha=0.01).fit_transform(X, y)\n    >>> X_new.shape\n    (569, 15)",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.datasets import load_breast_cancer\n    >>> from sklearn.feature_selection import SelectFwe, chi2\n    >>> X, y = load_breast_cancer(return_X_y=True)\n    >>> X.shape\n    (569, 30)\n    >>> X_new = SelectFwe(chi2, alpha=0.01).fit_transform(X, y)\n    >>> X_new.shape\n    (569, 15)"
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, X, y=None)",
          "documentation": {
            "description": "Run score function on (X, y) and get the appropriate features.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The training input samples.\n\n        y : array-like of shape (n_samples,) or None\n            The target values (class labels in classification, real numbers in\n            regression). If the selector is unsupervised then `y` can be set to `None`.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "target values (class labels in classification, real numbers in",
                "description": "regression). If the selector is unsupervised then `y` can be set to `None`.\nReturns\n-------"
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or None"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit to data, then transform it.\n\n        Fits transformer to `X` and `y` with optional parameters `fit_params`\n        and returns a transformed version of `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input samples.\n\n        y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n            Target values (None for unsupervised transformations).\n\n        **fit_params : dict\n            Additional fit parameters.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
              },
              "Target": {
                "type": "values (None for unsupervised transformations).",
                "description": "**fit_params : dict"
              },
              "Additional": {
                "type": "fit parameters.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray array of shape (n_samples, n_features_new)",
                "description": ""
              },
              "Transformed": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray array of shape (n_samples, n_features_new)\n            Transformed array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Mask feature names according to selected features.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Input features.\n\n            - If `input_features` is `None`, then `feature_names_in_` is\n              used as feature names in. If `feature_names_in_` is not defined,\n              then the following input feature names are generated:\n              `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n            - If `input_features` is an array-like, then `input_features` must\n              match `feature_names_in_` if `feature_names_in_` is defined.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Input": {
                "type": "features.",
                "description": "- If `input_features` is `None`, then `feature_names_in_` is"
              },
              "used": {
                "type": "as feature names in. If `feature_names_in_` is not defined,",
                "description": ""
              },
              "then": {
                "type": "the following input feature names are generated:",
                "description": "`[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n- If `input_features` is an array-like, then `input_features` must"
              },
              "match": {
                "type": "`feature_names_in_` if `feature_names_in_` is defined.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Transformed": {
                "type": "feature names.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_support",
          "signature": "get_support(self, indices=False)",
          "documentation": {
            "description": "Get a mask, or integer index, of the features selected.\n\n        Parameters\n        ----------\n        indices : bool, default=False\n            If True, the return value will be an array of integers, rather\n            than a boolean mask.",
            "parameters": {
              "indices": {
                "type": "bool, default=False",
                "description": ""
              },
              "If": {
                "type": "`indices` is False, this is a boolean array of shape",
                "description": "[# input features], in which an element is True iff its"
              },
              "than": {
                "type": "a boolean mask.",
                "description": "Returns\n-------"
              },
              "support": {
                "type": "array",
                "description": ""
              },
              "An": {
                "type": "index that selects the retained features from a feature vector.",
                "description": ""
              },
              "corresponding": {
                "type": "feature is selected for retention. If `indices` is",
                "description": "True, this is an integer array of shape [# output features] whose"
              },
              "values": {
                "type": "are indices into the input feature vector.",
                "description": ""
              }
            },
            "returns": "-------\n        support : array\n            An index that selects the retained features from a feature vector.\n            If `indices` is False, this is a boolean array of shape\n            [# input features], in which an element is True iff its\n            corresponding feature is selected for retention. If `indices` is\n            True, this is an integer array of shape [# output features] whose\n            values are indices into the input feature vector.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_transform",
          "signature": "inverse_transform(self, X)",
          "documentation": {
            "description": "Reverse the transformation operation.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_selected_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "X_r": {
                "type": "array of shape [n_samples, n_original_features]",
                "description": "`X` with columns of zeros inserted where features would have"
              },
              "been": {
                "type": "removed by :meth:`transform`.",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_original_features]\n            `X` with columns of zeros inserted where features would have\n            been removed by :meth:`transform`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "transform",
          "signature": "transform(self, X)",
          "documentation": {
            "description": "Reduce X to the selected features.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_features]",
                "description": ""
              },
              "The": {
                "type": "input samples with only the selected features.",
                "description": ""
              },
              "X_r": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_selected_features]\n            The input samples with only the selected features.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "SelectKBest",
      "documentation": {
        "description": "Select features according to the k highest scores.\n\n    Read more in the :ref:`User Guide <univariate_feature_selection>`.\n\n    Parameters\n    ----------\n    score_func : callable, default=f_classif\n        Function taking two arrays X and y, and returning a pair of arrays\n        (scores, pvalues) or a single array with scores.\n        Default is f_classif (see below \"See Also\"). The default function only\n        works with classification tasks.\n\n        .. versionadded:: 0.18\n\n    k : int or \"all\", default=10\n        Number of top features to select.\n        The \"all\" option bypasses selection, for use in a parameter search.\n\n    Attributes\n    ----------\n    scores_ : array-like of shape (n_features,)\n        Scores of features.\n\n    pvalues_ : array-like of shape (n_features,)\n        p-values of feature scores, None if `score_func` returned only scores.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    f_classif: ANOVA F-value between label/feature for classification tasks.\n    mutual_info_classif: Mutual information for a discrete target.\n    chi2: Chi-squared stats of non-negative features for classification tasks.\n    f_regression: F-value between label/feature for regression tasks.\n    mutual_info_regression: Mutual information for a continuous target.\n    SelectPercentile: Select features based on percentile of the highest\n        scores.\n    SelectFpr : Select features based on a false positive rate test.\n    SelectFdr : Select features based on an estimated false discovery rate.\n    SelectFwe : Select features based on family-wise error rate.\n    GenericUnivariateSelect : Univariate feature selector with configurable\n        mode.\n\n    Notes\n    -----\n    Ties between features with equal scores will be broken in an unspecified\n    way.\n\n    This filter supports unsupervised feature selection that only requests `X` for\n    computing the scores.",
        "parameters": {
          "score_func": {
            "type": "callable, default=f_classif",
            "description": ""
          },
          "Function": {
            "type": "taking two arrays X and y, and returning a pair of arrays",
            "description": "(scores, pvalues) or a single array with scores."
          },
          "Default": {
            "type": "is f_classif (see below \"See Also\"). The default function only",
            "description": ""
          },
          "works": {
            "type": "with classification tasks.",
            "description": ".. versionadded:: 0.18"
          },
          "k": {
            "type": "int or \"all\", default=10",
            "description": ""
          },
          "Number": {
            "type": "of features seen during :term:`fit`.",
            "description": ".. versionadded:: 0.24"
          },
          "The": {
            "type": "\"all\" option bypasses selection, for use in a parameter search.",
            "description": "Attributes\n----------"
          },
          "scores_": {
            "type": "array",
            "description": "like of shape (n_features,)"
          },
          "Scores": {
            "type": "of features.",
            "description": ""
          },
          "pvalues_": {
            "type": "array",
            "description": "like of shape (n_features,)\np-values of feature scores, None if `score_func` returned only scores."
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "f_classif": {
            "type": "ANOVA F",
            "description": "value between label/feature for classification tasks."
          },
          "mutual_info_classif": {
            "type": "Mutual information for a discrete target.",
            "description": ""
          },
          "chi2": {
            "type": "Chi",
            "description": "squared stats of non-negative features for classification tasks."
          },
          "f_regression": {
            "type": "F",
            "description": "value between label/feature for regression tasks."
          },
          "mutual_info_regression": {
            "type": "Mutual information for a continuous target.",
            "description": ""
          },
          "SelectPercentile": {
            "type": "Select features based on percentile of the highest",
            "description": "scores."
          },
          "SelectFpr": {
            "type": "Select features based on a false positive rate test.",
            "description": ""
          },
          "SelectFdr": {
            "type": "Select features based on an estimated false discovery rate.",
            "description": ""
          },
          "SelectFwe": {
            "type": "Select features based on family",
            "description": "wise error rate."
          },
          "GenericUnivariateSelect": {
            "type": "Univariate feature selector with configurable",
            "description": "mode.\nNotes\n-----"
          },
          "Ties": {
            "type": "between features with equal scores will be broken in an unspecified",
            "description": "way."
          },
          "This": {
            "type": "filter supports unsupervised feature selection that only requests `X` for",
            "description": ""
          },
          "computing": {
            "type": "the scores.",
            "description": "Examples\n--------\n>>> from sklearn.datasets import load_digits\n>>> from sklearn.feature_selection import SelectKBest, chi2\n>>> X, y = load_digits(return_X_y=True)\n>>> X.shape\n(1797, 64)\n>>> X_new = SelectKBest(chi2, k=20).fit_transform(X, y)\n>>> X_new.shape\n(1797, 20)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    f_classif: ANOVA F-value between label/feature for classification tasks.\n    mutual_info_classif: Mutual information for a discrete target.\n    chi2: Chi-squared stats of non-negative features for classification tasks.\n    f_regression: F-value between label/feature for regression tasks.\n    mutual_info_regression: Mutual information for a continuous target.\n    SelectPercentile: Select features based on percentile of the highest\n        scores.\n    SelectFpr : Select features based on a false positive rate test.\n    SelectFdr : Select features based on an estimated false discovery rate.\n    SelectFwe : Select features based on family-wise error rate.\n    GenericUnivariateSelect : Univariate feature selector with configurable\n        mode.\n\n    Notes\n    -----\n    Ties between features with equal scores will be broken in an unspecified\n    way.\n\n    This filter supports unsupervised feature selection that only requests `X` for\n    computing the scores.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_digits\n    >>> from sklearn.feature_selection import SelectKBest, chi2\n    >>> X, y = load_digits(return_X_y=True)\n    >>> X.shape\n    (1797, 64)\n    >>> X_new = SelectKBest(chi2, k=20).fit_transform(X, y)\n    >>> X_new.shape\n    (1797, 20)",
        "notes": "-----\n    Ties between features with equal scores will be broken in an unspecified\n    way.\n\n    This filter supports unsupervised feature selection that only requests `X` for\n    computing the scores.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_digits\n    >>> from sklearn.feature_selection import SelectKBest, chi2\n    >>> X, y = load_digits(return_X_y=True)\n    >>> X.shape\n    (1797, 64)\n    >>> X_new = SelectKBest(chi2, k=20).fit_transform(X, y)\n    >>> X_new.shape\n    (1797, 20)",
        "examples": "--------\n    >>> from sklearn.datasets import load_digits\n    >>> from sklearn.feature_selection import SelectKBest, chi2\n    >>> X, y = load_digits(return_X_y=True)\n    >>> X.shape\n    (1797, 64)\n    >>> X_new = SelectKBest(chi2, k=20).fit_transform(X, y)\n    >>> X_new.shape\n    (1797, 20)"
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, X, y=None)",
          "documentation": {
            "description": "Run score function on (X, y) and get the appropriate features.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The training input samples.\n\n        y : array-like of shape (n_samples,) or None\n            The target values (class labels in classification, real numbers in\n            regression). If the selector is unsupervised then `y` can be set to `None`.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "target values (class labels in classification, real numbers in",
                "description": "regression). If the selector is unsupervised then `y` can be set to `None`.\nReturns\n-------"
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or None"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit to data, then transform it.\n\n        Fits transformer to `X` and `y` with optional parameters `fit_params`\n        and returns a transformed version of `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input samples.\n\n        y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n            Target values (None for unsupervised transformations).\n\n        **fit_params : dict\n            Additional fit parameters.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
              },
              "Target": {
                "type": "values (None for unsupervised transformations).",
                "description": "**fit_params : dict"
              },
              "Additional": {
                "type": "fit parameters.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray array of shape (n_samples, n_features_new)",
                "description": ""
              },
              "Transformed": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray array of shape (n_samples, n_features_new)\n            Transformed array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Mask feature names according to selected features.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Input features.\n\n            - If `input_features` is `None`, then `feature_names_in_` is\n              used as feature names in. If `feature_names_in_` is not defined,\n              then the following input feature names are generated:\n              `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n            - If `input_features` is an array-like, then `input_features` must\n              match `feature_names_in_` if `feature_names_in_` is defined.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Input": {
                "type": "features.",
                "description": "- If `input_features` is `None`, then `feature_names_in_` is"
              },
              "used": {
                "type": "as feature names in. If `feature_names_in_` is not defined,",
                "description": ""
              },
              "then": {
                "type": "the following input feature names are generated:",
                "description": "`[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n- If `input_features` is an array-like, then `input_features` must"
              },
              "match": {
                "type": "`feature_names_in_` if `feature_names_in_` is defined.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Transformed": {
                "type": "feature names.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_support",
          "signature": "get_support(self, indices=False)",
          "documentation": {
            "description": "Get a mask, or integer index, of the features selected.\n\n        Parameters\n        ----------\n        indices : bool, default=False\n            If True, the return value will be an array of integers, rather\n            than a boolean mask.",
            "parameters": {
              "indices": {
                "type": "bool, default=False",
                "description": ""
              },
              "If": {
                "type": "`indices` is False, this is a boolean array of shape",
                "description": "[# input features], in which an element is True iff its"
              },
              "than": {
                "type": "a boolean mask.",
                "description": "Returns\n-------"
              },
              "support": {
                "type": "array",
                "description": ""
              },
              "An": {
                "type": "index that selects the retained features from a feature vector.",
                "description": ""
              },
              "corresponding": {
                "type": "feature is selected for retention. If `indices` is",
                "description": "True, this is an integer array of shape [# output features] whose"
              },
              "values": {
                "type": "are indices into the input feature vector.",
                "description": ""
              }
            },
            "returns": "-------\n        support : array\n            An index that selects the retained features from a feature vector.\n            If `indices` is False, this is a boolean array of shape\n            [# input features], in which an element is True iff its\n            corresponding feature is selected for retention. If `indices` is\n            True, this is an integer array of shape [# output features] whose\n            values are indices into the input feature vector.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_transform",
          "signature": "inverse_transform(self, X)",
          "documentation": {
            "description": "Reverse the transformation operation.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_selected_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "X_r": {
                "type": "array of shape [n_samples, n_original_features]",
                "description": "`X` with columns of zeros inserted where features would have"
              },
              "been": {
                "type": "removed by :meth:`transform`.",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_original_features]\n            `X` with columns of zeros inserted where features would have\n            been removed by :meth:`transform`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "transform",
          "signature": "transform(self, X)",
          "documentation": {
            "description": "Reduce X to the selected features.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_features]",
                "description": ""
              },
              "The": {
                "type": "input samples with only the selected features.",
                "description": ""
              },
              "X_r": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_selected_features]\n            The input samples with only the selected features.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "SelectPercentile",
      "documentation": {
        "description": "Select features according to a percentile of the highest scores.\n\n    Read more in the :ref:`User Guide <univariate_feature_selection>`.\n\n    Parameters\n    ----------\n    score_func : callable, default=f_classif\n        Function taking two arrays X and y, and returning a pair of arrays\n        (scores, pvalues) or a single array with scores.\n        Default is f_classif (see below \"See Also\"). The default function only\n        works with classification tasks.\n\n        .. versionadded:: 0.18\n\n    percentile : int, default=10\n        Percent of features to keep.\n\n    Attributes\n    ----------\n    scores_ : array-like of shape (n_features,)\n        Scores of features.\n\n    pvalues_ : array-like of shape (n_features,)\n        p-values of feature scores, None if `score_func` returned only scores.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    f_classif : ANOVA F-value between label/feature for classification tasks.\n    mutual_info_classif : Mutual information for a discrete target.\n    chi2 : Chi-squared stats of non-negative features for classification tasks.\n    f_regression : F-value between label/feature for regression tasks.\n    mutual_info_regression : Mutual information for a continuous target.\n    SelectKBest : Select features based on the k highest scores.\n    SelectFpr : Select features based on a false positive rate test.\n    SelectFdr : Select features based on an estimated false discovery rate.\n    SelectFwe : Select features based on family-wise error rate.\n    GenericUnivariateSelect : Univariate feature selector with configurable\n        mode.\n\n    Notes\n    -----\n    Ties between features with equal scores will be broken in an unspecified\n    way.\n\n    This filter supports unsupervised feature selection that only requests `X` for\n    computing the scores.",
        "parameters": {
          "score_func": {
            "type": "callable, default=f_classif",
            "description": ""
          },
          "Function": {
            "type": "taking two arrays X and y, and returning a pair of arrays",
            "description": "(scores, pvalues) or a single array with scores."
          },
          "Default": {
            "type": "is f_classif (see below \"See Also\"). The default function only",
            "description": ""
          },
          "works": {
            "type": "with classification tasks.",
            "description": ".. versionadded:: 0.18"
          },
          "percentile": {
            "type": "int, default=10",
            "description": ""
          },
          "Percent": {
            "type": "of features to keep.",
            "description": "Attributes\n----------"
          },
          "scores_": {
            "type": "array",
            "description": "like of shape (n_features,)"
          },
          "Scores": {
            "type": "of features.",
            "description": ""
          },
          "pvalues_": {
            "type": "array",
            "description": "like of shape (n_features,)\np-values of feature scores, None if `score_func` returned only scores."
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "Number": {
            "type": "of features seen during :term:`fit`.",
            "description": ".. versionadded:: 0.24"
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "f_classif": {
            "type": "ANOVA F",
            "description": "value between label/feature for classification tasks."
          },
          "mutual_info_classif": {
            "type": "Mutual information for a discrete target.",
            "description": ""
          },
          "chi2": {
            "type": "Chi",
            "description": "squared stats of non-negative features for classification tasks."
          },
          "f_regression": {
            "type": "F",
            "description": "value between label/feature for regression tasks."
          },
          "mutual_info_regression": {
            "type": "Mutual information for a continuous target.",
            "description": ""
          },
          "SelectKBest": {
            "type": "Select features based on the k highest scores.",
            "description": ""
          },
          "SelectFpr": {
            "type": "Select features based on a false positive rate test.",
            "description": ""
          },
          "SelectFdr": {
            "type": "Select features based on an estimated false discovery rate.",
            "description": ""
          },
          "SelectFwe": {
            "type": "Select features based on family",
            "description": "wise error rate."
          },
          "GenericUnivariateSelect": {
            "type": "Univariate feature selector with configurable",
            "description": "mode.\nNotes\n-----"
          },
          "Ties": {
            "type": "between features with equal scores will be broken in an unspecified",
            "description": "way."
          },
          "This": {
            "type": "filter supports unsupervised feature selection that only requests `X` for",
            "description": ""
          },
          "computing": {
            "type": "the scores.",
            "description": "Examples\n--------\n>>> from sklearn.datasets import load_digits\n>>> from sklearn.feature_selection import SelectPercentile, chi2\n>>> X, y = load_digits(return_X_y=True)\n>>> X.shape\n(1797, 64)\n>>> X_new = SelectPercentile(chi2, percentile=10).fit_transform(X, y)\n>>> X_new.shape\n(1797, 7)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    f_classif : ANOVA F-value between label/feature for classification tasks.\n    mutual_info_classif : Mutual information for a discrete target.\n    chi2 : Chi-squared stats of non-negative features for classification tasks.\n    f_regression : F-value between label/feature for regression tasks.\n    mutual_info_regression : Mutual information for a continuous target.\n    SelectKBest : Select features based on the k highest scores.\n    SelectFpr : Select features based on a false positive rate test.\n    SelectFdr : Select features based on an estimated false discovery rate.\n    SelectFwe : Select features based on family-wise error rate.\n    GenericUnivariateSelect : Univariate feature selector with configurable\n        mode.\n\n    Notes\n    -----\n    Ties between features with equal scores will be broken in an unspecified\n    way.\n\n    This filter supports unsupervised feature selection that only requests `X` for\n    computing the scores.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_digits\n    >>> from sklearn.feature_selection import SelectPercentile, chi2\n    >>> X, y = load_digits(return_X_y=True)\n    >>> X.shape\n    (1797, 64)\n    >>> X_new = SelectPercentile(chi2, percentile=10).fit_transform(X, y)\n    >>> X_new.shape\n    (1797, 7)",
        "notes": "-----\n    Ties between features with equal scores will be broken in an unspecified\n    way.\n\n    This filter supports unsupervised feature selection that only requests `X` for\n    computing the scores.\n\n    Examples\n    --------\n    >>> from sklearn.datasets import load_digits\n    >>> from sklearn.feature_selection import SelectPercentile, chi2\n    >>> X, y = load_digits(return_X_y=True)\n    >>> X.shape\n    (1797, 64)\n    >>> X_new = SelectPercentile(chi2, percentile=10).fit_transform(X, y)\n    >>> X_new.shape\n    (1797, 7)",
        "examples": "--------\n    >>> from sklearn.datasets import load_digits\n    >>> from sklearn.feature_selection import SelectPercentile, chi2\n    >>> X, y = load_digits(return_X_y=True)\n    >>> X.shape\n    (1797, 64)\n    >>> X_new = SelectPercentile(chi2, percentile=10).fit_transform(X, y)\n    >>> X_new.shape\n    (1797, 7)"
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, X, y=None)",
          "documentation": {
            "description": "Run score function on (X, y) and get the appropriate features.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The training input samples.\n\n        y : array-like of shape (n_samples,) or None\n            The target values (class labels in classification, real numbers in\n            regression). If the selector is unsupervised then `y` can be set to `None`.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "target values (class labels in classification, real numbers in",
                "description": "regression). If the selector is unsupervised then `y` can be set to `None`.\nReturns\n-------"
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or None"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit to data, then transform it.\n\n        Fits transformer to `X` and `y` with optional parameters `fit_params`\n        and returns a transformed version of `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input samples.\n\n        y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n            Target values (None for unsupervised transformations).\n\n        **fit_params : dict\n            Additional fit parameters.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
              },
              "Target": {
                "type": "values (None for unsupervised transformations).",
                "description": "**fit_params : dict"
              },
              "Additional": {
                "type": "fit parameters.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray array of shape (n_samples, n_features_new)",
                "description": ""
              },
              "Transformed": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray array of shape (n_samples, n_features_new)\n            Transformed array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Mask feature names according to selected features.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Input features.\n\n            - If `input_features` is `None`, then `feature_names_in_` is\n              used as feature names in. If `feature_names_in_` is not defined,\n              then the following input feature names are generated:\n              `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n            - If `input_features` is an array-like, then `input_features` must\n              match `feature_names_in_` if `feature_names_in_` is defined.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Input": {
                "type": "features.",
                "description": "- If `input_features` is `None`, then `feature_names_in_` is"
              },
              "used": {
                "type": "as feature names in. If `feature_names_in_` is not defined,",
                "description": ""
              },
              "then": {
                "type": "the following input feature names are generated:",
                "description": "`[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n- If `input_features` is an array-like, then `input_features` must"
              },
              "match": {
                "type": "`feature_names_in_` if `feature_names_in_` is defined.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Transformed": {
                "type": "feature names.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_support",
          "signature": "get_support(self, indices=False)",
          "documentation": {
            "description": "Get a mask, or integer index, of the features selected.\n\n        Parameters\n        ----------\n        indices : bool, default=False\n            If True, the return value will be an array of integers, rather\n            than a boolean mask.",
            "parameters": {
              "indices": {
                "type": "bool, default=False",
                "description": ""
              },
              "If": {
                "type": "`indices` is False, this is a boolean array of shape",
                "description": "[# input features], in which an element is True iff its"
              },
              "than": {
                "type": "a boolean mask.",
                "description": "Returns\n-------"
              },
              "support": {
                "type": "array",
                "description": ""
              },
              "An": {
                "type": "index that selects the retained features from a feature vector.",
                "description": ""
              },
              "corresponding": {
                "type": "feature is selected for retention. If `indices` is",
                "description": "True, this is an integer array of shape [# output features] whose"
              },
              "values": {
                "type": "are indices into the input feature vector.",
                "description": ""
              }
            },
            "returns": "-------\n        support : array\n            An index that selects the retained features from a feature vector.\n            If `indices` is False, this is a boolean array of shape\n            [# input features], in which an element is True iff its\n            corresponding feature is selected for retention. If `indices` is\n            True, this is an integer array of shape [# output features] whose\n            values are indices into the input feature vector.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_transform",
          "signature": "inverse_transform(self, X)",
          "documentation": {
            "description": "Reverse the transformation operation.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_selected_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "X_r": {
                "type": "array of shape [n_samples, n_original_features]",
                "description": "`X` with columns of zeros inserted where features would have"
              },
              "been": {
                "type": "removed by :meth:`transform`.",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_original_features]\n            `X` with columns of zeros inserted where features would have\n            been removed by :meth:`transform`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "transform",
          "signature": "transform(self, X)",
          "documentation": {
            "description": "Reduce X to the selected features.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_features]",
                "description": ""
              },
              "The": {
                "type": "input samples with only the selected features.",
                "description": ""
              },
              "X_r": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_selected_features]\n            The input samples with only the selected features.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "SelectorMixin",
      "documentation": {
        "description": "Transformer mixin that performs feature selection given a support mask\n\n    This mixin provides a feature selector implementation with `transform` and\n    `inverse_transform` functionality given an implementation of\n    `_get_support_mask`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.datasets import load_iris\n    >>> from sklearn.base import BaseEstimator\n    >>> from sklearn.feature_selection import SelectorMixin\n    >>> class FeatureSelector(SelectorMixin, BaseEstimator):\n    ...    def fit(self, X, y=None):\n    ...        self.n_features_in_ = X.shape[1]\n    ...        return self\n    ...    def _get_support_mask(self):\n    ...        mask = np.zeros(self.n_features_in_, dtype=bool)\n    ...        mask[:2] = True  # select the first two features\n    ...        return mask\n    >>> X, y = load_iris(return_X_y=True)\n    >>> FeatureSelector().fit_transform(X, y).shape\n    (150, 2)"
      },
      "methods": [
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit to data, then transform it.\n\n        Fits transformer to `X` and `y` with optional parameters `fit_params`\n        and returns a transformed version of `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input samples.\n\n        y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n            Target values (None for unsupervised transformations).\n\n        **fit_params : dict\n            Additional fit parameters.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
              },
              "Target": {
                "type": "values (None for unsupervised transformations).",
                "description": "**fit_params : dict"
              },
              "Additional": {
                "type": "fit parameters.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray array of shape (n_samples, n_features_new)",
                "description": ""
              },
              "Transformed": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray array of shape (n_samples, n_features_new)\n            Transformed array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Mask feature names according to selected features.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Input features.\n\n            - If `input_features` is `None`, then `feature_names_in_` is\n              used as feature names in. If `feature_names_in_` is not defined,\n              then the following input feature names are generated:\n              `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n            - If `input_features` is an array-like, then `input_features` must\n              match `feature_names_in_` if `feature_names_in_` is defined.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Input": {
                "type": "features.",
                "description": "- If `input_features` is `None`, then `feature_names_in_` is"
              },
              "used": {
                "type": "as feature names in. If `feature_names_in_` is not defined,",
                "description": ""
              },
              "then": {
                "type": "the following input feature names are generated:",
                "description": "`[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n- If `input_features` is an array-like, then `input_features` must"
              },
              "match": {
                "type": "`feature_names_in_` if `feature_names_in_` is defined.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Transformed": {
                "type": "feature names.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_support",
          "signature": "get_support(self, indices=False)",
          "documentation": {
            "description": "Get a mask, or integer index, of the features selected.\n\n        Parameters\n        ----------\n        indices : bool, default=False\n            If True, the return value will be an array of integers, rather\n            than a boolean mask.",
            "parameters": {
              "indices": {
                "type": "bool, default=False",
                "description": ""
              },
              "If": {
                "type": "`indices` is False, this is a boolean array of shape",
                "description": "[# input features], in which an element is True iff its"
              },
              "than": {
                "type": "a boolean mask.",
                "description": "Returns\n-------"
              },
              "support": {
                "type": "array",
                "description": ""
              },
              "An": {
                "type": "index that selects the retained features from a feature vector.",
                "description": ""
              },
              "corresponding": {
                "type": "feature is selected for retention. If `indices` is",
                "description": "True, this is an integer array of shape [# output features] whose"
              },
              "values": {
                "type": "are indices into the input feature vector.",
                "description": ""
              }
            },
            "returns": "-------\n        support : array\n            An index that selects the retained features from a feature vector.\n            If `indices` is False, this is a boolean array of shape\n            [# input features], in which an element is True iff its\n            corresponding feature is selected for retention. If `indices` is\n            True, this is an integer array of shape [# output features] whose\n            values are indices into the input feature vector.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_transform",
          "signature": "inverse_transform(self, X)",
          "documentation": {
            "description": "Reverse the transformation operation.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_selected_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "X_r": {
                "type": "array of shape [n_samples, n_original_features]",
                "description": "`X` with columns of zeros inserted where features would have"
              },
              "been": {
                "type": "removed by :meth:`transform`.",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_original_features]\n            `X` with columns of zeros inserted where features would have\n            been removed by :meth:`transform`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "transform",
          "signature": "transform(self, X)",
          "documentation": {
            "description": "Reduce X to the selected features.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_features]",
                "description": ""
              },
              "The": {
                "type": "input samples with only the selected features.",
                "description": ""
              },
              "X_r": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_selected_features]\n            The input samples with only the selected features.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "SequentialFeatureSelector",
      "documentation": {
        "description": "Transformer that performs Sequential Feature Selection.\n\n    This Sequential Feature Selector adds (forward selection) or\n    removes (backward selection) features to form a feature subset in a\n    greedy fashion. At each stage, this estimator chooses the best feature to\n    add or remove based on the cross-validation score of an estimator. In\n    the case of unsupervised learning, this Sequential Feature Selector\n    looks only at the features (X), not the desired outputs (y).\n\n    Read more in the :ref:`User Guide <sequential_feature_selection>`.\n\n    .. versionadded:: 0.24\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        An unfitted estimator.\n\n    n_features_to_select : \"auto\", int or float, default=\"auto\"\n        If `\"auto\"`, the behaviour depends on the `tol` parameter:\n\n        - if `tol` is not `None`, then features are selected while the score\n          change does not exceed `tol`.\n        - otherwise, half of the features are selected.\n\n        If integer, the parameter is the absolute number of features to select.\n        If float between 0 and 1, it is the fraction of features to select.\n\n        .. versionadded:: 1.1\n           The option `\"auto\"` was added in version 1.1.\n\n        .. versionchanged:: 1.3\n           The default changed from `\"warn\"` to `\"auto\"` in 1.3.\n\n    tol : float, default=None\n        If the score is not incremented by at least `tol` between two\n        consecutive feature additions or removals, stop adding or removing.\n\n        `tol` can be negative when removing features using `direction=\"backward\"`.\n        `tol` is required to be strictly positive when doing forward selection.\n        It can be useful to reduce the number of features at the cost of a small\n        decrease in the score.\n\n        `tol` is enabled only when `n_features_to_select` is `\"auto\"`.\n\n        .. versionadded:: 1.1\n\n    direction : {'forward', 'backward'}, default='forward'\n        Whether to perform forward selection or backward selection.\n\n    scoring : str or callable, default=None\n        A single str (see :ref:`scoring_parameter`) or a callable\n        (see :ref:`scoring_callable`) to evaluate the predictions on the test set.\n\n        NOTE that when using a custom scorer, it should return a single\n        value.\n\n        If None, the estimator's score method is used.\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the default 5-fold cross validation,\n        - integer, to specify the number of folds in a `(Stratified)KFold`,\n        - :term:`CV splitter`,\n        - An iterable yielding (train, test) splits as arrays of indices.\n\n        For integer/None inputs, if the estimator is a classifier and ``y`` is\n        either binary or multiclass,\n        :class:`~sklearn.model_selection.StratifiedKFold` is used. In all other\n        cases, :class:`~sklearn.model_selection.KFold` is used. These splitters\n        are instantiated with `shuffle=False` so the splits will be the same\n        across calls.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n    n_jobs : int, default=None\n        Number of jobs to run in parallel. When evaluating a new feature to\n        add or remove, the cross-validation procedure is parallel over the\n        folds.\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n    Attributes\n    ----------\n    n_features_in_ : int\n        Number of features seen during :term:`fit`. Only defined if the\n        underlying estimator exposes such an attribute when fit.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    n_features_to_select_ : int\n        The number of features that were selected.\n\n    support_ : ndarray of shape (n_features,), dtype=bool\n        The mask of selected features.\n\n    See Also\n    --------\n    GenericUnivariateSelect : Univariate feature selector with configurable\n        strategy.\n    RFE : Recursive feature elimination based on importance weights.\n    RFECV : Recursive feature elimination based on importance weights, with\n        automatic selection of the number of features.\n    SelectFromModel : Feature selection based on thresholds of importance\n        weights.",
        "parameters": {
          "estimator": {
            "type": "estimator instance",
            "description": ""
          },
          "An": {
            "type": "unfitted estimator.",
            "description": ""
          },
          "n_features_to_select": {
            "type": "\"auto\", int or float, default=\"auto\"",
            "description": ""
          },
          "If": {
            "type": "None, the estimator's score method is used.",
            "description": ""
          },
          "change": {
            "type": "does not exceed `tol`.",
            "description": "- otherwise, half of the features are selected."
          },
          "The": {
            "type": "mask of selected features.",
            "description": ""
          },
          "tol": {
            "type": "float, default=None",
            "description": ""
          },
          "consecutive": {
            "type": "feature additions or removals, stop adding or removing.",
            "description": "`tol` can be negative when removing features using `direction=\"backward\"`.\n`tol` is required to be strictly positive when doing forward selection."
          },
          "It": {
            "type": "can be useful to reduce the number of features at the cost of a small",
            "description": ""
          },
          "decrease": {
            "type": "in the score.",
            "description": "`tol` is enabled only when `n_features_to_select` is `\"auto\"`.\n.. versionadded:: 1.1"
          },
          "direction": {
            "type": "{'forward', 'backward'}, default='forward'",
            "description": ""
          },
          "Whether": {
            "type": "to perform forward selection or backward selection.",
            "description": ""
          },
          "scoring": {
            "type": "str or callable, default=None",
            "description": ""
          },
          "A": {
            "type": "single str (see :ref:`scoring_parameter`) or a callable",
            "description": "(see :ref:`scoring_callable`) to evaluate the predictions on the test set."
          },
          "NOTE": {
            "type": "that when using a custom scorer, it should return a single",
            "description": "value."
          },
          "cv": {
            "type": "int, cross",
            "description": "validation generator or an iterable, default=None"
          },
          "Determines": {
            "type": "the cross-validation splitting strategy.",
            "description": ""
          },
          "Possible": {
            "type": "inputs for cv are:",
            "description": "- None, to use the default 5-fold cross validation,\n- integer, to specify the number of folds in a `(Stratified)KFold`,\n- :term:`CV splitter`,\n- An iterable yielding (train, test) splits as arrays of indices."
          },
          "For": {
            "type": "integer/None inputs, if the estimator is a classifier and ``y`` is",
            "description": ""
          },
          "either": {
            "type": "binary or multiclass,",
            "description": ":class:`~sklearn.model_selection.StratifiedKFold` is used. In all other\ncases, :class:`~sklearn.model_selection.KFold` is used. These splitters"
          },
          "are": {
            "type": "instantiated with `shuffle=False` so the splits will be the same",
            "description": ""
          },
          "across": {
            "type": "calls.",
            "description": ""
          },
          "Refer": {
            "type": "ref:`User Guide <cross_validation>` for the various",
            "description": "cross-validation strategies that can be used here."
          },
          "n_jobs": {
            "type": "int, default=None",
            "description": ""
          },
          "Number": {
            "type": "of features seen during :term:`fit`. Only defined if the",
            "description": ""
          },
          "add": {
            "type": "or remove, the cross-validation procedure is parallel over the",
            "description": "folds.\n``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n``-1`` means using all processors. See :term:`Glossary <n_jobs>`"
          },
          "for": {
            "type": "more details.",
            "description": "Attributes\n----------"
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "underlying": {
            "type": "estimator exposes such an attribute when fit.",
            "description": ".. versionadded:: 0.24"
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "n_features_to_select_": {
            "type": "int",
            "description": ""
          },
          "support_": {
            "type": "ndarray of shape (n_features,), dtype=bool",
            "description": ""
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "GenericUnivariateSelect": {
            "type": "Univariate feature selector with configurable",
            "description": "strategy."
          },
          "RFE": {
            "type": "Recursive feature elimination based on importance weights.",
            "description": ""
          },
          "RFECV": {
            "type": "Recursive feature elimination based on importance weights, with",
            "description": ""
          },
          "automatic": {
            "type": "selection of the number of features.",
            "description": ""
          },
          "SelectFromModel": {
            "type": "Feature selection based on thresholds of importance",
            "description": "weights.\nExamples\n--------\n>>> from sklearn.feature_selection import SequentialFeatureSelector\n>>> from sklearn.neighbors import KNeighborsClassifier\n>>> from sklearn.datasets import load_iris\n>>> X, y = load_iris(return_X_y=True)\n>>> knn = KNeighborsClassifier(n_neighbors=3)\n>>> sfs = SequentialFeatureSelector(knn, n_features_to_select=3)\n>>> sfs.fit(X, y)"
          },
          "SequentialFeatureSelector": {
            "type": "estimator=KNeighborsClassifier(n_neighbors=3",
            "description": ",\nn_features_to_select=3)\n>>> sfs.get_support()"
          },
          "array": {
            "type": "[ True, False,  True,  True]",
            "description": ">>> sfs.transform(X).shape\n(150, 3)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    GenericUnivariateSelect : Univariate feature selector with configurable\n        strategy.\n    RFE : Recursive feature elimination based on importance weights.\n    RFECV : Recursive feature elimination based on importance weights, with\n        automatic selection of the number of features.\n    SelectFromModel : Feature selection based on thresholds of importance\n        weights.\n\n    Examples\n    --------\n    >>> from sklearn.feature_selection import SequentialFeatureSelector\n    >>> from sklearn.neighbors import KNeighborsClassifier\n    >>> from sklearn.datasets import load_iris\n    >>> X, y = load_iris(return_X_y=True)\n    >>> knn = KNeighborsClassifier(n_neighbors=3)\n    >>> sfs = SequentialFeatureSelector(knn, n_features_to_select=3)\n    >>> sfs.fit(X, y)\n    SequentialFeatureSelector(estimator=KNeighborsClassifier(n_neighbors=3),\n                              n_features_to_select=3)\n    >>> sfs.get_support()\n    array([ True, False,  True,  True])\n    >>> sfs.transform(X).shape\n    (150, 3)",
        "notes": "that when using a custom scorer, it should return a single\n        value.\n\n        If None, the estimator's score method is used.\n\n    cv : int, cross-validation generator or an iterable, default=None\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the default 5-fold cross validation,\n        - integer, to specify the number of folds in a `(Stratified)KFold`,\n        - :term:`CV splitter`,\n        - An iterable yielding (train, test) splits as arrays of indices.\n\n        For integer/None inputs, if the estimator is a classifier and ``y`` is\n        either binary or multiclass,\n        :class:`~sklearn.model_selection.StratifiedKFold` is used. In all other\n        cases, :class:`~sklearn.model_selection.KFold` is used. These splitters\n        are instantiated with `shuffle=False` so the splits will be the same\n        across calls.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validation strategies that can be used here.\n\n    n_jobs : int, default=None\n        Number of jobs to run in parallel. When evaluating a new feature to\n        add or remove, the cross-validation procedure is parallel over the\n        folds.\n        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n        for more details.\n\n    Attributes\n    ----------\n    n_features_in_ : int\n        Number of features seen during :term:`fit`. Only defined if the\n        underlying estimator exposes such an attribute when fit.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    n_features_to_select_ : int\n        The number of features that were selected.\n\n    support_ : ndarray of shape (n_features,), dtype=bool\n        The mask of selected features.\n\n    See Also\n    --------\n    GenericUnivariateSelect : Univariate feature selector with configurable\n        strategy.\n    RFE : Recursive feature elimination based on importance weights.\n    RFECV : Recursive feature elimination based on importance weights, with\n        automatic selection of the number of features.\n    SelectFromModel : Feature selection based on thresholds of importance\n        weights.\n\n    Examples\n    --------\n    >>> from sklearn.feature_selection import SequentialFeatureSelector\n    >>> from sklearn.neighbors import KNeighborsClassifier\n    >>> from sklearn.datasets import load_iris\n    >>> X, y = load_iris(return_X_y=True)\n    >>> knn = KNeighborsClassifier(n_neighbors=3)\n    >>> sfs = SequentialFeatureSelector(knn, n_features_to_select=3)\n    >>> sfs.fit(X, y)\n    SequentialFeatureSelector(estimator=KNeighborsClassifier(n_neighbors=3),\n                              n_features_to_select=3)\n    >>> sfs.get_support()\n    array([ True, False,  True,  True])\n    >>> sfs.transform(X).shape\n    (150, 3)",
        "examples": "--------\n    >>> from sklearn.feature_selection import SequentialFeatureSelector\n    >>> from sklearn.neighbors import KNeighborsClassifier\n    >>> from sklearn.datasets import load_iris\n    >>> X, y = load_iris(return_X_y=True)\n    >>> knn = KNeighborsClassifier(n_neighbors=3)\n    >>> sfs = SequentialFeatureSelector(knn, n_features_to_select=3)\n    >>> sfs.fit(X, y)\n    SequentialFeatureSelector(estimator=KNeighborsClassifier(n_neighbors=3),\n                              n_features_to_select=3)\n    >>> sfs.get_support()\n    array([ True, False,  True,  True])\n    >>> sfs.transform(X).shape\n    (150, 3)"
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, X, y=None, **params)",
          "documentation": {
            "description": "Learn the features to select from X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training vectors, where `n_samples` is the number of samples and\n            `n_features` is the number of predictors.\n\n        y : array-like of shape (n_samples,), default=None\n            Target values. This parameter may be ignored for\n            unsupervised learning.\n\n        **params : dict, default=None\n            Parameters to be passed to the underlying `estimator`, `cv`\n            and `scorer` objects.\n\n            .. versionadded:: 1.6\n\n                Only available if `enable_metadata_routing=True`,\n                which can be set by using\n                ``sklearn.set_config(enable_metadata_routing=True)``.\n                See :ref:`Metadata Routing User Guide <metadata_routing>` for\n                more details.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Training": {
                "type": "vectors, where `n_samples` is the number of samples and",
                "description": "`n_features` is the number of predictors."
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Target": {
                "type": "values. This parameter may be ignored for",
                "description": ""
              },
              "unsupervised": {
                "type": "learning.",
                "description": "**params : dict, default=None"
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit to data, then transform it.\n\n        Fits transformer to `X` and `y` with optional parameters `fit_params`\n        and returns a transformed version of `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input samples.\n\n        y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n            Target values (None for unsupervised transformations).\n\n        **fit_params : dict\n            Additional fit parameters.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
              },
              "Target": {
                "type": "values (None for unsupervised transformations).",
                "description": "**fit_params : dict"
              },
              "Additional": {
                "type": "fit parameters.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray array of shape (n_samples, n_features_new)",
                "description": ""
              },
              "Transformed": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray array of shape (n_samples, n_features_new)\n            Transformed array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Mask feature names according to selected features.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Input features.\n\n            - If `input_features` is `None`, then `feature_names_in_` is\n              used as feature names in. If `feature_names_in_` is not defined,\n              then the following input feature names are generated:\n              `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n            - If `input_features` is an array-like, then `input_features` must\n              match `feature_names_in_` if `feature_names_in_` is defined.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Input": {
                "type": "features.",
                "description": "- If `input_features` is `None`, then `feature_names_in_` is"
              },
              "used": {
                "type": "as feature names in. If `feature_names_in_` is not defined,",
                "description": ""
              },
              "then": {
                "type": "the following input feature names are generated:",
                "description": "`[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n- If `input_features` is an array-like, then `input_features` must"
              },
              "match": {
                "type": "`feature_names_in_` if `feature_names_in_` is defined.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Transformed": {
                "type": "feature names.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        .. versionadded:: 1.6",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRouter\n            A :class:`~sklearn.utils.metadata_routing.MetadataRouter` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_support",
          "signature": "get_support(self, indices=False)",
          "documentation": {
            "description": "Get a mask, or integer index, of the features selected.\n\n        Parameters\n        ----------\n        indices : bool, default=False\n            If True, the return value will be an array of integers, rather\n            than a boolean mask.",
            "parameters": {
              "indices": {
                "type": "bool, default=False",
                "description": ""
              },
              "If": {
                "type": "`indices` is False, this is a boolean array of shape",
                "description": "[# input features], in which an element is True iff its"
              },
              "than": {
                "type": "a boolean mask.",
                "description": "Returns\n-------"
              },
              "support": {
                "type": "array",
                "description": ""
              },
              "An": {
                "type": "index that selects the retained features from a feature vector.",
                "description": ""
              },
              "corresponding": {
                "type": "feature is selected for retention. If `indices` is",
                "description": "True, this is an integer array of shape [# output features] whose"
              },
              "values": {
                "type": "are indices into the input feature vector.",
                "description": ""
              }
            },
            "returns": "-------\n        support : array\n            An index that selects the retained features from a feature vector.\n            If `indices` is False, this is a boolean array of shape\n            [# input features], in which an element is True iff its\n            corresponding feature is selected for retention. If `indices` is\n            True, this is an integer array of shape [# output features] whose\n            values are indices into the input feature vector.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_transform",
          "signature": "inverse_transform(self, X)",
          "documentation": {
            "description": "Reverse the transformation operation.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_selected_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "X_r": {
                "type": "array of shape [n_samples, n_original_features]",
                "description": "`X` with columns of zeros inserted where features would have"
              },
              "been": {
                "type": "removed by :meth:`transform`.",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_original_features]\n            `X` with columns of zeros inserted where features would have\n            been removed by :meth:`transform`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "transform",
          "signature": "transform(self, X)",
          "documentation": {
            "description": "Reduce X to the selected features.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_features]",
                "description": ""
              },
              "The": {
                "type": "input samples with only the selected features.",
                "description": ""
              },
              "X_r": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_selected_features]\n            The input samples with only the selected features.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "VarianceThreshold",
      "documentation": {
        "description": "Feature selector that removes all low-variance features.\n\n    This feature selection algorithm looks only at the features (X), not the\n    desired outputs (y), and can thus be used for unsupervised learning.\n\n    Read more in the :ref:`User Guide <variance_threshold>`.\n\n    Parameters\n    ----------\n    threshold : float, default=0\n        Features with a training-set variance lower than this threshold will\n        be removed. The default is to keep all features with non-zero variance,\n        i.e. remove the features that have the same value in all samples.\n\n    Attributes\n    ----------\n    variances_ : array, shape (n_features,)\n        Variances of individual features.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    SelectFromModel: Meta-transformer for selecting features based on\n        importance weights.\n    SelectPercentile : Select features according to a percentile of the highest\n        scores.\n    SequentialFeatureSelector : Transformer that performs Sequential Feature\n        Selection.\n\n    Notes\n    -----\n    Allows NaN in the input.\n    Raises ValueError if no feature in X meets the variance threshold.",
        "parameters": {
          "threshold": {
            "type": "float, default=0",
            "description": ""
          },
          "Features": {
            "type": "with a training-set variance lower than this threshold will",
            "description": ""
          },
          "be": {
            "type": "removed. The default is to keep all features with non-zero variance,",
            "description": "i.e. remove the features that have the same value in all samples.\nAttributes\n----------"
          },
          "variances_": {
            "type": "array, shape (n_features,)",
            "description": ""
          },
          "Variances": {
            "type": "of individual features.",
            "description": ""
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "Number": {
            "type": "of features seen during :term:`fit`.",
            "description": ".. versionadded:: 0.24"
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "SelectFromModel": {
            "type": "Meta",
            "description": "transformer for selecting features based on"
          },
          "importance": {
            "type": "weights.",
            "description": ""
          },
          "SelectPercentile": {
            "type": "Select features according to a percentile of the highest",
            "description": "scores."
          },
          "SequentialFeatureSelector": {
            "type": "Transformer that performs Sequential Feature",
            "description": "Selection.\nNotes\n-----"
          },
          "Allows": {
            "type": "NaN in the input.",
            "description": ""
          },
          "Raises": {
            "type": "ValueError if no feature in X meets the variance threshold.",
            "description": "Examples\n--------"
          },
          "The": {
            "type": "following dataset has integer features, two of which are the same",
            "description": ""
          },
          "in": {
            "type": "every sample. These are removed with the default setting for threshold::",
            "description": ">>> from sklearn.feature_selection import VarianceThreshold\n>>> X = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]]\n>>> selector = VarianceThreshold()\n>>> selector.fit_transform(X)\narray([[2, 0],\n[1, 4],\n[1, 1]])"
          }
        },
        "returns": "",
        "raises": "ValueError if no feature in X meets the variance threshold.\n\n    Examples\n    --------\n    The following dataset has integer features, two of which are the same\n    in every sample. These are removed with the default setting for threshold::\n\n        >>> from sklearn.feature_selection import VarianceThreshold\n        >>> X = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]]\n        >>> selector = VarianceThreshold()\n        >>> selector.fit_transform(X)\n        array([[2, 0],\n               [1, 4],\n               [1, 1]])",
        "see_also": "--------\n    SelectFromModel: Meta-transformer for selecting features based on\n        importance weights.\n    SelectPercentile : Select features according to a percentile of the highest\n        scores.\n    SequentialFeatureSelector : Transformer that performs Sequential Feature\n        Selection.\n\n    Notes\n    -----\n    Allows NaN in the input.\n    Raises ValueError if no feature in X meets the variance threshold.\n\n    Examples\n    --------\n    The following dataset has integer features, two of which are the same\n    in every sample. These are removed with the default setting for threshold::\n\n        >>> from sklearn.feature_selection import VarianceThreshold\n        >>> X = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]]\n        >>> selector = VarianceThreshold()\n        >>> selector.fit_transform(X)\n        array([[2, 0],\n               [1, 4],\n               [1, 1]])",
        "notes": "-----\n    Allows NaN in the input.\n    Raises ValueError if no feature in X meets the variance threshold.\n\n    Examples\n    --------\n    The following dataset has integer features, two of which are the same\n    in every sample. These are removed with the default setting for threshold::\n\n        >>> from sklearn.feature_selection import VarianceThreshold\n        >>> X = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]]\n        >>> selector = VarianceThreshold()\n        >>> selector.fit_transform(X)\n        array([[2, 0],\n               [1, 4],\n               [1, 1]])",
        "examples": "--------\n    The following dataset has integer features, two of which are the same\n    in every sample. These are removed with the default setting for threshold::\n\n        >>> from sklearn.feature_selection import VarianceThreshold\n        >>> X = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]]\n        >>> selector = VarianceThreshold()\n        >>> selector.fit_transform(X)\n        array([[2, 0],\n               [1, 4],\n               [1, 1]])"
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, X, y=None)",
          "documentation": {
            "description": "Learn empirical variances from X.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n            Data from which to compute variances, where `n_samples` is\n            the number of samples and `n_features` is the number of features.\n\n        y : any, default=None\n            Ignored. This parameter exists only for compatibility with\n            sklearn.pipeline.Pipeline.",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like, sparse matrix}, shape (n_samples, n_features)"
              },
              "Data": {
                "type": "from which to compute variances, where `n_samples` is",
                "description": ""
              },
              "the": {
                "type": "number of samples and `n_features` is the number of features.",
                "description": ""
              },
              "y": {
                "type": "any, default=None",
                "description": "Ignored. This parameter exists only for compatibility with\nsklearn.pipeline.Pipeline.\nReturns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit to data, then transform it.\n\n        Fits transformer to `X` and `y` with optional parameters `fit_params`\n        and returns a transformed version of `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input samples.\n\n        y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n            Target values (None for unsupervised transformations).\n\n        **fit_params : dict\n            Additional fit parameters.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
              },
              "Target": {
                "type": "values (None for unsupervised transformations).",
                "description": "**fit_params : dict"
              },
              "Additional": {
                "type": "fit parameters.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray array of shape (n_samples, n_features_new)",
                "description": ""
              },
              "Transformed": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray array of shape (n_samples, n_features_new)\n            Transformed array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Mask feature names according to selected features.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Input features.\n\n            - If `input_features` is `None`, then `feature_names_in_` is\n              used as feature names in. If `feature_names_in_` is not defined,\n              then the following input feature names are generated:\n              `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n            - If `input_features` is an array-like, then `input_features` must\n              match `feature_names_in_` if `feature_names_in_` is defined.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Input": {
                "type": "features.",
                "description": "- If `input_features` is `None`, then `feature_names_in_` is"
              },
              "used": {
                "type": "as feature names in. If `feature_names_in_` is not defined,",
                "description": ""
              },
              "then": {
                "type": "the following input feature names are generated:",
                "description": "`[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n- If `input_features` is an array-like, then `input_features` must"
              },
              "match": {
                "type": "`feature_names_in_` if `feature_names_in_` is defined.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Transformed": {
                "type": "feature names.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_support",
          "signature": "get_support(self, indices=False)",
          "documentation": {
            "description": "Get a mask, or integer index, of the features selected.\n\n        Parameters\n        ----------\n        indices : bool, default=False\n            If True, the return value will be an array of integers, rather\n            than a boolean mask.",
            "parameters": {
              "indices": {
                "type": "bool, default=False",
                "description": ""
              },
              "If": {
                "type": "`indices` is False, this is a boolean array of shape",
                "description": "[# input features], in which an element is True iff its"
              },
              "than": {
                "type": "a boolean mask.",
                "description": "Returns\n-------"
              },
              "support": {
                "type": "array",
                "description": ""
              },
              "An": {
                "type": "index that selects the retained features from a feature vector.",
                "description": ""
              },
              "corresponding": {
                "type": "feature is selected for retention. If `indices` is",
                "description": "True, this is an integer array of shape [# output features] whose"
              },
              "values": {
                "type": "are indices into the input feature vector.",
                "description": ""
              }
            },
            "returns": "-------\n        support : array\n            An index that selects the retained features from a feature vector.\n            If `indices` is False, this is a boolean array of shape\n            [# input features], in which an element is True iff its\n            corresponding feature is selected for retention. If `indices` is\n            True, this is an integer array of shape [# output features] whose\n            values are indices into the input feature vector.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_transform",
          "signature": "inverse_transform(self, X)",
          "documentation": {
            "description": "Reverse the transformation operation.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_selected_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "X_r": {
                "type": "array of shape [n_samples, n_original_features]",
                "description": "`X` with columns of zeros inserted where features would have"
              },
              "been": {
                "type": "removed by :meth:`transform`.",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_original_features]\n            `X` with columns of zeros inserted where features would have\n            been removed by :meth:`transform`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "transform",
          "signature": "transform(self, X)",
          "documentation": {
            "description": "Reduce X to the selected features.\n\n        Parameters\n        ----------\n        X : array of shape [n_samples, n_features]\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array of shape [n_samples, n_features]",
                "description": ""
              },
              "The": {
                "type": "input samples with only the selected features.",
                "description": ""
              },
              "X_r": {
                "type": "array of shape [n_samples, n_selected_features]",
                "description": ""
              }
            },
            "returns": "-------\n        X_r : array of shape [n_samples, n_selected_features]\n            The input samples with only the selected features.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    }
  ]
}