{
  "description": "Base classes for all estimators and various utility functions.",
  "functions": [
    {
      "name": "check_array",
      "signature": "check_array(array, accept_sparse=False, *, accept_large_sparse=True, dtype='numeric', order=None, copy=False, force_writeable=False, force_all_finite='deprecated', ensure_all_finite=None, ensure_non_negative=False, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, estimator=None, input_name='')",
      "documentation": {
        "description": "Input validation on an array, list, sparse matrix or similar.\n\n    By default, the input is checked to be a non-empty 2D array containing\n    only finite values. If the dtype of the array is object, attempt\n    converting to float, raising on failure.\n\n    Parameters\n    ----------\n    array : object\n        Input object to check / convert.\n\n    accept_sparse : str, bool or list/tuple of str, default=False\n        String[s] representing allowed sparse matrix formats, such as 'csc',\n        'csr', etc. If the input is sparse but not in the allowed format,\n        it will be converted to the first listed format. True allows the input\n        to be any format. False means that a sparse matrix input will\n        raise an error.\n\n    accept_large_sparse : bool, default=True\n        If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by\n        accept_sparse, accept_large_sparse=False will cause it to be accepted\n        only if its indices are stored with a 32-bit dtype.\n\n        .. versionadded:: 0.20\n\n    dtype : 'numeric', type, list of type or None, default='numeric'\n        Data type of result. If None, the dtype of the input is preserved.\n        If \"numeric\", dtype is preserved unless array.dtype is object.\n        If dtype is a list of types, conversion on the first type is only\n        performed if the dtype of the input is not in the list.\n\n    order : {'F', 'C'} or None, default=None\n        Whether an array will be forced to be fortran or c-style.\n        When order is None (default), then if copy=False, nothing is ensured\n        about the memory layout of the output array; otherwise (copy=True)\n        the memory layout of the returned array is kept as close as possible\n        to the original array.\n\n    copy : bool, default=False\n        Whether a forced copy will be triggered. If copy=False, a copy might\n        be triggered by a conversion.\n\n    force_writeable : bool, default=False\n        Whether to force the output array to be writeable. If True, the returned array\n        is guaranteed to be writeable, which may require a copy. Otherwise the\n        writeability of the input array is preserved.\n\n        .. versionadded:: 1.6\n\n    force_all_finite : bool or 'allow-nan', default=True\n        Whether to raise an error on np.inf, np.nan, pd.NA in array. The\n        possibilities are:\n\n        - True: Force all values of array to be finite.\n        - False: accepts np.inf, np.nan, pd.NA in array.\n        - 'allow-nan': accepts only np.nan and pd.NA values in array. Values\n          cannot be infinite.\n\n        .. versionadded:: 0.20\n           ``force_all_finite`` accepts the string ``'allow-nan'``.\n\n        .. versionchanged:: 0.23\n           Accepts `pd.NA` and converts it into `np.nan`\n\n        .. deprecated:: 1.6\n           `force_all_finite` was renamed to `ensure_all_finite` and will be removed\n           in 1.8.\n\n    ensure_all_finite : bool or 'allow-nan', default=True\n        Whether to raise an error on np.inf, np.nan, pd.NA in array. The\n        possibilities are:\n\n        - True: Force all values of array to be finite.\n        - False: accepts np.inf, np.nan, pd.NA in array.\n        - 'allow-nan': accepts only np.nan and pd.NA values in array. Values\n          cannot be infinite.\n\n        .. versionadded:: 1.6\n           `force_all_finite` was renamed to `ensure_all_finite`.\n\n    ensure_non_negative : bool, default=False\n        Make sure the array has only non-negative values. If True, an array that\n        contains negative values will raise a ValueError.\n\n        .. versionadded:: 1.6\n\n    ensure_2d : bool, default=True\n        Whether to raise a value error if array is not 2D.\n\n    allow_nd : bool, default=False\n        Whether to allow array.ndim > 2.\n\n    ensure_min_samples : int, default=1\n        Make sure that the array has a minimum number of samples in its first\n        axis (rows for a 2D array). Setting to 0 disables this check.\n\n    ensure_min_features : int, default=1\n        Make sure that the 2D array has some minimum number of features\n        (columns). The default value of 1 rejects empty datasets.\n        This check is only enforced when the input data has effectively 2\n        dimensions or is originally 1D and ``ensure_2d`` is True. Setting to 0\n        disables this check.\n\n    estimator : str or estimator instance, default=None\n        If passed, include the name of the estimator in warning messages.\n\n    input_name : str, default=\"\"\n        The data name used to construct the error message. In particular\n        if `input_name` is \"X\" and the data has NaN values and\n        allow_nan is False, the error message will link to the imputer\n        documentation.\n\n        .. versionadded:: 1.1.0\n\n    Returns\n    -------\n    array_converted : object\n        The converted and validated array.",
        "parameters": {
          "array": {
            "type": "[[1, 2, 3], [4, 5, 6]]",
            "description": ""
          },
          "Input": {
            "type": "object to check / convert.",
            "description": ""
          },
          "accept_sparse": {
            "type": "str, bool or list/tuple of str, default=False",
            "description": "String[s] representing allowed sparse matrix formats, such as 'csc',\n'csr', etc. If the input is sparse but not in the allowed format,"
          },
          "it": {
            "type": "will be converted to the first listed format. True allows the input",
            "description": ""
          },
          "to": {
            "type": "the original array.",
            "description": ""
          },
          "raise": {
            "type": "an error.",
            "description": ""
          },
          "accept_large_sparse": {
            "type": "bool, default=True",
            "description": ""
          },
          "If": {
            "type": "passed, include the name of the estimator in warning messages.",
            "description": ""
          },
          "only": {
            "type": "if its indices are stored with a 32-bit dtype.",
            "description": ".. versionadded:: 0.20"
          },
          "dtype": {
            "type": "'numeric', type, list of type or None, default='numeric'",
            "description": ""
          },
          "Data": {
            "type": "type of result. If None, the dtype of the input is preserved.",
            "description": ""
          },
          "performed": {
            "type": "if the dtype of the input is not in the list.",
            "description": ""
          },
          "order": {
            "type": "{'F', 'C'} or None, default=None",
            "description": ""
          },
          "Whether": {
            "type": "to allow array.ndim > 2.",
            "description": ""
          },
          "When": {
            "type": "order is None (default), then if copy=False, nothing is ensured",
            "description": ""
          },
          "about": {
            "type": "the memory layout of the output array; otherwise (copy=True)",
            "description": ""
          },
          "the": {
            "type": "memory layout of the returned array is kept as close as possible",
            "description": ""
          },
          "copy": {
            "type": "bool, default=False",
            "description": ""
          },
          "be": {
            "type": "triggered by a conversion.",
            "description": ""
          },
          "force_writeable": {
            "type": "bool, default=False",
            "description": ""
          },
          "is": {
            "type": "guaranteed to be writeable, which may require a copy. Otherwise the",
            "description": ""
          },
          "writeability": {
            "type": "of the input array is preserved.",
            "description": ".. versionadded:: 1.6"
          },
          "force_all_finite": {
            "type": "bool or 'allow",
            "description": "nan', default=True"
          },
          "possibilities": {
            "type": "are:",
            "description": "- True: Force all values of array to be finite.\n- False: accepts np.inf, np.nan, pd.NA in array.\n- 'allow-nan': accepts only np.nan and pd.NA values in array. Values"
          },
          "cannot": {
            "type": "be infinite.",
            "description": ".. versionadded:: 1.6\n`force_all_finite` was renamed to `ensure_all_finite`."
          },
          "Accepts": {
            "type": "`pd.NA` and converts it into `np.nan`",
            "description": ".. deprecated:: 1.6\n`force_all_finite` was renamed to `ensure_all_finite` and will be removed"
          },
          "in": {
            "type": "1.8.",
            "description": ""
          },
          "ensure_all_finite": {
            "type": "bool or 'allow",
            "description": "nan', default=True"
          },
          "ensure_non_negative": {
            "type": "bool, default=False",
            "description": ""
          },
          "Make": {
            "type": "sure that the 2D array has some minimum number of features",
            "description": "(columns). The default value of 1 rejects empty datasets."
          },
          "contains": {
            "type": "negative values will raise a ValueError.",
            "description": ".. versionadded:: 1.6"
          },
          "ensure_2d": {
            "type": "bool, default=True",
            "description": ""
          },
          "allow_nd": {
            "type": "bool, default=False",
            "description": ""
          },
          "ensure_min_samples": {
            "type": "int, default=1",
            "description": ""
          },
          "axis": {
            "type": "rows for a 2D array",
            "description": ". Setting to 0 disables this check."
          },
          "ensure_min_features": {
            "type": "int, default=1",
            "description": ""
          },
          "This": {
            "type": "check is only enforced when the input data has effectively 2",
            "description": ""
          },
          "dimensions": {
            "type": "or is originally 1D and ``ensure_2d`` is True. Setting to 0",
            "description": ""
          },
          "disables": {
            "type": "this check.",
            "description": ""
          },
          "estimator": {
            "type": "str or estimator instance, default=None",
            "description": ""
          },
          "input_name": {
            "type": "str, default=\"\"",
            "description": ""
          },
          "The": {
            "type": "converted and validated array.",
            "description": "Examples\n--------\n>>> from sklearn.utils.validation import check_array\n>>> X = [[1, 2, 3], [4, 5, 6]]\n>>> X_checked = check_array(X)\n>>> X_checked"
          },
          "if": {
            "type": "`input_name` is \"X\" and the data has NaN values and",
            "description": ""
          },
          "allow_nan": {
            "type": "is False, the error message will link to the imputer",
            "description": "documentation.\n.. versionadded:: 1.1.0\nReturns\n-------"
          },
          "array_converted": {
            "type": "object",
            "description": ""
          }
        },
        "returns": "-------\n    array_converted : object\n        The converted and validated array.\n\n    Examples\n    --------\n    >>> from sklearn.utils.validation import check_array\n    >>> X = [[1, 2, 3], [4, 5, 6]]\n    >>> X_checked = check_array(X)\n    >>> X_checked\n    array([[1, 2, 3], [4, 5, 6]])",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils.validation import check_array\n    >>> X = [[1, 2, 3], [4, 5, 6]]\n    >>> X_checked = check_array(X)\n    >>> X_checked\n    array([[1, 2, 3], [4, 5, 6]])"
      }
    },
    {
      "name": "check_is_fitted",
      "signature": "check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=<built-in function all>)",
      "documentation": {
        "description": "Perform is_fitted validation for estimator.\n\n    Checks if the estimator is fitted by verifying the presence of\n    fitted attributes (ending with a trailing underscore) and otherwise\n    raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n\n    If an estimator does not set any attributes with a trailing underscore, it\n    can define a ``__sklearn_is_fitted__`` method returning a boolean to\n    specify if the estimator is fitted or not. See\n    :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n    for an example on how to use the API.\n\n    If no `attributes` are passed, this fuction will pass if an estimator is stateless.\n    An estimator can indicate it's stateless by setting the `requires_fit` tag. See\n    :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n    is ignored if `attributes` are passed.\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        Estimator instance for which the check is performed.\n\n    attributes : str, list or tuple of str, default=None\n        Attribute name(s) given as string or a list/tuple of strings\n        Eg.: ``[\"coef_\", \"estimator_\", ...], \"coef_\"``\n\n        If `None`, `estimator` is considered fitted if there exist an\n        attribute that ends with a underscore and does not start with double\n        underscore.\n\n    msg : str, default=None\n        The default error message is, \"This %(name)s instance is not fitted\n        yet. Call 'fit' with appropriate arguments before using this\n        estimator.\"\n\n        For custom messages if \"%(name)s\" is present in the message string,\n        it is substituted for the estimator name.\n\n        Eg. : \"Estimator, %(name)s, must be fitted before sparsifying\".\n\n    all_or_any : callable, {all, any}, default=all\n        Specify whether all or any of the given attributes must exist.\n\n    Raises\n    ------\n    TypeError\n        If the estimator is a class or not an estimator instance\n\n    NotFittedError\n        If the attributes are not found.",
        "parameters": {
          "estimator": {
            "type": "estimator instance",
            "description": ""
          },
          "Estimator": {
            "type": "instance for which the check is performed.",
            "description": ""
          },
          "attributes": {
            "type": "str, list or tuple of str, default=None",
            "description": ""
          },
          "Attribute": {
            "type": "name(s) given as string or a list/tuple of strings",
            "description": "Eg.: ``[\"coef_\", \"estimator_\", ...], \"coef_\"``"
          },
          "If": {
            "type": "the attributes are not found.",
            "description": "Examples\n--------\n>>> from sklearn.linear_model import LogisticRegression\n>>> from sklearn.utils.validation import check_is_fitted\n>>> from sklearn.exceptions import NotFittedError\n>>> lr = LogisticRegression()\n>>> try:\n...     check_is_fitted(lr)\n... except NotFittedError as exc:\n...     print(f\"Model is not fitted yet.\")"
          },
          "attribute": {
            "type": "that ends with a underscore and does not start with double",
            "description": "underscore."
          },
          "msg": {
            "type": "str, default=None",
            "description": ""
          },
          "The": {
            "type": "default error message is, \"This %(name)s instance is not fitted",
            "description": "yet. Call 'fit' with appropriate arguments before using this\nestimator.\""
          },
          "For": {
            "type": "custom messages if \"%(name)s\" is present in the message string,",
            "description": ""
          },
          "it": {
            "type": "is substituted for the estimator name.",
            "description": "Eg. : \"Estimator, %(name)s, must be fitted before sparsifying\"."
          },
          "all_or_any": {
            "type": "callable, {all, any}, default=all",
            "description": ""
          },
          "Specify": {
            "type": "whether all or any of the given attributes must exist.",
            "description": "Raises\n------\nTypeError"
          },
          "Model": {
            "type": "is not fitted yet.",
            "description": ">>> lr.fit([[1, 2], [1, 3]], [1, 0])"
          },
          "LogisticRegression": {
            "type": "",
            "description": ">>> check_is_fitted(lr)"
          }
        },
        "returns": "",
        "raises": "a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n\n    If an estimator does not set any attributes with a trailing underscore, it\n    can define a ``__sklearn_is_fitted__`` method returning a boolean to\n    specify if the estimator is fitted or not. See\n    :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n    for an example on how to use the API.\n\n    If no `attributes` are passed, this fuction will pass if an estimator is stateless.\n    An estimator can indicate it's stateless by setting the `requires_fit` tag. See\n    :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n    is ignored if `attributes` are passed.\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        Estimator instance for which the check is performed.\n\n    attributes : str, list or tuple of str, default=None\n        Attribute name(s) given as string or a list/tuple of strings\n        Eg.: ``[\"coef_\", \"estimator_\", ...], \"coef_\"``\n\n        If `None`, `estimator` is considered fitted if there exist an\n        attribute that ends with a underscore and does not start with double\n        underscore.\n\n    msg : str, default=None\n        The default error message is, \"This %(name)s instance is not fitted\n        yet. Call 'fit' with appropriate arguments before using this\n        estimator.\"\n\n        For custom messages if \"%(name)s\" is present in the message string,\n        it is substituted for the estimator name.\n\n        Eg. : \"Estimator, %(name)s, must be fitted before sparsifying\".\n\n    all_or_any : callable, {all, any}, default=all\n        Specify whether all or any of the given attributes must exist.",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> from sklearn.utils.validation import check_is_fitted\n    >>> from sklearn.exceptions import NotFittedError\n    >>> lr = LogisticRegression()\n    >>> try:\n    ...     check_is_fitted(lr)\n    ... except NotFittedError as exc:\n    ...     print(f\"Model is not fitted yet.\")\n    Model is not fitted yet.\n    >>> lr.fit([[1, 2], [1, 3]], [1, 0])\n    LogisticRegression()\n    >>> check_is_fitted(lr)"
      }
    },
    {
      "name": "clone",
      "signature": "clone(estimator, *, safe=True)",
      "documentation": {
        "description": "Construct a new unfitted estimator with the same parameters.\n\n    Clone does a deep copy of the model in an estimator\n    without actually copying attached data. It returns a new estimator\n    with the same parameters that has not been fitted on any data.\n\n    .. versionchanged:: 1.3\n        Delegates to `estimator.__sklearn_clone__` if the method exists.\n\n    Parameters\n    ----------\n    estimator : {list, tuple, set} of estimator instance or a single             estimator instance\n        The estimator or group of estimators to be cloned.\n    safe : bool, default=True\n        If safe is False, clone will fall back to a deep copy on objects\n        that are not estimators. Ignored if `estimator.__sklearn_clone__`\n        exists.\n\n    Returns\n    -------\n    estimator : object\n        The deep copy of the input, an estimator if input is an estimator.\n\n    Notes\n    -----\n    If the estimator's `random_state` parameter is an integer (or if the\n    estimator doesn't have a `random_state` parameter), an *exact clone* is\n    returned: the clone and the original estimator will give the exact same\n    results. Otherwise, *statistical clone* is returned: the clone might\n    return different results from the original estimator. More details can be\n    found in :ref:`randomness`.",
        "parameters": {
          "estimator": {
            "type": "doesn't have a `random_state` parameter), an *exact clone* is",
            "description": ""
          },
          "The": {
            "type": "deep copy of the input, an estimator if input is an estimator.",
            "description": "Notes\n-----"
          },
          "safe": {
            "type": "bool, default=True",
            "description": ""
          },
          "If": {
            "type": "the estimator's `random_state` parameter is an integer (or if the",
            "description": ""
          },
          "that": {
            "type": "are not estimators. Ignored if `estimator.__sklearn_clone__`",
            "description": "exists.\nReturns\n-------"
          },
          "returned": {
            "type": "the clone and the original estimator will give the exact same",
            "description": "results. Otherwise, *statistical clone* is returned: the clone might"
          },
          "return": {
            "type": "different results from the original estimator. More details can be",
            "description": ""
          },
          "found": {
            "type": "in :ref:`randomness`.",
            "description": "Examples\n--------\n>>> from sklearn.base import clone\n>>> from sklearn.linear_model import LogisticRegression\n>>> X = [[-1, 0], [0, 1], [0, -1], [1, 0]]\n>>> y = [0, 0, 1, 1]\n>>> classifier = LogisticRegression().fit(X, y)\n>>> cloned_classifier = clone(classifier)\n>>> hasattr(classifier, \"classes_\")\nTrue\n>>> hasattr(cloned_classifier, \"classes_\")\nFalse\n>>> classifier is cloned_classifier\nFalse"
          }
        },
        "returns": "different results from the original estimator. More details can be\n    found in :ref:`randomness`.\n\n    Examples\n    --------\n    >>> from sklearn.base import clone\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> X = [[-1, 0], [0, 1], [0, -1], [1, 0]]\n    >>> y = [0, 0, 1, 1]\n    >>> classifier = LogisticRegression().fit(X, y)\n    >>> cloned_classifier = clone(classifier)\n    >>> hasattr(classifier, \"classes_\")\n    True\n    >>> hasattr(cloned_classifier, \"classes_\")\n    False\n    >>> classifier is cloned_classifier\n    False",
        "raises": "",
        "see_also": "",
        "notes": "-----\n    If the estimator's `random_state` parameter is an integer (or if the\n    estimator doesn't have a `random_state` parameter), an *exact clone* is\n    returned: the clone and the original estimator will give the exact same\n    results. Otherwise, *statistical clone* is returned: the clone might\n    return different results from the original estimator. More details can be\n    found in :ref:`randomness`.\n\n    Examples\n    --------\n    >>> from sklearn.base import clone\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> X = [[-1, 0], [0, 1], [0, -1], [1, 0]]\n    >>> y = [0, 0, 1, 1]\n    >>> classifier = LogisticRegression().fit(X, y)\n    >>> cloned_classifier = clone(classifier)\n    >>> hasattr(classifier, \"classes_\")\n    True\n    >>> hasattr(cloned_classifier, \"classes_\")\n    False\n    >>> classifier is cloned_classifier\n    False",
        "examples": "--------\n    >>> from sklearn.base import clone\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> X = [[-1, 0], [0, 1], [0, -1], [1, 0]]\n    >>> y = [0, 0, 1, 1]\n    >>> classifier = LogisticRegression().fit(X, y)\n    >>> cloned_classifier = clone(classifier)\n    >>> hasattr(classifier, \"classes_\")\n    True\n    >>> hasattr(cloned_classifier, \"classes_\")\n    False\n    >>> classifier is cloned_classifier\n    False"
      }
    },
    {
      "name": "config_context",
      "signature": "config_context(*, assume_finite=None, working_memory=None, print_changed_only=None, display=None, pairwise_dist_chunk_size=None, enable_cython_pairwise_dist=None, array_api_dispatch=None, transform_output=None, enable_metadata_routing=None, skip_parameter_validation=None)",
      "documentation": {
        "description": "Context manager for global scikit-learn configuration.\n\n    Parameters\n    ----------\n    assume_finite : bool, default=None\n        If True, validation for finiteness will be skipped,\n        saving time, but leading to potential crashes. If\n        False, validation for finiteness will be performed,\n        avoiding error. If None, the existing value won't change.\n        The default value is False.\n\n    working_memory : int, default=None\n        If set, scikit-learn will attempt to limit the size of temporary arrays\n        to this number of MiB (per job when parallelised), often saving both\n        computation time and memory on expensive operations that can be\n        performed in chunks. If None, the existing value won't change.\n        The default value is 1024.\n\n    print_changed_only : bool, default=None\n        If True, only the parameters that were set to non-default\n        values will be printed when printing an estimator. For example,\n        ``print(SVC())`` while True will only print 'SVC()', but would print\n        'SVC(C=1.0, cache_size=200, ...)' with all the non-changed parameters\n        when False. If None, the existing value won't change.\n        The default value is True.\n\n        .. versionchanged:: 0.23\n           Default changed from False to True.\n\n    display : {'text', 'diagram'}, default=None\n        If 'diagram', estimators will be displayed as a diagram in a Jupyter\n        lab or notebook context. If 'text', estimators will be displayed as\n        text. If None, the existing value won't change.\n        The default value is 'diagram'.\n\n        .. versionadded:: 0.23\n\n    pairwise_dist_chunk_size : int, default=None\n        The number of row vectors per chunk for the accelerated pairwise-\n        distances reduction backend. Default is 256 (suitable for most of\n        modern laptops' caches and architectures).\n\n        Intended for easier benchmarking and testing of scikit-learn internals.\n        End users are not expected to benefit from customizing this configuration\n        setting.\n\n        .. versionadded:: 1.1\n\n    enable_cython_pairwise_dist : bool, default=None\n        Use the accelerated pairwise-distances reduction backend when\n        possible. Global default: True.\n\n        Intended for easier benchmarking and testing of scikit-learn internals.\n        End users are not expected to benefit from customizing this configuration\n        setting.\n\n        .. versionadded:: 1.1\n\n    array_api_dispatch : bool, default=None\n        Use Array API dispatching when inputs follow the Array API standard.\n        Default is False.\n\n        See the :ref:`User Guide <array_api>` for more details.\n\n        .. versionadded:: 1.2\n\n    transform_output : str, default=None\n        Configure output of `transform` and `fit_transform`.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        - `\"default\"`: Default output format of a transformer\n        - `\"pandas\"`: DataFrame output\n        - `\"polars\"`: Polars output\n        - `None`: Transform configuration is unchanged\n\n        .. versionadded:: 1.2\n        .. versionadded:: 1.4\n            `\"polars\"` option was added.\n\n    enable_metadata_routing : bool, default=None\n        Enable metadata routing. By default this feature is disabled.\n\n        Refer to :ref:`metadata routing user guide <metadata_routing>` for more\n        details.\n\n        - `True`: Metadata routing is enabled\n        - `False`: Metadata routing is disabled, use the old syntax.\n        - `None`: Configuration is unchanged\n\n        .. versionadded:: 1.3\n\n    skip_parameter_validation : bool, default=None\n        If `True`, disable the validation of the hyper-parameters' types and values in\n        the fit method of estimators and for arguments passed to public helper\n        functions. It can save time in some situations but can lead to low level\n        crashes and exceptions with confusing error messages.\n\n        Note that for data parameters, such as `X` and `y`, only type validation is\n        skipped but validation with `check_array` will continue to run.\n\n        .. versionadded:: 1.3\n\n    Yields\n    ------\n    None.\n\n    See Also\n    --------\n    set_config : Set global scikit-learn configuration.\n    get_config : Retrieve current values of the global configuration.\n\n    Notes\n    -----\n    All settings, not just those presently modified, will be returned to\n    their previous values when the context manager is exited.",
        "parameters": {
          "assume_finite": {
            "type": "bool, default=None",
            "description": ""
          },
          "If": {
            "type": "`True`, disable the validation of the hyper-parameters' types and values in",
            "description": ""
          },
          "saving": {
            "type": "time, but leading to potential crashes. If",
            "description": "False, validation for finiteness will be performed,"
          },
          "avoiding": {
            "type": "error. If None, the existing value won't change.",
            "description": ""
          },
          "The": {
            "type": "number of row vectors per chunk for the accelerated pairwise-",
            "description": ""
          },
          "working_memory": {
            "type": "int, default=None",
            "description": ""
          },
          "to": {
            "type": "this number of MiB (per job when parallelised), often saving both",
            "description": ""
          },
          "computation": {
            "type": "time and memory on expensive operations that can be",
            "description": ""
          },
          "performed": {
            "type": "in chunks. If None, the existing value won't change.",
            "description": ""
          },
          "print_changed_only": {
            "type": "bool, default=None",
            "description": ""
          },
          "values": {
            "type": "will be printed when printing an estimator. For example,",
            "description": "``print(SVC())`` while True will only print 'SVC()', but would print\n'SVC(C=1.0, cache_size=200, ...)' with all the non-changed parameters"
          },
          "when": {
            "type": "False. If None, the existing value won't change.",
            "description": ""
          },
          "Default": {
            "type": "is False.",
            "description": ""
          },
          "display": {
            "type": "{'text', 'diagram'}, default=None",
            "description": ""
          },
          "lab": {
            "type": "or notebook context. If 'text', estimators will be displayed as",
            "description": "text. If None, the existing value won't change."
          },
          "pairwise_dist_chunk_size": {
            "type": "int, default=None",
            "description": ""
          },
          "distances": {
            "type": "reduction backend. Default is 256 (suitable for most of",
            "description": ""
          },
          "modern": {
            "type": "laptops' caches and architectures).",
            "description": ""
          },
          "Intended": {
            "type": "for easier benchmarking and testing of scikit-learn internals.",
            "description": ""
          },
          "End": {
            "type": "users are not expected to benefit from customizing this configuration",
            "description": "setting.\n.. versionadded:: 1.1"
          },
          "enable_cython_pairwise_dist": {
            "type": "bool, default=None",
            "description": ""
          },
          "Use": {
            "type": "Array API dispatching when inputs follow the Array API standard.",
            "description": ""
          },
          "array_api_dispatch": {
            "type": "bool, default=None",
            "description": ""
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "transform_output": {
            "type": "str, default=None",
            "description": ""
          },
          "Configure": {
            "type": "output of `transform` and `fit_transform`.",
            "description": ""
          },
          "for": {
            "type": "an example on how to use the API.",
            "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.2\n.. versionadded:: 1.4\n`\"polars\"` option was added."
          },
          "enable_metadata_routing": {
            "type": "bool, default=None",
            "description": ""
          },
          "Enable": {
            "type": "metadata routing. By default this feature is disabled.",
            "description": ""
          },
          "Refer": {
            "type": "to :ref:`metadata routing user guide <metadata_routing>` for more",
            "description": "details.\n- `True`: Metadata routing is enabled\n- `False`: Metadata routing is disabled, use the old syntax.\n- `None`: Configuration is unchanged\n.. versionadded:: 1.3"
          },
          "skip_parameter_validation": {
            "type": "bool, default=None",
            "description": ""
          },
          "the": {
            "type": "fit method of estimators and for arguments passed to public helper",
            "description": "functions. It can save time in some situations but can lead to low level"
          },
          "crashes": {
            "type": "and exceptions with confusing error messages.",
            "description": ""
          },
          "Note": {
            "type": "that for data parameters, such as `X` and `y`, only type validation is",
            "description": ""
          },
          "skipped": {
            "type": "but validation with `check_array` will continue to run.",
            "description": ".. versionadded:: 1.3\nYields\n------\nNone."
          },
          "set_config": {
            "type": "Set global scikit",
            "description": "learn configuration."
          },
          "get_config": {
            "type": "Retrieve current values of the global configuration.",
            "description": "Notes\n-----"
          },
          "All": {
            "type": "settings, not just those presently modified, will be returned to",
            "description": ""
          },
          "their": {
            "type": "previous values when the context manager is exited.",
            "description": "Examples\n--------\n>>> import sklearn\n>>> from sklearn.utils.validation import assert_all_finite\n>>> with sklearn.config_context(assume_finite=True):\n...     assert_all_finite([float('nan')])\n>>> with sklearn.config_context(assume_finite=True):\n...     with sklearn.config_context(assume_finite=False):\n...         assert_all_finite([float('nan')])"
          },
          "Traceback": {
            "type": "most recent call last",
            "description": "..."
          },
          "ValueError": {
            "type": "Input contains NaN...",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    set_config : Set global scikit-learn configuration.\n    get_config : Retrieve current values of the global configuration.\n\n    Notes\n    -----\n    All settings, not just those presently modified, will be returned to\n    their previous values when the context manager is exited.\n\n    Examples\n    --------\n    >>> import sklearn\n    >>> from sklearn.utils.validation import assert_all_finite\n    >>> with sklearn.config_context(assume_finite=True):\n    ...     assert_all_finite([float('nan')])\n    >>> with sklearn.config_context(assume_finite=True):\n    ...     with sklearn.config_context(assume_finite=False):\n    ...         assert_all_finite([float('nan')])\n    Traceback (most recent call last):\n    ...\n    ValueError: Input contains NaN...",
        "notes": "that for data parameters, such as `X` and `y`, only type validation is\n        skipped but validation with `check_array` will continue to run.\n\n        .. versionadded:: 1.3\n\n    Yields\n    ------\n    None.\n\n    See Also\n    --------\n    set_config : Set global scikit-learn configuration.\n    get_config : Retrieve current values of the global configuration.\n\n    Notes\n    -----\n    All settings, not just those presently modified, will be returned to\n    their previous values when the context manager is exited.\n\n    Examples\n    --------\n    >>> import sklearn\n    >>> from sklearn.utils.validation import assert_all_finite\n    >>> with sklearn.config_context(assume_finite=True):\n    ...     assert_all_finite([float('nan')])\n    >>> with sklearn.config_context(assume_finite=True):\n    ...     with sklearn.config_context(assume_finite=False):\n    ...         assert_all_finite([float('nan')])\n    Traceback (most recent call last):\n    ...\n    ValueError: Input contains NaN...",
        "examples": "--------\n    >>> import sklearn\n    >>> from sklearn.utils.validation import assert_all_finite\n    >>> with sklearn.config_context(assume_finite=True):\n    ...     assert_all_finite([float('nan')])\n    >>> with sklearn.config_context(assume_finite=True):\n    ...     with sklearn.config_context(assume_finite=False):\n    ...         assert_all_finite([float('nan')])\n    Traceback (most recent call last):\n    ...\n    ValueError: Input contains NaN..."
      }
    },
    {
      "name": "estimator_html_repr",
      "signature": "estimator_html_repr(estimator)",
      "documentation": {
        "description": "Build a HTML representation of an estimator.\n\n    Read more in the :ref:`User Guide <visualizing_composite_estimators>`.\n\n    Parameters\n    ----------\n    estimator : estimator object\n        The estimator to visualize.\n\n    Returns\n    -------\n    html: str\n        HTML representation of estimator.",
        "parameters": {
          "estimator": {
            "type": "estimator object",
            "description": ""
          },
          "The": {
            "type": "estimator to visualize.",
            "description": "Returns\n-------"
          },
          "html": {
            "type": "str",
            "description": ""
          },
          "HTML": {
            "type": "representation of estimator.",
            "description": "Examples\n--------\n>>> from sklearn.utils._estimator_html_repr import estimator_html_repr\n>>> from sklearn.linear_model import LogisticRegression\n>>> estimator_html_repr(LogisticRegression())\n'<style>...</div>'"
          }
        },
        "returns": "-------\n    html: str\n        HTML representation of estimator.\n\n    Examples\n    --------\n    >>> from sklearn.utils._estimator_html_repr import estimator_html_repr\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> estimator_html_repr(LogisticRegression())\n    '<style>...</div>'",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils._estimator_html_repr import estimator_html_repr\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> estimator_html_repr(LogisticRegression())\n    '<style>...</div>'"
      }
    },
    {
      "name": "get_config",
      "signature": "get_config()",
      "documentation": {
        "description": "Retrieve current values for configuration set by :func:`set_config`.\n\n    Returns\n    -------\n    config : dict\n        Keys are parameter names that can be passed to :func:`set_config`.\n\n    See Also\n    --------\n    config_context : Context manager for global scikit-learn configuration.\n    set_config : Set global scikit-learn configuration.",
        "parameters": {},
        "returns": "-------\n    config : dict\n        Keys are parameter names that can be passed to :func:`set_config`.\n\n    See Also\n    --------\n    config_context : Context manager for global scikit-learn configuration.\n    set_config : Set global scikit-learn configuration.\n\n    Examples\n    --------\n    >>> import sklearn\n    >>> config = sklearn.get_config()\n    >>> config.keys()\n    dict_keys([...])",
        "raises": "",
        "see_also": "--------\n    config_context : Context manager for global scikit-learn configuration.\n    set_config : Set global scikit-learn configuration.\n\n    Examples\n    --------\n    >>> import sklearn\n    >>> config = sklearn.get_config()\n    >>> config.keys()\n    dict_keys([...])",
        "notes": "",
        "examples": "--------\n    >>> import sklearn\n    >>> config = sklearn.get_config()\n    >>> config.keys()\n    dict_keys([...])"
      }
    },
    {
      "name": "get_tags",
      "signature": "get_tags(estimator) -> 'Tags'",
      "documentation": {
        "description": "Get estimator tags.\n\n    :class:`~sklearn.BaseEstimator` provides the estimator tags machinery.\n    However, if an estimator does not inherit from this base class, we should\n    fall-back to the default tags.\n\n    For scikit-learn built-in estimators, we should still rely on\n    `self.__sklearn_tags__()`. `get_tags(est)` should be used when we\n    are not sure where `est` comes from: typically\n    `get_tags(self.estimator)` where `self` is a meta-estimator, or in\n    the common checks.\n\n    .. versionadded:: 1.6\n\n    Parameters\n    ----------\n    estimator : estimator object\n        The estimator from which to get the tag.",
        "parameters": {
          "estimator": {
            "type": "estimator object",
            "description": ""
          },
          "The": {
            "type": "estimator tags.",
            "description": ""
          },
          "tags": {
            "type": ":class:`~.sklearn.utils.Tags`",
            "description": ""
          }
        },
        "returns": "-------\n    tags : :class:`~.sklearn.utils.Tags`\n        The estimator tags.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "is_classifier",
      "signature": "is_classifier(estimator)",
      "documentation": {
        "description": "Return True if the given estimator is (probably) a classifier.\n\n    Parameters\n    ----------\n    estimator : object\n        Estimator object to test.\n\n    Returns\n    -------\n    out : bool\n        True if estimator is a classifier and False otherwise.",
        "parameters": {
          "estimator": {
            "type": "object",
            "description": ""
          },
          "Estimator": {
            "type": "object to test.",
            "description": "Returns\n-------"
          },
          "out": {
            "type": "bool",
            "description": ""
          },
          "True": {
            "type": "if estimator is a classifier and False otherwise.",
            "description": "Examples\n--------\n>>> from sklearn.base import is_classifier\n>>> from sklearn.cluster import KMeans\n>>> from sklearn.svm import SVC, SVR\n>>> classifier = SVC()\n>>> regressor = SVR()\n>>> kmeans = KMeans()\n>>> is_classifier(classifier)\nTrue\n>>> is_classifier(regressor)\nFalse\n>>> is_classifier(kmeans)\nFalse"
          }
        },
        "returns": "-------\n    out : bool\n        True if estimator is a classifier and False otherwise.\n\n    Examples\n    --------\n    >>> from sklearn.base import is_classifier\n    >>> from sklearn.cluster import KMeans\n    >>> from sklearn.svm import SVC, SVR\n    >>> classifier = SVC()\n    >>> regressor = SVR()\n    >>> kmeans = KMeans()\n    >>> is_classifier(classifier)\n    True\n    >>> is_classifier(regressor)\n    False\n    >>> is_classifier(kmeans)\n    False",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.base import is_classifier\n    >>> from sklearn.cluster import KMeans\n    >>> from sklearn.svm import SVC, SVR\n    >>> classifier = SVC()\n    >>> regressor = SVR()\n    >>> kmeans = KMeans()\n    >>> is_classifier(classifier)\n    True\n    >>> is_classifier(regressor)\n    False\n    >>> is_classifier(kmeans)\n    False"
      }
    },
    {
      "name": "is_clusterer",
      "signature": "is_clusterer(estimator)",
      "documentation": {
        "description": "Return True if the given estimator is (probably) a clusterer.\n\n    .. versionadded:: 1.6\n\n    Parameters\n    ----------\n    estimator : object\n        Estimator object to test.\n\n    Returns\n    -------\n    out : bool\n        True if estimator is a clusterer and False otherwise.",
        "parameters": {
          "estimator": {
            "type": "object",
            "description": ""
          },
          "Estimator": {
            "type": "object to test.",
            "description": "Returns\n-------"
          },
          "out": {
            "type": "bool",
            "description": ""
          },
          "True": {
            "type": "if estimator is a clusterer and False otherwise.",
            "description": "Examples\n--------\n>>> from sklearn.base import is_clusterer\n>>> from sklearn.cluster import KMeans\n>>> from sklearn.svm import SVC, SVR\n>>> classifier = SVC()\n>>> regressor = SVR()\n>>> kmeans = KMeans()\n>>> is_clusterer(classifier)\nFalse\n>>> is_clusterer(regressor)\nFalse\n>>> is_clusterer(kmeans)\nTrue"
          }
        },
        "returns": "-------\n    out : bool\n        True if estimator is a clusterer and False otherwise.\n\n    Examples\n    --------\n    >>> from sklearn.base import is_clusterer\n    >>> from sklearn.cluster import KMeans\n    >>> from sklearn.svm import SVC, SVR\n    >>> classifier = SVC()\n    >>> regressor = SVR()\n    >>> kmeans = KMeans()\n    >>> is_clusterer(classifier)\n    False\n    >>> is_clusterer(regressor)\n    False\n    >>> is_clusterer(kmeans)\n    True",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.base import is_clusterer\n    >>> from sklearn.cluster import KMeans\n    >>> from sklearn.svm import SVC, SVR\n    >>> classifier = SVC()\n    >>> regressor = SVR()\n    >>> kmeans = KMeans()\n    >>> is_clusterer(classifier)\n    False\n    >>> is_clusterer(regressor)\n    False\n    >>> is_clusterer(kmeans)\n    True"
      }
    },
    {
      "name": "is_outlier_detector",
      "signature": "is_outlier_detector(estimator)",
      "documentation": {
        "description": "Return True if the given estimator is (probably) an outlier detector.\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        Estimator object to test.",
        "parameters": {
          "estimator": {
            "type": "estimator instance",
            "description": ""
          },
          "Estimator": {
            "type": "object to test.",
            "description": "Returns\n-------"
          },
          "out": {
            "type": "bool",
            "description": ""
          },
          "True": {
            "type": "if estimator is an outlier detector and False otherwise.",
            "description": ""
          }
        },
        "returns": "-------\n    out : bool\n        True if estimator is an outlier detector and False otherwise.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "is_regressor",
      "signature": "is_regressor(estimator)",
      "documentation": {
        "description": "Return True if the given estimator is (probably) a regressor.\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        Estimator object to test.\n\n    Returns\n    -------\n    out : bool\n        True if estimator is a regressor and False otherwise.",
        "parameters": {
          "estimator": {
            "type": "estimator instance",
            "description": ""
          },
          "Estimator": {
            "type": "object to test.",
            "description": "Returns\n-------"
          },
          "out": {
            "type": "bool",
            "description": ""
          },
          "True": {
            "type": "if estimator is a regressor and False otherwise.",
            "description": "Examples\n--------\n>>> from sklearn.base import is_regressor\n>>> from sklearn.cluster import KMeans\n>>> from sklearn.svm import SVC, SVR\n>>> classifier = SVC()\n>>> regressor = SVR()\n>>> kmeans = KMeans()\n>>> is_regressor(classifier)\nFalse\n>>> is_regressor(regressor)\nTrue\n>>> is_regressor(kmeans)\nFalse"
          }
        },
        "returns": "-------\n    out : bool\n        True if estimator is a regressor and False otherwise.\n\n    Examples\n    --------\n    >>> from sklearn.base import is_regressor\n    >>> from sklearn.cluster import KMeans\n    >>> from sklearn.svm import SVC, SVR\n    >>> classifier = SVC()\n    >>> regressor = SVR()\n    >>> kmeans = KMeans()\n    >>> is_regressor(classifier)\n    False\n    >>> is_regressor(regressor)\n    True\n    >>> is_regressor(kmeans)\n    False",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.base import is_regressor\n    >>> from sklearn.cluster import KMeans\n    >>> from sklearn.svm import SVC, SVR\n    >>> classifier = SVC()\n    >>> regressor = SVR()\n    >>> kmeans = KMeans()\n    >>> is_regressor(classifier)\n    False\n    >>> is_regressor(regressor)\n    True\n    >>> is_regressor(kmeans)\n    False"
      }
    },
    {
      "name": "validate_data",
      "signature": "validate_data(_estimator, /, X='no_validation', y='no_validation', reset=True, validate_separately=False, skip_check_array=False, **check_params)",
      "documentation": {
        "description": "Validate input data and set or check feature names and counts of the input.\n\n    This helper function should be used in an estimator that requires input\n    validation. This mutates the estimator and sets the `n_features_in_` and\n    `feature_names_in_` attributes if `reset=True`.\n\n    .. versionadded:: 1.6\n\n    Parameters\n    ----------\n    _estimator : estimator instance\n        The estimator to validate the input for.\n\n    X : {array-like, sparse matrix, dataframe} of shape             (n_samples, n_features), default='no validation'\n        The input samples.\n        If `'no_validation'`, no validation is performed on `X`. This is\n        useful for meta-estimator which can delegate input validation to\n        their underlying estimator(s). In that case `y` must be passed and\n        the only accepted `check_params` are `multi_output` and\n        `y_numeric`.\n\n    y : array-like of shape (n_samples,), default='no_validation'\n        The targets.\n\n        - If `None`, :func:`~sklearn.utils.check_array` is called on `X`. If\n          the estimator's `requires_y` tag is True, then an error will be raised.\n        - If `'no_validation'`, :func:`~sklearn.utils.check_array` is called\n          on `X` and the estimator's `requires_y` tag is ignored. This is a default\n          placeholder and is never meant to be explicitly set. In that case `X` must be\n          passed.\n        - Otherwise, only `y` with `_check_y` or both `X` and `y` are checked with\n          either :func:`~sklearn.utils.check_array` or\n          :func:`~sklearn.utils.check_X_y` depending on `validate_separately`.\n\n    reset : bool, default=True\n        Whether to reset the `n_features_in_` attribute.\n        If False, the input will be checked for consistency with data\n        provided when reset was last True.\n\n        .. note::\n\n           It is recommended to call `reset=True` in `fit` and in the first\n           call to `partial_fit`. All other methods that validate `X`\n           should set `reset=False`.\n\n    validate_separately : False or tuple of dicts, default=False\n        Only used if `y` is not `None`.\n        If `False`, call :func:`~sklearn.utils.check_X_y`. Else, it must be a tuple of\n        kwargs to be used for calling :func:`~sklearn.utils.check_array` on `X` and `y`\n        respectively.\n\n        `estimator=self` is automatically added to these dicts to generate\n        more informative error message in case of invalid input data.\n\n    skip_check_array : bool, default=False\n        If `True`, `X` and `y` are unchanged and only `feature_names_in_` and\n        `n_features_in_` are checked. Otherwise, :func:`~sklearn.utils.check_array`\n        is called on `X` and `y`.\n\n    **check_params : kwargs\n        Parameters passed to :func:`~sklearn.utils.check_array` or\n        :func:`~sklearn.utils.check_X_y`. Ignored if validate_separately\n        is not False.\n\n        `estimator=self` is automatically added to these params to generate\n        more informative error message in case of invalid input data.",
        "parameters": {
          "_estimator": {
            "type": "estimator instance",
            "description": ""
          },
          "The": {
            "type": "targets.",
            "description": "- If `None`, :func:`~sklearn.utils.check_array` is called on `X`. If"
          },
          "X": {
            "type": "{array",
            "description": "like, sparse matrix, dataframe} of shape             (n_samples, n_features), default='no validation'"
          },
          "If": {
            "type": "`True`, `X` and `y` are unchanged and only `feature_names_in_` and",
            "description": "`n_features_in_` are checked. Otherwise, :func:`~sklearn.utils.check_array`"
          },
          "useful": {
            "type": "for meta-estimator which can delegate input validation to",
            "description": ""
          },
          "their": {
            "type": "underlying estimator(s). In that case `y` must be passed and",
            "description": ""
          },
          "the": {
            "type": "estimator's `requires_y` tag is True, then an error will be raised.",
            "description": "- If `'no_validation'`, :func:`~sklearn.utils.check_array` is called"
          },
          "y": {
            "type": "array",
            "description": "like of shape (n_samples,), default='no_validation'"
          },
          "on": {
            "type": "`X` and the estimator's `requires_y` tag is ignored. This is a default",
            "description": ""
          },
          "placeholder": {
            "type": "and is never meant to be explicitly set. In that case `X` must be",
            "description": "passed.\n- Otherwise, only `y` with `_check_y` or both `X` and `y` are checked with"
          },
          "either": {
            "type": "func:`~sklearn.utils.check_array` or",
            "description": ":func:`~sklearn.utils.check_X_y` depending on `validate_separately`."
          },
          "reset": {
            "type": "bool, default=True",
            "description": ""
          },
          "Whether": {
            "type": "to reset the `n_features_in_` attribute.",
            "description": ""
          },
          "provided": {
            "type": "when reset was last True.",
            "description": ".. note::"
          },
          "It": {
            "type": "is recommended to call `reset=True` in `fit` and in the first",
            "description": ""
          },
          "call": {
            "type": "to `partial_fit`. All other methods that validate `X`",
            "description": ""
          },
          "should": {
            "type": "set `reset=False`.",
            "description": ""
          },
          "validate_separately": {
            "type": "False or tuple of dicts, default=False",
            "description": ""
          },
          "Only": {
            "type": "used if `y` is not `None`.",
            "description": ""
          },
          "kwargs": {
            "type": "to be used for calling :func:`~sklearn.utils.check_array` on `X` and `y`",
            "description": "respectively.\n`estimator=self` is automatically added to these dicts to generate"
          },
          "more": {
            "type": "informative error message in case of invalid input data.",
            "description": ""
          },
          "skip_check_array": {
            "type": "bool, default=False",
            "description": ""
          },
          "is": {
            "type": "called on `X` and `y`.",
            "description": "**check_params : kwargs"
          }
        },
        "returns": "-------\n    out : {ndarray, sparse matrix} or tuple of these\n        The validated input. A tuple is returned if both `X` and `y` are\n        validated.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "validate_parameter_constraints",
      "signature": "validate_parameter_constraints(parameter_constraints, params, caller_name)",
      "documentation": {
        "description": "Validate types and values of given parameters.",
        "parameters": {
          "parameter_constraints": {
            "type": "dict or {\"no_validation\"}",
            "description": ""
          },
          "If": {
            "type": "a dict, it must be a dictionary `param_name: list of constraints`.",
            "description": ""
          },
          "A": {
            "type": "dictionary `param_name: param_value`. The parameters to validate against the",
            "description": "constraints."
          },
          "Constraints": {
            "type": "can be:",
            "description": "- an Interval object, representing a continuous or discrete range of numbers\n- the string \"array-like\"\n- the string \"sparse matrix\"\n- the string \"random_state\"\n- callable\n- None, meaning that None is a valid value for the parameter\n- any type, meaning that any instance of this type is valid\n- an Options object, representing a set of elements of a given type\n- a StrOptions object, representing a set of strings\n- the string \"boolean\"\n- the string \"verbose\"\n- the string \"cv_object\"\n- the string \"nan\"\n- a MissingValues object representing markers for missing values\n- a HasMethods object, representing method(s) an object must have\n- a Hidden object, representing a constraint not meant to be exposed to the user"
          },
          "params": {
            "type": "dict",
            "description": ""
          },
          "caller_name": {
            "type": "str",
            "description": ""
          },
          "The": {
            "type": "name of the estimator or function or method that called this function.",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    }
  ],
  "classes": [
    {
      "name": "BaseEstimator",
      "documentation": {
        "description": "Base class for all estimators in scikit-learn.\n\n    Inheriting from this class provides default implementations of:\n\n    - setting and getting parameters used by `GridSearchCV` and friends;\n    - textual and HTML representation displayed in terminals and IDEs;\n    - estimator serialization;\n    - parameters validation;\n    - data validation;\n    - feature names validation.\n\n    Read more in the :ref:`User Guide <rolling_your_own_estimator>`.\n\n\n    Notes\n    -----\n    All estimators should specify all the parameters that can be set\n    at the class level in their ``__init__`` as explicit keyword\n    arguments (no ``*args`` or ``**kwargs``).",
        "parameters": {
          "array": {
            "type": "[3, 3, 3]",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "-----\n    All estimators should specify all the parameters that can be set\n    at the class level in their ``__init__`` as explicit keyword\n    arguments (no ``*args`` or ``**kwargs``).\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.base import BaseEstimator\n    >>> class MyEstimator(BaseEstimator):\n    ...     def __init__(self, *, param=1):\n    ...         self.param = param\n    ...     def fit(self, X, y=None):\n    ...         self.is_fitted_ = True\n    ...         return self\n    ...     def predict(self, X):\n    ...         return np.full(shape=X.shape[0], fill_value=self.param)\n    >>> estimator = MyEstimator(param=2)\n    >>> estimator.get_params()\n    {'param': 2}\n    >>> X = np.array([[1, 2], [2, 3], [3, 4]])\n    >>> y = np.array([1, 0, 1])\n    >>> estimator.fit(X, y).predict(X)\n    array([2, 2, 2])\n    >>> estimator.set_params(param=3).fit(X, y).predict(X)\n    array([3, 3, 3])",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.base import BaseEstimator\n    >>> class MyEstimator(BaseEstimator):\n    ...     def __init__(self, *, param=1):\n    ...         self.param = param\n    ...     def fit(self, X, y=None):\n    ...         self.is_fitted_ = True\n    ...         return self\n    ...     def predict(self, X):\n    ...         return np.full(shape=X.shape[0], fill_value=self.param)\n    >>> estimator = MyEstimator(param=2)\n    >>> estimator.get_params()\n    {'param': 2}\n    >>> X = np.array([[1, 2], [2, 3], [3, 4]])\n    >>> y = np.array([1, 0, 1])\n    >>> estimator.fit(X, y).predict(X)\n    array([2, 2, 2])\n    >>> estimator.set_params(param=3).fit(X, y).predict(X)\n    array([3, 3, 3])"
      },
      "methods": [
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "BiclusterMixin",
      "documentation": {
        "description": "Mixin class for all bicluster estimators in scikit-learn.\n\n    This mixin defines the following functionality:\n\n    - `biclusters_` property that returns the row and column indicators;\n    - `get_indices` method that returns the row and column indices of a bicluster;\n    - `get_shape` method that returns the shape of a bicluster;\n    - `get_submatrix` method that returns the submatrix corresponding to a bicluster.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.base import BaseEstimator, BiclusterMixin\n    >>> class DummyBiClustering(BiclusterMixin, BaseEstimator):\n    ...     def fit(self, X, y=None):\n    ...         self.rows_ = np.ones(shape=(1, X.shape[0]), dtype=bool)\n    ...         self.columns_ = np.ones(shape=(1, X.shape[1]), dtype=bool)\n    ...         return self\n    >>> X = np.array([[1, 1], [2, 1], [1, 0],\n    ...               [4, 7], [3, 5], [3, 6]])\n    >>> bicluster = DummyBiClustering().fit(X)\n    >>> hasattr(bicluster, \"biclusters_\")\n    True\n    >>> bicluster.get_indices(0)\n    (array([0, 1, 2, 3, 4, 5]), array([0, 1]))"
      },
      "methods": [
        {
          "name": "get_indices",
          "signature": "get_indices(self, i)",
          "documentation": {
            "description": "Row and column indices of the `i`'th bicluster.\n\n        Only works if ``rows_`` and ``columns_`` attributes exist.\n\n        Parameters\n        ----------\n        i : int\n            The index of the cluster.",
            "parameters": {
              "i": {
                "type": "int",
                "description": ""
              },
              "The": {
                "type": "index of the cluster.",
                "description": "Returns\n-------"
              },
              "row_ind": {
                "type": "ndarray, dtype=np.intp",
                "description": ""
              },
              "Indices": {
                "type": "of columns in the dataset that belong to the bicluster.",
                "description": ""
              },
              "col_ind": {
                "type": "ndarray, dtype=np.intp",
                "description": ""
              }
            },
            "returns": "-------\n        row_ind : ndarray, dtype=np.intp\n            Indices of rows in the dataset that belong to the bicluster.\n        col_ind : ndarray, dtype=np.intp\n            Indices of columns in the dataset that belong to the bicluster.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_shape",
          "signature": "get_shape(self, i)",
          "documentation": {
            "description": "Shape of the `i`'th bicluster.\n\n        Parameters\n        ----------\n        i : int\n            The index of the cluster.",
            "parameters": {
              "i": {
                "type": "int",
                "description": ""
              },
              "The": {
                "type": "index of the cluster.",
                "description": "Returns\n-------"
              },
              "n_rows": {
                "type": "int",
                "description": ""
              },
              "Number": {
                "type": "of columns in the bicluster.",
                "description": ""
              },
              "n_cols": {
                "type": "int",
                "description": ""
              }
            },
            "returns": "-------\n        n_rows : int\n            Number of rows in the bicluster.\n\n        n_cols : int\n            Number of columns in the bicluster.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_submatrix",
          "signature": "get_submatrix(self, i, data)",
          "documentation": {
            "description": "Return the submatrix corresponding to bicluster `i`.\n\n        Parameters\n        ----------\n        i : int\n            The index of the cluster.\n        data : array-like of shape (n_samples, n_features)\n            The data.\n\n        Returns\n        -------\n        submatrix : ndarray of shape (n_rows, n_cols)\n            The submatrix corresponding to bicluster `i`.",
            "parameters": {
              "i": {
                "type": "int",
                "description": ""
              },
              "The": {
                "type": "submatrix corresponding to bicluster `i`.",
                "description": "Notes\n-----"
              },
              "data": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "submatrix": {
                "type": "ndarray of shape (n_rows, n_cols)",
                "description": ""
              },
              "Works": {
                "type": "with sparse matrices. Only works if ``rows_`` and",
                "description": "``columns_`` attributes exist."
              }
            },
            "returns": "-------\n        submatrix : ndarray of shape (n_rows, n_cols)\n            The submatrix corresponding to bicluster `i`.\n\n        Notes\n        -----\n        Works with sparse matrices. Only works if ``rows_`` and\n        ``columns_`` attributes exist.",
            "raises": "",
            "see_also": "",
            "notes": "-----\n        Works with sparse matrices. Only works if ``rows_`` and\n        ``columns_`` attributes exist.",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "ClassNamePrefixFeaturesOutMixin",
      "documentation": {
        "description": "Mixin class for transformers that generate their own names by prefixing.\n\n    This mixin is useful when the transformer needs to generate its own feature\n    names out, such as :class:`~sklearn.decomposition.PCA`. For example, if\n    :class:`~sklearn.decomposition.PCA` outputs 3 features, then the generated feature\n    names out are: `[\"pca0\", \"pca1\", \"pca2\"]`.\n\n    This mixin assumes that a `_n_features_out` attribute is defined when the\n    transformer is fitted. `_n_features_out` is the number of output features\n    that the transformer will return in `transform` of `fit_transform`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.base import ClassNamePrefixFeaturesOutMixin, BaseEstimator\n    >>> class MyEstimator(ClassNamePrefixFeaturesOutMixin, BaseEstimator):\n    ...     def fit(self, X, y=None):\n    ...         self._n_features_out = X.shape[1]\n    ...         return self\n    >>> X = np.array([[1, 2], [3, 4]])\n    >>> MyEstimator().fit(X).get_feature_names_out()\n    array(['myestimator0', 'myestimator1'], dtype=object)"
      },
      "methods": [
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Get output feature names for transformation.\n\n        The feature names out will prefixed by the lowercased class name. For\n        example, if the transformer outputs 3 features, then the feature names\n        out are: `[\"class_name0\", \"class_name1\", \"class_name2\"]`.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Only used to validate feature names with the names seen in `fit`.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Only": {
                "type": "used to validate feature names with the names seen in `fit`.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Transformed": {
                "type": "feature names.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Transformed feature names.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "ClassifierMixin",
      "documentation": {
        "description": "Mixin class for all classifiers in scikit-learn.\n\n    This mixin defines the following functionality:\n\n    - set estimator type to `\"classifier\"` through the `estimator_type` tag;\n    - `score` method that default to :func:`~sklearn.metrics.accuracy_score`.\n    - enforce that `fit` requires `y` to be passed through the `requires_y` tag,\n      which is done by setting the classifier type tag.\n\n    Read more in the :ref:`User Guide <rolling_your_own_estimator>`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.base import BaseEstimator, ClassifierMixin\n    >>> # Mixin classes should always be on the left-hand side for a correct MRO\n    >>> class MyEstimator(ClassifierMixin, BaseEstimator):\n    ...     def __init__(self, *, param=1):\n    ...         self.param = param\n    ...     def fit(self, X, y=None):\n    ...         self.is_fitted_ = True\n    ...         return self\n    ...     def predict(self, X):\n    ...         return np.full(shape=X.shape[0], fill_value=self.param)\n    >>> estimator = MyEstimator(param=1)\n    >>> X = np.array([[1, 2], [2, 3], [3, 4]])\n    >>> y = np.array([1, 0, 1])\n    >>> estimator.fit(X, y).predict(X)\n    array([1, 1, 1])\n    >>> estimator.score(X, y)\n    0.66..."
      },
      "methods": [
        {
          "name": "score",
          "signature": "score(self, X, y, sample_weight=None)",
          "documentation": {
            "description": "",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Test": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs)"
              },
              "True": {
                "type": "labels for `X`.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Sample": {
                "type": "weights.",
                "description": "Returns\n-------"
              },
              "score": {
                "type": "float",
                "description": ""
              },
              "Mean": {
                "type": "accuracy of ``self.predict(X)`` w.r.t. `y`.",
                "description": ""
              }
            },
            "returns": "the mean accuracy on the given test data and labels.\n\n        In multi-label classification, this is the subset accuracy\n        which is a harsh metric since you require for each sample that\n        each label set be correctly predicted.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Test samples.\n\n        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n            True labels for `X`.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Sample weights.\n\n        Returns\n        -------\n        score : float\n            Mean accuracy of ``self.predict(X)`` w.r.t. `y`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "ClassifierTags",
      "documentation": {
        "description": "Tags for the classifier.",
        "parameters": {
          "poor_score": {
            "type": "bool, default=False",
            "description": ""
          },
          "Whether": {
            "type": "the classifier supports multi-label output: a data point can",
            "description": ""
          },
          "datasets": {
            "type": "and values are based on current estimators in scikit-learn",
            "description": ""
          },
          "and": {
            "type": "might be replaced by something more systematic.",
            "description": ""
          },
          "multi_class": {
            "type": "bool, default=True",
            "description": ""
          },
          "classifier": {
            "type": "is a binary-classifier-only or not.",
            "description": ""
          },
          "See": {
            "type": "term:`multi",
            "description": "label` in the glossary."
          },
          "multi_label": {
            "type": "bool, default=False",
            "description": ""
          },
          "be": {
            "type": "predicted to belong to a variable number of classes.",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": []
    },
    {
      "name": "ClusterMixin",
      "documentation": {
        "description": "Mixin class for all cluster estimators in scikit-learn.\n\n    - set estimator type to `\"clusterer\"` through the `estimator_type` tag;\n    - `fit_predict` method returning the cluster labels associated to each sample.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.base import BaseEstimator, ClusterMixin\n    >>> class MyClusterer(ClusterMixin, BaseEstimator):\n    ...     def fit(self, X, y=None):\n    ...         self.labels_ = np.ones(shape=(len(X),), dtype=np.int64)\n    ...         return self\n    >>> X = [[1, 2], [2, 3], [3, 4]]\n    >>> MyClusterer().fit_predict(X)\n    array([1, 1, 1])"
      },
      "methods": [
        {
          "name": "fit_predict",
          "signature": "fit_predict(self, X, y=None, **kwargs)",
          "documentation": {
            "description": "Perform clustering on `X` and returns cluster labels.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input data.\n\n        y : Ignored\n            Not used, present for API consistency by convention.\n\n        **kwargs : dict\n            Arguments to be passed to ``fit``.\n\n            .. versionadded:: 1.4",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "data.",
                "description": ""
              },
              "y": {
                "type": "Ignored",
                "description": ""
              },
              "Not": {
                "type": "used, present for API consistency by convention.",
                "description": "**kwargs : dict"
              },
              "Arguments": {
                "type": "to be passed to ``fit``.",
                "description": ".. versionadded:: 1.4\nReturns\n-------"
              },
              "labels": {
                "type": "ndarray of shape (n_samples,), dtype=np.int64",
                "description": ""
              },
              "Cluster": {
                "type": "labels.",
                "description": ""
              },
              "to": {
                "type": "be passed to ``fit``.",
                "description": ".. versionadded:: 1.4\nReturns\n-------"
              }
            },
            "returns": "-------\n        labels : ndarray of shape (n_samples,), dtype=np.int64\n            Cluster labels.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "DensityMixin",
      "documentation": {
        "description": "Mixin class for all density estimators in scikit-learn.\n\n    This mixin defines the following functionality:\n\n    - sets estimator type to `\"density_estimator\"` through the `estimator_type` tag;\n    - `score` method that default that do no-op.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.base import DensityMixin\n    >>> class MyEstimator(DensityMixin):\n    ...     def fit(self, X, y=None):\n    ...         self.is_fitted_ = True\n    ...         return self\n    >>> estimator = MyEstimator()\n    >>> hasattr(estimator, \"score\")\n    True"
      },
      "methods": [
        {
          "name": "score",
          "signature": "score(self, X, y=None)",
          "documentation": {
            "description": "Return the score of the model on the data `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Test samples.\n\n        y : Ignored\n            Not used, present for API consistency by convention.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Test": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "Ignored",
                "description": ""
              },
              "Not": {
                "type": "used, present for API consistency by convention.",
                "description": "Returns\n-------"
              },
              "score": {
                "type": "float",
                "description": ""
              }
            },
            "returns": "-------\n        score : float",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "InconsistentVersionWarning",
      "documentation": {
        "description": "Warning raised when an estimator is unpickled with a inconsistent version.",
        "parameters": {
          "estimator_name": {
            "type": "str",
            "description": ""
          },
          "Estimator": {
            "type": "name.",
            "description": ""
          },
          "current_sklearn_version": {
            "type": "str",
            "description": ""
          },
          "Current": {
            "type": "scikit-learn version.",
            "description": ""
          },
          "original_sklearn_version": {
            "type": "str",
            "description": ""
          },
          "Original": {
            "type": "scikit-learn version.",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "add_note",
          "signature": "add_note(note)",
          "documentation": {
            "description": "Exception.add_note(note) --\n    add a note to the exception",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_traceback",
          "signature": "with_traceback(tb)",
          "documentation": {
            "description": "Exception.with_traceback(tb) --\n    set self.__traceback__ to tb and return self.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "MetaEstimatorMixin",
      "documentation": {
        "description": "Mixin class for all meta estimators in scikit-learn.\n\n    This mixin is empty, and only exists to indicate that the estimator is a\n    meta-estimator.\n\n    .. versionchanged:: 1.6\n        The `_required_parameters` is now removed and is unnecessary since tests are\n        refactored and don't use this anymore.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.base import MetaEstimatorMixin\n    >>> from sklearn.datasets import load_iris\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> class MyEstimator(MetaEstimatorMixin):\n    ...     def __init__(self, *, estimator=None):\n    ...         self.estimator = estimator\n    ...     def fit(self, X, y=None):\n    ...         if self.estimator is None:\n    ...             self.estimator_ = LogisticRegression()\n    ...         else:\n    ...             self.estimator_ = self.estimator\n    ...         return self\n    >>> X, y = load_iris(return_X_y=True)\n    >>> estimator = MyEstimator().fit(X, y)\n    >>> estimator.estimator_\n    LogisticRegression()"
      },
      "methods": []
    },
    {
      "name": "MultiOutputMixin",
      "documentation": {
        "description": "Mixin to mark estimators that support multioutput.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": []
    },
    {
      "name": "OneToOneFeatureMixin",
      "documentation": {
        "description": "Provides `get_feature_names_out` for simple transformers.\n\n    This mixin assumes there's a 1-to-1 correspondence between input features\n    and output features, such as :class:`~sklearn.preprocessing.StandardScaler`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.base import OneToOneFeatureMixin, BaseEstimator\n    >>> class MyEstimator(OneToOneFeatureMixin, BaseEstimator):\n    ...     def fit(self, X, y=None):\n    ...         self.n_features_in_ = X.shape[1]\n    ...         return self\n    >>> X = np.array([[1, 2], [3, 4]])\n    >>> MyEstimator().fit(X).get_feature_names_out()\n    array(['x0', 'x1'], dtype=object)"
      },
      "methods": [
        {
          "name": "get_feature_names_out",
          "signature": "get_feature_names_out(self, input_features=None)",
          "documentation": {
            "description": "Get output feature names for transformation.\n\n        Parameters\n        ----------\n        input_features : array-like of str or None, default=None\n            Input features.\n\n            - If `input_features` is `None`, then `feature_names_in_` is\n              used as feature names in. If `feature_names_in_` is not defined,\n              then the following input feature names are generated:\n              `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n            - If `input_features` is an array-like, then `input_features` must\n              match `feature_names_in_` if `feature_names_in_` is defined.",
            "parameters": {
              "input_features": {
                "type": "array",
                "description": "like of str or None, default=None"
              },
              "Input": {
                "type": "features.",
                "description": "- If `input_features` is `None`, then `feature_names_in_` is"
              },
              "used": {
                "type": "as feature names in. If `feature_names_in_` is not defined,",
                "description": ""
              },
              "then": {
                "type": "the following input feature names are generated:",
                "description": "`[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n- If `input_features` is an array-like, then `input_features` must"
              },
              "match": {
                "type": "`feature_names_in_` if `feature_names_in_` is defined.",
                "description": "Returns\n-------"
              },
              "feature_names_out": {
                "type": "ndarray of str objects",
                "description": ""
              },
              "Same": {
                "type": "as input features.",
                "description": ""
              }
            },
            "returns": "-------\n        feature_names_out : ndarray of str objects\n            Same as input features.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "OutlierMixin",
      "documentation": {
        "description": "Mixin class for all outlier detection estimators in scikit-learn.\n\n    This mixin defines the following functionality:\n\n    - set estimator type to `\"outlier_detector\"` through the `estimator_type` tag;\n    - `fit_predict` method that default to `fit` and `predict`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.base import BaseEstimator, OutlierMixin\n    >>> class MyEstimator(OutlierMixin):\n    ...     def fit(self, X, y=None):\n    ...         self.is_fitted_ = True\n    ...         return self\n    ...     def predict(self, X):\n    ...         return np.ones(shape=len(X))\n    >>> estimator = MyEstimator()\n    >>> X = np.array([[1, 2], [2, 3], [3, 4]])\n    >>> estimator.fit_predict(X)\n    array([1., 1., 1.])"
      },
      "methods": [
        {
          "name": "fit_predict",
          "signature": "fit_predict(self, X, y=None, **kwargs)",
          "documentation": {
            "description": "Perform fit on X and returns labels for X.",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like, sparse matrix} of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": ""
              },
              "y": {
                "type": "ndarray of shape (n_samples,)",
                "description": ""
              },
              "Not": {
                "type": "used, present for API consistency by convention.",
                "description": "**kwargs : dict"
              },
              "Arguments": {
                "type": "to be passed to ``fit``.",
                "description": ".. versionadded:: 1.4\nReturns\n-------"
              },
              "1": {
                "type": "for inliers, -1 for outliers.",
                "description": ""
              },
              "to": {
                "type": "be passed to ``fit``.",
                "description": ".. versionadded:: 1.4\nReturns\n-------"
              }
            },
            "returns": "-1 for outliers and 1 for inliers.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            The input samples.\n\n        y : Ignored\n            Not used, present for API consistency by convention.\n\n        **kwargs : dict\n            Arguments to be passed to ``fit``.\n\n            .. versionadded:: 1.4",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "RegressorMixin",
      "documentation": {
        "description": "Mixin class for all regression estimators in scikit-learn.\n\n    This mixin defines the following functionality:\n\n    - set estimator type to `\"regressor\"` through the `estimator_type` tag;\n    - `score` method that default to :func:`~sklearn.metrics.r2_score`.\n    - enforce that `fit` requires `y` to be passed through the `requires_y` tag,\n      which is done by setting the regressor type tag.\n\n    Read more in the :ref:`User Guide <rolling_your_own_estimator>`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.base import BaseEstimator, RegressorMixin\n    >>> # Mixin classes should always be on the left-hand side for a correct MRO\n    >>> class MyEstimator(RegressorMixin, BaseEstimator):\n    ...     def __init__(self, *, param=1):\n    ...         self.param = param\n    ...     def fit(self, X, y=None):\n    ...         self.is_fitted_ = True\n    ...         return self\n    ...     def predict(self, X):\n    ...         return np.full(shape=X.shape[0], fill_value=self.param)\n    >>> estimator = MyEstimator(param=0)\n    >>> X = np.array([[1, 2], [2, 3], [3, 4]])\n    >>> y = np.array([-1, 0, 1])\n    >>> estimator.fit(X, y).predict(X)\n    array([0, 0, 0])\n    >>> estimator.score(X, y)\n    0.0"
      },
      "methods": [
        {
          "name": "score",
          "signature": "score(self, X, y, sample_weight=None)",
          "documentation": {
            "description": "Return the coefficient of determination of the prediction.\n\n        The coefficient of determination :math:`R^2` is defined as\n        :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n        sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n        is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n        The best possible score is 1.0 and it can be negative (because the\n        model can be arbitrarily worse). A constant model that always predicts\n        the expected value of `y`, disregarding the input features, would get\n        a :math:`R^2` score of 0.0.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Test samples. For some estimators this may be a precomputed\n            kernel matrix or a list of generic objects instead with shape\n            ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n            is the number of samples used in the fitting for the estimator.\n\n        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n            True values for `X`.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Sample weights.\n\n        Returns\n        -------\n        score : float\n            :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Test": {
                "type": "samples. For some estimators this may be a precomputed",
                "description": ""
              },
              "kernel": {
                "type": "matrix or a list of generic objects instead with shape",
                "description": "``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``"
              },
              "is": {
                "type": "the number of samples used in the fitting for the estimator.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs)"
              },
              "True": {
                "type": "values for `X`.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Sample": {
                "type": "weights.",
                "description": "Returns\n-------"
              },
              "score": {
                "type": "float",
                "description": ":math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\nNotes\n-----"
              },
              "The": {
                "type": "math:`R^2` score used when calling ``score`` on a regressor uses",
                "description": "``multioutput='uniform_average'`` from version 0.23 to keep consistent"
              },
              "with": {
                "type": "default value of :func:`~sklearn.metrics.r2_score`.",
                "description": ""
              },
              "This": {
                "type": "influences the ``score`` method of all the multioutput",
                "description": ""
              },
              "regressors": {
                "type": "(except for",
                "description": ":class:`~sklearn.multioutput.MultiOutputRegressor`)."
              }
            },
            "returns": "-------\n        score : float\n            :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n\n        Notes\n        -----\n        The :math:`R^2` score used when calling ``score`` on a regressor uses\n        ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n        with default value of :func:`~sklearn.metrics.r2_score`.\n        This influences the ``score`` method of all the multioutput\n        regressors (except for\n        :class:`~sklearn.multioutput.MultiOutputRegressor`).",
            "raises": "",
            "see_also": "",
            "notes": "-----\n        The :math:`R^2` score used when calling ``score`` on a regressor uses\n        ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n        with default value of :func:`~sklearn.metrics.r2_score`.\n        This influences the ``score`` method of all the multioutput\n        regressors (except for\n        :class:`~sklearn.multioutput.MultiOutputRegressor`).",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "RegressorTags",
      "documentation": {
        "description": "Tags for the regressor.",
        "parameters": {
          "poor_score": {
            "type": "bool, default=False",
            "description": ""
          },
          "Whether": {
            "type": "the estimator fails to provide a \"reasonable\" test-set",
            "description": "score, which currently for regression is an R2 of 0.5 on\n``make_regression(n_samples=200, n_features=10,\nn_informative=1, bias=5.0, noise=20, random_state=42)``. The"
          },
          "dataset": {
            "type": "and values are based on current estimators in scikit-learn",
            "description": ""
          },
          "and": {
            "type": "might be replaced by something more systematic.",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": []
    },
    {
      "name": "Tags",
      "documentation": {
        "description": "Tags for the estimator.\n\n    See :ref:`estimator_tags` for more information.",
        "parameters": {
          "estimator_type": {
            "type": "str or None",
            "description": ""
          },
          "The": {
            "type": "input data(X) tags.",
            "description": ""
          },
          "target_tags": {
            "type": ":class:`TargetTags`",
            "description": ""
          },
          "transformer_tags": {
            "type": ":class:`TransformerTags` or None",
            "description": ""
          },
          "classifier_tags": {
            "type": ":class:`ClassifierTags` or None",
            "description": ""
          },
          "regressor_tags": {
            "type": ":class:`RegressorTags` or None",
            "description": ""
          },
          "array_api_support": {
            "type": "bool, default=False",
            "description": ""
          },
          "Whether": {
            "type": "to skip common tests entirely. Don't use this unless",
            "description": ""
          },
          "no_validation": {
            "type": "bool, default=False",
            "description": ""
          },
          "stateless": {
            "type": "and dummy transformers!",
            "description": ""
          },
          "non_deterministic": {
            "type": "bool, default=False",
            "description": ""
          },
          "requires_fit": {
            "type": "bool, default=True",
            "description": ""
          },
          "_skip_test": {
            "type": "bool, default=False",
            "description": ""
          },
          "you": {
            "type": "have a *very good* reason.",
            "description": ""
          },
          "input_tags": {
            "type": ":class:`InputTags`",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": []
    },
    {
      "name": "TargetTags",
      "documentation": {
        "description": "Tags for the target data.",
        "parameters": {
          "required": {
            "type": "bool",
            "description": ""
          },
          "Whether": {
            "type": "the target can be single-output. This can be ``False`` if the",
            "description": ""
          },
          "for": {
            "type": "regression).",
            "description": ""
          },
          "and": {
            "type": "`~sklearn.base.ClassifierMixin`.",
            "description": ""
          },
          "one_d_labels": {
            "type": "bool, default=False",
            "description": ""
          },
          "two_d_labels": {
            "type": "bool, default=False",
            "description": ""
          },
          "positive_only": {
            "type": "bool, default=False",
            "description": ""
          },
          "multi_output": {
            "type": "bool, default=False",
            "description": ""
          },
          "See": {
            "type": "term:`multi",
            "description": "output` in the glossary."
          },
          "single_output": {
            "type": "bool, default=True",
            "description": ""
          },
          "estimator": {
            "type": "supports only multi-output cases.",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": []
    },
    {
      "name": "TransformerMixin",
      "documentation": {
        "description": "Mixin class for all transformers in scikit-learn.\n\n    This mixin defines the following functionality:\n\n    - a `fit_transform` method that delegates to `fit` and `transform`;\n    - a `set_output` method to output `X` as a specific container type.\n\n    If :term:`get_feature_names_out` is defined, then :class:`BaseEstimator` will\n    automatically wrap `transform` and `fit_transform` to follow the `set_output`\n    API. See the :ref:`developer_api_set_output` for details.\n\n    :class:`OneToOneFeatureMixin` and\n    :class:`ClassNamePrefixFeaturesOutMixin` are helpful mixins for\n    defining :term:`get_feature_names_out`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.base import BaseEstimator, TransformerMixin\n    >>> class MyTransformer(TransformerMixin, BaseEstimator):\n    ...     def __init__(self, *, param=1):\n    ...         self.param = param\n    ...     def fit(self, X, y=None):\n    ...         return self\n    ...     def transform(self, X):\n    ...         return np.full(shape=len(X), fill_value=self.param)\n    >>> transformer = MyTransformer()\n    >>> X = [[1, 2], [2, 3], [3, 4]]\n    >>> transformer.fit_transform(X)\n    array([1, 1, 1])"
      },
      "methods": [
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, X, y=None, **fit_params)",
          "documentation": {
            "description": "Fit to data, then transform it.\n\n        Fits transformer to `X` and `y` with optional parameters `fit_params`\n        and returns a transformed version of `X`.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Input samples.\n\n        y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n            Target values (None for unsupervised transformations).\n\n        **fit_params : dict\n            Additional fit parameters.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Input": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
              },
              "Target": {
                "type": "values (None for unsupervised transformations).",
                "description": "**fit_params : dict"
              },
              "Additional": {
                "type": "fit parameters.",
                "description": "Returns\n-------"
              },
              "X_new": {
                "type": "ndarray array of shape (n_samples, n_features_new)",
                "description": ""
              },
              "Transformed": {
                "type": "array.",
                "description": ""
              }
            },
            "returns": "-------\n        X_new : ndarray array of shape (n_samples, n_features_new)\n            Transformed array.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "TransformerTags",
      "documentation": {
        "description": "Tags for the transformer.",
        "parameters": {
          "preserves_dtype": {
            "type": "list[str], default=[\"float64\"]",
            "description": ""
          },
          "Applies": {
            "type": "only on transformers. It corresponds to the data types",
            "description": ""
          },
          "which": {
            "type": "will be preserved such that `X_trans.dtype` is the same",
            "description": ""
          },
          "as": {
            "type": "`X.dtype` after calling `transformer.transform(X)`. If this",
            "description": ""
          },
          "list": {
            "type": "is empty, then the transformer is not expected to",
            "description": ""
          },
          "preserve": {
            "type": "the data type. The first value in the list is",
            "description": ""
          },
          "considered": {
            "type": "as the default data type, corresponding to the data",
            "description": ""
          },
          "type": {
            "type": "of the output when the input data type is not going to be",
            "description": "preserved."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": []
    },
    {
      "name": "defaultdict",
      "documentation": {
        "description": "defaultdict(default_factory=None, /, [...]) --> dict with default factory\n\nThe default factory is called without arguments to produce\na new value when a key is not present, in __getitem__ only.\nA defaultdict compares equal to a dict with the same items.\nAll remaining arguments are treated the same as if they were\npassed to the dict constructor, including keyword arguments.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "clear",
          "signature": "clear()",
          "documentation": {
            "description": "D.clear() -> None.  Remove all items from D.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "copy",
          "signature": "copy()",
          "documentation": {
            "description": "D.copy() -> a shallow copy of D.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fromkeys",
          "signature": "fromkeys(iterable, value=None, /)",
          "documentation": {
            "description": "Create a new dictionary with keys from iterable and values set to value.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get",
          "signature": "get(self, key, default=None, /)",
          "documentation": {
            "description": "Return the value for key if key is in the dictionary, else default.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "items",
          "signature": "items()",
          "documentation": {
            "description": "D.items() -> a set-like object providing a view on D's items",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "keys",
          "signature": "keys()",
          "documentation": {
            "description": "D.keys() -> a set-like object providing a view on D's keys",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "pop",
          "signature": "pop(k[,d])",
          "documentation": {
            "description": "D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n\nIf the key is not found, return the default if given; otherwise,\nraise a KeyError.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "popitem",
          "signature": "popitem(self, /)",
          "documentation": {
            "description": "Remove and return a (key, value) pair as a 2-tuple.\n\nPairs are returned in LIFO (last-in, first-out) order.",
            "parameters": {},
            "returns": "",
            "raises": "KeyError if the dict is empty.",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "setdefault",
          "signature": "setdefault(self, key, default=None, /)",
          "documentation": {
            "description": "Insert key with a value of default if key is not in the dictionary.",
            "parameters": {},
            "returns": "the value for key if key is in the dictionary, else default.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "update",
          "signature": "update([E, ]**F)",
          "documentation": {
            "description": "D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.\nIf E is present and has a .keys() method, then does:  for k in E: D[k] = E[k]\nIf E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\nIn either case, this is followed by: for k in F:  D[k] = F[k]",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "values",
          "signature": "values()",
          "documentation": {
            "description": "D.values() -> an object providing a view on D's values",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    }
  ]
}