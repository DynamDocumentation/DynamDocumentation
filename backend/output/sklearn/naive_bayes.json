{
  "description": "Naive Bayes algorithms.\n\nThese are supervised learning methods based on applying Bayes' theorem with strong\n(naive) feature independence assumptions.",
  "functions": [
    {
      "name": "abstractmethod",
      "signature": "abstractmethod(funcobj)",
      "documentation": {
        "description": "A decorator indicating abstract methods.\n\n    Requires that the metaclass is ABCMeta or derived from it.  A\n    class that has a metaclass derived from ABCMeta cannot be\n    instantiated unless all of its abstract methods are overridden.\n    The abstract methods can be called using any of the normal\n    'super' call mechanisms.  abstractmethod() may be used to declare\n    abstract methods for properties and descriptors.\n\n    Usage:\n\n        class C(metaclass=ABCMeta):\n            @abstractmethod\n            def my_abstract_method(self, arg1, arg2, argN):\n                ...",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "binarize",
      "signature": "binarize(X, *, threshold=0.0, copy=True)",
      "documentation": {
        "description": "Boolean thresholding of array-like or scipy.sparse matrix.\n\n    Read more in the :ref:`User Guide <preprocessing_binarization>`.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n        The data to binarize, element by element.\n        scipy.sparse matrices should be in CSR or CSC format to avoid an\n        un-necessary copy.\n\n    threshold : float, default=0.0\n        Feature values below or equal to this are replaced by 0, above it by 1.\n        Threshold may not be less than 0 for operations on sparse matrices.\n\n    copy : bool, default=True\n        If False, try to avoid a copy and binarize in place.\n        This is not guaranteed to always work in place; e.g. if the data is\n        a numpy array with an object dtype, a copy will be returned even with\n        copy=False.\n\n    Returns\n    -------\n    X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n        The transformed data.\n\n    See Also\n    --------\n    Binarizer : Performs binarization using the Transformer API\n        (e.g. as part of a preprocessing :class:`~sklearn.pipeline.Pipeline`).",
        "parameters": {
          "X": {
            "type": "{array",
            "description": "like, sparse matrix} of shape (n_samples, n_features)"
          },
          "The": {
            "type": "transformed data.",
            "description": ""
          },
          "threshold": {
            "type": "float, default=0.0",
            "description": ""
          },
          "Feature": {
            "type": "values below or equal to this are replaced by 0, above it by 1.",
            "description": ""
          },
          "Threshold": {
            "type": "may not be less than 0 for operations on sparse matrices.",
            "description": ""
          },
          "copy": {
            "type": "bool, default=True",
            "description": ""
          },
          "If": {
            "type": "False, try to avoid a copy and binarize in place.",
            "description": ""
          },
          "This": {
            "type": "is not guaranteed to always work in place; e.g. if the data is",
            "description": ""
          },
          "a": {
            "type": "numpy array with an object dtype, a copy will be returned even with",
            "description": "copy=False.\nReturns\n-------"
          },
          "X_tr": {
            "type": "{ndarray, sparse matrix} of shape (n_samples, n_features)",
            "description": ""
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "Binarizer": {
            "type": "Performs binarization using the Transformer API",
            "description": "(e.g. as part of a preprocessing :class:`~sklearn.pipeline.Pipeline`).\nExamples\n--------\n>>> from sklearn.preprocessing import binarize\n>>> X = [[0.4, 0.6, 0.5], [0.6, 0.1, 0.2]]\n>>> binarize(X, threshold=0.5)\narray([[0., 1., 0.],\n[1., 0., 0.]])"
          }
        },
        "returns": "-------\n    X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n        The transformed data.\n\n    See Also\n    --------\n    Binarizer : Performs binarization using the Transformer API\n        (e.g. as part of a preprocessing :class:`~sklearn.pipeline.Pipeline`).\n\n    Examples\n    --------\n    >>> from sklearn.preprocessing import binarize\n    >>> X = [[0.4, 0.6, 0.5], [0.6, 0.1, 0.2]]\n    >>> binarize(X, threshold=0.5)\n    array([[0., 1., 0.],\n           [1., 0., 0.]])",
        "raises": "",
        "see_also": "--------\n    Binarizer : Performs binarization using the Transformer API\n        (e.g. as part of a preprocessing :class:`~sklearn.pipeline.Pipeline`).\n\n    Examples\n    --------\n    >>> from sklearn.preprocessing import binarize\n    >>> X = [[0.4, 0.6, 0.5], [0.6, 0.1, 0.2]]\n    >>> binarize(X, threshold=0.5)\n    array([[0., 1., 0.],\n           [1., 0., 0.]])",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.preprocessing import binarize\n    >>> X = [[0.4, 0.6, 0.5], [0.6, 0.1, 0.2]]\n    >>> binarize(X, threshold=0.5)\n    array([[0., 1., 0.],\n           [1., 0., 0.]])"
      }
    },
    {
      "name": "check_is_fitted",
      "signature": "check_is_fitted(estimator, attributes=None, *, msg=None, all_or_any=<built-in function all>)",
      "documentation": {
        "description": "Perform is_fitted validation for estimator.\n\n    Checks if the estimator is fitted by verifying the presence of\n    fitted attributes (ending with a trailing underscore) and otherwise\n    raises a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n\n    If an estimator does not set any attributes with a trailing underscore, it\n    can define a ``__sklearn_is_fitted__`` method returning a boolean to\n    specify if the estimator is fitted or not. See\n    :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n    for an example on how to use the API.\n\n    If no `attributes` are passed, this fuction will pass if an estimator is stateless.\n    An estimator can indicate it's stateless by setting the `requires_fit` tag. See\n    :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n    is ignored if `attributes` are passed.\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        Estimator instance for which the check is performed.\n\n    attributes : str, list or tuple of str, default=None\n        Attribute name(s) given as string or a list/tuple of strings\n        Eg.: ``[\"coef_\", \"estimator_\", ...], \"coef_\"``\n\n        If `None`, `estimator` is considered fitted if there exist an\n        attribute that ends with a underscore and does not start with double\n        underscore.\n\n    msg : str, default=None\n        The default error message is, \"This %(name)s instance is not fitted\n        yet. Call 'fit' with appropriate arguments before using this\n        estimator.\"\n\n        For custom messages if \"%(name)s\" is present in the message string,\n        it is substituted for the estimator name.\n\n        Eg. : \"Estimator, %(name)s, must be fitted before sparsifying\".\n\n    all_or_any : callable, {all, any}, default=all\n        Specify whether all or any of the given attributes must exist.\n\n    Raises\n    ------\n    TypeError\n        If the estimator is a class or not an estimator instance\n\n    NotFittedError\n        If the attributes are not found.",
        "parameters": {
          "estimator": {
            "type": "estimator instance",
            "description": ""
          },
          "Estimator": {
            "type": "instance for which the check is performed.",
            "description": ""
          },
          "attributes": {
            "type": "str, list or tuple of str, default=None",
            "description": ""
          },
          "Attribute": {
            "type": "name(s) given as string or a list/tuple of strings",
            "description": "Eg.: ``[\"coef_\", \"estimator_\", ...], \"coef_\"``"
          },
          "If": {
            "type": "the attributes are not found.",
            "description": "Examples\n--------\n>>> from sklearn.linear_model import LogisticRegression\n>>> from sklearn.utils.validation import check_is_fitted\n>>> from sklearn.exceptions import NotFittedError\n>>> lr = LogisticRegression()\n>>> try:\n...     check_is_fitted(lr)\n... except NotFittedError as exc:\n...     print(f\"Model is not fitted yet.\")"
          },
          "attribute": {
            "type": "that ends with a underscore and does not start with double",
            "description": "underscore."
          },
          "msg": {
            "type": "str, default=None",
            "description": ""
          },
          "The": {
            "type": "default error message is, \"This %(name)s instance is not fitted",
            "description": "yet. Call 'fit' with appropriate arguments before using this\nestimator.\""
          },
          "For": {
            "type": "custom messages if \"%(name)s\" is present in the message string,",
            "description": ""
          },
          "it": {
            "type": "is substituted for the estimator name.",
            "description": "Eg. : \"Estimator, %(name)s, must be fitted before sparsifying\"."
          },
          "all_or_any": {
            "type": "callable, {all, any}, default=all",
            "description": ""
          },
          "Specify": {
            "type": "whether all or any of the given attributes must exist.",
            "description": "Raises\n------\nTypeError"
          },
          "Model": {
            "type": "is not fitted yet.",
            "description": ">>> lr.fit([[1, 2], [1, 3]], [1, 0])"
          },
          "LogisticRegression": {
            "type": "",
            "description": ">>> check_is_fitted(lr)"
          }
        },
        "returns": "",
        "raises": "a :class:`~sklearn.exceptions.NotFittedError` with the given message.\n\n    If an estimator does not set any attributes with a trailing underscore, it\n    can define a ``__sklearn_is_fitted__`` method returning a boolean to\n    specify if the estimator is fitted or not. See\n    :ref:`sphx_glr_auto_examples_developing_estimators_sklearn_is_fitted.py`\n    for an example on how to use the API.\n\n    If no `attributes` are passed, this fuction will pass if an estimator is stateless.\n    An estimator can indicate it's stateless by setting the `requires_fit` tag. See\n    :ref:`estimator_tags` for more information. Note that the `requires_fit` tag\n    is ignored if `attributes` are passed.\n\n    Parameters\n    ----------\n    estimator : estimator instance\n        Estimator instance for which the check is performed.\n\n    attributes : str, list or tuple of str, default=None\n        Attribute name(s) given as string or a list/tuple of strings\n        Eg.: ``[\"coef_\", \"estimator_\", ...], \"coef_\"``\n\n        If `None`, `estimator` is considered fitted if there exist an\n        attribute that ends with a underscore and does not start with double\n        underscore.\n\n    msg : str, default=None\n        The default error message is, \"This %(name)s instance is not fitted\n        yet. Call 'fit' with appropriate arguments before using this\n        estimator.\"\n\n        For custom messages if \"%(name)s\" is present in the message string,\n        it is substituted for the estimator name.\n\n        Eg. : \"Estimator, %(name)s, must be fitted before sparsifying\".\n\n    all_or_any : callable, {all, any}, default=all\n        Specify whether all or any of the given attributes must exist.",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> from sklearn.utils.validation import check_is_fitted\n    >>> from sklearn.exceptions import NotFittedError\n    >>> lr = LogisticRegression()\n    >>> try:\n    ...     check_is_fitted(lr)\n    ... except NotFittedError as exc:\n    ...     print(f\"Model is not fitted yet.\")\n    Model is not fitted yet.\n    >>> lr.fit([[1, 2], [1, 3]], [1, 0])\n    LogisticRegression()\n    >>> check_is_fitted(lr)"
      }
    },
    {
      "name": "check_non_negative",
      "signature": "check_non_negative(X, whom)",
      "documentation": {
        "description": "Check if there is any negative value in an array.",
        "parameters": {
          "X": {
            "type": "{array",
            "description": "like, sparse matrix}"
          },
          "Input": {
            "type": "data.",
            "description": ""
          },
          "whom": {
            "type": "str",
            "description": ""
          },
          "Who": {
            "type": "passed X to this function.",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "label_binarize",
      "signature": "label_binarize(y, *, classes, neg_label=0, pos_label=1, sparse_output=False)",
      "documentation": {
        "description": "Binarize labels in a one-vs-all fashion.\n\n    Several regression and binary classification algorithms are\n    available in scikit-learn. A simple way to extend these algorithms\n    to the multi-class classification case is to use the so-called\n    one-vs-all scheme.\n\n    This function makes it possible to compute this transformation for a\n    fixed set of class labels known ahead of time.\n\n    Parameters\n    ----------\n    y : array-like or sparse matrix\n        Sequence of integer labels or multilabel data to encode.\n\n    classes : array-like of shape (n_classes,)\n        Uniquely holds the label for each class.\n\n    neg_label : int, default=0\n        Value with which negative labels must be encoded.\n\n    pos_label : int, default=1\n        Value with which positive labels must be encoded.\n\n    sparse_output : bool, default=False,\n        Set to true if output binary array is desired in CSR sparse format.\n\n    Returns\n    -------\n    Y : {ndarray, sparse matrix} of shape (n_samples, n_classes)\n        Shape will be (n_samples, 1) for binary problems. Sparse matrix will\n        be of CSR format.\n\n    See Also\n    --------\n    LabelBinarizer : Class used to wrap the functionality of label_binarize and\n        allow for fitting to classes independently of the transform operation.",
        "parameters": {
          "y": {
            "type": "array",
            "description": "like or sparse matrix"
          },
          "Sequence": {
            "type": "of integer labels or multilabel data to encode.",
            "description": ""
          },
          "classes": {
            "type": "array",
            "description": "like of shape (n_classes,)"
          },
          "Uniquely": {
            "type": "holds the label for each class.",
            "description": ""
          },
          "neg_label": {
            "type": "int, default=0",
            "description": ""
          },
          "Value": {
            "type": "with which positive labels must be encoded.",
            "description": ""
          },
          "pos_label": {
            "type": "int, default=1",
            "description": ""
          },
          "sparse_output": {
            "type": "bool, default=False,",
            "description": ""
          },
          "Set": {
            "type": "to true if output binary array is desired in CSR sparse format.",
            "description": "Returns\n-------"
          },
          "Y": {
            "type": "{ndarray, sparse matrix} of shape (n_samples, n_classes)",
            "description": ""
          },
          "Shape": {
            "type": "will be (n_samples, 1) for binary problems. Sparse matrix will",
            "description": ""
          },
          "be": {
            "type": "of CSR format.",
            "description": ""
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "LabelBinarizer": {
            "type": "Class used to wrap the functionality of label_binarize and",
            "description": ""
          },
          "allow": {
            "type": "for fitting to classes independently of the transform operation.",
            "description": "Examples\n--------\n>>> from sklearn.preprocessing import label_binarize\n>>> label_binarize([1, 6], classes=[1, 2, 4, 6])\narray([[1, 0, 0, 0],\n[0, 0, 0, 1]])"
          },
          "The": {
            "type": "class ordering is preserved:",
            "description": ">>> label_binarize([1, 6], classes=[1, 6, 4, 2])\narray([[1, 0, 0, 0],\n[0, 1, 0, 0]])"
          },
          "Binary": {
            "type": "targets transform to a column vector",
            "description": ">>> label_binarize(['yes', 'no', 'no', 'yes'], classes=['no', 'yes'])\narray([[1],\n[0],\n[0],\n[1]])"
          }
        },
        "returns": "-------\n    Y : {ndarray, sparse matrix} of shape (n_samples, n_classes)\n        Shape will be (n_samples, 1) for binary problems. Sparse matrix will\n        be of CSR format.\n\n    See Also\n    --------\n    LabelBinarizer : Class used to wrap the functionality of label_binarize and\n        allow for fitting to classes independently of the transform operation.\n\n    Examples\n    --------\n    >>> from sklearn.preprocessing import label_binarize\n    >>> label_binarize([1, 6], classes=[1, 2, 4, 6])\n    array([[1, 0, 0, 0],\n           [0, 0, 0, 1]])\n\n    The class ordering is preserved:\n\n    >>> label_binarize([1, 6], classes=[1, 6, 4, 2])\n    array([[1, 0, 0, 0],\n           [0, 1, 0, 0]])\n\n    Binary targets transform to a column vector\n\n    >>> label_binarize(['yes', 'no', 'no', 'yes'], classes=['no', 'yes'])\n    array([[1],\n           [0],\n           [0],\n           [1]])",
        "raises": "",
        "see_also": "--------\n    LabelBinarizer : Class used to wrap the functionality of label_binarize and\n        allow for fitting to classes independently of the transform operation.\n\n    Examples\n    --------\n    >>> from sklearn.preprocessing import label_binarize\n    >>> label_binarize([1, 6], classes=[1, 2, 4, 6])\n    array([[1, 0, 0, 0],\n           [0, 0, 0, 1]])\n\n    The class ordering is preserved:\n\n    >>> label_binarize([1, 6], classes=[1, 6, 4, 2])\n    array([[1, 0, 0, 0],\n           [0, 1, 0, 0]])\n\n    Binary targets transform to a column vector\n\n    >>> label_binarize(['yes', 'no', 'no', 'yes'], classes=['no', 'yes'])\n    array([[1],\n           [0],\n           [0],\n           [1]])",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.preprocessing import label_binarize\n    >>> label_binarize([1, 6], classes=[1, 2, 4, 6])\n    array([[1, 0, 0, 0],\n           [0, 0, 0, 1]])\n\n    The class ordering is preserved:\n\n    >>> label_binarize([1, 6], classes=[1, 6, 4, 2])\n    array([[1, 0, 0, 0],\n           [0, 1, 0, 0]])\n\n    Binary targets transform to a column vector\n\n    >>> label_binarize(['yes', 'no', 'no', 'yes'], classes=['no', 'yes'])\n    array([[1],\n           [0],\n           [0],\n           [1]])"
      }
    },
    {
      "name": "logsumexp",
      "signature": "logsumexp(a, axis=None, b=None, keepdims=False, return_sign=False)",
      "documentation": {
        "description": "Compute the log of the sum of exponentials of input elements.\n\n    Parameters\n    ----------\n    a : array_like\n        Input array.\n    axis : None or int or tuple of ints, optional\n        Axis or axes over which the sum is taken. By default `axis` is None,\n        and all elements are summed.\n\n        .. versionadded:: 0.11.0\n    b : array-like, optional\n        Scaling factor for exp(`a`) must be of the same shape as `a` or\n        broadcastable to `a`. These values may be negative in order to\n        implement subtraction.\n\n        .. versionadded:: 0.12.0\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left in the\n        result as dimensions with size one. With this option, the result\n        will broadcast correctly against the original array.\n\n        .. versionadded:: 0.15.0\n    return_sign : bool, optional\n        If this is set to True, the result will be a pair containing sign\n        information; if False, results that are negative will be returned\n        as NaN. Default is False (no sign information).\n\n        .. versionadded:: 0.16.0\n\n    Returns\n    -------\n    res : ndarray\n        The result, ``np.log(np.sum(np.exp(a)))`` calculated in a numerically\n        more stable way. If `b` is given then ``np.log(np.sum(b*np.exp(a)))``\n        is returned. If ``return_sign`` is True, ``res`` contains the log of\n        the absolute value of the argument.\n    sgn : ndarray\n        If ``return_sign`` is True, this will be an array of floating-point\n        numbers matching res containing +1, 0, -1 (for real-valued inputs)\n        or a complex phase (for complex inputs). This gives the sign of the\n        argument of the logarithm in ``res``.\n        If ``return_sign`` is False, only one result is returned.\n\n    See Also\n    --------\n    numpy.logaddexp, numpy.logaddexp2\n\n    Notes\n    -----\n    NumPy has a logaddexp function which is very similar to `logsumexp`, but\n    only handles two arguments. `logaddexp.reduce` is similar to this\n    function, but may be less stable.\n\n    The logarithm is a multivalued function: for each :math:`x` there is an\n    infinite number of :math:`z` such that :math:`exp(z) = x`. The convention\n    is to return the :math:`z` whose imaginary part lies in :math:`(-pi, pi]`.",
        "parameters": {
          "a": {
            "type": "array_like",
            "description": ""
          },
          "Input": {
            "type": "array.",
            "description": ""
          },
          "axis": {
            "type": "None or int or tuple of ints, optional",
            "description": ""
          },
          "Axis": {
            "type": "or axes over which the sum is taken. By default `axis` is None,",
            "description": ""
          },
          "and": {
            "type": "all elements are summed.",
            "description": ".. versionadded:: 0.11.0"
          },
          "b": {
            "type": "array",
            "description": "like, optional"
          },
          "Scaling": {
            "type": "factor for exp(`a`) must be of the same shape as `a` or",
            "description": ""
          },
          "broadcastable": {
            "type": "to `a`. These values may be negative in order to",
            "description": ""
          },
          "implement": {
            "type": "subtraction.",
            "description": ".. versionadded:: 0.12.0"
          },
          "keepdims": {
            "type": "bool, optional",
            "description": ""
          },
          "If": {
            "type": "``return_sign`` is False, only one result is returned.",
            "description": ""
          },
          "result": {
            "type": "as dimensions with size one. With this option, the result",
            "description": ""
          },
          "will": {
            "type": "broadcast correctly against the original array.",
            "description": ".. versionadded:: 0.15.0"
          },
          "return_sign": {
            "type": "bool, optional",
            "description": ""
          },
          "as": {
            "type": "NaN. Default is False (no sign information).",
            "description": ".. versionadded:: 0.16.0\nReturns\n-------"
          },
          "res": {
            "type": "ndarray",
            "description": ""
          },
          "The": {
            "type": "logarithm is a multivalued function: for each :math:`x` there is an",
            "description": ""
          },
          "more": {
            "type": "stable way. If `b` is given then ``np.log(np.sum(b*np.exp(a)))``",
            "description": ""
          },
          "is": {
            "type": "to return the :math:`z` whose imaginary part lies in :math:`(-pi, pi]`.",
            "description": "Examples\n--------\n>>> import numpy as np\n>>> from scipy.special import logsumexp\n>>> a = np.arange(10)\n>>> logsumexp(a)\n9.4586297444267107\n>>> np.log(np.sum(np.exp(a)))\n9.4586297444267107"
          },
          "the": {
            "type": "absolute value of the argument.",
            "description": ""
          },
          "sgn": {
            "type": "ndarray",
            "description": ""
          },
          "numbers": {
            "type": "matching res containing +1, 0, -1 (for real-valued inputs)",
            "description": ""
          },
          "or": {
            "type": "a complex phase (for complex inputs). This gives the sign of the",
            "description": ""
          },
          "argument": {
            "type": "of the logarithm in ``res``.",
            "description": ""
          },
          "See": {
            "type": "Also",
            "description": "--------\nnumpy.logaddexp, numpy.logaddexp2\nNotes\n-----"
          },
          "NumPy": {
            "type": "has a logaddexp function which is very similar to `logsumexp`, but",
            "description": ""
          },
          "only": {
            "type": "handles two arguments. `logaddexp.reduce` is similar to this",
            "description": "function, but may be less stable."
          },
          "infinite": {
            "type": "number of :math:`z` such that :math:`exp(z) = x`. The convention",
            "description": ""
          },
          "With": {
            "type": "weights",
            "description": ">>> a = np.arange(10)\n>>> b = np.arange(10, 0, -1)\n>>> logsumexp(a, b=b)\n9.9170178533034665\n>>> np.log(np.sum(b*np.exp(a)))\n9.9170178533034647"
          },
          "Returning": {
            "type": "a sign flag",
            "description": ">>> logsumexp([1,2],b=[1,-1],return_sign=True)\n(1.5413248546129181, -1.0)"
          },
          "Notice": {
            "type": "that `logsumexp` does not directly support masked arrays. To use it",
            "description": ""
          },
          "on": {
            "type": "a masked array, convert the mask into zero weights:",
            "description": ">>> a = np.ma.array([np.log(2), 2, np.log(3)],\n...                  mask=[False, True, False])\n>>> b = (~a.mask).astype(int)\n>>> logsumexp(a.data, b=b), np.log(5)\n1.6094379124341005, 1.6094379124341005"
          }
        },
        "returns": "-------\n    res : ndarray\n        The result, ``np.log(np.sum(np.exp(a)))`` calculated in a numerically\n        more stable way. If `b` is given then ``np.log(np.sum(b*np.exp(a)))``\n        is returned. If ``return_sign`` is True, ``res`` contains the log of\n        the absolute value of the argument.\n    sgn : ndarray\n        If ``return_sign`` is True, this will be an array of floating-point\n        numbers matching res containing +1, 0, -1 (for real-valued inputs)\n        or a complex phase (for complex inputs). This gives the sign of the\n        argument of the logarithm in ``res``.\n        If ``return_sign`` is False, only one result is returned.\n\n    See Also\n    --------\n    numpy.logaddexp, numpy.logaddexp2\n\n    Notes\n    -----\n    NumPy has a logaddexp function which is very similar to `logsumexp`, but\n    only handles two arguments. `logaddexp.reduce` is similar to this\n    function, but may be less stable.\n\n    The logarithm is a multivalued function: for each :math:`x` there is an\n    infinite number of :math:`z` such that :math:`exp(z) = x`. The convention\n    is to return the :math:`z` whose imaginary part lies in :math:`(-pi, pi]`.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from scipy.special import logsumexp\n    >>> a = np.arange(10)\n    >>> logsumexp(a)\n    9.4586297444267107\n    >>> np.log(np.sum(np.exp(a)))\n    9.4586297444267107\n\n    With weights\n\n    >>> a = np.arange(10)\n    >>> b = np.arange(10, 0, -1)\n    >>> logsumexp(a, b=b)\n    9.9170178533034665\n    >>> np.log(np.sum(b*np.exp(a)))\n    9.9170178533034647\n\n    Returning a sign flag\n\n    >>> logsumexp([1,2],b=[1,-1],return_sign=True)\n    (1.5413248546129181, -1.0)\n\n    Notice that `logsumexp` does not directly support masked arrays. To use it\n    on a masked array, convert the mask into zero weights:\n\n    >>> a = np.ma.array([np.log(2), 2, np.log(3)],\n    ...                  mask=[False, True, False])\n    >>> b = (~a.mask).astype(int)\n    >>> logsumexp(a.data, b=b), np.log(5)\n    1.6094379124341005, 1.6094379124341005",
        "raises": "",
        "see_also": "--------\n    numpy.logaddexp, numpy.logaddexp2\n\n    Notes\n    -----\n    NumPy has a logaddexp function which is very similar to `logsumexp`, but\n    only handles two arguments. `logaddexp.reduce` is similar to this\n    function, but may be less stable.\n\n    The logarithm is a multivalued function: for each :math:`x` there is an\n    infinite number of :math:`z` such that :math:`exp(z) = x`. The convention\n    is to return the :math:`z` whose imaginary part lies in :math:`(-pi, pi]`.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from scipy.special import logsumexp\n    >>> a = np.arange(10)\n    >>> logsumexp(a)\n    9.4586297444267107\n    >>> np.log(np.sum(np.exp(a)))\n    9.4586297444267107\n\n    With weights\n\n    >>> a = np.arange(10)\n    >>> b = np.arange(10, 0, -1)\n    >>> logsumexp(a, b=b)\n    9.9170178533034665\n    >>> np.log(np.sum(b*np.exp(a)))\n    9.9170178533034647\n\n    Returning a sign flag\n\n    >>> logsumexp([1,2],b=[1,-1],return_sign=True)\n    (1.5413248546129181, -1.0)\n\n    Notice that `logsumexp` does not directly support masked arrays. To use it\n    on a masked array, convert the mask into zero weights:\n\n    >>> a = np.ma.array([np.log(2), 2, np.log(3)],\n    ...                  mask=[False, True, False])\n    >>> b = (~a.mask).astype(int)\n    >>> logsumexp(a.data, b=b), np.log(5)\n    1.6094379124341005, 1.6094379124341005",
        "notes": "-----\n    NumPy has a logaddexp function which is very similar to `logsumexp`, but\n    only handles two arguments. `logaddexp.reduce` is similar to this\n    function, but may be less stable.\n\n    The logarithm is a multivalued function: for each :math:`x` there is an\n    infinite number of :math:`z` such that :math:`exp(z) = x`. The convention\n    is to return the :math:`z` whose imaginary part lies in :math:`(-pi, pi]`.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from scipy.special import logsumexp\n    >>> a = np.arange(10)\n    >>> logsumexp(a)\n    9.4586297444267107\n    >>> np.log(np.sum(np.exp(a)))\n    9.4586297444267107\n\n    With weights\n\n    >>> a = np.arange(10)\n    >>> b = np.arange(10, 0, -1)\n    >>> logsumexp(a, b=b)\n    9.9170178533034665\n    >>> np.log(np.sum(b*np.exp(a)))\n    9.9170178533034647\n\n    Returning a sign flag\n\n    >>> logsumexp([1,2],b=[1,-1],return_sign=True)\n    (1.5413248546129181, -1.0)\n\n    Notice that `logsumexp` does not directly support masked arrays. To use it\n    on a masked array, convert the mask into zero weights:\n\n    >>> a = np.ma.array([np.log(2), 2, np.log(3)],\n    ...                  mask=[False, True, False])\n    >>> b = (~a.mask).astype(int)\n    >>> logsumexp(a.data, b=b), np.log(5)\n    1.6094379124341005, 1.6094379124341005",
        "examples": "--------\n    >>> import numpy as np\n    >>> from scipy.special import logsumexp\n    >>> a = np.arange(10)\n    >>> logsumexp(a)\n    9.4586297444267107\n    >>> np.log(np.sum(np.exp(a)))\n    9.4586297444267107\n\n    With weights\n\n    >>> a = np.arange(10)\n    >>> b = np.arange(10, 0, -1)\n    >>> logsumexp(a, b=b)\n    9.9170178533034665\n    >>> np.log(np.sum(b*np.exp(a)))\n    9.9170178533034647\n\n    Returning a sign flag\n\n    >>> logsumexp([1,2],b=[1,-1],return_sign=True)\n    (1.5413248546129181, -1.0)\n\n    Notice that `logsumexp` does not directly support masked arrays. To use it\n    on a masked array, convert the mask into zero weights:\n\n    >>> a = np.ma.array([np.log(2), 2, np.log(3)],\n    ...                  mask=[False, True, False])\n    >>> b = (~a.mask).astype(int)\n    >>> logsumexp(a.data, b=b), np.log(5)\n    1.6094379124341005, 1.6094379124341005"
      }
    },
    {
      "name": "safe_sparse_dot",
      "signature": "safe_sparse_dot(a, b, *, dense_output=False)",
      "documentation": {
        "description": "Dot product that handle the sparse matrix case correctly.\n\n    Parameters\n    ----------\n    a : {ndarray, sparse matrix}\n    b : {ndarray, sparse matrix}\n    dense_output : bool, default=False\n        When False, ``a`` and ``b`` both being sparse will yield sparse output.\n        When True, output will always be a dense array.\n\n    Returns\n    -------\n    dot_product : {ndarray, sparse matrix}\n        Sparse if ``a`` and ``b`` are sparse and ``dense_output=False``.",
        "parameters": {
          "a": {
            "type": "{ndarray, sparse matrix}",
            "description": ""
          },
          "b": {
            "type": "{ndarray, sparse matrix}",
            "description": ""
          },
          "dense_output": {
            "type": "bool, default=False",
            "description": ""
          },
          "When": {
            "type": "True, output will always be a dense array.",
            "description": "Returns\n-------"
          },
          "dot_product": {
            "type": "{ndarray, sparse matrix}",
            "description": ""
          },
          "Sparse": {
            "type": "if ``a`` and ``b`` are sparse and ``dense_output=False``.",
            "description": "Examples\n--------\n>>> from scipy.sparse import csr_matrix\n>>> from sklearn.utils.extmath import safe_sparse_dot\n>>> X = csr_matrix([[1, 2], [3, 4], [5, 6]])\n>>> dot_product = safe_sparse_dot(X, X.T)\n>>> dot_product.toarray()\narray([[ 5, 11, 17],\n[11, 25, 39],\n[17, 39, 61]])"
          }
        },
        "returns": "-------\n    dot_product : {ndarray, sparse matrix}\n        Sparse if ``a`` and ``b`` are sparse and ``dense_output=False``.\n\n    Examples\n    --------\n    >>> from scipy.sparse import csr_matrix\n    >>> from sklearn.utils.extmath import safe_sparse_dot\n    >>> X = csr_matrix([[1, 2], [3, 4], [5, 6]])\n    >>> dot_product = safe_sparse_dot(X, X.T)\n    >>> dot_product.toarray()\n    array([[ 5, 11, 17],\n           [11, 25, 39],\n           [17, 39, 61]])",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from scipy.sparse import csr_matrix\n    >>> from sklearn.utils.extmath import safe_sparse_dot\n    >>> X = csr_matrix([[1, 2], [3, 4], [5, 6]])\n    >>> dot_product = safe_sparse_dot(X, X.T)\n    >>> dot_product.toarray()\n    array([[ 5, 11, 17],\n           [11, 25, 39],\n           [17, 39, 61]])"
      }
    },
    {
      "name": "validate_data",
      "signature": "validate_data(_estimator, /, X='no_validation', y='no_validation', reset=True, validate_separately=False, skip_check_array=False, **check_params)",
      "documentation": {
        "description": "Validate input data and set or check feature names and counts of the input.\n\n    This helper function should be used in an estimator that requires input\n    validation. This mutates the estimator and sets the `n_features_in_` and\n    `feature_names_in_` attributes if `reset=True`.\n\n    .. versionadded:: 1.6\n\n    Parameters\n    ----------\n    _estimator : estimator instance\n        The estimator to validate the input for.\n\n    X : {array-like, sparse matrix, dataframe} of shape             (n_samples, n_features), default='no validation'\n        The input samples.\n        If `'no_validation'`, no validation is performed on `X`. This is\n        useful for meta-estimator which can delegate input validation to\n        their underlying estimator(s). In that case `y` must be passed and\n        the only accepted `check_params` are `multi_output` and\n        `y_numeric`.\n\n    y : array-like of shape (n_samples,), default='no_validation'\n        The targets.\n\n        - If `None`, :func:`~sklearn.utils.check_array` is called on `X`. If\n          the estimator's `requires_y` tag is True, then an error will be raised.\n        - If `'no_validation'`, :func:`~sklearn.utils.check_array` is called\n          on `X` and the estimator's `requires_y` tag is ignored. This is a default\n          placeholder and is never meant to be explicitly set. In that case `X` must be\n          passed.\n        - Otherwise, only `y` with `_check_y` or both `X` and `y` are checked with\n          either :func:`~sklearn.utils.check_array` or\n          :func:`~sklearn.utils.check_X_y` depending on `validate_separately`.\n\n    reset : bool, default=True\n        Whether to reset the `n_features_in_` attribute.\n        If False, the input will be checked for consistency with data\n        provided when reset was last True.\n\n        .. note::\n\n           It is recommended to call `reset=True` in `fit` and in the first\n           call to `partial_fit`. All other methods that validate `X`\n           should set `reset=False`.\n\n    validate_separately : False or tuple of dicts, default=False\n        Only used if `y` is not `None`.\n        If `False`, call :func:`~sklearn.utils.check_X_y`. Else, it must be a tuple of\n        kwargs to be used for calling :func:`~sklearn.utils.check_array` on `X` and `y`\n        respectively.\n\n        `estimator=self` is automatically added to these dicts to generate\n        more informative error message in case of invalid input data.\n\n    skip_check_array : bool, default=False\n        If `True`, `X` and `y` are unchanged and only `feature_names_in_` and\n        `n_features_in_` are checked. Otherwise, :func:`~sklearn.utils.check_array`\n        is called on `X` and `y`.\n\n    **check_params : kwargs\n        Parameters passed to :func:`~sklearn.utils.check_array` or\n        :func:`~sklearn.utils.check_X_y`. Ignored if validate_separately\n        is not False.\n\n        `estimator=self` is automatically added to these params to generate\n        more informative error message in case of invalid input data.",
        "parameters": {
          "_estimator": {
            "type": "estimator instance",
            "description": ""
          },
          "The": {
            "type": "targets.",
            "description": "- If `None`, :func:`~sklearn.utils.check_array` is called on `X`. If"
          },
          "X": {
            "type": "{array",
            "description": "like, sparse matrix, dataframe} of shape             (n_samples, n_features), default='no validation'"
          },
          "If": {
            "type": "`True`, `X` and `y` are unchanged and only `feature_names_in_` and",
            "description": "`n_features_in_` are checked. Otherwise, :func:`~sklearn.utils.check_array`"
          },
          "useful": {
            "type": "for meta-estimator which can delegate input validation to",
            "description": ""
          },
          "their": {
            "type": "underlying estimator(s). In that case `y` must be passed and",
            "description": ""
          },
          "the": {
            "type": "estimator's `requires_y` tag is True, then an error will be raised.",
            "description": "- If `'no_validation'`, :func:`~sklearn.utils.check_array` is called"
          },
          "y": {
            "type": "array",
            "description": "like of shape (n_samples,), default='no_validation'"
          },
          "on": {
            "type": "`X` and the estimator's `requires_y` tag is ignored. This is a default",
            "description": ""
          },
          "placeholder": {
            "type": "and is never meant to be explicitly set. In that case `X` must be",
            "description": "passed.\n- Otherwise, only `y` with `_check_y` or both `X` and `y` are checked with"
          },
          "either": {
            "type": "func:`~sklearn.utils.check_array` or",
            "description": ":func:`~sklearn.utils.check_X_y` depending on `validate_separately`."
          },
          "reset": {
            "type": "bool, default=True",
            "description": ""
          },
          "Whether": {
            "type": "to reset the `n_features_in_` attribute.",
            "description": ""
          },
          "provided": {
            "type": "when reset was last True.",
            "description": ".. note::"
          },
          "It": {
            "type": "is recommended to call `reset=True` in `fit` and in the first",
            "description": ""
          },
          "call": {
            "type": "to `partial_fit`. All other methods that validate `X`",
            "description": ""
          },
          "should": {
            "type": "set `reset=False`.",
            "description": ""
          },
          "validate_separately": {
            "type": "False or tuple of dicts, default=False",
            "description": ""
          },
          "Only": {
            "type": "used if `y` is not `None`.",
            "description": ""
          },
          "kwargs": {
            "type": "to be used for calling :func:`~sklearn.utils.check_array` on `X` and `y`",
            "description": "respectively.\n`estimator=self` is automatically added to these dicts to generate"
          },
          "more": {
            "type": "informative error message in case of invalid input data.",
            "description": ""
          },
          "skip_check_array": {
            "type": "bool, default=False",
            "description": ""
          },
          "is": {
            "type": "called on `X` and `y`.",
            "description": "**check_params : kwargs"
          }
        },
        "returns": "-------\n    out : {ndarray, sparse matrix} or tuple of these\n        The validated input. A tuple is returned if both `X` and `y` are\n        validated.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    }
  ],
  "classes": [
    {
      "name": "ABCMeta",
      "documentation": {
        "description": "Metaclass for defining Abstract Base Classes (ABCs).\n\n        Use this metaclass to create an ABC.  An ABC can be subclassed\n        directly, and then acts as a mix-in class.  You can also register\n        unrelated concrete classes (even built-in classes) and unrelated\n        ABCs as 'virtual subclasses' -- these and their descendants will\n        be considered subclasses of the registering ABC by the built-in\n        issubclass() function, but the registering ABC won't show up in\n        their MRO (Method Resolution Order) nor will method\n        implementations defined by the registering ABC be callable (not\n        even via super()).",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "mro",
          "signature": "mro(self, /)",
          "documentation": {
            "description": "Return a type's method resolution order.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "register",
          "signature": "register(cls, subclass)",
          "documentation": {
            "description": "Register a virtual subclass of an ABC.",
            "parameters": {},
            "returns": "the subclass, to allow usage as a class decorator.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "BaseEstimator",
      "documentation": {
        "description": "Base class for all estimators in scikit-learn.\n\n    Inheriting from this class provides default implementations of:\n\n    - setting and getting parameters used by `GridSearchCV` and friends;\n    - textual and HTML representation displayed in terminals and IDEs;\n    - estimator serialization;\n    - parameters validation;\n    - data validation;\n    - feature names validation.\n\n    Read more in the :ref:`User Guide <rolling_your_own_estimator>`.\n\n\n    Notes\n    -----\n    All estimators should specify all the parameters that can be set\n    at the class level in their ``__init__`` as explicit keyword\n    arguments (no ``*args`` or ``**kwargs``).",
        "parameters": {
          "array": {
            "type": "[3, 3, 3]",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "-----\n    All estimators should specify all the parameters that can be set\n    at the class level in their ``__init__`` as explicit keyword\n    arguments (no ``*args`` or ``**kwargs``).\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.base import BaseEstimator\n    >>> class MyEstimator(BaseEstimator):\n    ...     def __init__(self, *, param=1):\n    ...         self.param = param\n    ...     def fit(self, X, y=None):\n    ...         self.is_fitted_ = True\n    ...         return self\n    ...     def predict(self, X):\n    ...         return np.full(shape=X.shape[0], fill_value=self.param)\n    >>> estimator = MyEstimator(param=2)\n    >>> estimator.get_params()\n    {'param': 2}\n    >>> X = np.array([[1, 2], [2, 3], [3, 4]])\n    >>> y = np.array([1, 0, 1])\n    >>> estimator.fit(X, y).predict(X)\n    array([2, 2, 2])\n    >>> estimator.set_params(param=3).fit(X, y).predict(X)\n    array([3, 3, 3])",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.base import BaseEstimator\n    >>> class MyEstimator(BaseEstimator):\n    ...     def __init__(self, *, param=1):\n    ...         self.param = param\n    ...     def fit(self, X, y=None):\n    ...         self.is_fitted_ = True\n    ...         return self\n    ...     def predict(self, X):\n    ...         return np.full(shape=X.shape[0], fill_value=self.param)\n    >>> estimator = MyEstimator(param=2)\n    >>> estimator.get_params()\n    {'param': 2}\n    >>> X = np.array([[1, 2], [2, 3], [3, 4]])\n    >>> y = np.array([1, 0, 1])\n    >>> estimator.fit(X, y).predict(X)\n    array([2, 2, 2])\n    >>> estimator.set_params(param=3).fit(X, y).predict(X)\n    array([3, 3, 3])"
      },
      "methods": [
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "BernoulliNB",
      "documentation": {
        "description": "Naive Bayes classifier for multivariate Bernoulli models.\n\n    Like MultinomialNB, this classifier is suitable for discrete data. The\n    difference is that while MultinomialNB works with occurrence counts,\n    BernoulliNB is designed for binary/boolean features.\n\n    Read more in the :ref:`User Guide <bernoulli_naive_bayes>`.\n\n    Parameters\n    ----------\n    alpha : float or array-like of shape (n_features,), default=1.0\n        Additive (Laplace/Lidstone) smoothing parameter\n        (set alpha=0 and force_alpha=True, for no smoothing).\n\n    force_alpha : bool, default=True\n        If False and alpha is less than 1e-10, it will set alpha to\n        1e-10. If True, alpha will remain unchanged. This may cause\n        numerical errors if alpha is too close to 0.\n\n        .. versionadded:: 1.2\n        .. versionchanged:: 1.4\n           The default value of `force_alpha` changed to `True`.\n\n    binarize : float or None, default=0.0\n        Threshold for binarizing (mapping to booleans) of sample features.\n        If None, input is presumed to already consist of binary vectors.\n\n    fit_prior : bool, default=True\n        Whether to learn class prior probabilities or not.\n        If false, a uniform prior will be used.\n\n    class_prior : array-like of shape (n_classes,), default=None\n        Prior probabilities of the classes. If specified, the priors are not\n        adjusted according to the data.\n\n    Attributes\n    ----------\n    class_count_ : ndarray of shape (n_classes,)\n        Number of samples encountered for each class during fitting. This\n        value is weighted by the sample weight when provided.\n\n    class_log_prior_ : ndarray of shape (n_classes,)\n        Log probability of each class (smoothed).\n\n    classes_ : ndarray of shape (n_classes,)\n        Class labels known to the classifier\n\n    feature_count_ : ndarray of shape (n_classes, n_features)\n        Number of samples encountered for each (class, feature)\n        during fitting. This value is weighted by the sample weight when\n        provided.\n\n    feature_log_prob_ : ndarray of shape (n_classes, n_features)\n        Empirical log probability of features given a class, P(x_i|y).\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    CategoricalNB : Naive Bayes classifier for categorical features.\n    ComplementNB : The Complement Naive Bayes classifier\n        described in Rennie et al. (2003).\n    GaussianNB : Gaussian Naive Bayes (GaussianNB).\n    MultinomialNB : Naive Bayes classifier for multinomial models.\n\n    References\n    ----------\n    C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to\n    Information Retrieval. Cambridge University Press, pp. 234-265.\n    https://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html\n\n    A. McCallum and K. Nigam (1998). A comparison of event models for naive\n    Bayes text classification. Proc. AAAI/ICML-98 Workshop on Learning for\n    Text Categorization, pp. 41-48.\n\n    V. Metsis, I. Androutsopoulos and G. Paliouras (2006). Spam filtering with\n    naive Bayes -- Which naive Bayes? 3rd Conf. on Email and Anti-Spam (CEAS).",
        "parameters": {
          "alpha": {
            "type": "float or array",
            "description": "like of shape (n_features,), default=1.0"
          },
          "Additive": {
            "type": "Laplace/Lidstone",
            "description": "smoothing parameter\n(set alpha=0 and force_alpha=True, for no smoothing)."
          },
          "force_alpha": {
            "type": "bool, default=True",
            "description": ""
          },
          "If": {
            "type": "false, a uniform prior will be used.",
            "description": ""
          },
          "numerical": {
            "type": "errors if alpha is too close to 0.",
            "description": ".. versionadded:: 1.2\n.. versionchanged:: 1.4"
          },
          "The": {
            "type": "default value of `force_alpha` changed to `True`.",
            "description": ""
          },
          "binarize": {
            "type": "float or None, default=0.0",
            "description": ""
          },
          "Threshold": {
            "type": "for binarizing (mapping to booleans) of sample features.",
            "description": ""
          },
          "fit_prior": {
            "type": "bool, default=True",
            "description": ""
          },
          "Whether": {
            "type": "to learn class prior probabilities or not.",
            "description": ""
          },
          "class_prior": {
            "type": "array",
            "description": "like of shape (n_classes,), default=None"
          },
          "Prior": {
            "type": "probabilities of the classes. If specified, the priors are not",
            "description": ""
          },
          "adjusted": {
            "type": "according to the data.",
            "description": "Attributes\n----------"
          },
          "class_count_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "Number": {
            "type": "of features seen during :term:`fit`.",
            "description": ".. versionadded:: 0.24"
          },
          "value": {
            "type": "is weighted by the sample weight when provided.",
            "description": ""
          },
          "class_log_prior_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "Log": {
            "type": "probability of each class (smoothed).",
            "description": ""
          },
          "classes_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "Class": {
            "type": "labels known to the classifier",
            "description": ""
          },
          "feature_count_": {
            "type": "ndarray of shape (n_classes, n_features)",
            "description": ""
          },
          "during": {
            "type": "fitting. This value is weighted by the sample weight when",
            "description": "provided."
          },
          "feature_log_prob_": {
            "type": "ndarray of shape (n_classes, n_features)",
            "description": ""
          },
          "Empirical": {
            "type": "log probability of features given a class, P(x_i|y).",
            "description": ""
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "CategoricalNB": {
            "type": "Naive Bayes classifier for categorical features.",
            "description": ""
          },
          "ComplementNB": {
            "type": "The Complement Naive Bayes classifier",
            "description": ""
          },
          "described": {
            "type": "in Rennie et al. (2003).",
            "description": ""
          },
          "GaussianNB": {
            "type": "Gaussian Naive Bayes (GaussianNB).",
            "description": ""
          },
          "MultinomialNB": {
            "type": "Naive Bayes classifier for multinomial models.",
            "description": "References\n----------\nC.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to"
          },
          "Information": {
            "type": "Retrieval. Cambridge University Press, pp. 234-265.",
            "description": ""
          },
          "https": {
            "type": "//nlp.stanford.edu/IR",
            "description": "book/html/htmledition/the-bernoulli-model-1.html\nA. McCallum and K. Nigam (1998). A comparison of event models for naive"
          },
          "Bayes": {
            "type": "text classification. Proc. AAAI/ICML-98 Workshop on Learning for",
            "description": ""
          },
          "Text": {
            "type": "Categorization, pp. 41-48.",
            "description": "V. Metsis, I. Androutsopoulos and G. Paliouras (2006). Spam filtering with"
          },
          "naive": {
            "type": "Bayes -- Which naive Bayes? 3rd Conf. on Email and Anti-Spam (CEAS).",
            "description": "Examples\n--------\n>>> import numpy as np\n>>> rng = np.random.RandomState(1)\n>>> X = rng.randint(5, size=(6, 100))\n>>> Y = np.array([1, 2, 3, 4, 4, 5])\n>>> from sklearn.naive_bayes import BernoulliNB\n>>> clf = BernoulliNB()\n>>> clf.fit(X, Y)"
          },
          "BernoulliNB": {
            "type": "",
            "description": ">>> print(clf.predict(X[2:3]))\n[3]"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    CategoricalNB : Naive Bayes classifier for categorical features.\n    ComplementNB : The Complement Naive Bayes classifier\n        described in Rennie et al. (2003).\n    GaussianNB : Gaussian Naive Bayes (GaussianNB).\n    MultinomialNB : Naive Bayes classifier for multinomial models.\n\n    References\n    ----------\n    C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to\n    Information Retrieval. Cambridge University Press, pp. 234-265.\n    https://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html\n\n    A. McCallum and K. Nigam (1998). A comparison of event models for naive\n    Bayes text classification. Proc. AAAI/ICML-98 Workshop on Learning for\n    Text Categorization, pp. 41-48.\n\n    V. Metsis, I. Androutsopoulos and G. Paliouras (2006). Spam filtering with\n    naive Bayes -- Which naive Bayes? 3rd Conf. on Email and Anti-Spam (CEAS).\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> rng = np.random.RandomState(1)\n    >>> X = rng.randint(5, size=(6, 100))\n    >>> Y = np.array([1, 2, 3, 4, 4, 5])\n    >>> from sklearn.naive_bayes import BernoulliNB\n    >>> clf = BernoulliNB()\n    >>> clf.fit(X, Y)\n    BernoulliNB()\n    >>> print(clf.predict(X[2:3]))\n    [3]",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> rng = np.random.RandomState(1)\n    >>> X = rng.randint(5, size=(6, 100))\n    >>> Y = np.array([1, 2, 3, 4, 4, 5])\n    >>> from sklearn.naive_bayes import BernoulliNB\n    >>> clf = BernoulliNB()\n    >>> clf.fit(X, Y)\n    BernoulliNB()\n    >>> print(clf.predict(X[2:3]))\n    [3]"
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, X, y, sample_weight=None)",
          "documentation": {
            "description": "Fit Naive Bayes classifier according to X, y.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training vectors, where `n_samples` is the number of samples and\n            `n_features` is the number of features.\n\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Weights applied to individual samples (1. for unweighted).",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like, sparse matrix} of shape (n_samples, n_features)"
              },
              "Training": {
                "type": "vectors, where `n_samples` is the number of samples and",
                "description": "`n_features` is the number of features."
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,)"
              },
              "Target": {
                "type": "values.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Weights": {
                "type": "applied to individual samples (1. for unweighted).",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "partial_fit",
          "signature": "partial_fit(self, X, y, classes=None, sample_weight=None)",
          "documentation": {
            "description": "Incremental fit on a batch of samples.\n\n        This method is expected to be called several times consecutively\n        on different chunks of a dataset so as to implement out-of-core\n        or online learning.\n\n        This is especially useful when the whole dataset is too big to fit in\n        memory at once.\n\n        This method has some performance overhead hence it is better to call\n        partial_fit on chunks of data that are as large as possible\n        (as long as fitting in the memory budget) to hide the overhead.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training vectors, where `n_samples` is the number of samples and\n            `n_features` is the number of features.\n\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        classes : array-like of shape (n_classes,), default=None\n            List of all the classes that can possibly appear in the y vector.\n\n            Must be provided at the first call to partial_fit, can be omitted\n            in subsequent calls.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Weights applied to individual samples (1. for unweighted).",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like, sparse matrix} of shape (n_samples, n_features)"
              },
              "Training": {
                "type": "vectors, where `n_samples` is the number of samples and",
                "description": "`n_features` is the number of features."
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,)"
              },
              "Target": {
                "type": "values.",
                "description": ""
              },
              "classes": {
                "type": "array",
                "description": "like of shape (n_classes,), default=None"
              },
              "List": {
                "type": "of all the classes that can possibly appear in the y vector.",
                "description": ""
              },
              "Must": {
                "type": "be provided at the first call to partial_fit, can be omitted",
                "description": ""
              },
              "in": {
                "type": "subsequent calls.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Weights": {
                "type": "applied to individual samples (1. for unweighted).",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict",
          "signature": "predict(self, X)",
          "documentation": {
            "description": "Perform classification on an array of test vectors X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "ndarray of shape (n_samples,)",
                "description": ""
              },
              "Predicted": {
                "type": "target values for X.",
                "description": ""
              }
            },
            "returns": "-------\n        C : ndarray of shape (n_samples,)\n            Predicted target values for X.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_joint_log_proba",
          "signature": "predict_joint_log_proba(self, X)",
          "documentation": {
            "description": "Return joint log probability estimates for the test vector X.\n\n        For each row x of X and class y, the joint log probability is given by\n        ``log P(x, y) = log P(y) + log P(x|y),``\n        where ``log P(y)`` is the class prior probability and ``log P(x|y)`` is\n        the class-conditional probability.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "ndarray of shape (n_samples, n_classes)",
                "description": ""
              },
              "Returns": {
                "type": "the joint log-probability of the samples for each class in",
                "description": ""
              },
              "the": {
                "type": "model. The columns correspond to the classes in sorted",
                "description": "order, as they appear in the attribute :term:`classes_`."
              }
            },
            "returns": "-------\n        C : ndarray of shape (n_samples, n_classes)",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_log_proba",
          "signature": "predict_log_proba(self, X)",
          "documentation": {
            "description": "",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "array",
                "description": "like of shape (n_samples, n_classes)"
              },
              "Returns": {
                "type": "the log-probability of the samples for each class in",
                "description": ""
              },
              "the": {
                "type": "model. The columns correspond to the classes in sorted",
                "description": "order, as they appear in the attribute :term:`classes_`."
              }
            },
            "returns": "log-probability estimates for the test vector X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.\n\n        Returns\n        -------\n        C : array-like of shape (n_samples, n_classes)\n            Returns the log-probability of the samples for each class in\n            the model. The columns correspond to the classes in sorted\n            order, as they appear in the attribute :term:`classes_`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_proba",
          "signature": "predict_proba(self, X)",
          "documentation": {
            "description": "",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "array",
                "description": "like of shape (n_samples, n_classes)"
              },
              "Returns": {
                "type": "the probability of the samples for each class in",
                "description": ""
              },
              "the": {
                "type": "model. The columns correspond to the classes in sorted",
                "description": "order, as they appear in the attribute :term:`classes_`."
              }
            },
            "returns": "probability estimates for the test vector X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.\n\n        Returns\n        -------\n        C : array-like of shape (n_samples, n_classes)\n            Returns the probability of the samples for each class in\n            the model. The columns correspond to the classes in sorted\n            order, as they appear in the attribute :term:`classes_`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "score",
          "signature": "score(self, X, y, sample_weight=None)",
          "documentation": {
            "description": "",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Test": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs)"
              },
              "True": {
                "type": "labels for `X`.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Sample": {
                "type": "weights.",
                "description": "Returns\n-------"
              },
              "score": {
                "type": "float",
                "description": ""
              },
              "Mean": {
                "type": "accuracy of ``self.predict(X)`` w.r.t. `y`.",
                "description": ""
              }
            },
            "returns": "the mean accuracy on the given test data and labels.\n\n        In multi-label classification, this is the subset accuracy\n        which is a harsh metric since you require for each sample that\n        each label set be correctly predicted.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Test samples.\n\n        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n            True labels for `X`.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Sample weights.\n\n        Returns\n        -------\n        score : float\n            Mean accuracy of ``self.predict(X)`` w.r.t. `y`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_fit_request",
          "signature": "set_fit_request(self: sklearn.naive_bayes.BernoulliNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.BernoulliNB",
          "documentation": {
            "description": "Request metadata passed to the ``fit`` method.",
            "parameters": {
              "sample_weight": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "Metadata": {
                "type": "routing for ``sample_weight`` parameter in ``fit``.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "The": {
                "type": "updated object.",
                "description": ""
              },
              "and": {
                "type": "not others.",
                "description": ".. versionadded:: 1.3\n.. note::"
              },
              "This": {
                "type": "method is only relevant if this estimator is used as a",
                "description": "sub-estimator of a meta-estimator, e.g. used inside a\n:class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect."
              }
            },
            "returns": "-------\n        self : object\n            The updated object.",
            "raises": "",
            "see_also": "",
            "notes": "that this method is only relevant if\n        ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n        Please see :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        The options for each parameter are:\n\n        - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n\n        - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n\n        - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n\n        - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n\n        The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n        existing request. This allows you to change the request for some\n        parameters and not others.\n\n        .. versionadded:: 1.3\n\n        .. note::\n            This method is only relevant if this estimator is used as a\n            sub-estimator of a meta-estimator, e.g. used inside a\n            :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n\n        Parameters\n        ----------\n        sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``sample_weight`` parameter in ``fit``.\n\n        Returns\n        -------\n        self : object\n            The updated object.",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_partial_fit_request",
          "signature": "set_partial_fit_request(self: sklearn.naive_bayes.BernoulliNB, *, classes: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.BernoulliNB",
          "documentation": {
            "description": "Request metadata passed to the ``partial_fit`` method.",
            "parameters": {
              "classes": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "Metadata": {
                "type": "routing for ``sample_weight`` parameter in ``partial_fit``.",
                "description": "Returns\n-------"
              },
              "sample_weight": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "The": {
                "type": "updated object.",
                "description": ""
              },
              "and": {
                "type": "not others.",
                "description": ".. versionadded:: 1.3\n.. note::"
              },
              "This": {
                "type": "method is only relevant if this estimator is used as a",
                "description": "sub-estimator of a meta-estimator, e.g. used inside a\n:class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect."
              }
            },
            "returns": "-------\n        self : object\n            The updated object.",
            "raises": "",
            "see_also": "",
            "notes": "that this method is only relevant if\n        ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n        Please see :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        The options for each parameter are:\n\n        - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n\n        - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n\n        - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n\n        - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n\n        The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n        existing request. This allows you to change the request for some\n        parameters and not others.\n\n        .. versionadded:: 1.3\n\n        .. note::\n            This method is only relevant if this estimator is used as a\n            sub-estimator of a meta-estimator, e.g. used inside a\n            :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n\n        Parameters\n        ----------\n        classes : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``classes`` parameter in ``partial_fit``.\n\n        sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n\n        Returns\n        -------\n        self : object\n            The updated object.",
            "examples": ""
          }
        },
        {
          "name": "set_score_request",
          "signature": "set_score_request(self: sklearn.naive_bayes.BernoulliNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.BernoulliNB",
          "documentation": {
            "description": "Request metadata passed to the ``score`` method.",
            "parameters": {
              "sample_weight": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "Metadata": {
                "type": "routing for ``sample_weight`` parameter in ``score``.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "The": {
                "type": "updated object.",
                "description": ""
              },
              "and": {
                "type": "not others.",
                "description": ".. versionadded:: 1.3\n.. note::"
              },
              "This": {
                "type": "method is only relevant if this estimator is used as a",
                "description": "sub-estimator of a meta-estimator, e.g. used inside a\n:class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect."
              }
            },
            "returns": "-------\n        self : object\n            The updated object.",
            "raises": "",
            "see_also": "",
            "notes": "that this method is only relevant if\n        ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n        Please see :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        The options for each parameter are:\n\n        - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n\n        - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n\n        - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n\n        - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n\n        The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n        existing request. This allows you to change the request for some\n        parameters and not others.\n\n        .. versionadded:: 1.3\n\n        .. note::\n            This method is only relevant if this estimator is used as a\n            sub-estimator of a meta-estimator, e.g. used inside a\n            :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n\n        Parameters\n        ----------\n        sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``sample_weight`` parameter in ``score``.\n\n        Returns\n        -------\n        self : object\n            The updated object.",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "CategoricalNB",
      "documentation": {
        "description": "Naive Bayes classifier for categorical features.\n\n    The categorical Naive Bayes classifier is suitable for classification with\n    discrete features that are categorically distributed. The categories of\n    each feature are drawn from a categorical distribution.\n\n    Read more in the :ref:`User Guide <categorical_naive_bayes>`.\n\n    Parameters\n    ----------\n    alpha : float, default=1.0\n        Additive (Laplace/Lidstone) smoothing parameter\n        (set alpha=0 and force_alpha=True, for no smoothing).\n\n    force_alpha : bool, default=True\n        If False and alpha is less than 1e-10, it will set alpha to\n        1e-10. If True, alpha will remain unchanged. This may cause\n        numerical errors if alpha is too close to 0.\n\n        .. versionadded:: 1.2\n        .. versionchanged:: 1.4\n           The default value of `force_alpha` changed to `True`.\n\n    fit_prior : bool, default=True\n        Whether to learn class prior probabilities or not.\n        If false, a uniform prior will be used.\n\n    class_prior : array-like of shape (n_classes,), default=None\n        Prior probabilities of the classes. If specified, the priors are not\n        adjusted according to the data.\n\n    min_categories : int or array-like of shape (n_features,), default=None\n        Minimum number of categories per feature.\n\n        - integer: Sets the minimum number of categories per feature to\n          `n_categories` for each features.\n        - array-like: shape (n_features,) where `n_categories[i]` holds the\n          minimum number of categories for the ith column of the input.\n        - None (default): Determines the number of categories automatically\n          from the training data.\n\n        .. versionadded:: 0.24\n\n    Attributes\n    ----------\n    category_count_ : list of arrays of shape (n_features,)\n        Holds arrays of shape (n_classes, n_categories of respective feature)\n        for each feature. Each array provides the number of samples\n        encountered for each class and category of the specific feature.\n\n    class_count_ : ndarray of shape (n_classes,)\n        Number of samples encountered for each class during fitting. This\n        value is weighted by the sample weight when provided.\n\n    class_log_prior_ : ndarray of shape (n_classes,)\n        Smoothed empirical log probability for each class.\n\n    classes_ : ndarray of shape (n_classes,)\n        Class labels known to the classifier\n\n    feature_log_prob_ : list of arrays of shape (n_features,)\n        Holds arrays of shape (n_classes, n_categories of respective feature)\n        for each feature. Each array provides the empirical log probability\n        of categories given the respective feature and class, ``P(x_i|y)``.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    n_categories_ : ndarray of shape (n_features,), dtype=np.int64\n        Number of categories for each feature. This value is\n        inferred from the data or set by the minimum number of categories.\n\n        .. versionadded:: 0.24\n\n    See Also\n    --------\n    BernoulliNB : Naive Bayes classifier for multivariate Bernoulli models.\n    ComplementNB : Complement Naive Bayes classifier.\n    GaussianNB : Gaussian Naive Bayes.\n    MultinomialNB : Naive Bayes classifier for multinomial models.",
        "parameters": {
          "alpha": {
            "type": "float, default=1.0",
            "description": ""
          },
          "Additive": {
            "type": "Laplace/Lidstone",
            "description": "smoothing parameter\n(set alpha=0 and force_alpha=True, for no smoothing)."
          },
          "force_alpha": {
            "type": "bool, default=True",
            "description": ""
          },
          "If": {
            "type": "false, a uniform prior will be used.",
            "description": ""
          },
          "numerical": {
            "type": "errors if alpha is too close to 0.",
            "description": ".. versionadded:: 1.2\n.. versionchanged:: 1.4"
          },
          "The": {
            "type": "default value of `force_alpha` changed to `True`.",
            "description": ""
          },
          "fit_prior": {
            "type": "bool, default=True",
            "description": ""
          },
          "Whether": {
            "type": "to learn class prior probabilities or not.",
            "description": ""
          },
          "class_prior": {
            "type": "array",
            "description": "like of shape (n_classes,), default=None"
          },
          "Prior": {
            "type": "probabilities of the classes. If specified, the priors are not",
            "description": ""
          },
          "adjusted": {
            "type": "according to the data.",
            "description": ""
          },
          "min_categories": {
            "type": "int or array",
            "description": "like of shape (n_features,), default=None"
          },
          "Minimum": {
            "type": "number of categories per feature.",
            "description": "- integer: Sets the minimum number of categories per feature to\n`n_categories` for each features.\n- array-like: shape (n_features,) where `n_categories[i]` holds the"
          },
          "minimum": {
            "type": "number of categories for the ith column of the input.",
            "description": "- None (default): Determines the number of categories automatically"
          },
          "from": {
            "type": "the training data.",
            "description": ".. versionadded:: 0.24\nAttributes\n----------"
          },
          "category_count_": {
            "type": "list of arrays of shape (n_features,)",
            "description": ""
          },
          "Holds": {
            "type": "arrays of shape (n_classes, n_categories of respective feature)",
            "description": ""
          },
          "for": {
            "type": "each feature. Each array provides the empirical log probability",
            "description": ""
          },
          "encountered": {
            "type": "for each class and category of the specific feature.",
            "description": ""
          },
          "class_count_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "Number": {
            "type": "of categories for each feature. This value is",
            "description": ""
          },
          "value": {
            "type": "is weighted by the sample weight when provided.",
            "description": ""
          },
          "class_log_prior_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "Smoothed": {
            "type": "empirical log probability for each class.",
            "description": ""
          },
          "classes_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "Class": {
            "type": "labels known to the classifier",
            "description": ""
          },
          "feature_log_prob_": {
            "type": "list of arrays of shape (n_features,)",
            "description": ""
          },
          "of": {
            "type": "categories given the respective feature and class, ``P(x_i|y)``.",
            "description": ""
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "n_categories_": {
            "type": "ndarray of shape (n_features,), dtype=np.int64",
            "description": ""
          },
          "inferred": {
            "type": "from the data or set by the minimum number of categories.",
            "description": ".. versionadded:: 0.24"
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "BernoulliNB": {
            "type": "Naive Bayes classifier for multivariate Bernoulli models.",
            "description": ""
          },
          "ComplementNB": {
            "type": "Complement Naive Bayes classifier.",
            "description": ""
          },
          "GaussianNB": {
            "type": "Gaussian Naive Bayes.",
            "description": ""
          },
          "MultinomialNB": {
            "type": "Naive Bayes classifier for multinomial models.",
            "description": "Examples\n--------\n>>> import numpy as np\n>>> rng = np.random.RandomState(1)\n>>> X = rng.randint(5, size=(6, 100))\n>>> y = np.array([1, 2, 3, 4, 5, 6])\n>>> from sklearn.naive_bayes import CategoricalNB\n>>> clf = CategoricalNB()\n>>> clf.fit(X, y)"
          },
          "CategoricalNB": {
            "type": "",
            "description": ">>> print(clf.predict(X[2:3]))\n[3]"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    BernoulliNB : Naive Bayes classifier for multivariate Bernoulli models.\n    ComplementNB : Complement Naive Bayes classifier.\n    GaussianNB : Gaussian Naive Bayes.\n    MultinomialNB : Naive Bayes classifier for multinomial models.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> rng = np.random.RandomState(1)\n    >>> X = rng.randint(5, size=(6, 100))\n    >>> y = np.array([1, 2, 3, 4, 5, 6])\n    >>> from sklearn.naive_bayes import CategoricalNB\n    >>> clf = CategoricalNB()\n    >>> clf.fit(X, y)\n    CategoricalNB()\n    >>> print(clf.predict(X[2:3]))\n    [3]",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> rng = np.random.RandomState(1)\n    >>> X = rng.randint(5, size=(6, 100))\n    >>> y = np.array([1, 2, 3, 4, 5, 6])\n    >>> from sklearn.naive_bayes import CategoricalNB\n    >>> clf = CategoricalNB()\n    >>> clf.fit(X, y)\n    CategoricalNB()\n    >>> print(clf.predict(X[2:3]))\n    [3]"
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, X, y, sample_weight=None)",
          "documentation": {
            "description": "Fit Naive Bayes classifier according to X, y.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training vectors, where `n_samples` is the number of samples and\n            `n_features` is the number of features. Here, each feature of X is\n            assumed to be from a different categorical distribution.\n            It is further assumed that all categories of each feature are\n            represented by the numbers 0, ..., n - 1, where n refers to the\n            total number of categories for the given feature. This can, for\n            instance, be achieved with the help of OrdinalEncoder.\n\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Weights applied to individual samples (1. for unweighted).",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like, sparse matrix} of shape (n_samples, n_features)"
              },
              "Training": {
                "type": "vectors, where `n_samples` is the number of samples and",
                "description": "`n_features` is the number of features. Here, each feature of X is"
              },
              "assumed": {
                "type": "to be from a different categorical distribution.",
                "description": ""
              },
              "It": {
                "type": "is further assumed that all categories of each feature are",
                "description": ""
              },
              "represented": {
                "type": "by the numbers 0, ..., n - 1, where n refers to the",
                "description": ""
              },
              "total": {
                "type": "number of categories for the given feature. This can, for",
                "description": "instance, be achieved with the help of OrdinalEncoder."
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,)"
              },
              "Target": {
                "type": "values.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Weights": {
                "type": "applied to individual samples (1. for unweighted).",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "partial_fit",
          "signature": "partial_fit(self, X, y, classes=None, sample_weight=None)",
          "documentation": {
            "description": "Incremental fit on a batch of samples.\n\n        This method is expected to be called several times consecutively\n        on different chunks of a dataset so as to implement out-of-core\n        or online learning.\n\n        This is especially useful when the whole dataset is too big to fit in\n        memory at once.\n\n        This method has some performance overhead hence it is better to call\n        partial_fit on chunks of data that are as large as possible\n        (as long as fitting in the memory budget) to hide the overhead.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training vectors, where `n_samples` is the number of samples and\n            `n_features` is the number of features. Here, each feature of X is\n            assumed to be from a different categorical distribution.\n            It is further assumed that all categories of each feature are\n            represented by the numbers 0, ..., n - 1, where n refers to the\n            total number of categories for the given feature. This can, for\n            instance, be achieved with the help of OrdinalEncoder.\n\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        classes : array-like of shape (n_classes,), default=None\n            List of all the classes that can possibly appear in the y vector.\n\n            Must be provided at the first call to partial_fit, can be omitted\n            in subsequent calls.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Weights applied to individual samples (1. for unweighted).",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like, sparse matrix} of shape (n_samples, n_features)"
              },
              "Training": {
                "type": "vectors, where `n_samples` is the number of samples and",
                "description": "`n_features` is the number of features. Here, each feature of X is"
              },
              "assumed": {
                "type": "to be from a different categorical distribution.",
                "description": ""
              },
              "It": {
                "type": "is further assumed that all categories of each feature are",
                "description": ""
              },
              "represented": {
                "type": "by the numbers 0, ..., n - 1, where n refers to the",
                "description": ""
              },
              "total": {
                "type": "number of categories for the given feature. This can, for",
                "description": "instance, be achieved with the help of OrdinalEncoder."
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,)"
              },
              "Target": {
                "type": "values.",
                "description": ""
              },
              "classes": {
                "type": "array",
                "description": "like of shape (n_classes,), default=None"
              },
              "List": {
                "type": "of all the classes that can possibly appear in the y vector.",
                "description": ""
              },
              "Must": {
                "type": "be provided at the first call to partial_fit, can be omitted",
                "description": ""
              },
              "in": {
                "type": "subsequent calls.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Weights": {
                "type": "applied to individual samples (1. for unweighted).",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict",
          "signature": "predict(self, X)",
          "documentation": {
            "description": "Perform classification on an array of test vectors X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "ndarray of shape (n_samples,)",
                "description": ""
              },
              "Predicted": {
                "type": "target values for X.",
                "description": ""
              }
            },
            "returns": "-------\n        C : ndarray of shape (n_samples,)\n            Predicted target values for X.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_joint_log_proba",
          "signature": "predict_joint_log_proba(self, X)",
          "documentation": {
            "description": "Return joint log probability estimates for the test vector X.\n\n        For each row x of X and class y, the joint log probability is given by\n        ``log P(x, y) = log P(y) + log P(x|y),``\n        where ``log P(y)`` is the class prior probability and ``log P(x|y)`` is\n        the class-conditional probability.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "ndarray of shape (n_samples, n_classes)",
                "description": ""
              },
              "Returns": {
                "type": "the joint log-probability of the samples for each class in",
                "description": ""
              },
              "the": {
                "type": "model. The columns correspond to the classes in sorted",
                "description": "order, as they appear in the attribute :term:`classes_`."
              }
            },
            "returns": "-------\n        C : ndarray of shape (n_samples, n_classes)",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_log_proba",
          "signature": "predict_log_proba(self, X)",
          "documentation": {
            "description": "",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "array",
                "description": "like of shape (n_samples, n_classes)"
              },
              "Returns": {
                "type": "the log-probability of the samples for each class in",
                "description": ""
              },
              "the": {
                "type": "model. The columns correspond to the classes in sorted",
                "description": "order, as they appear in the attribute :term:`classes_`."
              }
            },
            "returns": "log-probability estimates for the test vector X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.\n\n        Returns\n        -------\n        C : array-like of shape (n_samples, n_classes)\n            Returns the log-probability of the samples for each class in\n            the model. The columns correspond to the classes in sorted\n            order, as they appear in the attribute :term:`classes_`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_proba",
          "signature": "predict_proba(self, X)",
          "documentation": {
            "description": "",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "array",
                "description": "like of shape (n_samples, n_classes)"
              },
              "Returns": {
                "type": "the probability of the samples for each class in",
                "description": ""
              },
              "the": {
                "type": "model. The columns correspond to the classes in sorted",
                "description": "order, as they appear in the attribute :term:`classes_`."
              }
            },
            "returns": "probability estimates for the test vector X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.\n\n        Returns\n        -------\n        C : array-like of shape (n_samples, n_classes)\n            Returns the probability of the samples for each class in\n            the model. The columns correspond to the classes in sorted\n            order, as they appear in the attribute :term:`classes_`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "score",
          "signature": "score(self, X, y, sample_weight=None)",
          "documentation": {
            "description": "",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Test": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs)"
              },
              "True": {
                "type": "labels for `X`.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Sample": {
                "type": "weights.",
                "description": "Returns\n-------"
              },
              "score": {
                "type": "float",
                "description": ""
              },
              "Mean": {
                "type": "accuracy of ``self.predict(X)`` w.r.t. `y`.",
                "description": ""
              }
            },
            "returns": "the mean accuracy on the given test data and labels.\n\n        In multi-label classification, this is the subset accuracy\n        which is a harsh metric since you require for each sample that\n        each label set be correctly predicted.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Test samples.\n\n        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n            True labels for `X`.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Sample weights.\n\n        Returns\n        -------\n        score : float\n            Mean accuracy of ``self.predict(X)`` w.r.t. `y`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_fit_request",
          "signature": "set_fit_request(self: sklearn.naive_bayes.CategoricalNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.CategoricalNB",
          "documentation": {
            "description": "Request metadata passed to the ``fit`` method.",
            "parameters": {
              "sample_weight": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "Metadata": {
                "type": "routing for ``sample_weight`` parameter in ``fit``.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "The": {
                "type": "updated object.",
                "description": ""
              },
              "and": {
                "type": "not others.",
                "description": ".. versionadded:: 1.3\n.. note::"
              },
              "This": {
                "type": "method is only relevant if this estimator is used as a",
                "description": "sub-estimator of a meta-estimator, e.g. used inside a\n:class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect."
              }
            },
            "returns": "-------\n        self : object\n            The updated object.",
            "raises": "",
            "see_also": "",
            "notes": "that this method is only relevant if\n        ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n        Please see :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        The options for each parameter are:\n\n        - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n\n        - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n\n        - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n\n        - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n\n        The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n        existing request. This allows you to change the request for some\n        parameters and not others.\n\n        .. versionadded:: 1.3\n\n        .. note::\n            This method is only relevant if this estimator is used as a\n            sub-estimator of a meta-estimator, e.g. used inside a\n            :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n\n        Parameters\n        ----------\n        sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``sample_weight`` parameter in ``fit``.\n\n        Returns\n        -------\n        self : object\n            The updated object.",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_partial_fit_request",
          "signature": "set_partial_fit_request(self: sklearn.naive_bayes.CategoricalNB, *, classes: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.CategoricalNB",
          "documentation": {
            "description": "Request metadata passed to the ``partial_fit`` method.",
            "parameters": {
              "classes": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "Metadata": {
                "type": "routing for ``sample_weight`` parameter in ``partial_fit``.",
                "description": "Returns\n-------"
              },
              "sample_weight": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "The": {
                "type": "updated object.",
                "description": ""
              },
              "and": {
                "type": "not others.",
                "description": ".. versionadded:: 1.3\n.. note::"
              },
              "This": {
                "type": "method is only relevant if this estimator is used as a",
                "description": "sub-estimator of a meta-estimator, e.g. used inside a\n:class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect."
              }
            },
            "returns": "-------\n        self : object\n            The updated object.",
            "raises": "",
            "see_also": "",
            "notes": "that this method is only relevant if\n        ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n        Please see :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        The options for each parameter are:\n\n        - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n\n        - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n\n        - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n\n        - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n\n        The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n        existing request. This allows you to change the request for some\n        parameters and not others.\n\n        .. versionadded:: 1.3\n\n        .. note::\n            This method is only relevant if this estimator is used as a\n            sub-estimator of a meta-estimator, e.g. used inside a\n            :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n\n        Parameters\n        ----------\n        classes : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``classes`` parameter in ``partial_fit``.\n\n        sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n\n        Returns\n        -------\n        self : object\n            The updated object.",
            "examples": ""
          }
        },
        {
          "name": "set_score_request",
          "signature": "set_score_request(self: sklearn.naive_bayes.CategoricalNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.CategoricalNB",
          "documentation": {
            "description": "Request metadata passed to the ``score`` method.",
            "parameters": {
              "sample_weight": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "Metadata": {
                "type": "routing for ``sample_weight`` parameter in ``score``.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "The": {
                "type": "updated object.",
                "description": ""
              },
              "and": {
                "type": "not others.",
                "description": ".. versionadded:: 1.3\n.. note::"
              },
              "This": {
                "type": "method is only relevant if this estimator is used as a",
                "description": "sub-estimator of a meta-estimator, e.g. used inside a\n:class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect."
              }
            },
            "returns": "-------\n        self : object\n            The updated object.",
            "raises": "",
            "see_also": "",
            "notes": "that this method is only relevant if\n        ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n        Please see :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        The options for each parameter are:\n\n        - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n\n        - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n\n        - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n\n        - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n\n        The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n        existing request. This allows you to change the request for some\n        parameters and not others.\n\n        .. versionadded:: 1.3\n\n        .. note::\n            This method is only relevant if this estimator is used as a\n            sub-estimator of a meta-estimator, e.g. used inside a\n            :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n\n        Parameters\n        ----------\n        sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``sample_weight`` parameter in ``score``.\n\n        Returns\n        -------\n        self : object\n            The updated object.",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "ClassifierMixin",
      "documentation": {
        "description": "Mixin class for all classifiers in scikit-learn.\n\n    This mixin defines the following functionality:\n\n    - set estimator type to `\"classifier\"` through the `estimator_type` tag;\n    - `score` method that default to :func:`~sklearn.metrics.accuracy_score`.\n    - enforce that `fit` requires `y` to be passed through the `requires_y` tag,\n      which is done by setting the classifier type tag.\n\n    Read more in the :ref:`User Guide <rolling_your_own_estimator>`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.base import BaseEstimator, ClassifierMixin\n    >>> # Mixin classes should always be on the left-hand side for a correct MRO\n    >>> class MyEstimator(ClassifierMixin, BaseEstimator):\n    ...     def __init__(self, *, param=1):\n    ...         self.param = param\n    ...     def fit(self, X, y=None):\n    ...         self.is_fitted_ = True\n    ...         return self\n    ...     def predict(self, X):\n    ...         return np.full(shape=X.shape[0], fill_value=self.param)\n    >>> estimator = MyEstimator(param=1)\n    >>> X = np.array([[1, 2], [2, 3], [3, 4]])\n    >>> y = np.array([1, 0, 1])\n    >>> estimator.fit(X, y).predict(X)\n    array([1, 1, 1])\n    >>> estimator.score(X, y)\n    0.66..."
      },
      "methods": [
        {
          "name": "score",
          "signature": "score(self, X, y, sample_weight=None)",
          "documentation": {
            "description": "",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Test": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs)"
              },
              "True": {
                "type": "labels for `X`.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Sample": {
                "type": "weights.",
                "description": "Returns\n-------"
              },
              "score": {
                "type": "float",
                "description": ""
              },
              "Mean": {
                "type": "accuracy of ``self.predict(X)`` w.r.t. `y`.",
                "description": ""
              }
            },
            "returns": "the mean accuracy on the given test data and labels.\n\n        In multi-label classification, this is the subset accuracy\n        which is a harsh metric since you require for each sample that\n        each label set be correctly predicted.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Test samples.\n\n        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n            True labels for `X`.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Sample weights.\n\n        Returns\n        -------\n        score : float\n            Mean accuracy of ``self.predict(X)`` w.r.t. `y`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "ComplementNB",
      "documentation": {
        "description": "The Complement Naive Bayes classifier described in Rennie et al. (2003).\n\n    The Complement Naive Bayes classifier was designed to correct the \"severe\n    assumptions\" made by the standard Multinomial Naive Bayes classifier. It is\n    particularly suited for imbalanced data sets.\n\n    Read more in the :ref:`User Guide <complement_naive_bayes>`.\n\n    .. versionadded:: 0.20\n\n    Parameters\n    ----------\n    alpha : float or array-like of shape (n_features,), default=1.0\n        Additive (Laplace/Lidstone) smoothing parameter\n        (set alpha=0 and force_alpha=True, for no smoothing).\n\n    force_alpha : bool, default=True\n        If False and alpha is less than 1e-10, it will set alpha to\n        1e-10. If True, alpha will remain unchanged. This may cause\n        numerical errors if alpha is too close to 0.\n\n        .. versionadded:: 1.2\n        .. versionchanged:: 1.4\n           The default value of `force_alpha` changed to `True`.\n\n    fit_prior : bool, default=True\n        Only used in edge case with a single class in the training set.\n\n    class_prior : array-like of shape (n_classes,), default=None\n        Prior probabilities of the classes. Not used.\n\n    norm : bool, default=False\n        Whether or not a second normalization of the weights is performed. The\n        default behavior mirrors the implementations found in Mahout and Weka,\n        which do not follow the full algorithm described in Table 9 of the\n        paper.\n\n    Attributes\n    ----------\n    class_count_ : ndarray of shape (n_classes,)\n        Number of samples encountered for each class during fitting. This\n        value is weighted by the sample weight when provided.\n\n    class_log_prior_ : ndarray of shape (n_classes,)\n        Smoothed empirical log probability for each class. Only used in edge\n        case with a single class in the training set.\n\n    classes_ : ndarray of shape (n_classes,)\n        Class labels known to the classifier\n\n    feature_all_ : ndarray of shape (n_features,)\n        Number of samples encountered for each feature during fitting. This\n        value is weighted by the sample weight when provided.\n\n    feature_count_ : ndarray of shape (n_classes, n_features)\n        Number of samples encountered for each (class, feature) during fitting.\n        This value is weighted by the sample weight when provided.\n\n    feature_log_prob_ : ndarray of shape (n_classes, n_features)\n        Empirical weights for class complements.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    BernoulliNB : Naive Bayes classifier for multivariate Bernoulli models.\n    CategoricalNB : Naive Bayes classifier for categorical features.\n    GaussianNB : Gaussian Naive Bayes.\n    MultinomialNB : Naive Bayes classifier for multinomial models.\n\n    References\n    ----------\n    Rennie, J. D., Shih, L., Teevan, J., & Karger, D. R. (2003).\n    Tackling the poor assumptions of naive bayes text classifiers. In ICML\n    (Vol. 3, pp. 616-623).\n    https://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf",
        "parameters": {
          "alpha": {
            "type": "float or array",
            "description": "like of shape (n_features,), default=1.0"
          },
          "Additive": {
            "type": "Laplace/Lidstone",
            "description": "smoothing parameter\n(set alpha=0 and force_alpha=True, for no smoothing)."
          },
          "force_alpha": {
            "type": "bool, default=True",
            "description": ""
          },
          "If": {
            "type": "False and alpha is less than 1e-10, it will set alpha to",
            "description": "1e-10. If True, alpha will remain unchanged. This may cause"
          },
          "numerical": {
            "type": "errors if alpha is too close to 0.",
            "description": ".. versionadded:: 1.2\n.. versionchanged:: 1.4"
          },
          "The": {
            "type": "default value of `force_alpha` changed to `True`.",
            "description": ""
          },
          "fit_prior": {
            "type": "bool, default=True",
            "description": ""
          },
          "Only": {
            "type": "used in edge case with a single class in the training set.",
            "description": ""
          },
          "class_prior": {
            "type": "array",
            "description": "like of shape (n_classes,), default=None"
          },
          "Prior": {
            "type": "probabilities of the classes. Not used.",
            "description": ""
          },
          "norm": {
            "type": "bool, default=False",
            "description": ""
          },
          "Whether": {
            "type": "or not a second normalization of the weights is performed. The",
            "description": ""
          },
          "default": {
            "type": "behavior mirrors the implementations found in Mahout and Weka,",
            "description": ""
          },
          "which": {
            "type": "do not follow the full algorithm described in Table 9 of the",
            "description": "paper.\nAttributes\n----------"
          },
          "class_count_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "Number": {
            "type": "of features seen during :term:`fit`.",
            "description": ".. versionadded:: 0.24"
          },
          "value": {
            "type": "is weighted by the sample weight when provided.",
            "description": ""
          },
          "class_log_prior_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "Smoothed": {
            "type": "empirical log probability for each class. Only used in edge",
            "description": ""
          },
          "case": {
            "type": "with a single class in the training set.",
            "description": ""
          },
          "classes_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "Class": {
            "type": "labels known to the classifier",
            "description": ""
          },
          "feature_all_": {
            "type": "ndarray of shape (n_features,)",
            "description": ""
          },
          "feature_count_": {
            "type": "ndarray of shape (n_classes, n_features)",
            "description": ""
          },
          "This": {
            "type": "value is weighted by the sample weight when provided.",
            "description": ""
          },
          "feature_log_prob_": {
            "type": "ndarray of shape (n_classes, n_features)",
            "description": ""
          },
          "Empirical": {
            "type": "weights for class complements.",
            "description": ""
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "BernoulliNB": {
            "type": "Naive Bayes classifier for multivariate Bernoulli models.",
            "description": ""
          },
          "CategoricalNB": {
            "type": "Naive Bayes classifier for categorical features.",
            "description": ""
          },
          "GaussianNB": {
            "type": "Gaussian Naive Bayes.",
            "description": ""
          },
          "MultinomialNB": {
            "type": "Naive Bayes classifier for multinomial models.",
            "description": "References\n----------\nRennie, J. D., Shih, L., Teevan, J., & Karger, D. R. (2003)."
          },
          "Tackling": {
            "type": "the poor assumptions of naive bayes text classifiers. In ICML",
            "description": "(Vol. 3, pp. 616-623)."
          },
          "https": {
            "type": "//people.csail.mit.edu/jrennie/papers/icml03",
            "description": "nb.pdf\nExamples\n--------\n>>> import numpy as np\n>>> rng = np.random.RandomState(1)\n>>> X = rng.randint(5, size=(6, 100))\n>>> y = np.array([1, 2, 3, 4, 5, 6])\n>>> from sklearn.naive_bayes import ComplementNB\n>>> clf = ComplementNB()\n>>> clf.fit(X, y)"
          },
          "ComplementNB": {
            "type": "",
            "description": ">>> print(clf.predict(X[2:3]))\n[3]"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    BernoulliNB : Naive Bayes classifier for multivariate Bernoulli models.\n    CategoricalNB : Naive Bayes classifier for categorical features.\n    GaussianNB : Gaussian Naive Bayes.\n    MultinomialNB : Naive Bayes classifier for multinomial models.\n\n    References\n    ----------\n    Rennie, J. D., Shih, L., Teevan, J., & Karger, D. R. (2003).\n    Tackling the poor assumptions of naive bayes text classifiers. In ICML\n    (Vol. 3, pp. 616-623).\n    https://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> rng = np.random.RandomState(1)\n    >>> X = rng.randint(5, size=(6, 100))\n    >>> y = np.array([1, 2, 3, 4, 5, 6])\n    >>> from sklearn.naive_bayes import ComplementNB\n    >>> clf = ComplementNB()\n    >>> clf.fit(X, y)\n    ComplementNB()\n    >>> print(clf.predict(X[2:3]))\n    [3]",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> rng = np.random.RandomState(1)\n    >>> X = rng.randint(5, size=(6, 100))\n    >>> y = np.array([1, 2, 3, 4, 5, 6])\n    >>> from sklearn.naive_bayes import ComplementNB\n    >>> clf = ComplementNB()\n    >>> clf.fit(X, y)\n    ComplementNB()\n    >>> print(clf.predict(X[2:3]))\n    [3]"
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, X, y, sample_weight=None)",
          "documentation": {
            "description": "Fit Naive Bayes classifier according to X, y.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training vectors, where `n_samples` is the number of samples and\n            `n_features` is the number of features.\n\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Weights applied to individual samples (1. for unweighted).",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like, sparse matrix} of shape (n_samples, n_features)"
              },
              "Training": {
                "type": "vectors, where `n_samples` is the number of samples and",
                "description": "`n_features` is the number of features."
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,)"
              },
              "Target": {
                "type": "values.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Weights": {
                "type": "applied to individual samples (1. for unweighted).",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "partial_fit",
          "signature": "partial_fit(self, X, y, classes=None, sample_weight=None)",
          "documentation": {
            "description": "Incremental fit on a batch of samples.\n\n        This method is expected to be called several times consecutively\n        on different chunks of a dataset so as to implement out-of-core\n        or online learning.\n\n        This is especially useful when the whole dataset is too big to fit in\n        memory at once.\n\n        This method has some performance overhead hence it is better to call\n        partial_fit on chunks of data that are as large as possible\n        (as long as fitting in the memory budget) to hide the overhead.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training vectors, where `n_samples` is the number of samples and\n            `n_features` is the number of features.\n\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        classes : array-like of shape (n_classes,), default=None\n            List of all the classes that can possibly appear in the y vector.\n\n            Must be provided at the first call to partial_fit, can be omitted\n            in subsequent calls.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Weights applied to individual samples (1. for unweighted).",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like, sparse matrix} of shape (n_samples, n_features)"
              },
              "Training": {
                "type": "vectors, where `n_samples` is the number of samples and",
                "description": "`n_features` is the number of features."
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,)"
              },
              "Target": {
                "type": "values.",
                "description": ""
              },
              "classes": {
                "type": "array",
                "description": "like of shape (n_classes,), default=None"
              },
              "List": {
                "type": "of all the classes that can possibly appear in the y vector.",
                "description": ""
              },
              "Must": {
                "type": "be provided at the first call to partial_fit, can be omitted",
                "description": ""
              },
              "in": {
                "type": "subsequent calls.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Weights": {
                "type": "applied to individual samples (1. for unweighted).",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict",
          "signature": "predict(self, X)",
          "documentation": {
            "description": "Perform classification on an array of test vectors X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "ndarray of shape (n_samples,)",
                "description": ""
              },
              "Predicted": {
                "type": "target values for X.",
                "description": ""
              }
            },
            "returns": "-------\n        C : ndarray of shape (n_samples,)\n            Predicted target values for X.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_joint_log_proba",
          "signature": "predict_joint_log_proba(self, X)",
          "documentation": {
            "description": "Return joint log probability estimates for the test vector X.\n\n        For each row x of X and class y, the joint log probability is given by\n        ``log P(x, y) = log P(y) + log P(x|y),``\n        where ``log P(y)`` is the class prior probability and ``log P(x|y)`` is\n        the class-conditional probability.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "ndarray of shape (n_samples, n_classes)",
                "description": ""
              },
              "Returns": {
                "type": "the joint log-probability of the samples for each class in",
                "description": ""
              },
              "the": {
                "type": "model. The columns correspond to the classes in sorted",
                "description": "order, as they appear in the attribute :term:`classes_`."
              }
            },
            "returns": "-------\n        C : ndarray of shape (n_samples, n_classes)",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_log_proba",
          "signature": "predict_log_proba(self, X)",
          "documentation": {
            "description": "",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "array",
                "description": "like of shape (n_samples, n_classes)"
              },
              "Returns": {
                "type": "the log-probability of the samples for each class in",
                "description": ""
              },
              "the": {
                "type": "model. The columns correspond to the classes in sorted",
                "description": "order, as they appear in the attribute :term:`classes_`."
              }
            },
            "returns": "log-probability estimates for the test vector X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.\n\n        Returns\n        -------\n        C : array-like of shape (n_samples, n_classes)\n            Returns the log-probability of the samples for each class in\n            the model. The columns correspond to the classes in sorted\n            order, as they appear in the attribute :term:`classes_`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_proba",
          "signature": "predict_proba(self, X)",
          "documentation": {
            "description": "",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "array",
                "description": "like of shape (n_samples, n_classes)"
              },
              "Returns": {
                "type": "the probability of the samples for each class in",
                "description": ""
              },
              "the": {
                "type": "model. The columns correspond to the classes in sorted",
                "description": "order, as they appear in the attribute :term:`classes_`."
              }
            },
            "returns": "probability estimates for the test vector X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.\n\n        Returns\n        -------\n        C : array-like of shape (n_samples, n_classes)\n            Returns the probability of the samples for each class in\n            the model. The columns correspond to the classes in sorted\n            order, as they appear in the attribute :term:`classes_`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "score",
          "signature": "score(self, X, y, sample_weight=None)",
          "documentation": {
            "description": "",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Test": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs)"
              },
              "True": {
                "type": "labels for `X`.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Sample": {
                "type": "weights.",
                "description": "Returns\n-------"
              },
              "score": {
                "type": "float",
                "description": ""
              },
              "Mean": {
                "type": "accuracy of ``self.predict(X)`` w.r.t. `y`.",
                "description": ""
              }
            },
            "returns": "the mean accuracy on the given test data and labels.\n\n        In multi-label classification, this is the subset accuracy\n        which is a harsh metric since you require for each sample that\n        each label set be correctly predicted.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Test samples.\n\n        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n            True labels for `X`.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Sample weights.\n\n        Returns\n        -------\n        score : float\n            Mean accuracy of ``self.predict(X)`` w.r.t. `y`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_fit_request",
          "signature": "set_fit_request(self: sklearn.naive_bayes.ComplementNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.ComplementNB",
          "documentation": {
            "description": "Request metadata passed to the ``fit`` method.",
            "parameters": {
              "sample_weight": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "Metadata": {
                "type": "routing for ``sample_weight`` parameter in ``fit``.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "The": {
                "type": "updated object.",
                "description": ""
              },
              "and": {
                "type": "not others.",
                "description": ".. versionadded:: 1.3\n.. note::"
              },
              "This": {
                "type": "method is only relevant if this estimator is used as a",
                "description": "sub-estimator of a meta-estimator, e.g. used inside a\n:class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect."
              }
            },
            "returns": "-------\n        self : object\n            The updated object.",
            "raises": "",
            "see_also": "",
            "notes": "that this method is only relevant if\n        ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n        Please see :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        The options for each parameter are:\n\n        - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n\n        - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n\n        - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n\n        - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n\n        The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n        existing request. This allows you to change the request for some\n        parameters and not others.\n\n        .. versionadded:: 1.3\n\n        .. note::\n            This method is only relevant if this estimator is used as a\n            sub-estimator of a meta-estimator, e.g. used inside a\n            :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n\n        Parameters\n        ----------\n        sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``sample_weight`` parameter in ``fit``.\n\n        Returns\n        -------\n        self : object\n            The updated object.",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_partial_fit_request",
          "signature": "set_partial_fit_request(self: sklearn.naive_bayes.ComplementNB, *, classes: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.ComplementNB",
          "documentation": {
            "description": "Request metadata passed to the ``partial_fit`` method.",
            "parameters": {
              "classes": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "Metadata": {
                "type": "routing for ``sample_weight`` parameter in ``partial_fit``.",
                "description": "Returns\n-------"
              },
              "sample_weight": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "The": {
                "type": "updated object.",
                "description": ""
              },
              "and": {
                "type": "not others.",
                "description": ".. versionadded:: 1.3\n.. note::"
              },
              "This": {
                "type": "method is only relevant if this estimator is used as a",
                "description": "sub-estimator of a meta-estimator, e.g. used inside a\n:class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect."
              }
            },
            "returns": "-------\n        self : object\n            The updated object.",
            "raises": "",
            "see_also": "",
            "notes": "that this method is only relevant if\n        ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n        Please see :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        The options for each parameter are:\n\n        - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n\n        - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n\n        - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n\n        - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n\n        The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n        existing request. This allows you to change the request for some\n        parameters and not others.\n\n        .. versionadded:: 1.3\n\n        .. note::\n            This method is only relevant if this estimator is used as a\n            sub-estimator of a meta-estimator, e.g. used inside a\n            :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n\n        Parameters\n        ----------\n        classes : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``classes`` parameter in ``partial_fit``.\n\n        sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n\n        Returns\n        -------\n        self : object\n            The updated object.",
            "examples": ""
          }
        },
        {
          "name": "set_score_request",
          "signature": "set_score_request(self: sklearn.naive_bayes.ComplementNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.ComplementNB",
          "documentation": {
            "description": "Request metadata passed to the ``score`` method.",
            "parameters": {
              "sample_weight": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "Metadata": {
                "type": "routing for ``sample_weight`` parameter in ``score``.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "The": {
                "type": "updated object.",
                "description": ""
              },
              "and": {
                "type": "not others.",
                "description": ".. versionadded:: 1.3\n.. note::"
              },
              "This": {
                "type": "method is only relevant if this estimator is used as a",
                "description": "sub-estimator of a meta-estimator, e.g. used inside a\n:class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect."
              }
            },
            "returns": "-------\n        self : object\n            The updated object.",
            "raises": "",
            "see_also": "",
            "notes": "that this method is only relevant if\n        ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n        Please see :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        The options for each parameter are:\n\n        - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n\n        - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n\n        - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n\n        - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n\n        The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n        existing request. This allows you to change the request for some\n        parameters and not others.\n\n        .. versionadded:: 1.3\n\n        .. note::\n            This method is only relevant if this estimator is used as a\n            sub-estimator of a meta-estimator, e.g. used inside a\n            :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n\n        Parameters\n        ----------\n        sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``sample_weight`` parameter in ``score``.\n\n        Returns\n        -------\n        self : object\n            The updated object.",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "GaussianNB",
      "documentation": {
        "description": "Gaussian Naive Bayes (GaussianNB).\n\n    Can perform online updates to model parameters via :meth:`partial_fit`.\n    For details on algorithm used to update feature means and variance online,\n    see `Stanford CS tech report STAN-CS-79-773 by Chan, Golub, and LeVeque\n    <http://i.stanford.edu/pub/cstr/reports/cs/tr/79/773/CS-TR-79-773.pdf>`_.\n\n    Read more in the :ref:`User Guide <gaussian_naive_bayes>`.\n\n    Parameters\n    ----------\n    priors : array-like of shape (n_classes,), default=None\n        Prior probabilities of the classes. If specified, the priors are not\n        adjusted according to the data.\n\n    var_smoothing : float, default=1e-9\n        Portion of the largest variance of all features that is added to\n        variances for calculation stability.\n\n        .. versionadded:: 0.20\n\n    Attributes\n    ----------\n    class_count_ : ndarray of shape (n_classes,)\n        number of training samples observed in each class.\n\n    class_prior_ : ndarray of shape (n_classes,)\n        probability of each class.\n\n    classes_ : ndarray of shape (n_classes,)\n        class labels known to the classifier.\n\n    epsilon_ : float\n        absolute additive value to variances.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    var_ : ndarray of shape (n_classes, n_features)\n        Variance of each feature per class.\n\n        .. versionadded:: 1.0\n\n    theta_ : ndarray of shape (n_classes, n_features)\n        mean of each feature per class.\n\n    See Also\n    --------\n    BernoulliNB : Naive Bayes classifier for multivariate Bernoulli models.\n    CategoricalNB : Naive Bayes classifier for categorical features.\n    ComplementNB : Complement Naive Bayes classifier.\n    MultinomialNB : Naive Bayes classifier for multinomial models.",
        "parameters": {
          "priors": {
            "type": "array",
            "description": "like of shape (n_classes,), default=None"
          },
          "Prior": {
            "type": "probabilities of the classes. If specified, the priors are not",
            "description": ""
          },
          "adjusted": {
            "type": "according to the data.",
            "description": ""
          },
          "var_smoothing": {
            "type": "float, default=1e",
            "description": "9"
          },
          "Portion": {
            "type": "of the largest variance of all features that is added to",
            "description": ""
          },
          "variances": {
            "type": "for calculation stability.",
            "description": ".. versionadded:: 0.20\nAttributes\n----------"
          },
          "class_count_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "number": {
            "type": "of training samples observed in each class.",
            "description": ""
          },
          "class_prior_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "probability": {
            "type": "of each class.",
            "description": ""
          },
          "classes_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "class": {
            "type": "labels known to the classifier.",
            "description": ""
          },
          "epsilon_": {
            "type": "float",
            "description": ""
          },
          "absolute": {
            "type": "additive value to variances.",
            "description": ""
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "Number": {
            "type": "of features seen during :term:`fit`.",
            "description": ".. versionadded:: 0.24"
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "var_": {
            "type": "ndarray of shape (n_classes, n_features)",
            "description": ""
          },
          "Variance": {
            "type": "of each feature per class.",
            "description": ".. versionadded:: 1.0"
          },
          "theta_": {
            "type": "ndarray of shape (n_classes, n_features)",
            "description": ""
          },
          "mean": {
            "type": "of each feature per class.",
            "description": ""
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "BernoulliNB": {
            "type": "Naive Bayes classifier for multivariate Bernoulli models.",
            "description": ""
          },
          "CategoricalNB": {
            "type": "Naive Bayes classifier for categorical features.",
            "description": ""
          },
          "ComplementNB": {
            "type": "Complement Naive Bayes classifier.",
            "description": ""
          },
          "MultinomialNB": {
            "type": "Naive Bayes classifier for multinomial models.",
            "description": "Examples\n--------\n>>> import numpy as np\n>>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n>>> Y = np.array([1, 1, 1, 2, 2, 2])\n>>> from sklearn.naive_bayes import GaussianNB\n>>> clf = GaussianNB()\n>>> clf.fit(X, Y)"
          },
          "GaussianNB": {
            "type": "",
            "description": ">>> print(clf_pf.predict([[-0.8, -1]]))\n[1]"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    BernoulliNB : Naive Bayes classifier for multivariate Bernoulli models.\n    CategoricalNB : Naive Bayes classifier for categorical features.\n    ComplementNB : Complement Naive Bayes classifier.\n    MultinomialNB : Naive Bayes classifier for multinomial models.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n    >>> Y = np.array([1, 1, 1, 2, 2, 2])\n    >>> from sklearn.naive_bayes import GaussianNB\n    >>> clf = GaussianNB()\n    >>> clf.fit(X, Y)\n    GaussianNB()\n    >>> print(clf.predict([[-0.8, -1]]))\n    [1]\n    >>> clf_pf = GaussianNB()\n    >>> clf_pf.partial_fit(X, Y, np.unique(Y))\n    GaussianNB()\n    >>> print(clf_pf.predict([[-0.8, -1]]))\n    [1]",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n    >>> Y = np.array([1, 1, 1, 2, 2, 2])\n    >>> from sklearn.naive_bayes import GaussianNB\n    >>> clf = GaussianNB()\n    >>> clf.fit(X, Y)\n    GaussianNB()\n    >>> print(clf.predict([[-0.8, -1]]))\n    [1]\n    >>> clf_pf = GaussianNB()\n    >>> clf_pf.partial_fit(X, Y, np.unique(Y))\n    GaussianNB()\n    >>> print(clf_pf.predict([[-0.8, -1]]))\n    [1]"
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, X, y, sample_weight=None)",
          "documentation": {
            "description": "Fit Gaussian Naive Bayes according to X, y.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training vectors, where `n_samples` is the number of samples\n            and `n_features` is the number of features.\n\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Weights applied to individual samples (1. for unweighted).\n\n            .. versionadded:: 0.17\n               Gaussian Naive Bayes supports fitting with *sample_weight*.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Training": {
                "type": "vectors, where `n_samples` is the number of samples",
                "description": ""
              },
              "and": {
                "type": "`n_features` is the number of features.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,)"
              },
              "Target": {
                "type": "values.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Weights": {
                "type": "applied to individual samples (1. for unweighted).",
                "description": ".. versionadded:: 0.17"
              },
              "Gaussian": {
                "type": "Naive Bayes supports fitting with *sample_weight*.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "partial_fit",
          "signature": "partial_fit(self, X, y, classes=None, sample_weight=None)",
          "documentation": {
            "description": "Incremental fit on a batch of samples.\n\n        This method is expected to be called several times consecutively\n        on different chunks of a dataset so as to implement out-of-core\n        or online learning.\n\n        This is especially useful when the whole dataset is too big to fit in\n        memory at once.\n\n        This method has some performance and numerical stability overhead,\n        hence it is better to call partial_fit on chunks of data that are\n        as large as possible (as long as fitting in the memory budget) to\n        hide the overhead.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training vectors, where `n_samples` is the number of samples and\n            `n_features` is the number of features.\n\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        classes : array-like of shape (n_classes,), default=None\n            List of all the classes that can possibly appear in the y vector.\n\n            Must be provided at the first call to partial_fit, can be omitted\n            in subsequent calls.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Weights applied to individual samples (1. for unweighted).\n\n            .. versionadded:: 0.17",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Training": {
                "type": "vectors, where `n_samples` is the number of samples and",
                "description": "`n_features` is the number of features."
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,)"
              },
              "Target": {
                "type": "values.",
                "description": ""
              },
              "classes": {
                "type": "array",
                "description": "like of shape (n_classes,), default=None"
              },
              "List": {
                "type": "of all the classes that can possibly appear in the y vector.",
                "description": ""
              },
              "Must": {
                "type": "be provided at the first call to partial_fit, can be omitted",
                "description": ""
              },
              "in": {
                "type": "subsequent calls.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Weights": {
                "type": "applied to individual samples (1. for unweighted).",
                "description": ".. versionadded:: 0.17\nReturns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict",
          "signature": "predict(self, X)",
          "documentation": {
            "description": "Perform classification on an array of test vectors X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "ndarray of shape (n_samples,)",
                "description": ""
              },
              "Predicted": {
                "type": "target values for X.",
                "description": ""
              }
            },
            "returns": "-------\n        C : ndarray of shape (n_samples,)\n            Predicted target values for X.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_joint_log_proba",
          "signature": "predict_joint_log_proba(self, X)",
          "documentation": {
            "description": "Return joint log probability estimates for the test vector X.\n\n        For each row x of X and class y, the joint log probability is given by\n        ``log P(x, y) = log P(y) + log P(x|y),``\n        where ``log P(y)`` is the class prior probability and ``log P(x|y)`` is\n        the class-conditional probability.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "ndarray of shape (n_samples, n_classes)",
                "description": ""
              },
              "Returns": {
                "type": "the joint log-probability of the samples for each class in",
                "description": ""
              },
              "the": {
                "type": "model. The columns correspond to the classes in sorted",
                "description": "order, as they appear in the attribute :term:`classes_`."
              }
            },
            "returns": "-------\n        C : ndarray of shape (n_samples, n_classes)",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_log_proba",
          "signature": "predict_log_proba(self, X)",
          "documentation": {
            "description": "",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "array",
                "description": "like of shape (n_samples, n_classes)"
              },
              "Returns": {
                "type": "the log-probability of the samples for each class in",
                "description": ""
              },
              "the": {
                "type": "model. The columns correspond to the classes in sorted",
                "description": "order, as they appear in the attribute :term:`classes_`."
              }
            },
            "returns": "log-probability estimates for the test vector X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.\n\n        Returns\n        -------\n        C : array-like of shape (n_samples, n_classes)\n            Returns the log-probability of the samples for each class in\n            the model. The columns correspond to the classes in sorted\n            order, as they appear in the attribute :term:`classes_`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_proba",
          "signature": "predict_proba(self, X)",
          "documentation": {
            "description": "",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "array",
                "description": "like of shape (n_samples, n_classes)"
              },
              "Returns": {
                "type": "the probability of the samples for each class in",
                "description": ""
              },
              "the": {
                "type": "model. The columns correspond to the classes in sorted",
                "description": "order, as they appear in the attribute :term:`classes_`."
              }
            },
            "returns": "probability estimates for the test vector X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.\n\n        Returns\n        -------\n        C : array-like of shape (n_samples, n_classes)\n            Returns the probability of the samples for each class in\n            the model. The columns correspond to the classes in sorted\n            order, as they appear in the attribute :term:`classes_`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "score",
          "signature": "score(self, X, y, sample_weight=None)",
          "documentation": {
            "description": "",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Test": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs)"
              },
              "True": {
                "type": "labels for `X`.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Sample": {
                "type": "weights.",
                "description": "Returns\n-------"
              },
              "score": {
                "type": "float",
                "description": ""
              },
              "Mean": {
                "type": "accuracy of ``self.predict(X)`` w.r.t. `y`.",
                "description": ""
              }
            },
            "returns": "the mean accuracy on the given test data and labels.\n\n        In multi-label classification, this is the subset accuracy\n        which is a harsh metric since you require for each sample that\n        each label set be correctly predicted.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Test samples.\n\n        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n            True labels for `X`.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Sample weights.\n\n        Returns\n        -------\n        score : float\n            Mean accuracy of ``self.predict(X)`` w.r.t. `y`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_fit_request",
          "signature": "set_fit_request(self: sklearn.naive_bayes.GaussianNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.GaussianNB",
          "documentation": {
            "description": "Request metadata passed to the ``fit`` method.",
            "parameters": {
              "sample_weight": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "Metadata": {
                "type": "routing for ``sample_weight`` parameter in ``fit``.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "The": {
                "type": "updated object.",
                "description": ""
              },
              "and": {
                "type": "not others.",
                "description": ".. versionadded:: 1.3\n.. note::"
              },
              "This": {
                "type": "method is only relevant if this estimator is used as a",
                "description": "sub-estimator of a meta-estimator, e.g. used inside a\n:class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect."
              }
            },
            "returns": "-------\n        self : object\n            The updated object.",
            "raises": "",
            "see_also": "",
            "notes": "that this method is only relevant if\n        ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n        Please see :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        The options for each parameter are:\n\n        - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n\n        - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n\n        - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n\n        - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n\n        The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n        existing request. This allows you to change the request for some\n        parameters and not others.\n\n        .. versionadded:: 1.3\n\n        .. note::\n            This method is only relevant if this estimator is used as a\n            sub-estimator of a meta-estimator, e.g. used inside a\n            :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n\n        Parameters\n        ----------\n        sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``sample_weight`` parameter in ``fit``.\n\n        Returns\n        -------\n        self : object\n            The updated object.",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_partial_fit_request",
          "signature": "set_partial_fit_request(self: sklearn.naive_bayes.GaussianNB, *, classes: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.GaussianNB",
          "documentation": {
            "description": "Request metadata passed to the ``partial_fit`` method.",
            "parameters": {
              "classes": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "Metadata": {
                "type": "routing for ``sample_weight`` parameter in ``partial_fit``.",
                "description": "Returns\n-------"
              },
              "sample_weight": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "The": {
                "type": "updated object.",
                "description": ""
              },
              "and": {
                "type": "not others.",
                "description": ".. versionadded:: 1.3\n.. note::"
              },
              "This": {
                "type": "method is only relevant if this estimator is used as a",
                "description": "sub-estimator of a meta-estimator, e.g. used inside a\n:class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect."
              }
            },
            "returns": "-------\n        self : object\n            The updated object.",
            "raises": "",
            "see_also": "",
            "notes": "that this method is only relevant if\n        ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n        Please see :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        The options for each parameter are:\n\n        - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n\n        - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n\n        - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n\n        - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n\n        The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n        existing request. This allows you to change the request for some\n        parameters and not others.\n\n        .. versionadded:: 1.3\n\n        .. note::\n            This method is only relevant if this estimator is used as a\n            sub-estimator of a meta-estimator, e.g. used inside a\n            :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n\n        Parameters\n        ----------\n        classes : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``classes`` parameter in ``partial_fit``.\n\n        sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n\n        Returns\n        -------\n        self : object\n            The updated object.",
            "examples": ""
          }
        },
        {
          "name": "set_score_request",
          "signature": "set_score_request(self: sklearn.naive_bayes.GaussianNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.GaussianNB",
          "documentation": {
            "description": "Request metadata passed to the ``score`` method.",
            "parameters": {
              "sample_weight": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "Metadata": {
                "type": "routing for ``sample_weight`` parameter in ``score``.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "The": {
                "type": "updated object.",
                "description": ""
              },
              "and": {
                "type": "not others.",
                "description": ".. versionadded:: 1.3\n.. note::"
              },
              "This": {
                "type": "method is only relevant if this estimator is used as a",
                "description": "sub-estimator of a meta-estimator, e.g. used inside a\n:class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect."
              }
            },
            "returns": "-------\n        self : object\n            The updated object.",
            "raises": "",
            "see_also": "",
            "notes": "that this method is only relevant if\n        ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n        Please see :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        The options for each parameter are:\n\n        - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n\n        - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n\n        - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n\n        - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n\n        The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n        existing request. This allows you to change the request for some\n        parameters and not others.\n\n        .. versionadded:: 1.3\n\n        .. note::\n            This method is only relevant if this estimator is used as a\n            sub-estimator of a meta-estimator, e.g. used inside a\n            :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n\n        Parameters\n        ----------\n        sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``sample_weight`` parameter in ``score``.\n\n        Returns\n        -------\n        self : object\n            The updated object.",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Integral",
      "documentation": {
        "description": "Integral adds methods that work on integral numbers.\n\n    In short, these are conversion to int, pow with modulus, and the\n    bit-string operations.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "conjugate",
          "signature": "conjugate(self)",
          "documentation": {
            "description": "Conjugate is a no-op for Reals.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Interval",
      "documentation": {
        "description": "Constraint representing a typed interval.\n\n    Parameters\n    ----------\n    type : {numbers.Integral, numbers.Real, RealNotInt}\n        The set of numbers in which to set the interval.\n\n        If RealNotInt, only reals that don't have the integer type\n        are allowed. For example 1.0 is allowed but 1 is not.\n\n    left : float or int or None\n        The left bound of the interval. None means left bound is -.\n\n    right : float, int or None\n        The right bound of the interval. None means right bound is +.\n\n    closed : {\"left\", \"right\", \"both\", \"neither\"}\n        Whether the interval is open or closed. Possible choices are:\n\n        - `\"left\"`: the interval is closed on the left and open on the right.\n          It is equivalent to the interval `[ left, right )`.\n        - `\"right\"`: the interval is closed on the right and open on the left.\n          It is equivalent to the interval `( left, right ]`.\n        - `\"both\"`: the interval is closed.\n          It is equivalent to the interval `[ left, right ]`.\n        - `\"neither\"`: the interval is open.\n          It is equivalent to the interval `( left, right )`.",
        "parameters": {
          "type": {
            "type": "{numbers.Integral, numbers.Real, RealNotInt}",
            "description": ""
          },
          "The": {
            "type": "right bound of the interval. None means right bound is +.",
            "description": ""
          },
          "If": {
            "type": "RealNotInt, only reals that don't have the integer type",
            "description": ""
          },
          "are": {
            "type": "allowed. For example 1.0 is allowed but 1 is not.",
            "description": ""
          },
          "left": {
            "type": "float or int or None",
            "description": ""
          },
          "right": {
            "type": "float, int or None",
            "description": ""
          },
          "closed": {
            "type": "{\"left\", \"right\", \"both\", \"neither\"}",
            "description": ""
          },
          "Whether": {
            "type": "the interval is open or closed. Possible choices are:",
            "description": "- `\"left\"`: the interval is closed on the left and open on the right."
          },
          "It": {
            "type": "is equivalent to the interval `( left, right )`.",
            "description": "Notes\n-----"
          },
          "Setting": {
            "type": "a bound to `None` and setting the interval closed is valid. For instance,",
            "description": ""
          },
          "strictly": {
            "type": "speaking, `Interval(Real, 0, None, closed=\"both\")` corresponds to",
            "description": "`[0, +) U {+}`."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "-----\n    Setting a bound to `None` and setting the interval closed is valid. For instance,\n    strictly speaking, `Interval(Real, 0, None, closed=\"both\")` corresponds to\n    `[0, +) U {+}`.",
        "examples": ""
      },
      "methods": [
        {
          "name": "is_satisfied_by",
          "signature": "is_satisfied_by(self, val)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "LabelBinarizer",
      "documentation": {
        "description": "Binarize labels in a one-vs-all fashion.\n\n    Several regression and binary classification algorithms are\n    available in scikit-learn. A simple way to extend these algorithms\n    to the multi-class classification case is to use the so-called\n    one-vs-all scheme.\n\n    At learning time, this simply consists in learning one regressor\n    or binary classifier per class. In doing so, one needs to convert\n    multi-class labels to binary labels (belong or does not belong\n    to the class). `LabelBinarizer` makes this process easy with the\n    transform method.\n\n    At prediction time, one assigns the class for which the corresponding\n    model gave the greatest confidence. `LabelBinarizer` makes this easy\n    with the :meth:`inverse_transform` method.\n\n    Read more in the :ref:`User Guide <preprocessing_targets>`.\n\n    Parameters\n    ----------\n    neg_label : int, default=0\n        Value with which negative labels must be encoded.\n\n    pos_label : int, default=1\n        Value with which positive labels must be encoded.\n\n    sparse_output : bool, default=False\n        True if the returned array from transform is desired to be in sparse\n        CSR format.\n\n    Attributes\n    ----------\n    classes_ : ndarray of shape (n_classes,)\n        Holds the label for each class.\n\n    y_type_ : str\n        Represents the type of the target data as evaluated by\n        :func:`~sklearn.utils.multiclass.type_of_target`. Possible type are\n        'continuous', 'continuous-multioutput', 'binary', 'multiclass',\n        'multiclass-multioutput', 'multilabel-indicator', and 'unknown'.\n\n    sparse_input_ : bool\n        `True` if the input data to transform is given as a sparse matrix,\n         `False` otherwise.\n\n    See Also\n    --------\n    label_binarize : Function to perform the transform operation of\n        LabelBinarizer with fixed classes.\n    OneHotEncoder : Encode categorical features using a one-hot aka one-of-K\n        scheme.",
        "parameters": {
          "neg_label": {
            "type": "int, default=0",
            "description": ""
          },
          "Value": {
            "type": "with which positive labels must be encoded.",
            "description": ""
          },
          "pos_label": {
            "type": "int, default=1",
            "description": ""
          },
          "sparse_output": {
            "type": "bool, default=False",
            "description": ""
          },
          "True": {
            "type": "if the returned array from transform is desired to be in sparse",
            "description": ""
          },
          "CSR": {
            "type": "format.",
            "description": "Attributes\n----------"
          },
          "classes_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "Holds": {
            "type": "the label for each class.",
            "description": ""
          },
          "y_type_": {
            "type": "str",
            "description": ""
          },
          "Represents": {
            "type": "the type of the target data as evaluated by",
            "description": ":func:`~sklearn.utils.multiclass.type_of_target`. Possible type are\n'continuous', 'continuous-multioutput', 'binary', 'multiclass',\n'multiclass-multioutput', 'multilabel-indicator', and 'unknown'."
          },
          "sparse_input_": {
            "type": "bool",
            "description": "`True` if the input data to transform is given as a sparse matrix,\n`False` otherwise."
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "label_binarize": {
            "type": "Function to perform the transform operation of",
            "description": ""
          },
          "LabelBinarizer": {
            "type": "",
            "description": ">>> lb.classes_"
          },
          "OneHotEncoder": {
            "type": "Encode categorical features using a one",
            "description": "hot aka one-of-K\nscheme.\nExamples\n--------\n>>> from sklearn.preprocessing import LabelBinarizer\n>>> lb = LabelBinarizer()\n>>> lb.fit([1, 2, 6, 4, 2])"
          },
          "array": {
            "type": "[0, 1, 2]",
            "description": ">>> lb.transform([0, 1, 2, 1])\narray([[1, 0, 0],\n[0, 1, 0],\n[0, 0, 1],\n[0, 1, 0]])"
          },
          "Binary": {
            "type": "targets transform to a column vector",
            "description": ">>> lb = LabelBinarizer()\n>>> lb.fit_transform(['yes', 'no', 'no', 'yes'])\narray([[1],\n[0],\n[0],\n[1]])"
          },
          "Passing": {
            "type": "a 2D matrix for multilabel classification",
            "description": ">>> import numpy as np\n>>> lb.fit(np.array([[0, 1, 1], [1, 0, 0]]))"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    label_binarize : Function to perform the transform operation of\n        LabelBinarizer with fixed classes.\n    OneHotEncoder : Encode categorical features using a one-hot aka one-of-K\n        scheme.\n\n    Examples\n    --------\n    >>> from sklearn.preprocessing import LabelBinarizer\n    >>> lb = LabelBinarizer()\n    >>> lb.fit([1, 2, 6, 4, 2])\n    LabelBinarizer()\n    >>> lb.classes_\n    array([1, 2, 4, 6])\n    >>> lb.transform([1, 6])\n    array([[1, 0, 0, 0],\n           [0, 0, 0, 1]])\n\n    Binary targets transform to a column vector\n\n    >>> lb = LabelBinarizer()\n    >>> lb.fit_transform(['yes', 'no', 'no', 'yes'])\n    array([[1],\n           [0],\n           [0],\n           [1]])\n\n    Passing a 2D matrix for multilabel classification\n\n    >>> import numpy as np\n    >>> lb.fit(np.array([[0, 1, 1], [1, 0, 0]]))\n    LabelBinarizer()\n    >>> lb.classes_\n    array([0, 1, 2])\n    >>> lb.transform([0, 1, 2, 1])\n    array([[1, 0, 0],\n           [0, 1, 0],\n           [0, 0, 1],\n           [0, 1, 0]])",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.preprocessing import LabelBinarizer\n    >>> lb = LabelBinarizer()\n    >>> lb.fit([1, 2, 6, 4, 2])\n    LabelBinarizer()\n    >>> lb.classes_\n    array([1, 2, 4, 6])\n    >>> lb.transform([1, 6])\n    array([[1, 0, 0, 0],\n           [0, 0, 0, 1]])\n\n    Binary targets transform to a column vector\n\n    >>> lb = LabelBinarizer()\n    >>> lb.fit_transform(['yes', 'no', 'no', 'yes'])\n    array([[1],\n           [0],\n           [0],\n           [1]])\n\n    Passing a 2D matrix for multilabel classification\n\n    >>> import numpy as np\n    >>> lb.fit(np.array([[0, 1, 1], [1, 0, 0]]))\n    LabelBinarizer()\n    >>> lb.classes_\n    array([0, 1, 2])\n    >>> lb.transform([0, 1, 2, 1])\n    array([[1, 0, 0],\n           [0, 1, 0],\n           [0, 0, 1],\n           [0, 1, 0]])"
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, y)",
          "documentation": {
            "description": "Fit label binarizer.\n\n        Parameters\n        ----------\n        y : ndarray of shape (n_samples,) or (n_samples, n_classes)\n            Target values. The 2-d matrix should only contain 0 and 1,\n            represents multilabel classification.",
            "parameters": {
              "y": {
                "type": "ndarray of shape (n_samples,) or (n_samples, n_classes)",
                "description": ""
              },
              "Target": {
                "type": "values. The 2-d matrix should only contain 0 and 1,",
                "description": ""
              },
              "represents": {
                "type": "multilabel classification.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fit_transform",
          "signature": "fit_transform(self, y)",
          "documentation": {
            "description": "Fit label binarizer/transform multi-class labels to binary labels.\n\n        The output of transform is sometimes referred to as\n        the 1-of-K coding scheme.\n\n        Parameters\n        ----------\n        y : {ndarray, sparse matrix} of shape (n_samples,) or                 (n_samples, n_classes)\n            Target values. The 2-d matrix should only contain 0 and 1,\n            represents multilabel classification. Sparse matrix can be\n            CSR, CSC, COO, DOK, or LIL.",
            "parameters": {
              "y": {
                "type": "{ndarray, sparse matrix} of shape (n_samples,) or                 (n_samples, n_classes)",
                "description": ""
              },
              "Target": {
                "type": "values. The 2-d matrix should only contain 0 and 1,",
                "description": ""
              },
              "represents": {
                "type": "multilabel classification. Sparse matrix can be",
                "description": "CSR, CSC, COO, DOK, or LIL.\nReturns\n-------"
              },
              "Y": {
                "type": "{ndarray, sparse matrix} of shape (n_samples, n_classes)",
                "description": ""
              },
              "Shape": {
                "type": "will be (n_samples, 1) for binary problems. Sparse matrix",
                "description": ""
              },
              "will": {
                "type": "be of CSR format.",
                "description": ""
              }
            },
            "returns": "-------\n        Y : {ndarray, sparse matrix} of shape (n_samples, n_classes)\n            Shape will be (n_samples, 1) for binary problems. Sparse matrix\n            will be of CSR format.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "inverse_transform",
          "signature": "inverse_transform(self, Y, threshold=None)",
          "documentation": {
            "description": "Transform binary labels back to multi-class labels.\n\n        Parameters\n        ----------\n        Y : {ndarray, sparse matrix} of shape (n_samples, n_classes)\n            Target values. All sparse matrices are converted to CSR before\n            inverse transformation.\n\n        threshold : float, default=None\n            Threshold used in the binary and multi-label cases.\n\n            Use 0 when ``Y`` contains the output of :term:`decision_function`\n            (classifier).\n            Use 0.5 when ``Y`` contains the output of :term:`predict_proba`.\n\n            If None, the threshold is assumed to be half way between\n            neg_label and pos_label.\n\n        Returns\n        -------\n        y : {ndarray, sparse matrix} of shape (n_samples,)\n            Target values. Sparse matrix will be of CSR format.",
            "parameters": {
              "Y": {
                "type": "{ndarray, sparse matrix} of shape (n_samples, n_classes)",
                "description": ""
              },
              "Target": {
                "type": "values. Sparse matrix will be of CSR format.",
                "description": "Notes\n-----"
              },
              "inverse": {
                "type": "transformation.",
                "description": ""
              },
              "threshold": {
                "type": "float, default=None",
                "description": ""
              },
              "Threshold": {
                "type": "used in the binary and multi-label cases.",
                "description": ""
              },
              "Use": {
                "type": "0.5 when ``Y`` contains the output of :term:`predict_proba`.",
                "description": ""
              },
              "If": {
                "type": "None, the threshold is assumed to be half way between",
                "description": ""
              },
              "neg_label": {
                "type": "and pos_label.",
                "description": "Returns\n-------"
              },
              "y": {
                "type": "{ndarray, sparse matrix} of shape (n_samples,)",
                "description": ""
              },
              "In": {
                "type": "the case when the binary labels are fractional",
                "description": "(probabilistic), :meth:`inverse_transform` chooses the class with the"
              },
              "greatest": {
                "type": "value. Typically, this allows to use the output of a",
                "description": ""
              },
              "linear": {
                "type": "model's :term:`decision_function` method directly as the input",
                "description": ""
              },
              "of": {
                "type": "meth:`inverse_transform`.",
                "description": ""
              }
            },
            "returns": "-------\n        y : {ndarray, sparse matrix} of shape (n_samples,)\n            Target values. Sparse matrix will be of CSR format.\n\n        Notes\n        -----\n        In the case when the binary labels are fractional\n        (probabilistic), :meth:`inverse_transform` chooses the class with the\n        greatest value. Typically, this allows to use the output of a\n        linear model's :term:`decision_function` method directly as the input\n        of :meth:`inverse_transform`.",
            "raises": "",
            "see_also": "",
            "notes": "-----\n        In the case when the binary labels are fractional\n        (probabilistic), :meth:`inverse_transform` chooses the class with the\n        greatest value. Typically, this allows to use the output of a\n        linear model's :term:`decision_function` method directly as the input\n        of :meth:`inverse_transform`.",
            "examples": ""
          }
        },
        {
          "name": "set_inverse_transform_request",
          "signature": "set_inverse_transform_request(self: sklearn.preprocessing._label.LabelBinarizer, *, threshold: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._label.LabelBinarizer",
          "documentation": {
            "description": "Request metadata passed to the ``inverse_transform`` method.",
            "parameters": {
              "threshold": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "Metadata": {
                "type": "routing for ``threshold`` parameter in ``inverse_transform``.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "The": {
                "type": "updated object.",
                "description": ""
              },
              "and": {
                "type": "not others.",
                "description": ".. versionadded:: 1.3\n.. note::"
              },
              "This": {
                "type": "method is only relevant if this estimator is used as a",
                "description": "sub-estimator of a meta-estimator, e.g. used inside a\n:class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect."
              }
            },
            "returns": "-------\n        self : object\n            The updated object.",
            "raises": "",
            "see_also": "",
            "notes": "that this method is only relevant if\n        ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n        Please see :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        The options for each parameter are:\n\n        - ``True``: metadata is requested, and passed to ``inverse_transform`` if provided. The request is ignored if metadata is not provided.\n\n        - ``False``: metadata is not requested and the meta-estimator will not pass it to ``inverse_transform``.\n\n        - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n\n        - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n\n        The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n        existing request. This allows you to change the request for some\n        parameters and not others.\n\n        .. versionadded:: 1.3\n\n        .. note::\n            This method is only relevant if this estimator is used as a\n            sub-estimator of a meta-estimator, e.g. used inside a\n            :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n\n        Parameters\n        ----------\n        threshold : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``threshold`` parameter in ``inverse_transform``.\n\n        Returns\n        -------\n        self : object\n            The updated object.",
            "examples": ""
          }
        },
        {
          "name": "set_output",
          "signature": "set_output(self, *, transform=None)",
          "documentation": {
            "description": "Set output container.\n\n        See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n        for an example on how to use the API.\n\n        Parameters\n        ----------\n        transform : {\"default\", \"pandas\", \"polars\"}, default=None\n            Configure output of `transform` and `fit_transform`.\n\n            - `\"default\"`: Default output format of a transformer\n            - `\"pandas\"`: DataFrame output\n            - `\"polars\"`: Polars output\n            - `None`: Transform configuration is unchanged\n\n            .. versionadded:: 1.4\n                `\"polars\"` option was added.",
            "parameters": {
              "transform": {
                "type": "{\"default\", \"pandas\", \"polars\"}, default=None",
                "description": ""
              },
              "Configure": {
                "type": "output of `transform` and `fit_transform`.",
                "description": "- `\"default\"`: Default output format of a transformer\n- `\"pandas\"`: DataFrame output\n- `\"polars\"`: Polars output\n- `None`: Transform configuration is unchanged\n.. versionadded:: 1.4\n`\"polars\"` option was added.\nReturns\n-------"
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "Estimator": {
                "type": "instance.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "transform",
          "signature": "transform(self, y)",
          "documentation": {
            "description": "Transform multi-class labels to binary labels.\n\n        The output of transform is sometimes referred to by some authors as\n        the 1-of-K coding scheme.\n\n        Parameters\n        ----------\n        y : {array, sparse matrix} of shape (n_samples,) or                 (n_samples, n_classes)\n            Target values. The 2-d matrix should only contain 0 and 1,\n            represents multilabel classification. Sparse matrix can be\n            CSR, CSC, COO, DOK, or LIL.",
            "parameters": {
              "y": {
                "type": "{array, sparse matrix} of shape (n_samples,) or                 (n_samples, n_classes)",
                "description": ""
              },
              "Target": {
                "type": "values. The 2-d matrix should only contain 0 and 1,",
                "description": ""
              },
              "represents": {
                "type": "multilabel classification. Sparse matrix can be",
                "description": "CSR, CSC, COO, DOK, or LIL.\nReturns\n-------"
              },
              "Y": {
                "type": "{ndarray, sparse matrix} of shape (n_samples, n_classes)",
                "description": ""
              },
              "Shape": {
                "type": "will be (n_samples, 1) for binary problems. Sparse matrix",
                "description": ""
              },
              "will": {
                "type": "be of CSR format.",
                "description": ""
              }
            },
            "returns": "-------\n        Y : {ndarray, sparse matrix} of shape (n_samples, n_classes)\n            Shape will be (n_samples, 1) for binary problems. Sparse matrix\n            will be of CSR format.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "MultinomialNB",
      "documentation": {
        "description": "Naive Bayes classifier for multinomial models.\n\n    The multinomial Naive Bayes classifier is suitable for classification with\n    discrete features (e.g., word counts for text classification). The\n    multinomial distribution normally requires integer feature counts. However,\n    in practice, fractional counts such as tf-idf may also work.\n\n    Read more in the :ref:`User Guide <multinomial_naive_bayes>`.\n\n    Parameters\n    ----------\n    alpha : float or array-like of shape (n_features,), default=1.0\n        Additive (Laplace/Lidstone) smoothing parameter\n        (set alpha=0 and force_alpha=True, for no smoothing).\n\n    force_alpha : bool, default=True\n        If False and alpha is less than 1e-10, it will set alpha to\n        1e-10. If True, alpha will remain unchanged. This may cause\n        numerical errors if alpha is too close to 0.\n\n        .. versionadded:: 1.2\n        .. versionchanged:: 1.4\n           The default value of `force_alpha` changed to `True`.\n\n    fit_prior : bool, default=True\n        Whether to learn class prior probabilities or not.\n        If false, a uniform prior will be used.\n\n    class_prior : array-like of shape (n_classes,), default=None\n        Prior probabilities of the classes. If specified, the priors are not\n        adjusted according to the data.\n\n    Attributes\n    ----------\n    class_count_ : ndarray of shape (n_classes,)\n        Number of samples encountered for each class during fitting. This\n        value is weighted by the sample weight when provided.\n\n    class_log_prior_ : ndarray of shape (n_classes,)\n        Smoothed empirical log probability for each class.\n\n    classes_ : ndarray of shape (n_classes,)\n        Class labels known to the classifier\n\n    feature_count_ : ndarray of shape (n_classes, n_features)\n        Number of samples encountered for each (class, feature)\n        during fitting. This value is weighted by the sample weight when\n        provided.\n\n    feature_log_prob_ : ndarray of shape (n_classes, n_features)\n        Empirical log probability of features\n        given a class, ``P(x_i|y)``.\n\n    n_features_in_ : int\n        Number of features seen during :term:`fit`.\n\n        .. versionadded:: 0.24\n\n    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n        Names of features seen during :term:`fit`. Defined only when `X`\n        has feature names that are all strings.\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    BernoulliNB : Naive Bayes classifier for multivariate Bernoulli models.\n    CategoricalNB : Naive Bayes classifier for categorical features.\n    ComplementNB : Complement Naive Bayes classifier.\n    GaussianNB : Gaussian Naive Bayes.\n\n    References\n    ----------\n    C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to\n    Information Retrieval. Cambridge University Press, pp. 234-265.\n    https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html",
        "parameters": {
          "alpha": {
            "type": "float or array",
            "description": "like of shape (n_features,), default=1.0"
          },
          "Additive": {
            "type": "Laplace/Lidstone",
            "description": "smoothing parameter\n(set alpha=0 and force_alpha=True, for no smoothing)."
          },
          "force_alpha": {
            "type": "bool, default=True",
            "description": ""
          },
          "If": {
            "type": "false, a uniform prior will be used.",
            "description": ""
          },
          "numerical": {
            "type": "errors if alpha is too close to 0.",
            "description": ".. versionadded:: 1.2\n.. versionchanged:: 1.4"
          },
          "The": {
            "type": "default value of `force_alpha` changed to `True`.",
            "description": ""
          },
          "fit_prior": {
            "type": "bool, default=True",
            "description": ""
          },
          "Whether": {
            "type": "to learn class prior probabilities or not.",
            "description": ""
          },
          "class_prior": {
            "type": "array",
            "description": "like of shape (n_classes,), default=None"
          },
          "Prior": {
            "type": "probabilities of the classes. If specified, the priors are not",
            "description": ""
          },
          "adjusted": {
            "type": "according to the data.",
            "description": "Attributes\n----------"
          },
          "class_count_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "Number": {
            "type": "of features seen during :term:`fit`.",
            "description": ".. versionadded:: 0.24"
          },
          "value": {
            "type": "is weighted by the sample weight when provided.",
            "description": ""
          },
          "class_log_prior_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "Smoothed": {
            "type": "empirical log probability for each class.",
            "description": ""
          },
          "classes_": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "Class": {
            "type": "labels known to the classifier",
            "description": ""
          },
          "feature_count_": {
            "type": "ndarray of shape (n_classes, n_features)",
            "description": ""
          },
          "during": {
            "type": "fitting. This value is weighted by the sample weight when",
            "description": "provided."
          },
          "feature_log_prob_": {
            "type": "ndarray of shape (n_classes, n_features)",
            "description": ""
          },
          "Empirical": {
            "type": "log probability of features",
            "description": ""
          },
          "given": {
            "type": "a class, ``P(x_i|y)``.",
            "description": ""
          },
          "n_features_in_": {
            "type": "int",
            "description": ""
          },
          "feature_names_in_": {
            "type": "ndarray of shape (`n_features_in_`,)",
            "description": ""
          },
          "Names": {
            "type": "of features seen during :term:`fit`. Defined only when `X`",
            "description": ""
          },
          "has": {
            "type": "feature names that are all strings.",
            "description": ".. versionadded:: 1.0"
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "BernoulliNB": {
            "type": "Naive Bayes classifier for multivariate Bernoulli models.",
            "description": ""
          },
          "CategoricalNB": {
            "type": "Naive Bayes classifier for categorical features.",
            "description": ""
          },
          "ComplementNB": {
            "type": "Complement Naive Bayes classifier.",
            "description": ""
          },
          "GaussianNB": {
            "type": "Gaussian Naive Bayes.",
            "description": "References\n----------\nC.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to"
          },
          "Information": {
            "type": "Retrieval. Cambridge University Press, pp. 234-265.",
            "description": ""
          },
          "https": {
            "type": "//nlp.stanford.edu/IR",
            "description": "book/html/htmledition/naive-bayes-text-classification-1.html\nExamples\n--------\n>>> import numpy as np\n>>> rng = np.random.RandomState(1)\n>>> X = rng.randint(5, size=(6, 100))\n>>> y = np.array([1, 2, 3, 4, 5, 6])\n>>> from sklearn.naive_bayes import MultinomialNB\n>>> clf = MultinomialNB()\n>>> clf.fit(X, y)"
          },
          "MultinomialNB": {
            "type": "",
            "description": ">>> print(clf.predict(X[2:3]))\n[3]"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    BernoulliNB : Naive Bayes classifier for multivariate Bernoulli models.\n    CategoricalNB : Naive Bayes classifier for categorical features.\n    ComplementNB : Complement Naive Bayes classifier.\n    GaussianNB : Gaussian Naive Bayes.\n\n    References\n    ----------\n    C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to\n    Information Retrieval. Cambridge University Press, pp. 234-265.\n    https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> rng = np.random.RandomState(1)\n    >>> X = rng.randint(5, size=(6, 100))\n    >>> y = np.array([1, 2, 3, 4, 5, 6])\n    >>> from sklearn.naive_bayes import MultinomialNB\n    >>> clf = MultinomialNB()\n    >>> clf.fit(X, y)\n    MultinomialNB()\n    >>> print(clf.predict(X[2:3]))\n    [3]",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> rng = np.random.RandomState(1)\n    >>> X = rng.randint(5, size=(6, 100))\n    >>> y = np.array([1, 2, 3, 4, 5, 6])\n    >>> from sklearn.naive_bayes import MultinomialNB\n    >>> clf = MultinomialNB()\n    >>> clf.fit(X, y)\n    MultinomialNB()\n    >>> print(clf.predict(X[2:3]))\n    [3]"
      },
      "methods": [
        {
          "name": "fit",
          "signature": "fit(self, X, y, sample_weight=None)",
          "documentation": {
            "description": "Fit Naive Bayes classifier according to X, y.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training vectors, where `n_samples` is the number of samples and\n            `n_features` is the number of features.\n\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Weights applied to individual samples (1. for unweighted).",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like, sparse matrix} of shape (n_samples, n_features)"
              },
              "Training": {
                "type": "vectors, where `n_samples` is the number of samples and",
                "description": "`n_features` is the number of features."
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,)"
              },
              "Target": {
                "type": "values.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Weights": {
                "type": "applied to individual samples (1. for unweighted).",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_metadata_routing",
          "signature": "get_metadata_routing(self)",
          "documentation": {
            "description": "Get metadata routing of this object.\n\n        Please check :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.",
            "parameters": {},
            "returns": "-------\n        routing : MetadataRequest\n            A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n            routing information.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get_params",
          "signature": "get_params(self, deep=True)",
          "documentation": {
            "description": "Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.",
            "parameters": {
              "deep": {
                "type": "bool, default=True",
                "description": ""
              },
              "If": {
                "type": "True, will return the parameters for this estimator and",
                "description": ""
              },
              "contained": {
                "type": "subobjects that are estimators.",
                "description": "Returns\n-------"
              },
              "params": {
                "type": "dict",
                "description": ""
              },
              "Parameter": {
                "type": "names mapped to their values.",
                "description": ""
              }
            },
            "returns": "-------\n        params : dict\n            Parameter names mapped to their values.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "partial_fit",
          "signature": "partial_fit(self, X, y, classes=None, sample_weight=None)",
          "documentation": {
            "description": "Incremental fit on a batch of samples.\n\n        This method is expected to be called several times consecutively\n        on different chunks of a dataset so as to implement out-of-core\n        or online learning.\n\n        This is especially useful when the whole dataset is too big to fit in\n        memory at once.\n\n        This method has some performance overhead hence it is better to call\n        partial_fit on chunks of data that are as large as possible\n        (as long as fitting in the memory budget) to hide the overhead.\n\n        Parameters\n        ----------\n        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n            Training vectors, where `n_samples` is the number of samples and\n            `n_features` is the number of features.\n\n        y : array-like of shape (n_samples,)\n            Target values.\n\n        classes : array-like of shape (n_classes,), default=None\n            List of all the classes that can possibly appear in the y vector.\n\n            Must be provided at the first call to partial_fit, can be omitted\n            in subsequent calls.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Weights applied to individual samples (1. for unweighted).",
            "parameters": {
              "X": {
                "type": "{array",
                "description": "like, sparse matrix} of shape (n_samples, n_features)"
              },
              "Training": {
                "type": "vectors, where `n_samples` is the number of samples and",
                "description": "`n_features` is the number of features."
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,)"
              },
              "Target": {
                "type": "values.",
                "description": ""
              },
              "classes": {
                "type": "array",
                "description": "like of shape (n_classes,), default=None"
              },
              "List": {
                "type": "of all the classes that can possibly appear in the y vector.",
                "description": ""
              },
              "Must": {
                "type": "be provided at the first call to partial_fit, can be omitted",
                "description": ""
              },
              "in": {
                "type": "subsequent calls.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Weights": {
                "type": "applied to individual samples (1. for unweighted).",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "Returns": {
                "type": "the instance itself.",
                "description": ""
              }
            },
            "returns": "-------\n        self : object",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict",
          "signature": "predict(self, X)",
          "documentation": {
            "description": "Perform classification on an array of test vectors X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "ndarray of shape (n_samples,)",
                "description": ""
              },
              "Predicted": {
                "type": "target values for X.",
                "description": ""
              }
            },
            "returns": "-------\n        C : ndarray of shape (n_samples,)\n            Predicted target values for X.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_joint_log_proba",
          "signature": "predict_joint_log_proba(self, X)",
          "documentation": {
            "description": "Return joint log probability estimates for the test vector X.\n\n        For each row x of X and class y, the joint log probability is given by\n        ``log P(x, y) = log P(y) + log P(x|y),``\n        where ``log P(y)`` is the class prior probability and ``log P(x|y)`` is\n        the class-conditional probability.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "ndarray of shape (n_samples, n_classes)",
                "description": ""
              },
              "Returns": {
                "type": "the joint log-probability of the samples for each class in",
                "description": ""
              },
              "the": {
                "type": "model. The columns correspond to the classes in sorted",
                "description": "order, as they appear in the attribute :term:`classes_`."
              }
            },
            "returns": "-------\n        C : ndarray of shape (n_samples, n_classes)",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_log_proba",
          "signature": "predict_log_proba(self, X)",
          "documentation": {
            "description": "",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "array",
                "description": "like of shape (n_samples, n_classes)"
              },
              "Returns": {
                "type": "the log-probability of the samples for each class in",
                "description": ""
              },
              "the": {
                "type": "model. The columns correspond to the classes in sorted",
                "description": "order, as they appear in the attribute :term:`classes_`."
              }
            },
            "returns": "log-probability estimates for the test vector X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.\n\n        Returns\n        -------\n        C : array-like of shape (n_samples, n_classes)\n            Returns the log-probability of the samples for each class in\n            the model. The columns correspond to the classes in sorted\n            order, as they appear in the attribute :term:`classes_`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "predict_proba",
          "signature": "predict_proba(self, X)",
          "documentation": {
            "description": "",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "The": {
                "type": "input samples.",
                "description": "Returns\n-------"
              },
              "C": {
                "type": "array",
                "description": "like of shape (n_samples, n_classes)"
              },
              "Returns": {
                "type": "the probability of the samples for each class in",
                "description": ""
              },
              "the": {
                "type": "model. The columns correspond to the classes in sorted",
                "description": "order, as they appear in the attribute :term:`classes_`."
              }
            },
            "returns": "probability estimates for the test vector X.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input samples.\n\n        Returns\n        -------\n        C : array-like of shape (n_samples, n_classes)\n            Returns the probability of the samples for each class in\n            the model. The columns correspond to the classes in sorted\n            order, as they appear in the attribute :term:`classes_`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "score",
          "signature": "score(self, X, y, sample_weight=None)",
          "documentation": {
            "description": "",
            "parameters": {
              "X": {
                "type": "array",
                "description": "like of shape (n_samples, n_features)"
              },
              "Test": {
                "type": "samples.",
                "description": ""
              },
              "y": {
                "type": "array",
                "description": "like of shape (n_samples,) or (n_samples, n_outputs)"
              },
              "True": {
                "type": "labels for `X`.",
                "description": ""
              },
              "sample_weight": {
                "type": "array",
                "description": "like of shape (n_samples,), default=None"
              },
              "Sample": {
                "type": "weights.",
                "description": "Returns\n-------"
              },
              "score": {
                "type": "float",
                "description": ""
              },
              "Mean": {
                "type": "accuracy of ``self.predict(X)`` w.r.t. `y`.",
                "description": ""
              }
            },
            "returns": "the mean accuracy on the given test data and labels.\n\n        In multi-label classification, this is the subset accuracy\n        which is a harsh metric since you require for each sample that\n        each label set be correctly predicted.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Test samples.\n\n        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n            True labels for `X`.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Sample weights.\n\n        Returns\n        -------\n        score : float\n            Mean accuracy of ``self.predict(X)`` w.r.t. `y`.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_fit_request",
          "signature": "set_fit_request(self: sklearn.naive_bayes.MultinomialNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.MultinomialNB",
          "documentation": {
            "description": "Request metadata passed to the ``fit`` method.",
            "parameters": {
              "sample_weight": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "Metadata": {
                "type": "routing for ``sample_weight`` parameter in ``fit``.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "The": {
                "type": "updated object.",
                "description": ""
              },
              "and": {
                "type": "not others.",
                "description": ".. versionadded:: 1.3\n.. note::"
              },
              "This": {
                "type": "method is only relevant if this estimator is used as a",
                "description": "sub-estimator of a meta-estimator, e.g. used inside a\n:class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect."
              }
            },
            "returns": "-------\n        self : object\n            The updated object.",
            "raises": "",
            "see_also": "",
            "notes": "that this method is only relevant if\n        ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n        Please see :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        The options for each parameter are:\n\n        - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n\n        - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n\n        - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n\n        - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n\n        The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n        existing request. This allows you to change the request for some\n        parameters and not others.\n\n        .. versionadded:: 1.3\n\n        .. note::\n            This method is only relevant if this estimator is used as a\n            sub-estimator of a meta-estimator, e.g. used inside a\n            :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n\n        Parameters\n        ----------\n        sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``sample_weight`` parameter in ``fit``.\n\n        Returns\n        -------\n        self : object\n            The updated object.",
            "examples": ""
          }
        },
        {
          "name": "set_params",
          "signature": "set_params(self, **params)",
          "documentation": {
            "description": "Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n        parameters of the form ``<component>__<parameter>`` so that it's\n        possible to update each component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.",
            "parameters": {
              "Estimator": {
                "type": "instance.",
                "description": ""
              },
              "self": {
                "type": "estimator instance",
                "description": ""
              },
              "of": {
                "type": "the form ``<component>__<parameter>`` so that it's",
                "description": ""
              },
              "possible": {
                "type": "to update each component of a nested object.",
                "description": ""
              }
            },
            "returns": "-------\n        self : estimator instance\n            Estimator instance.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "set_partial_fit_request",
          "signature": "set_partial_fit_request(self: sklearn.naive_bayes.MultinomialNB, *, classes: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.MultinomialNB",
          "documentation": {
            "description": "Request metadata passed to the ``partial_fit`` method.",
            "parameters": {
              "classes": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "Metadata": {
                "type": "routing for ``sample_weight`` parameter in ``partial_fit``.",
                "description": "Returns\n-------"
              },
              "sample_weight": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "The": {
                "type": "updated object.",
                "description": ""
              },
              "and": {
                "type": "not others.",
                "description": ".. versionadded:: 1.3\n.. note::"
              },
              "This": {
                "type": "method is only relevant if this estimator is used as a",
                "description": "sub-estimator of a meta-estimator, e.g. used inside a\n:class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect."
              }
            },
            "returns": "-------\n        self : object\n            The updated object.",
            "raises": "",
            "see_also": "",
            "notes": "that this method is only relevant if\n        ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n        Please see :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        The options for each parameter are:\n\n        - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n\n        - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n\n        - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n\n        - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n\n        The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n        existing request. This allows you to change the request for some\n        parameters and not others.\n\n        .. versionadded:: 1.3\n\n        .. note::\n            This method is only relevant if this estimator is used as a\n            sub-estimator of a meta-estimator, e.g. used inside a\n            :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n\n        Parameters\n        ----------\n        classes : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``classes`` parameter in ``partial_fit``.\n\n        sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n\n        Returns\n        -------\n        self : object\n            The updated object.",
            "examples": ""
          }
        },
        {
          "name": "set_score_request",
          "signature": "set_score_request(self: sklearn.naive_bayes.MultinomialNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.MultinomialNB",
          "documentation": {
            "description": "Request metadata passed to the ``score`` method.",
            "parameters": {
              "sample_weight": {
                "type": "str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED",
                "description": ""
              },
              "Metadata": {
                "type": "routing for ``sample_weight`` parameter in ``score``.",
                "description": "Returns\n-------"
              },
              "self": {
                "type": "object",
                "description": ""
              },
              "The": {
                "type": "updated object.",
                "description": ""
              },
              "and": {
                "type": "not others.",
                "description": ".. versionadded:: 1.3\n.. note::"
              },
              "This": {
                "type": "method is only relevant if this estimator is used as a",
                "description": "sub-estimator of a meta-estimator, e.g. used inside a\n:class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect."
              }
            },
            "returns": "-------\n        self : object\n            The updated object.",
            "raises": "",
            "see_also": "",
            "notes": "that this method is only relevant if\n        ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n        Please see :ref:`User Guide <metadata_routing>` on how the routing\n        mechanism works.\n\n        The options for each parameter are:\n\n        - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n\n        - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n\n        - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n\n        - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n\n        The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n        existing request. This allows you to change the request for some\n        parameters and not others.\n\n        .. versionadded:: 1.3\n\n        .. note::\n            This method is only relevant if this estimator is used as a\n            sub-estimator of a meta-estimator, e.g. used inside a\n            :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n\n        Parameters\n        ----------\n        sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n            Metadata routing for ``sample_weight`` parameter in ``score``.\n\n        Returns\n        -------\n        self : object\n            The updated object.",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Real",
      "documentation": {
        "description": "To Complex, Real adds the operations that work on real numbers.\n\n    In short, those are: a conversion to float, trunc(), divmod,\n    %, <, <=, >, and >=.\n\n    Real also provides defaults for the derived operations.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "conjugate",
          "signature": "conjugate(self)",
          "documentation": {
            "description": "Conjugate is a no-op for Reals.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    }
  ]
}