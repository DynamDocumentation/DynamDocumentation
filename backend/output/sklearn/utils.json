{
  "description": "Various utilities to help with development.",
  "functions": [
    {
      "name": "all_estimators",
      "signature": "all_estimators(type_filter=None)",
      "documentation": {
        "description": "Get a list of all estimators from `sklearn`.\n\n    This function crawls the module and gets all classes that inherit\n    from BaseEstimator. Classes that are defined in test-modules are not\n    included.\n\n    Parameters\n    ----------\n    type_filter : {\"classifier\", \"regressor\", \"cluster\", \"transformer\"}             or list of such str, default=None\n        Which kind of estimators should be returned. If None, no filter is\n        applied and all estimators are returned.  Possible values are\n        'classifier', 'regressor', 'cluster' and 'transformer' to get\n        estimators only of these specific types, or a list of these to\n        get the estimators that fit at least one of the types.\n\n    Returns\n    -------\n    estimators : list of tuples\n        List of (name, class), where ``name`` is the class name as string\n        and ``class`` is the actual type of the class.",
        "parameters": {
          "type_filter": {
            "type": "{\"classifier\", \"regressor\", \"cluster\", \"transformer\"}             or list of such str, default=None",
            "description": ""
          },
          "Which": {
            "type": "kind of estimators should be returned. If None, no filter is",
            "description": ""
          },
          "applied": {
            "type": "and all estimators are returned.  Possible values are",
            "description": "'classifier', 'regressor', 'cluster' and 'transformer' to get"
          },
          "estimators": {
            "type": "list of tuples",
            "description": ""
          },
          "get": {
            "type": "the estimators that fit at least one of the types.",
            "description": "Returns\n-------"
          },
          "List": {
            "type": "of (name, class), where ``name`` is the class name as string",
            "description": ""
          },
          "and": {
            "type": "``class`` is the actual type of the class.",
            "description": "Examples\n--------\n>>> from sklearn.utils.discovery import all_estimators\n>>> estimators = all_estimators()\n>>> type(estimators)\n<class 'list'>\n>>> type(estimators[0])\n<class 'tuple'>\n>>> estimators[:2]\n[('ARDRegression', <class 'sklearn.linear_model._bayes.ARDRegression'>),\n('AdaBoostClassifier',\n<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>)]\n>>> classifiers = all_estimators(type_filter=\"classifier\")\n>>> classifiers[:2]\n[('AdaBoostClassifier',\n<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>),\n('BaggingClassifier', <class 'sklearn.ensemble._bagging.BaggingClassifier'>)]\n>>> regressors = all_estimators(type_filter=\"regressor\")\n>>> regressors[:2]\n[('ARDRegression', <class 'sklearn.linear_model._bayes.ARDRegression'>),\n('AdaBoostRegressor',\n<class 'sklearn.ensemble._weight_boosting.AdaBoostRegressor'>)]\n>>> both = all_estimators(type_filter=[\"classifier\", \"regressor\"])\n>>> both[:2]\n[('ARDRegression', <class 'sklearn.linear_model._bayes.ARDRegression'>),\n('AdaBoostClassifier',\n<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>)]"
          }
        },
        "returns": "-------\n    estimators : list of tuples\n        List of (name, class), where ``name`` is the class name as string\n        and ``class`` is the actual type of the class.\n\n    Examples\n    --------\n    >>> from sklearn.utils.discovery import all_estimators\n    >>> estimators = all_estimators()\n    >>> type(estimators)\n    <class 'list'>\n    >>> type(estimators[0])\n    <class 'tuple'>\n    >>> estimators[:2]\n    [('ARDRegression', <class 'sklearn.linear_model._bayes.ARDRegression'>),\n     ('AdaBoostClassifier',\n      <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>)]\n    >>> classifiers = all_estimators(type_filter=\"classifier\")\n    >>> classifiers[:2]\n    [('AdaBoostClassifier',\n      <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>),\n     ('BaggingClassifier', <class 'sklearn.ensemble._bagging.BaggingClassifier'>)]\n    >>> regressors = all_estimators(type_filter=\"regressor\")\n    >>> regressors[:2]\n    [('ARDRegression', <class 'sklearn.linear_model._bayes.ARDRegression'>),\n     ('AdaBoostRegressor',\n      <class 'sklearn.ensemble._weight_boosting.AdaBoostRegressor'>)]\n    >>> both = all_estimators(type_filter=[\"classifier\", \"regressor\"])\n    >>> both[:2]\n    [('ARDRegression', <class 'sklearn.linear_model._bayes.ARDRegression'>),\n     ('AdaBoostClassifier',\n      <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>)]",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils.discovery import all_estimators\n    >>> estimators = all_estimators()\n    >>> type(estimators)\n    <class 'list'>\n    >>> type(estimators[0])\n    <class 'tuple'>\n    >>> estimators[:2]\n    [('ARDRegression', <class 'sklearn.linear_model._bayes.ARDRegression'>),\n     ('AdaBoostClassifier',\n      <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>)]\n    >>> classifiers = all_estimators(type_filter=\"classifier\")\n    >>> classifiers[:2]\n    [('AdaBoostClassifier',\n      <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>),\n     ('BaggingClassifier', <class 'sklearn.ensemble._bagging.BaggingClassifier'>)]\n    >>> regressors = all_estimators(type_filter=\"regressor\")\n    >>> regressors[:2]\n    [('ARDRegression', <class 'sklearn.linear_model._bayes.ARDRegression'>),\n     ('AdaBoostRegressor',\n      <class 'sklearn.ensemble._weight_boosting.AdaBoostRegressor'>)]\n    >>> both = all_estimators(type_filter=[\"classifier\", \"regressor\"])\n    >>> both[:2]\n    [('ARDRegression', <class 'sklearn.linear_model._bayes.ARDRegression'>),\n     ('AdaBoostClassifier',\n      <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>)]"
      }
    },
    {
      "name": "as_float_array",
      "signature": "as_float_array(X, *, copy=True, force_all_finite='deprecated', ensure_all_finite=None)",
      "documentation": {
        "description": "Convert an array-like to an array of floats.\n\n    The new dtype will be np.float32 or np.float64, depending on the original\n    type. The function can create a copy or modify the argument depending\n    on the argument copy.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix}\n        The input data.\n\n    copy : bool, default=True\n        If True, a copy of X will be created. If False, a copy may still be\n        returned if X's dtype is not a floating point type.\n\n    force_all_finite : bool or 'allow-nan', default=True\n        Whether to raise an error on np.inf, np.nan, pd.NA in X. The\n        possibilities are:\n\n        - True: Force all values of X to be finite.\n        - False: accepts np.inf, np.nan, pd.NA in X.\n        - 'allow-nan': accepts only np.nan and pd.NA values in X. Values cannot\n          be infinite.\n\n        .. versionadded:: 0.20\n           ``force_all_finite`` accepts the string ``'allow-nan'``.\n\n        .. versionchanged:: 0.23\n           Accepts `pd.NA` and converts it into `np.nan`\n\n        .. deprecated:: 1.6\n           `force_all_finite` was renamed to `ensure_all_finite` and will be removed\n           in 1.8.\n\n    ensure_all_finite : bool or 'allow-nan', default=True\n        Whether to raise an error on np.inf, np.nan, pd.NA in X. The\n        possibilities are:\n\n        - True: Force all values of X to be finite.\n        - False: accepts np.inf, np.nan, pd.NA in X.\n        - 'allow-nan': accepts only np.nan and pd.NA values in X. Values cannot\n          be infinite.\n\n        .. versionadded:: 1.6\n           `force_all_finite` was renamed to `ensure_all_finite`.\n\n    Returns\n    -------\n    XT : {ndarray, sparse matrix}\n        An array of type float.",
        "parameters": {
          "X": {
            "type": "{array",
            "description": "like, sparse matrix}"
          },
          "The": {
            "type": "input data.",
            "description": ""
          },
          "copy": {
            "type": "bool, default=True",
            "description": ""
          },
          "If": {
            "type": "True, a copy of X will be created. If False, a copy may still be",
            "description": ""
          },
          "returned": {
            "type": "if X's dtype is not a floating point type.",
            "description": ""
          },
          "force_all_finite": {
            "type": "bool or 'allow",
            "description": "nan', default=True"
          },
          "Whether": {
            "type": "to raise an error on np.inf, np.nan, pd.NA in X. The",
            "description": ""
          },
          "possibilities": {
            "type": "are:",
            "description": "- True: Force all values of X to be finite.\n- False: accepts np.inf, np.nan, pd.NA in X.\n- 'allow-nan': accepts only np.nan and pd.NA values in X. Values cannot"
          },
          "be": {
            "type": "infinite.",
            "description": ".. versionadded:: 1.6\n`force_all_finite` was renamed to `ensure_all_finite`.\nReturns\n-------"
          },
          "Accepts": {
            "type": "`pd.NA` and converts it into `np.nan`",
            "description": ".. deprecated:: 1.6\n`force_all_finite` was renamed to `ensure_all_finite` and will be removed"
          },
          "in": {
            "type": "1.8.",
            "description": ""
          },
          "ensure_all_finite": {
            "type": "bool or 'allow",
            "description": "nan', default=True"
          },
          "XT": {
            "type": "{ndarray, sparse matrix}",
            "description": ""
          },
          "An": {
            "type": "array of type float.",
            "description": "Examples\n--------\n>>> from sklearn.utils import as_float_array\n>>> import numpy as np\n>>> array = np.array([0, 0, 1, 2, 2], dtype=np.int64)\n>>> as_float_array(array)"
          },
          "array": {
            "type": "[0., 0., 1., 2., 2.]",
            "description": ""
          }
        },
        "returns": "-------\n    XT : {ndarray, sparse matrix}\n        An array of type float.\n\n    Examples\n    --------\n    >>> from sklearn.utils import as_float_array\n    >>> import numpy as np\n    >>> array = np.array([0, 0, 1, 2, 2], dtype=np.int64)\n    >>> as_float_array(array)\n    array([0., 0., 1., 2., 2.])",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils import as_float_array\n    >>> import numpy as np\n    >>> array = np.array([0, 0, 1, 2, 2], dtype=np.int64)\n    >>> as_float_array(array)\n    array([0., 0., 1., 2., 2.])"
      }
    },
    {
      "name": "assert_all_finite",
      "signature": "assert_all_finite(X, *, allow_nan=False, estimator_name=None, input_name='')",
      "documentation": {
        "description": "Throw a ValueError if X contains NaN or infinity.\n\n    Parameters\n    ----------\n    X : {ndarray, sparse matrix}\n        The input data.\n\n    allow_nan : bool, default=False\n        If True, do not throw error when `X` contains NaN.\n\n    estimator_name : str, default=None\n        The estimator name, used to construct the error message.\n\n    input_name : str, default=\"\"\n        The data name used to construct the error message. In particular\n        if `input_name` is \"X\" and the data has NaN values and\n        allow_nan is False, the error message will link to the imputer\n        documentation.",
        "parameters": {
          "X": {
            "type": "{ndarray, sparse matrix}",
            "description": ""
          },
          "The": {
            "type": "data name used to construct the error message. In particular",
            "description": ""
          },
          "allow_nan": {
            "type": "is False, the error message will link to the imputer",
            "description": "documentation.\nExamples\n--------\n>>> from sklearn.utils import assert_all_finite\n>>> import numpy as np\n>>> array = np.array([1, np.inf, np.nan, 4])\n>>> try:\n...     assert_all_finite(array)\n...     print(\"Test passed: Array contains only finite values.\")\n... except ValueError:\n...     print(\"Test failed: Array contains non-finite values.\")"
          },
          "If": {
            "type": "True, do not throw error when `X` contains NaN.",
            "description": ""
          },
          "estimator_name": {
            "type": "str, default=None",
            "description": ""
          },
          "input_name": {
            "type": "str, default=\"\"",
            "description": ""
          },
          "if": {
            "type": "`input_name` is \"X\" and the data has NaN values and",
            "description": ""
          },
          "Test": {
            "type": "failed: Array contains non-finite values.",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils import assert_all_finite\n    >>> import numpy as np\n    >>> array = np.array([1, np.inf, np.nan, 4])\n    >>> try:\n    ...     assert_all_finite(array)\n    ...     print(\"Test passed: Array contains only finite values.\")\n    ... except ValueError:\n    ...     print(\"Test failed: Array contains non-finite values.\")\n    Test failed: Array contains non-finite values."
      }
    },
    {
      "name": "check_X_y",
      "signature": "check_X_y(X, y, accept_sparse=False, *, accept_large_sparse=True, dtype='numeric', order=None, copy=False, force_writeable=False, force_all_finite='deprecated', ensure_all_finite=None, ensure_2d=True, allow_nd=False, multi_output=False, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, estimator=None)",
      "documentation": {
        "description": "Input validation for standard estimators.\n\n    Checks X and y for consistent length, enforces X to be 2D and y 1D. By\n    default, X is checked to be non-empty and containing only finite values.\n    Standard input checks are also applied to y, such as checking that y\n    does not have np.nan or np.inf targets. For multi-label y, set\n    multi_output=True to allow 2D and sparse y. If the dtype of X is\n    object, attempt converting to float, raising on failure.\n\n    Parameters\n    ----------\n    X : {ndarray, list, sparse matrix}\n        Input data.\n\n    y : {ndarray, list, sparse matrix}\n        Labels.\n\n    accept_sparse : str, bool or list of str, default=False\n        String[s] representing allowed sparse matrix formats, such as 'csc',\n        'csr', etc. If the input is sparse but not in the allowed format,\n        it will be converted to the first listed format. True allows the input\n        to be any format. False means that a sparse matrix input will\n        raise an error.\n\n    accept_large_sparse : bool, default=True\n        If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by\n        accept_sparse, accept_large_sparse will cause it to be accepted only\n        if its indices are stored with a 32-bit dtype.\n\n        .. versionadded:: 0.20\n\n    dtype : 'numeric', type, list of type or None, default='numeric'\n        Data type of result. If None, the dtype of the input is preserved.\n        If \"numeric\", dtype is preserved unless array.dtype is object.\n        If dtype is a list of types, conversion on the first type is only\n        performed if the dtype of the input is not in the list.\n\n    order : {'F', 'C'}, default=None\n        Whether an array will be forced to be fortran or c-style. If\n        `None`, then the input data's order is preserved when possible.\n\n    copy : bool, default=False\n        Whether a forced copy will be triggered. If copy=False, a copy might\n        be triggered by a conversion.\n\n    force_writeable : bool, default=False\n        Whether to force the output array to be writeable. If True, the returned array\n        is guaranteed to be writeable, which may require a copy. Otherwise the\n        writeability of the input array is preserved.\n\n        .. versionadded:: 1.6\n\n    force_all_finite : bool or 'allow-nan', default=True\n        Whether to raise an error on np.inf, np.nan, pd.NA in array. This parameter\n        does not influence whether y can have np.inf, np.nan, pd.NA values.\n        The possibilities are:\n\n        - True: Force all values of X to be finite.\n        - False: accepts np.inf, np.nan, pd.NA in X.\n        - 'allow-nan': accepts only np.nan or pd.NA values in X. Values cannot\n          be infinite.\n\n        .. versionadded:: 0.20\n           ``force_all_finite`` accepts the string ``'allow-nan'``.\n\n        .. versionchanged:: 0.23\n           Accepts `pd.NA` and converts it into `np.nan`\n\n        .. deprecated:: 1.6\n           `force_all_finite` was renamed to `ensure_all_finite` and will be removed\n           in 1.8.\n\n    ensure_all_finite : bool or 'allow-nan', default=True\n        Whether to raise an error on np.inf, np.nan, pd.NA in array. This parameter\n        does not influence whether y can have np.inf, np.nan, pd.NA values.\n        The possibilities are:\n\n        - True: Force all values of X to be finite.\n        - False: accepts np.inf, np.nan, pd.NA in X.\n        - 'allow-nan': accepts only np.nan or pd.NA values in X. Values cannot\n          be infinite.\n\n        .. versionadded:: 1.6\n           `force_all_finite` was renamed to `ensure_all_finite`.\n\n    ensure_2d : bool, default=True\n        Whether to raise a value error if X is not 2D.\n\n    allow_nd : bool, default=False\n        Whether to allow X.ndim > 2.\n\n    multi_output : bool, default=False\n        Whether to allow 2D y (array or sparse matrix). If false, y will be\n        validated as a vector. y cannot have np.nan or np.inf values if\n        multi_output=True.\n\n    ensure_min_samples : int, default=1\n        Make sure that X has a minimum number of samples in its first\n        axis (rows for a 2D array).\n\n    ensure_min_features : int, default=1\n        Make sure that the 2D array has some minimum number of features\n        (columns). The default value of 1 rejects empty datasets.\n        This check is only enforced when X has effectively 2 dimensions or\n        is originally 1D and ``ensure_2d`` is True. Setting to 0 disables\n        this check.\n\n    y_numeric : bool, default=False\n        Whether to ensure that y has a numeric type. If dtype of y is object,\n        it is converted to float64. Should only be used for regression\n        algorithms.\n\n    estimator : str or estimator instance, default=None\n        If passed, include the name of the estimator in warning messages.\n\n    Returns\n    -------\n    X_converted : object\n        The converted and validated X.\n\n    y_converted : object\n        The converted and validated y.",
        "parameters": {
          "X": {
            "type": "{ndarray, list, sparse matrix}",
            "description": ""
          },
          "Input": {
            "type": "data.",
            "description": ""
          },
          "y": {
            "type": "{ndarray, list, sparse matrix}",
            "description": "Labels."
          },
          "accept_sparse": {
            "type": "str, bool or list of str, default=False",
            "description": "String[s] representing allowed sparse matrix formats, such as 'csc',\n'csr', etc. If the input is sparse but not in the allowed format,"
          },
          "it": {
            "type": "is converted to float64. Should only be used for regression",
            "description": "algorithms."
          },
          "to": {
            "type": "be any format. False means that a sparse matrix input will",
            "description": ""
          },
          "raise": {
            "type": "an error.",
            "description": ""
          },
          "accept_large_sparse": {
            "type": "bool, default=True",
            "description": ""
          },
          "If": {
            "type": "passed, include the name of the estimator in warning messages.",
            "description": "Returns\n-------"
          },
          "if": {
            "type": "its indices are stored with a 32-bit dtype.",
            "description": ".. versionadded:: 0.20"
          },
          "dtype": {
            "type": "'numeric', type, list of type or None, default='numeric'",
            "description": ""
          },
          "Data": {
            "type": "type of result. If None, the dtype of the input is preserved.",
            "description": ""
          },
          "performed": {
            "type": "if the dtype of the input is not in the list.",
            "description": ""
          },
          "order": {
            "type": "{'F', 'C'}, default=None",
            "description": ""
          },
          "Whether": {
            "type": "to ensure that y has a numeric type. If dtype of y is object,",
            "description": ""
          },
          "copy": {
            "type": "bool, default=False",
            "description": ""
          },
          "be": {
            "type": "infinite.",
            "description": ".. versionadded:: 1.6\n`force_all_finite` was renamed to `ensure_all_finite`."
          },
          "force_writeable": {
            "type": "bool, default=False",
            "description": ""
          },
          "is": {
            "type": "originally 1D and ``ensure_2d`` is True. Setting to 0 disables",
            "description": ""
          },
          "writeability": {
            "type": "of the input array is preserved.",
            "description": ".. versionadded:: 1.6"
          },
          "force_all_finite": {
            "type": "bool or 'allow",
            "description": "nan', default=True"
          },
          "does": {
            "type": "not influence whether y can have np.inf, np.nan, pd.NA values.",
            "description": ""
          },
          "The": {
            "type": "converted and validated y.",
            "description": "Examples\n--------\n>>> from sklearn.utils.validation import check_X_y\n>>> X = [[1, 2], [3, 4], [5, 6]]\n>>> y = [1, 2, 3]\n>>> X, y = check_X_y(X, y)\n>>> X\narray([[1, 2],\n[3, 4],\n[5, 6]])\n>>> y"
          },
          "Accepts": {
            "type": "`pd.NA` and converts it into `np.nan`",
            "description": ".. deprecated:: 1.6\n`force_all_finite` was renamed to `ensure_all_finite` and will be removed"
          },
          "in": {
            "type": "1.8.",
            "description": ""
          },
          "ensure_all_finite": {
            "type": "bool or 'allow",
            "description": "nan', default=True"
          },
          "ensure_2d": {
            "type": "bool, default=True",
            "description": ""
          },
          "allow_nd": {
            "type": "bool, default=False",
            "description": ""
          },
          "multi_output": {
            "type": "bool, default=False",
            "description": ""
          },
          "validated": {
            "type": "as a vector. y cannot have np.nan or np.inf values if",
            "description": "multi_output=True."
          },
          "ensure_min_samples": {
            "type": "int, default=1",
            "description": ""
          },
          "Make": {
            "type": "sure that the 2D array has some minimum number of features",
            "description": "(columns). The default value of 1 rejects empty datasets."
          },
          "axis": {
            "type": "rows for a 2D array",
            "description": "."
          },
          "ensure_min_features": {
            "type": "int, default=1",
            "description": ""
          },
          "This": {
            "type": "check is only enforced when X has effectively 2 dimensions or",
            "description": ""
          },
          "this": {
            "type": "check.",
            "description": ""
          },
          "y_numeric": {
            "type": "bool, default=False",
            "description": ""
          },
          "estimator": {
            "type": "str or estimator instance, default=None",
            "description": ""
          },
          "X_converted": {
            "type": "object",
            "description": ""
          },
          "y_converted": {
            "type": "object",
            "description": ""
          },
          "array": {
            "type": "[1, 2, 3]",
            "description": ""
          }
        },
        "returns": "-------\n    X_converted : object\n        The converted and validated X.\n\n    y_converted : object\n        The converted and validated y.\n\n    Examples\n    --------\n    >>> from sklearn.utils.validation import check_X_y\n    >>> X = [[1, 2], [3, 4], [5, 6]]\n    >>> y = [1, 2, 3]\n    >>> X, y = check_X_y(X, y)\n    >>> X\n    array([[1, 2],\n          [3, 4],\n          [5, 6]])\n    >>> y\n    array([1, 2, 3])",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils.validation import check_X_y\n    >>> X = [[1, 2], [3, 4], [5, 6]]\n    >>> y = [1, 2, 3]\n    >>> X, y = check_X_y(X, y)\n    >>> X\n    array([[1, 2],\n          [3, 4],\n          [5, 6]])\n    >>> y\n    array([1, 2, 3])"
      }
    },
    {
      "name": "check_array",
      "signature": "check_array(array, accept_sparse=False, *, accept_large_sparse=True, dtype='numeric', order=None, copy=False, force_writeable=False, force_all_finite='deprecated', ensure_all_finite=None, ensure_non_negative=False, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, estimator=None, input_name='')",
      "documentation": {
        "description": "Input validation on an array, list, sparse matrix or similar.\n\n    By default, the input is checked to be a non-empty 2D array containing\n    only finite values. If the dtype of the array is object, attempt\n    converting to float, raising on failure.\n\n    Parameters\n    ----------\n    array : object\n        Input object to check / convert.\n\n    accept_sparse : str, bool or list/tuple of str, default=False\n        String[s] representing allowed sparse matrix formats, such as 'csc',\n        'csr', etc. If the input is sparse but not in the allowed format,\n        it will be converted to the first listed format. True allows the input\n        to be any format. False means that a sparse matrix input will\n        raise an error.\n\n    accept_large_sparse : bool, default=True\n        If a CSR, CSC, COO or BSR sparse matrix is supplied and accepted by\n        accept_sparse, accept_large_sparse=False will cause it to be accepted\n        only if its indices are stored with a 32-bit dtype.\n\n        .. versionadded:: 0.20\n\n    dtype : 'numeric', type, list of type or None, default='numeric'\n        Data type of result. If None, the dtype of the input is preserved.\n        If \"numeric\", dtype is preserved unless array.dtype is object.\n        If dtype is a list of types, conversion on the first type is only\n        performed if the dtype of the input is not in the list.\n\n    order : {'F', 'C'} or None, default=None\n        Whether an array will be forced to be fortran or c-style.\n        When order is None (default), then if copy=False, nothing is ensured\n        about the memory layout of the output array; otherwise (copy=True)\n        the memory layout of the returned array is kept as close as possible\n        to the original array.\n\n    copy : bool, default=False\n        Whether a forced copy will be triggered. If copy=False, a copy might\n        be triggered by a conversion.\n\n    force_writeable : bool, default=False\n        Whether to force the output array to be writeable. If True, the returned array\n        is guaranteed to be writeable, which may require a copy. Otherwise the\n        writeability of the input array is preserved.\n\n        .. versionadded:: 1.6\n\n    force_all_finite : bool or 'allow-nan', default=True\n        Whether to raise an error on np.inf, np.nan, pd.NA in array. The\n        possibilities are:\n\n        - True: Force all values of array to be finite.\n        - False: accepts np.inf, np.nan, pd.NA in array.\n        - 'allow-nan': accepts only np.nan and pd.NA values in array. Values\n          cannot be infinite.\n\n        .. versionadded:: 0.20\n           ``force_all_finite`` accepts the string ``'allow-nan'``.\n\n        .. versionchanged:: 0.23\n           Accepts `pd.NA` and converts it into `np.nan`\n\n        .. deprecated:: 1.6\n           `force_all_finite` was renamed to `ensure_all_finite` and will be removed\n           in 1.8.\n\n    ensure_all_finite : bool or 'allow-nan', default=True\n        Whether to raise an error on np.inf, np.nan, pd.NA in array. The\n        possibilities are:\n\n        - True: Force all values of array to be finite.\n        - False: accepts np.inf, np.nan, pd.NA in array.\n        - 'allow-nan': accepts only np.nan and pd.NA values in array. Values\n          cannot be infinite.\n\n        .. versionadded:: 1.6\n           `force_all_finite` was renamed to `ensure_all_finite`.\n\n    ensure_non_negative : bool, default=False\n        Make sure the array has only non-negative values. If True, an array that\n        contains negative values will raise a ValueError.\n\n        .. versionadded:: 1.6\n\n    ensure_2d : bool, default=True\n        Whether to raise a value error if array is not 2D.\n\n    allow_nd : bool, default=False\n        Whether to allow array.ndim > 2.\n\n    ensure_min_samples : int, default=1\n        Make sure that the array has a minimum number of samples in its first\n        axis (rows for a 2D array). Setting to 0 disables this check.\n\n    ensure_min_features : int, default=1\n        Make sure that the 2D array has some minimum number of features\n        (columns). The default value of 1 rejects empty datasets.\n        This check is only enforced when the input data has effectively 2\n        dimensions or is originally 1D and ``ensure_2d`` is True. Setting to 0\n        disables this check.\n\n    estimator : str or estimator instance, default=None\n        If passed, include the name of the estimator in warning messages.\n\n    input_name : str, default=\"\"\n        The data name used to construct the error message. In particular\n        if `input_name` is \"X\" and the data has NaN values and\n        allow_nan is False, the error message will link to the imputer\n        documentation.\n\n        .. versionadded:: 1.1.0\n\n    Returns\n    -------\n    array_converted : object\n        The converted and validated array.",
        "parameters": {
          "array": {
            "type": "[[1, 2, 3], [4, 5, 6]]",
            "description": ""
          },
          "Input": {
            "type": "object to check / convert.",
            "description": ""
          },
          "accept_sparse": {
            "type": "str, bool or list/tuple of str, default=False",
            "description": "String[s] representing allowed sparse matrix formats, such as 'csc',\n'csr', etc. If the input is sparse but not in the allowed format,"
          },
          "it": {
            "type": "will be converted to the first listed format. True allows the input",
            "description": ""
          },
          "to": {
            "type": "the original array.",
            "description": ""
          },
          "raise": {
            "type": "an error.",
            "description": ""
          },
          "accept_large_sparse": {
            "type": "bool, default=True",
            "description": ""
          },
          "If": {
            "type": "passed, include the name of the estimator in warning messages.",
            "description": ""
          },
          "only": {
            "type": "if its indices are stored with a 32-bit dtype.",
            "description": ".. versionadded:: 0.20"
          },
          "dtype": {
            "type": "'numeric', type, list of type or None, default='numeric'",
            "description": ""
          },
          "Data": {
            "type": "type of result. If None, the dtype of the input is preserved.",
            "description": ""
          },
          "performed": {
            "type": "if the dtype of the input is not in the list.",
            "description": ""
          },
          "order": {
            "type": "{'F', 'C'} or None, default=None",
            "description": ""
          },
          "Whether": {
            "type": "to allow array.ndim > 2.",
            "description": ""
          },
          "When": {
            "type": "order is None (default), then if copy=False, nothing is ensured",
            "description": ""
          },
          "about": {
            "type": "the memory layout of the output array; otherwise (copy=True)",
            "description": ""
          },
          "the": {
            "type": "memory layout of the returned array is kept as close as possible",
            "description": ""
          },
          "copy": {
            "type": "bool, default=False",
            "description": ""
          },
          "be": {
            "type": "triggered by a conversion.",
            "description": ""
          },
          "force_writeable": {
            "type": "bool, default=False",
            "description": ""
          },
          "is": {
            "type": "guaranteed to be writeable, which may require a copy. Otherwise the",
            "description": ""
          },
          "writeability": {
            "type": "of the input array is preserved.",
            "description": ".. versionadded:: 1.6"
          },
          "force_all_finite": {
            "type": "bool or 'allow",
            "description": "nan', default=True"
          },
          "possibilities": {
            "type": "are:",
            "description": "- True: Force all values of array to be finite.\n- False: accepts np.inf, np.nan, pd.NA in array.\n- 'allow-nan': accepts only np.nan and pd.NA values in array. Values"
          },
          "cannot": {
            "type": "be infinite.",
            "description": ".. versionadded:: 1.6\n`force_all_finite` was renamed to `ensure_all_finite`."
          },
          "Accepts": {
            "type": "`pd.NA` and converts it into `np.nan`",
            "description": ".. deprecated:: 1.6\n`force_all_finite` was renamed to `ensure_all_finite` and will be removed"
          },
          "in": {
            "type": "1.8.",
            "description": ""
          },
          "ensure_all_finite": {
            "type": "bool or 'allow",
            "description": "nan', default=True"
          },
          "ensure_non_negative": {
            "type": "bool, default=False",
            "description": ""
          },
          "Make": {
            "type": "sure that the 2D array has some minimum number of features",
            "description": "(columns). The default value of 1 rejects empty datasets."
          },
          "contains": {
            "type": "negative values will raise a ValueError.",
            "description": ".. versionadded:: 1.6"
          },
          "ensure_2d": {
            "type": "bool, default=True",
            "description": ""
          },
          "allow_nd": {
            "type": "bool, default=False",
            "description": ""
          },
          "ensure_min_samples": {
            "type": "int, default=1",
            "description": ""
          },
          "axis": {
            "type": "rows for a 2D array",
            "description": ". Setting to 0 disables this check."
          },
          "ensure_min_features": {
            "type": "int, default=1",
            "description": ""
          },
          "This": {
            "type": "check is only enforced when the input data has effectively 2",
            "description": ""
          },
          "dimensions": {
            "type": "or is originally 1D and ``ensure_2d`` is True. Setting to 0",
            "description": ""
          },
          "disables": {
            "type": "this check.",
            "description": ""
          },
          "estimator": {
            "type": "str or estimator instance, default=None",
            "description": ""
          },
          "input_name": {
            "type": "str, default=\"\"",
            "description": ""
          },
          "The": {
            "type": "converted and validated array.",
            "description": "Examples\n--------\n>>> from sklearn.utils.validation import check_array\n>>> X = [[1, 2, 3], [4, 5, 6]]\n>>> X_checked = check_array(X)\n>>> X_checked"
          },
          "if": {
            "type": "`input_name` is \"X\" and the data has NaN values and",
            "description": ""
          },
          "allow_nan": {
            "type": "is False, the error message will link to the imputer",
            "description": "documentation.\n.. versionadded:: 1.1.0\nReturns\n-------"
          },
          "array_converted": {
            "type": "object",
            "description": ""
          }
        },
        "returns": "-------\n    array_converted : object\n        The converted and validated array.\n\n    Examples\n    --------\n    >>> from sklearn.utils.validation import check_array\n    >>> X = [[1, 2, 3], [4, 5, 6]]\n    >>> X_checked = check_array(X)\n    >>> X_checked\n    array([[1, 2, 3], [4, 5, 6]])",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils.validation import check_array\n    >>> X = [[1, 2, 3], [4, 5, 6]]\n    >>> X_checked = check_array(X)\n    >>> X_checked\n    array([[1, 2, 3], [4, 5, 6]])"
      }
    },
    {
      "name": "check_consistent_length",
      "signature": "check_consistent_length(*arrays)",
      "documentation": {
        "description": "Check that all arrays have consistent first dimensions.\n\n    Checks whether all objects in arrays have the same shape or length.\n\n    Parameters\n    ----------\n    *arrays : list or tuple of input objects.\n        Objects that will be checked for consistent length.",
        "parameters": {
          "Objects": {
            "type": "that will be checked for consistent length.",
            "description": "Examples\n--------\n>>> from sklearn.utils.validation import check_consistent_length\n>>> a = [1, 2, 3]\n>>> b = [2, 3, 4]\n>>> check_consistent_length(a, b)"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils.validation import check_consistent_length\n    >>> a = [1, 2, 3]\n    >>> b = [2, 3, 4]\n    >>> check_consistent_length(a, b)"
      }
    },
    {
      "name": "check_random_state",
      "signature": "check_random_state(seed)",
      "documentation": {
        "description": "Turn seed into a np.random.RandomState instance.\n\n    Parameters\n    ----------\n    seed : None, int or instance of RandomState\n        If seed is None, return the RandomState singleton used by np.random.\n        If seed is an int, return a new RandomState instance seeded with seed.\n        If seed is already a RandomState instance, return it.\n        Otherwise raise ValueError.\n\n    Returns\n    -------\n    :class:`numpy:numpy.random.RandomState`\n        The random state object based on `seed` parameter.",
        "parameters": {
          "seed": {
            "type": "None, int or instance of RandomState",
            "description": ""
          },
          "If": {
            "type": "seed is already a RandomState instance, return it.",
            "description": ""
          },
          "Otherwise": {
            "type": "raise ValueError.",
            "description": "Returns\n-------\n:class:`numpy:numpy.random.RandomState`"
          },
          "The": {
            "type": "random state object based on `seed` parameter.",
            "description": "Examples\n--------\n>>> from sklearn.utils.validation import check_random_state\n>>> check_random_state(42)"
          },
          "RandomState": {
            "type": "MT19937",
            "description": "at 0x..."
          }
        },
        "returns": "-------\n    :class:`numpy:numpy.random.RandomState`\n        The random state object based on `seed` parameter.\n\n    Examples\n    --------\n    >>> from sklearn.utils.validation import check_random_state\n    >>> check_random_state(42)\n    RandomState(MT19937) at 0x...",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils.validation import check_random_state\n    >>> check_random_state(42)\n    RandomState(MT19937) at 0x..."
      }
    },
    {
      "name": "check_scalar",
      "signature": "check_scalar(x, name, target_type, *, min_val=None, max_val=None, include_boundaries='both')",
      "documentation": {
        "description": "Validate scalar parameters type and value.\n\n    Parameters\n    ----------\n    x : object\n        The scalar parameter to validate.\n\n    name : str\n        The name of the parameter to be printed in error messages.\n\n    target_type : type or tuple\n        Acceptable data types for the parameter.\n\n    min_val : float or int, default=None\n        The minimum valid value the parameter can take. If None (default) it\n        is implied that the parameter does not have a lower bound.\n\n    max_val : float or int, default=None\n        The maximum valid value the parameter can take. If None (default) it\n        is implied that the parameter does not have an upper bound.\n\n    include_boundaries : {\"left\", \"right\", \"both\", \"neither\"}, default=\"both\"\n        Whether the interval defined by `min_val` and `max_val` should include\n        the boundaries. Possible choices are:\n\n        - `\"left\"`: only `min_val` is included in the valid interval.\n          It is equivalent to the interval `[ min_val, max_val )`.\n        - `\"right\"`: only `max_val` is included in the valid interval.\n          It is equivalent to the interval `( min_val, max_val ]`.\n        - `\"both\"`: `min_val` and `max_val` are included in the valid interval.\n          It is equivalent to the interval `[ min_val, max_val ]`.\n        - `\"neither\"`: neither `min_val` nor `max_val` are included in the\n          valid interval. It is equivalent to the interval `( min_val, max_val )`.\n\n    Returns\n    -------\n    x : numbers.Number\n        The validated number.\n\n    Raises\n    ------\n    TypeError\n        If the parameter's type does not match the desired type.\n\n    ValueError\n        If the parameter's value violates the given bounds.\n        If `min_val`, `max_val` and `include_boundaries` are inconsistent.",
        "parameters": {
          "x": {
            "type": "numbers.Number",
            "description": ""
          },
          "The": {
            "type": "validated number.",
            "description": "Raises\n------\nTypeError"
          },
          "name": {
            "type": "str",
            "description": ""
          },
          "target_type": {
            "type": "type or tuple",
            "description": ""
          },
          "Acceptable": {
            "type": "data types for the parameter.",
            "description": ""
          },
          "min_val": {
            "type": "float or int, default=None",
            "description": ""
          },
          "is": {
            "type": "implied that the parameter does not have an upper bound.",
            "description": ""
          },
          "max_val": {
            "type": "float or int, default=None",
            "description": ""
          },
          "include_boundaries": {
            "type": "{\"left\", \"right\", \"both\", \"neither\"}, default=\"both\"",
            "description": ""
          },
          "Whether": {
            "type": "the interval defined by `min_val` and `max_val` should include",
            "description": ""
          },
          "the": {
            "type": "boundaries. Possible choices are:",
            "description": "- `\"left\"`: only `min_val` is included in the valid interval."
          },
          "It": {
            "type": "is equivalent to the interval `[ min_val, max_val ]`.",
            "description": "- `\"neither\"`: neither `min_val` nor `max_val` are included in the"
          },
          "valid": {
            "type": "interval. It is equivalent to the interval `( min_val, max_val )`.",
            "description": "Returns\n-------"
          },
          "If": {
            "type": "`min_val`, `max_val` and `include_boundaries` are inconsistent.",
            "description": "Examples\n--------\n>>> from sklearn.utils.validation import check_scalar\n>>> check_scalar(10, \"x\", int, min_val=1, max_val=20)\n10"
          }
        },
        "returns": "-------\n    x : numbers.Number\n        The validated number.\n\n    Raises\n    ------\n    TypeError\n        If the parameter's type does not match the desired type.\n\n    ValueError\n        If the parameter's value violates the given bounds.\n        If `min_val`, `max_val` and `include_boundaries` are inconsistent.\n\n    Examples\n    --------\n    >>> from sklearn.utils.validation import check_scalar\n    >>> check_scalar(10, \"x\", int, min_val=1, max_val=20)\n    10",
        "raises": "------\n    TypeError\n        If the parameter's type does not match the desired type.\n\n    ValueError\n        If the parameter's value violates the given bounds.\n        If `min_val`, `max_val` and `include_boundaries` are inconsistent.\n\n    Examples\n    --------\n    >>> from sklearn.utils.validation import check_scalar\n    >>> check_scalar(10, \"x\", int, min_val=1, max_val=20)\n    10",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils.validation import check_scalar\n    >>> check_scalar(10, \"x\", int, min_val=1, max_val=20)\n    10"
      }
    },
    {
      "name": "check_symmetric",
      "signature": "check_symmetric(array, *, tol=1e-10, raise_warning=True, raise_exception=False)",
      "documentation": {
        "description": "Make sure that array is 2D, square and symmetric.\n\n    If the array is not symmetric, then a symmetrized version is returned.\n    Optionally, a warning or exception is raised if the matrix is not\n    symmetric.\n\n    Parameters\n    ----------\n    array : {ndarray, sparse matrix}\n        Input object to check / convert. Must be two-dimensional and square,\n        otherwise a ValueError will be raised.\n\n    tol : float, default=1e-10\n        Absolute tolerance for equivalence of arrays. Default = 1E-10.\n\n    raise_warning : bool, default=True\n        If True then raise a warning if conversion is required.\n\n    raise_exception : bool, default=False\n        If True then raise an exception if array is not symmetric.\n\n    Returns\n    -------\n    array_sym : {ndarray, sparse matrix}\n        Symmetrized version of the input array, i.e. the average of array\n        and array.transpose(). If sparse, then duplicate entries are first\n        summed and zeros are eliminated.",
        "parameters": {
          "array": {
            "type": "{ndarray, sparse matrix}",
            "description": ""
          },
          "Input": {
            "type": "object to check / convert. Must be two-dimensional and square,",
            "description": ""
          },
          "otherwise": {
            "type": "a ValueError will be raised.",
            "description": ""
          },
          "tol": {
            "type": "float, default=1e",
            "description": "10"
          },
          "Absolute": {
            "type": "tolerance for equivalence of arrays. Default = 1E-10.",
            "description": ""
          },
          "raise_warning": {
            "type": "bool, default=True",
            "description": ""
          },
          "If": {
            "type": "True then raise an exception if array is not symmetric.",
            "description": "Returns\n-------"
          },
          "raise_exception": {
            "type": "bool, default=False",
            "description": ""
          },
          "array_sym": {
            "type": "{ndarray, sparse matrix}",
            "description": ""
          },
          "Symmetrized": {
            "type": "version of the input array, i.e. the average of array",
            "description": ""
          },
          "and": {
            "type": "array.transpose(). If sparse, then duplicate entries are first",
            "description": ""
          },
          "summed": {
            "type": "and zeros are eliminated.",
            "description": "Examples\n--------\n>>> import numpy as np\n>>> from sklearn.utils.validation import check_symmetric\n>>> symmetric_array = np.array([[0, 1, 2], [1, 0, 1], [2, 1, 0]])\n>>> check_symmetric(symmetric_array)\narray([[0, 1, 2],\n[1, 0, 1],\n[2, 1, 0]])\n>>> from scipy.sparse import csr_matrix\n>>> sparse_symmetric_array = csr_matrix(symmetric_array)\n>>> check_symmetric(sparse_symmetric_array)\n<Compressed Sparse Row sparse matrix of dtype 'int64'"
          },
          "with": {
            "type": "6 stored elements and shape (3, 3)>",
            "description": ""
          }
        },
        "returns": "-------\n    array_sym : {ndarray, sparse matrix}\n        Symmetrized version of the input array, i.e. the average of array\n        and array.transpose(). If sparse, then duplicate entries are first\n        summed and zeros are eliminated.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.utils.validation import check_symmetric\n    >>> symmetric_array = np.array([[0, 1, 2], [1, 0, 1], [2, 1, 0]])\n    >>> check_symmetric(symmetric_array)\n    array([[0, 1, 2],\n           [1, 0, 1],\n           [2, 1, 0]])\n    >>> from scipy.sparse import csr_matrix\n    >>> sparse_symmetric_array = csr_matrix(symmetric_array)\n    >>> check_symmetric(sparse_symmetric_array)\n    <Compressed Sparse Row sparse matrix of dtype 'int64'\n        with 6 stored elements and shape (3, 3)>",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.utils.validation import check_symmetric\n    >>> symmetric_array = np.array([[0, 1, 2], [1, 0, 1], [2, 1, 0]])\n    >>> check_symmetric(symmetric_array)\n    array([[0, 1, 2],\n           [1, 0, 1],\n           [2, 1, 0]])\n    >>> from scipy.sparse import csr_matrix\n    >>> sparse_symmetric_array = csr_matrix(symmetric_array)\n    >>> check_symmetric(sparse_symmetric_array)\n    <Compressed Sparse Row sparse matrix of dtype 'int64'\n        with 6 stored elements and shape (3, 3)>"
      }
    },
    {
      "name": "column_or_1d",
      "signature": "column_or_1d(y, *, dtype=None, warn=False, device=None)",
      "documentation": {
        "description": "Ravel column or 1d numpy array, else raises an error.\n\n    Parameters\n    ----------\n    y : array-like\n       Input data.\n\n    dtype : data-type, default=None\n        Data type for `y`.\n\n        .. versionadded:: 1.2\n\n    warn : bool, default=False\n       To control display of warnings.\n\n    device : device, default=None\n        `device` object.\n        See the :ref:`Array API User Guide <array_api>` for more details.\n\n        .. versionadded:: 1.6\n\n    Returns\n    -------\n    y : ndarray\n       Output data.\n\n    Raises\n    ------\n    ValueError\n        If `y` is not a 1D array or a 2D array with a single row or column.",
        "parameters": {
          "y": {
            "type": "ndarray",
            "description": ""
          },
          "Input": {
            "type": "data.",
            "description": ""
          },
          "dtype": {
            "type": "data",
            "description": "type, default=None"
          },
          "Data": {
            "type": "type for `y`.",
            "description": ".. versionadded:: 1.2"
          },
          "warn": {
            "type": "bool, default=False",
            "description": ""
          },
          "To": {
            "type": "control display of warnings.",
            "description": ""
          },
          "device": {
            "type": "device, default=None",
            "description": "`device` object."
          },
          "See": {
            "type": "the :ref:`Array API User Guide <array_api>` for more details.",
            "description": ".. versionadded:: 1.6\nReturns\n-------"
          },
          "Output": {
            "type": "data.",
            "description": "Raises\n------\nValueError"
          },
          "If": {
            "type": "`y` is not a 1D array or a 2D array with a single row or column.",
            "description": "Examples\n--------\n>>> from sklearn.utils.validation import column_or_1d\n>>> column_or_1d([1, 1])"
          },
          "array": {
            "type": "[1, 1]",
            "description": ""
          }
        },
        "returns": "-------\n    y : ndarray\n       Output data.\n\n    Raises\n    ------\n    ValueError\n        If `y` is not a 1D array or a 2D array with a single row or column.\n\n    Examples\n    --------\n    >>> from sklearn.utils.validation import column_or_1d\n    >>> column_or_1d([1, 1])\n    array([1, 1])",
        "raises": "------\n    ValueError\n        If `y` is not a 1D array or a 2D array with a single row or column.\n\n    Examples\n    --------\n    >>> from sklearn.utils.validation import column_or_1d\n    >>> column_or_1d([1, 1])\n    array([1, 1])",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils.validation import column_or_1d\n    >>> column_or_1d([1, 1])\n    array([1, 1])"
      }
    },
    {
      "name": "compute_class_weight",
      "signature": "compute_class_weight(class_weight, *, classes, y)",
      "documentation": {
        "description": "Estimate class weights for unbalanced datasets.\n\n    Parameters\n    ----------\n    class_weight : dict, \"balanced\" or None\n        If \"balanced\", class weights will be given by\n        `n_samples / (n_classes * np.bincount(y))`.\n        If a dictionary is given, keys are classes and values are corresponding class\n        weights.\n        If `None` is given, the class weights will be uniform.\n\n    classes : ndarray\n        Array of the classes occurring in the data, as given by\n        `np.unique(y_org)` with `y_org` the original class labels.\n\n    y : array-like of shape (n_samples,)\n        Array of original class labels per sample.\n\n    Returns\n    -------\n    class_weight_vect : ndarray of shape (n_classes,)\n        Array with `class_weight_vect[i]` the weight for i-th class.\n\n    References\n    ----------\n    The \"balanced\" heuristic is inspired by\n    Logistic Regression in Rare Events Data, King, Zen, 2001.",
        "parameters": {
          "class_weight": {
            "type": "dict, \"balanced\" or None",
            "description": ""
          },
          "If": {
            "type": "`None` is given, the class weights will be uniform.",
            "description": ""
          },
          "classes": {
            "type": "ndarray",
            "description": ""
          },
          "Array": {
            "type": "with `class_weight_vect[i]` the weight for i-th class.",
            "description": "References\n----------"
          },
          "y": {
            "type": "array",
            "description": "like of shape (n_samples,)"
          },
          "class_weight_vect": {
            "type": "ndarray of shape (n_classes,)",
            "description": ""
          },
          "The": {
            "type": "\"balanced\" heuristic is inspired by",
            "description": ""
          },
          "Logistic": {
            "type": "Regression in Rare Events Data, King, Zen, 2001.",
            "description": "Examples\n--------\n>>> import numpy as np\n>>> from sklearn.utils.class_weight import compute_class_weight\n>>> y = [1, 1, 1, 1, 0, 0]\n>>> compute_class_weight(class_weight=\"balanced\", classes=np.unique(y), y=y)"
          },
          "array": {
            "type": "[1.5 , 0.75]",
            "description": ""
          }
        },
        "returns": "-------\n    class_weight_vect : ndarray of shape (n_classes,)\n        Array with `class_weight_vect[i]` the weight for i-th class.\n\n    References\n    ----------\n    The \"balanced\" heuristic is inspired by\n    Logistic Regression in Rare Events Data, King, Zen, 2001.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.utils.class_weight import compute_class_weight\n    >>> y = [1, 1, 1, 1, 0, 0]\n    >>> compute_class_weight(class_weight=\"balanced\", classes=np.unique(y), y=y)\n    array([1.5 , 0.75])",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> import numpy as np\n    >>> from sklearn.utils.class_weight import compute_class_weight\n    >>> y = [1, 1, 1, 1, 0, 0]\n    >>> compute_class_weight(class_weight=\"balanced\", classes=np.unique(y), y=y)\n    array([1.5 , 0.75])"
      }
    },
    {
      "name": "compute_sample_weight",
      "signature": "compute_sample_weight(class_weight, y, *, indices=None)",
      "documentation": {
        "description": "Estimate sample weights by class for unbalanced datasets.\n\n    Parameters\n    ----------\n    class_weight : dict, list of dicts, \"balanced\", or None\n        Weights associated with classes in the form `{class_label: weight}`.\n        If not given, all classes are supposed to have weight one. For\n        multi-output problems, a list of dicts can be provided in the same\n        order as the columns of y.\n\n        Note that for multioutput (including multilabel) weights should be\n        defined for each class of every column in its own dict. For example,\n        for four-class multilabel classification weights should be\n        `[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}]` instead of\n        `[{1:1}, {2:5}, {3:1}, {4:1}]`.\n\n        The `\"balanced\"` mode uses the values of y to automatically adjust\n        weights inversely proportional to class frequencies in the input data:\n        `n_samples / (n_classes * np.bincount(y))`.\n\n        For multi-output, the weights of each column of y will be multiplied.\n\n    y : {array-like, sparse matrix} of shape (n_samples,) or (n_samples, n_outputs)\n        Array of original class labels per sample.\n\n    indices : array-like of shape (n_subsample,), default=None\n        Array of indices to be used in a subsample. Can be of length less than\n        `n_samples` in the case of a subsample, or equal to `n_samples` in the\n        case of a bootstrap subsample with repeated indices. If `None`, the\n        sample weight will be calculated over the full sample. Only `\"balanced\"`\n        is supported for `class_weight` if this is provided.\n\n    Returns\n    -------\n    sample_weight_vect : ndarray of shape (n_samples,)\n        Array with sample weights as applied to the original `y`.",
        "parameters": {
          "class_weight": {
            "type": "dict, list of dicts, \"balanced\", or None",
            "description": ""
          },
          "Weights": {
            "type": "associated with classes in the form `{class_label: weight}`.",
            "description": ""
          },
          "If": {
            "type": "not given, all classes are supposed to have weight one. For",
            "description": "multi-output problems, a list of dicts can be provided in the same"
          },
          "order": {
            "type": "as the columns of y.",
            "description": ""
          },
          "Note": {
            "type": "that for multioutput (including multilabel) weights should be",
            "description": ""
          },
          "defined": {
            "type": "for each class of every column in its own dict. For example,",
            "description": ""
          },
          "for": {
            "type": "four-class multilabel classification weights should be",
            "description": "`[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}]` instead of\n`[{1:1}, {2:5}, {3:1}, {4:1}]`."
          },
          "The": {
            "type": "`\"balanced\"` mode uses the values of y to automatically adjust",
            "description": ""
          },
          "weights": {
            "type": "inversely proportional to class frequencies in the input data:",
            "description": "`n_samples / (n_classes * np.bincount(y))`."
          },
          "For": {
            "type": "multi-output, the weights of each column of y will be multiplied.",
            "description": ""
          },
          "y": {
            "type": "{array",
            "description": "like, sparse matrix} of shape (n_samples,) or (n_samples, n_outputs)"
          },
          "Array": {
            "type": "with sample weights as applied to the original `y`.",
            "description": "Examples\n--------\n>>> from sklearn.utils.class_weight import compute_sample_weight\n>>> y = [1, 1, 1, 1, 0, 0]\n>>> compute_sample_weight(class_weight=\"balanced\", y=y)"
          },
          "indices": {
            "type": "array",
            "description": "like of shape (n_subsample,), default=None"
          },
          "case": {
            "type": "of a bootstrap subsample with repeated indices. If `None`, the",
            "description": ""
          },
          "sample": {
            "type": "weight will be calculated over the full sample. Only `\"balanced\"`",
            "description": ""
          },
          "is": {
            "type": "supported for `class_weight` if this is provided.",
            "description": "Returns\n-------"
          },
          "sample_weight_vect": {
            "type": "ndarray of shape (n_samples,)",
            "description": ""
          },
          "array": {
            "type": "[0.75, 0.75, 0.75, 0.75, 1.5 , 1.5 ]",
            "description": ""
          }
        },
        "returns": "-------\n    sample_weight_vect : ndarray of shape (n_samples,)\n        Array with sample weights as applied to the original `y`.\n\n    Examples\n    --------\n    >>> from sklearn.utils.class_weight import compute_sample_weight\n    >>> y = [1, 1, 1, 1, 0, 0]\n    >>> compute_sample_weight(class_weight=\"balanced\", y=y)\n    array([0.75, 0.75, 0.75, 0.75, 1.5 , 1.5 ])",
        "raises": "",
        "see_also": "",
        "notes": "that for multioutput (including multilabel) weights should be\n        defined for each class of every column in its own dict. For example,\n        for four-class multilabel classification weights should be\n        `[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}]` instead of\n        `[{1:1}, {2:5}, {3:1}, {4:1}]`.\n\n        The `\"balanced\"` mode uses the values of y to automatically adjust\n        weights inversely proportional to class frequencies in the input data:\n        `n_samples / (n_classes * np.bincount(y))`.\n\n        For multi-output, the weights of each column of y will be multiplied.\n\n    y : {array-like, sparse matrix} of shape (n_samples,) or (n_samples, n_outputs)\n        Array of original class labels per sample.\n\n    indices : array-like of shape (n_subsample,), default=None\n        Array of indices to be used in a subsample. Can be of length less than\n        `n_samples` in the case of a subsample, or equal to `n_samples` in the\n        case of a bootstrap subsample with repeated indices. If `None`, the\n        sample weight will be calculated over the full sample. Only `\"balanced\"`\n        is supported for `class_weight` if this is provided.\n\n    Returns\n    -------\n    sample_weight_vect : ndarray of shape (n_samples,)\n        Array with sample weights as applied to the original `y`.\n\n    Examples\n    --------\n    >>> from sklearn.utils.class_weight import compute_sample_weight\n    >>> y = [1, 1, 1, 1, 0, 0]\n    >>> compute_sample_weight(class_weight=\"balanced\", y=y)\n    array([0.75, 0.75, 0.75, 0.75, 1.5 , 1.5 ])",
        "examples": "--------\n    >>> from sklearn.utils.class_weight import compute_sample_weight\n    >>> y = [1, 1, 1, 1, 0, 0]\n    >>> compute_sample_weight(class_weight=\"balanced\", y=y)\n    array([0.75, 0.75, 0.75, 0.75, 1.5 , 1.5 ])"
      }
    },
    {
      "name": "estimator_html_repr",
      "signature": "estimator_html_repr(estimator)",
      "documentation": {
        "description": "Build a HTML representation of an estimator.\n\n    Read more in the :ref:`User Guide <visualizing_composite_estimators>`.\n\n    Parameters\n    ----------\n    estimator : estimator object\n        The estimator to visualize.\n\n    Returns\n    -------\n    html: str\n        HTML representation of estimator.",
        "parameters": {
          "estimator": {
            "type": "estimator object",
            "description": ""
          },
          "The": {
            "type": "estimator to visualize.",
            "description": "Returns\n-------"
          },
          "html": {
            "type": "str",
            "description": ""
          },
          "HTML": {
            "type": "representation of estimator.",
            "description": "Examples\n--------\n>>> from sklearn.utils._estimator_html_repr import estimator_html_repr\n>>> from sklearn.linear_model import LogisticRegression\n>>> estimator_html_repr(LogisticRegression())\n'<style>...</div>'"
          }
        },
        "returns": "-------\n    html: str\n        HTML representation of estimator.\n\n    Examples\n    --------\n    >>> from sklearn.utils._estimator_html_repr import estimator_html_repr\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> estimator_html_repr(LogisticRegression())\n    '<style>...</div>'",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils._estimator_html_repr import estimator_html_repr\n    >>> from sklearn.linear_model import LogisticRegression\n    >>> estimator_html_repr(LogisticRegression())\n    '<style>...</div>'"
      }
    },
    {
      "name": "gen_batches",
      "signature": "gen_batches(n, batch_size, *, min_batch_size=0)",
      "documentation": {
        "description": "Generator to create slices containing `batch_size` elements from 0 to `n`.\n\n    The last slice may contain less than `batch_size` elements, when\n    `batch_size` does not divide `n`.\n\n    Parameters\n    ----------\n    n : int\n        Size of the sequence.\n    batch_size : int\n        Number of elements in each batch.\n    min_batch_size : int, default=0\n        Minimum number of elements in each batch.\n\n    Yields\n    ------\n    slice of `batch_size` elements\n\n    See Also\n    --------\n    gen_even_slices: Generator to create n_packs slices going up to n.",
        "parameters": {
          "n": {
            "type": "int",
            "description": ""
          },
          "Size": {
            "type": "of the sequence.",
            "description": ""
          },
          "batch_size": {
            "type": "int",
            "description": ""
          },
          "Number": {
            "type": "of elements in each batch.",
            "description": ""
          },
          "min_batch_size": {
            "type": "int, default=0",
            "description": ""
          },
          "Minimum": {
            "type": "number of elements in each batch.",
            "description": "Yields\n------"
          },
          "slice": {
            "type": "of `batch_size` elements",
            "description": ""
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "gen_even_slices": {
            "type": "Generator to create n_packs slices going up to n.",
            "description": "Examples\n--------\n>>> from sklearn.utils import gen_batches\n>>> list(gen_batches(7, 3))\n[slice(0, 3, None), slice(3, 6, None), slice(6, 7, None)]\n>>> list(gen_batches(6, 3))\n[slice(0, 3, None), slice(3, 6, None)]\n>>> list(gen_batches(2, 3))\n[slice(0, 2, None)]\n>>> list(gen_batches(7, 3, min_batch_size=0))\n[slice(0, 3, None), slice(3, 6, None), slice(6, 7, None)]\n>>> list(gen_batches(7, 3, min_batch_size=2))\n[slice(0, 3, None), slice(3, 7, None)]"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    gen_even_slices: Generator to create n_packs slices going up to n.\n\n    Examples\n    --------\n    >>> from sklearn.utils import gen_batches\n    >>> list(gen_batches(7, 3))\n    [slice(0, 3, None), slice(3, 6, None), slice(6, 7, None)]\n    >>> list(gen_batches(6, 3))\n    [slice(0, 3, None), slice(3, 6, None)]\n    >>> list(gen_batches(2, 3))\n    [slice(0, 2, None)]\n    >>> list(gen_batches(7, 3, min_batch_size=0))\n    [slice(0, 3, None), slice(3, 6, None), slice(6, 7, None)]\n    >>> list(gen_batches(7, 3, min_batch_size=2))\n    [slice(0, 3, None), slice(3, 7, None)]",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils import gen_batches\n    >>> list(gen_batches(7, 3))\n    [slice(0, 3, None), slice(3, 6, None), slice(6, 7, None)]\n    >>> list(gen_batches(6, 3))\n    [slice(0, 3, None), slice(3, 6, None)]\n    >>> list(gen_batches(2, 3))\n    [slice(0, 2, None)]\n    >>> list(gen_batches(7, 3, min_batch_size=0))\n    [slice(0, 3, None), slice(3, 6, None), slice(6, 7, None)]\n    >>> list(gen_batches(7, 3, min_batch_size=2))\n    [slice(0, 3, None), slice(3, 7, None)]"
      }
    },
    {
      "name": "gen_even_slices",
      "signature": "gen_even_slices(n, n_packs, *, n_samples=None)",
      "documentation": {
        "description": "Generator to create `n_packs` evenly spaced slices going up to `n`.\n\n    If `n_packs` does not divide `n`, except for the first `n % n_packs`\n    slices, remaining slices may contain fewer elements.\n\n    Parameters\n    ----------\n    n : int\n        Size of the sequence.\n    n_packs : int\n        Number of slices to generate.\n    n_samples : int, default=None\n        Number of samples. Pass `n_samples` when the slices are to be used for\n        sparse matrix indexing; slicing off-the-end raises an exception, while\n        it works for NumPy arrays.\n\n    Yields\n    ------\n    `slice` representing a set of indices from 0 to n.\n\n    See Also\n    --------\n    gen_batches: Generator to create slices containing batch_size elements\n        from 0 to n.",
        "parameters": {
          "n": {
            "type": "int",
            "description": ""
          },
          "Size": {
            "type": "of the sequence.",
            "description": ""
          },
          "n_packs": {
            "type": "int",
            "description": ""
          },
          "Number": {
            "type": "of samples. Pass `n_samples` when the slices are to be used for",
            "description": ""
          },
          "n_samples": {
            "type": "int, default=None",
            "description": ""
          },
          "sparse": {
            "type": "matrix indexing; slicing off-the-end raises an exception, while",
            "description": ""
          },
          "it": {
            "type": "works for NumPy arrays.",
            "description": "Yields\n------\n`slice` representing a set of indices from 0 to n."
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "gen_batches": {
            "type": "Generator to create slices containing batch_size elements",
            "description": ""
          },
          "from": {
            "type": "0 to n.",
            "description": "Examples\n--------\n>>> from sklearn.utils import gen_even_slices\n>>> list(gen_even_slices(10, 1))\n[slice(0, 10, None)]\n>>> list(gen_even_slices(10, 10))\n[slice(0, 1, None), slice(1, 2, None), ..., slice(9, 10, None)]\n>>> list(gen_even_slices(10, 5))\n[slice(0, 2, None), slice(2, 4, None), ..., slice(8, 10, None)]\n>>> list(gen_even_slices(10, 3))\n[slice(0, 4, None), slice(4, 7, None), slice(7, 10, None)]"
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "--------\n    gen_batches: Generator to create slices containing batch_size elements\n        from 0 to n.\n\n    Examples\n    --------\n    >>> from sklearn.utils import gen_even_slices\n    >>> list(gen_even_slices(10, 1))\n    [slice(0, 10, None)]\n    >>> list(gen_even_slices(10, 10))\n    [slice(0, 1, None), slice(1, 2, None), ..., slice(9, 10, None)]\n    >>> list(gen_even_slices(10, 5))\n    [slice(0, 2, None), slice(2, 4, None), ..., slice(8, 10, None)]\n    >>> list(gen_even_slices(10, 3))\n    [slice(0, 4, None), slice(4, 7, None), slice(7, 10, None)]",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils import gen_even_slices\n    >>> list(gen_even_slices(10, 1))\n    [slice(0, 10, None)]\n    >>> list(gen_even_slices(10, 10))\n    [slice(0, 1, None), slice(1, 2, None), ..., slice(9, 10, None)]\n    >>> list(gen_even_slices(10, 5))\n    [slice(0, 2, None), slice(2, 4, None), ..., slice(8, 10, None)]\n    >>> list(gen_even_slices(10, 3))\n    [slice(0, 4, None), slice(4, 7, None), slice(7, 10, None)]"
      }
    },
    {
      "name": "get_tags",
      "signature": "get_tags(estimator) -> 'Tags'",
      "documentation": {
        "description": "Get estimator tags.\n\n    :class:`~sklearn.BaseEstimator` provides the estimator tags machinery.\n    However, if an estimator does not inherit from this base class, we should\n    fall-back to the default tags.\n\n    For scikit-learn built-in estimators, we should still rely on\n    `self.__sklearn_tags__()`. `get_tags(est)` should be used when we\n    are not sure where `est` comes from: typically\n    `get_tags(self.estimator)` where `self` is a meta-estimator, or in\n    the common checks.\n\n    .. versionadded:: 1.6\n\n    Parameters\n    ----------\n    estimator : estimator object\n        The estimator from which to get the tag.",
        "parameters": {
          "estimator": {
            "type": "estimator object",
            "description": ""
          },
          "The": {
            "type": "estimator tags.",
            "description": ""
          },
          "tags": {
            "type": ":class:`~.sklearn.utils.Tags`",
            "description": ""
          }
        },
        "returns": "-------\n    tags : :class:`~.sklearn.utils.Tags`\n        The estimator tags.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "indexable",
      "signature": "indexable(*iterables)",
      "documentation": {
        "description": "Make arrays indexable for cross-validation.\n\n    Checks consistent length, passes through None, and ensures that everything\n    can be indexed by converting sparse matrices to csr and converting\n    non-iterable objects to arrays.\n\n    Parameters\n    ----------\n    *iterables : {lists, dataframes, ndarrays, sparse matrices}\n        List of objects to ensure sliceability.\n\n    Returns\n    -------\n    result : list of {ndarray, sparse matrix, dataframe} or None\n        Returns a list containing indexable arrays (i.e. NumPy array,\n        sparse matrix, or dataframe) or `None`.",
        "parameters": {
          "List": {
            "type": "of objects to ensure sliceability.",
            "description": "Returns\n-------"
          },
          "result": {
            "type": "list of {ndarray, sparse matrix, dataframe} or None",
            "description": ""
          },
          "Returns": {
            "type": "a list containing indexable arrays (i.e. NumPy array,",
            "description": ""
          },
          "sparse": {
            "type": "matrix, or dataframe) or `None`.",
            "description": "Examples\n--------\n>>> from sklearn.utils import indexable\n>>> from scipy.sparse import csr_matrix\n>>> import numpy as np\n>>> iterables = [\n...     [1, 2, 3], np.array([2, 3, 4]), None, csr_matrix([[5], [6], [7]])\n... ]\n>>> indexable(*iterables)\n[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]"
          }
        },
        "returns": "-------\n    result : list of {ndarray, sparse matrix, dataframe} or None",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils import indexable\n    >>> from scipy.sparse import csr_matrix\n    >>> import numpy as np\n    >>> iterables = [\n    ...     [1, 2, 3], np.array([2, 3, 4]), None, csr_matrix([[5], [6], [7]])\n    ... ]\n    >>> indexable(*iterables)\n    [[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]"
      }
    },
    {
      "name": "murmurhash3_32",
      "signature": "murmurhash3_32(key, seed=0, positive=False)",
      "documentation": {
        "description": "Compute the 32bit murmurhash3 of key at seed.\n\n    The underlying implementation is MurmurHash3_x86_32 generating low\n    latency 32bits hash suitable for implementing lookup tables, Bloom\n    filters, count min sketch or feature hashing.\n\n    Parameters\n    ----------\n    key : np.int32, bytes, unicode or ndarray of dtype=np.int32\n        The physical object to hash.\n\n    seed : int, default=0\n        Integer seed for the hashing algorithm.\n\n    positive : bool, default=False\n        True: the results is casted to an unsigned int\n          from 0 to 2 ** 32 - 1\n        False: the results is casted to a signed int\n          from -(2 ** 31) to 2 ** 31 - 1",
        "parameters": {
          "key": {
            "type": "np.int32, bytes, unicode or ndarray of dtype=np.int32",
            "description": ""
          },
          "The": {
            "type": "physical object to hash.",
            "description": ""
          },
          "seed": {
            "type": "int, default=0",
            "description": ""
          },
          "Integer": {
            "type": "seed for the hashing algorithm.",
            "description": ""
          },
          "positive": {
            "type": "bool, default=False",
            "description": ""
          },
          "True": {
            "type": "the results is casted to an unsigned int",
            "description": ""
          },
          "from": {
            "type": "-(2 ** 31) to 2 ** 31 - 1",
            "description": "Examples\n--------\n>>> from sklearn.utils import murmurhash3_32\n>>> murmurhash3_32(b\"Hello World!\", seed=42)\n3565178"
          },
          "False": {
            "type": "the results is casted to a signed int",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils import murmurhash3_32\n    >>> murmurhash3_32(b\"Hello World!\", seed=42)\n    3565178"
      }
    },
    {
      "name": "register_parallel_backend",
      "signature": "register_parallel_backend(name, factory, make_default=False)",
      "documentation": {
        "description": "Register a new Parallel backend factory.\n\n    The new backend can then be selected by passing its name as the backend\n    argument to the :class:`~Parallel` class. Moreover, the default backend can\n    be overwritten globally by setting make_default=True.\n\n    The factory can be any callable that takes no argument and return an\n    instance of ``ParallelBackendBase``.\n\n    Warning: this function is experimental and subject to change in a future\n    version of joblib.\n\n    .. versionadded:: 0.10",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    },
    {
      "name": "resample",
      "signature": "resample(*arrays, replace=True, n_samples=None, random_state=None, stratify=None)",
      "documentation": {
        "description": "Resample arrays or sparse matrices in a consistent way.\n\n    The default strategy implements one step of the bootstrapping\n    procedure.\n\n    Parameters\n    ----------\n    *arrays : sequence of array-like of shape (n_samples,) or             (n_samples, n_outputs)\n        Indexable data-structures can be arrays, lists, dataframes or scipy\n        sparse matrices with consistent first dimension.\n\n    replace : bool, default=True\n        Implements resampling with replacement. If False, this will implement\n        (sliced) random permutations.\n\n    n_samples : int, default=None\n        Number of samples to generate. If left to None this is\n        automatically set to the first dimension of the arrays.\n        If replace is False it should not be larger than the length of\n        arrays.\n\n    random_state : int, RandomState instance or None, default=None\n        Determines random number generation for shuffling\n        the data.\n        Pass an int for reproducible results across multiple function calls.\n        See :term:`Glossary <random_state>`.\n\n    stratify : {array-like, sparse matrix} of shape (n_samples,) or             (n_samples, n_outputs), default=None\n        If not None, data is split in a stratified fashion, using this as\n        the class labels.\n\n    Returns\n    -------\n    resampled_arrays : sequence of array-like of shape (n_samples,) or             (n_samples, n_outputs)\n        Sequence of resampled copies of the collections. The original arrays\n        are not impacted.\n\n    See Also\n    --------\n    shuffle : Shuffle arrays or sparse matrices in a consistent way.\n\n    Examples\n    --------\n    It is possible to mix sparse and dense arrays in the same run::\n\n      >>> import numpy as np\n      >>> X = np.array([[1., 0.], [2., 1.], [0., 0.]])\n      >>> y = np.array([0, 1, 2])\n\n      >>> from scipy.sparse import coo_matrix\n      >>> X_sparse = coo_matrix(X)\n\n      >>> from sklearn.utils import resample\n      >>> X, X_sparse, y = resample(X, X_sparse, y, random_state=0)\n      >>> X\n      array([[1., 0.],\n             [2., 1.],\n             [1., 0.]])\n\n      >>> X_sparse\n      <Compressed Sparse Row sparse matrix of dtype 'float64'\n          with 4 stored elements and shape (3, 2)>\n\n      >>> X_sparse.toarray()\n      array([[1., 0.],\n             [2., 1.],\n             [1., 0.]])\n\n      >>> y\n      array([0, 1, 0])\n\n      >>> resample(y, n_samples=2, random_state=0)\n      array([0, 1])",
        "parameters": {
          "Indexable": {
            "type": "data-structures can be arrays, lists, dataframes or scipy",
            "description": ""
          },
          "sparse": {
            "type": "matrices with consistent first dimension.",
            "description": ""
          },
          "replace": {
            "type": "bool, default=True",
            "description": ""
          },
          "Implements": {
            "type": "resampling with replacement. If False, this will implement",
            "description": "(sliced) random permutations."
          },
          "n_samples": {
            "type": "int, default=None",
            "description": ""
          },
          "Number": {
            "type": "of samples to generate. If left to None this is",
            "description": ""
          },
          "automatically": {
            "type": "set to the first dimension of the arrays.",
            "description": ""
          },
          "If": {
            "type": "not None, data is split in a stratified fashion, using this as",
            "description": ""
          },
          "random_state": {
            "type": "int, RandomState instance or None, default=None",
            "description": ""
          },
          "Determines": {
            "type": "random number generation for shuffling",
            "description": ""
          },
          "the": {
            "type": "class labels.",
            "description": "Returns\n-------"
          },
          "Pass": {
            "type": "an int for reproducible results across multiple function calls.",
            "description": ""
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "stratify": {
            "type": "{array",
            "description": "like, sparse matrix} of shape (n_samples,) or             (n_samples, n_outputs), default=None"
          },
          "resampled_arrays": {
            "type": "sequence of array",
            "description": "like of shape (n_samples,) or             (n_samples, n_outputs)"
          },
          "Sequence": {
            "type": "of resampled copies of the collections. The original arrays",
            "description": ""
          },
          "are": {
            "type": "not impacted.",
            "description": ""
          },
          "shuffle": {
            "type": "Shuffle arrays or sparse matrices in a consistent way.",
            "description": "Examples\n--------"
          },
          "It": {
            "type": "is possible to mix sparse and dense arrays in the same run::",
            "description": ">>> import numpy as np\n>>> X = np.array([[1., 0.], [2., 1.], [0., 0.]])\n>>> y = np.array([0, 1, 2])\n>>> from scipy.sparse import coo_matrix\n>>> X_sparse = coo_matrix(X)\n>>> from sklearn.utils import resample\n>>> X, X_sparse, y = resample(X, X_sparse, y, random_state=0)\n>>> X\narray([[1., 0.],\n[2., 1.],\n[1., 0.]])\n>>> X_sparse\n<Compressed Sparse Row sparse matrix of dtype 'float64'"
          },
          "with": {
            "type": "4 stored elements and shape (3, 2)>",
            "description": ">>> X_sparse.toarray()\narray([[1., 0.],\n[2., 1.],\n[1., 0.]])\n>>> y"
          },
          "array": {
            "type": "[0, 1]",
            "description": ""
          },
          "Example": {
            "type": "using stratification::",
            "description": ">>> y = [0, 0, 1, 1, 1, 1, 1, 1, 1]\n>>> resample(y, n_samples=5, replace=False, stratify=y,\n...          random_state=0)\n[1, 1, 1, 0, 1]"
          }
        },
        "returns": "-------\n    resampled_arrays : sequence of array-like of shape (n_samples,) or             (n_samples, n_outputs)\n        Sequence of resampled copies of the collections. The original arrays\n        are not impacted.\n\n    See Also\n    --------\n    shuffle : Shuffle arrays or sparse matrices in a consistent way.\n\n    Examples\n    --------\n    It is possible to mix sparse and dense arrays in the same run::\n\n      >>> import numpy as np\n      >>> X = np.array([[1., 0.], [2., 1.], [0., 0.]])\n      >>> y = np.array([0, 1, 2])\n\n      >>> from scipy.sparse import coo_matrix\n      >>> X_sparse = coo_matrix(X)\n\n      >>> from sklearn.utils import resample\n      >>> X, X_sparse, y = resample(X, X_sparse, y, random_state=0)\n      >>> X\n      array([[1., 0.],\n             [2., 1.],\n             [1., 0.]])\n\n      >>> X_sparse\n      <Compressed Sparse Row sparse matrix of dtype 'float64'\n          with 4 stored elements and shape (3, 2)>\n\n      >>> X_sparse.toarray()\n      array([[1., 0.],\n             [2., 1.],\n             [1., 0.]])\n\n      >>> y\n      array([0, 1, 0])\n\n      >>> resample(y, n_samples=2, random_state=0)\n      array([0, 1])\n\n    Example using stratification::\n\n      >>> y = [0, 0, 1, 1, 1, 1, 1, 1, 1]\n      >>> resample(y, n_samples=5, replace=False, stratify=y,\n      ...          random_state=0)\n      [1, 1, 1, 0, 1]",
        "raises": "",
        "see_also": "--------\n    shuffle : Shuffle arrays or sparse matrices in a consistent way.\n\n    Examples\n    --------\n    It is possible to mix sparse and dense arrays in the same run::\n\n      >>> import numpy as np\n      >>> X = np.array([[1., 0.], [2., 1.], [0., 0.]])\n      >>> y = np.array([0, 1, 2])\n\n      >>> from scipy.sparse import coo_matrix\n      >>> X_sparse = coo_matrix(X)\n\n      >>> from sklearn.utils import resample\n      >>> X, X_sparse, y = resample(X, X_sparse, y, random_state=0)\n      >>> X\n      array([[1., 0.],\n             [2., 1.],\n             [1., 0.]])\n\n      >>> X_sparse\n      <Compressed Sparse Row sparse matrix of dtype 'float64'\n          with 4 stored elements and shape (3, 2)>\n\n      >>> X_sparse.toarray()\n      array([[1., 0.],\n             [2., 1.],\n             [1., 0.]])\n\n      >>> y\n      array([0, 1, 0])\n\n      >>> resample(y, n_samples=2, random_state=0)\n      array([0, 1])\n\n    Example using stratification::\n\n      >>> y = [0, 0, 1, 1, 1, 1, 1, 1, 1]\n      >>> resample(y, n_samples=5, replace=False, stratify=y,\n      ...          random_state=0)\n      [1, 1, 1, 0, 1]",
        "notes": "",
        "examples": "using stratification::\n\n      >>> y = [0, 0, 1, 1, 1, 1, 1, 1, 1]\n      >>> resample(y, n_samples=5, replace=False, stratify=y,\n      ...          random_state=0)\n      [1, 1, 1, 0, 1]"
      }
    },
    {
      "name": "safe_mask",
      "signature": "safe_mask(X, mask)",
      "documentation": {
        "description": "Return a mask which is safe to use on X.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix}\n        Data on which to apply mask.\n\n    mask : array-like\n        Mask to be used on X.\n\n    Returns\n    -------\n    mask : ndarray\n        Array that is safe to use on X.",
        "parameters": {
          "X": {
            "type": "{array",
            "description": "like, sparse matrix}"
          },
          "Data": {
            "type": "on which to apply mask.",
            "description": ""
          },
          "mask": {
            "type": "ndarray",
            "description": ""
          },
          "Mask": {
            "type": "to be used on X.",
            "description": "Returns\n-------"
          },
          "Array": {
            "type": "that is safe to use on X.",
            "description": "Examples\n--------\n>>> from sklearn.utils import safe_mask\n>>> from scipy.sparse import csr_matrix\n>>> data = csr_matrix([[1], [2], [3], [4], [5]])\n>>> condition = [False, True, True, False, True]\n>>> mask = safe_mask(data, condition)\n>>> data[mask].toarray()\narray([[2],\n[3],\n[5]])"
          }
        },
        "returns": "-------\n    mask : ndarray\n        Array that is safe to use on X.\n\n    Examples\n    --------\n    >>> from sklearn.utils import safe_mask\n    >>> from scipy.sparse import csr_matrix\n    >>> data = csr_matrix([[1], [2], [3], [4], [5]])\n    >>> condition = [False, True, True, False, True]\n    >>> mask = safe_mask(data, condition)\n    >>> data[mask].toarray()\n    array([[2],\n           [3],\n           [5]])",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils import safe_mask\n    >>> from scipy.sparse import csr_matrix\n    >>> data = csr_matrix([[1], [2], [3], [4], [5]])\n    >>> condition = [False, True, True, False, True]\n    >>> mask = safe_mask(data, condition)\n    >>> data[mask].toarray()\n    array([[2],\n           [3],\n           [5]])"
      }
    },
    {
      "name": "safe_sqr",
      "signature": "safe_sqr(X, *, copy=True)",
      "documentation": {
        "description": "Element wise squaring of array-likes and sparse matrices.\n\n    Parameters\n    ----------\n    X : {array-like, ndarray, sparse matrix}\n\n    copy : bool, default=True\n        Whether to create a copy of X and operate on it or to perform\n        inplace computation (default behaviour).\n\n    Returns\n    -------\n    X ** 2 : element wise square\n         Return the element-wise square of the input.",
        "parameters": {
          "X": {
            "type": "** 2 : element wise square",
            "description": ""
          },
          "copy": {
            "type": "bool, default=True",
            "description": ""
          },
          "Whether": {
            "type": "to create a copy of X and operate on it or to perform",
            "description": ""
          },
          "inplace": {
            "type": "computation (default behaviour).",
            "description": "Returns\n-------"
          },
          "Return": {
            "type": "the element-wise square of the input.",
            "description": "Examples\n--------\n>>> from sklearn.utils import safe_sqr\n>>> safe_sqr([1, 2, 3])"
          },
          "array": {
            "type": "[1, 4, 9]",
            "description": ""
          }
        },
        "returns": "the element-wise square of the input.\n\n    Examples\n    --------\n    >>> from sklearn.utils import safe_sqr\n    >>> safe_sqr([1, 2, 3])\n    array([1, 4, 9])",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils import safe_sqr\n    >>> safe_sqr([1, 2, 3])\n    array([1, 4, 9])"
      }
    },
    {
      "name": "shuffle",
      "signature": "shuffle(*arrays, random_state=None, n_samples=None)",
      "documentation": {
        "description": "Shuffle arrays or sparse matrices in a consistent way.\n\n    This is a convenience alias to ``resample(*arrays, replace=False)`` to do\n    random permutations of the collections.\n\n    Parameters\n    ----------\n    *arrays : sequence of indexable data-structures\n        Indexable data-structures can be arrays, lists, dataframes or scipy\n        sparse matrices with consistent first dimension.\n\n    random_state : int, RandomState instance or None, default=None\n        Determines random number generation for shuffling\n        the data.\n        Pass an int for reproducible results across multiple function calls.\n        See :term:`Glossary <random_state>`.\n\n    n_samples : int, default=None\n        Number of samples to generate. If left to None this is\n        automatically set to the first dimension of the arrays.  It should\n        not be larger than the length of arrays.\n\n    Returns\n    -------\n    shuffled_arrays : sequence of indexable data-structures\n        Sequence of shuffled copies of the collections. The original arrays\n        are not impacted.\n\n    See Also\n    --------\n    resample : Resample arrays or sparse matrices in a consistent way.",
        "parameters": {
          "Indexable": {
            "type": "data-structures can be arrays, lists, dataframes or scipy",
            "description": ""
          },
          "sparse": {
            "type": "matrices with consistent first dimension.",
            "description": ""
          },
          "random_state": {
            "type": "int, RandomState instance or None, default=None",
            "description": ""
          },
          "Determines": {
            "type": "random number generation for shuffling",
            "description": ""
          },
          "the": {
            "type": "data.",
            "description": ""
          },
          "Pass": {
            "type": "an int for reproducible results across multiple function calls.",
            "description": ""
          },
          "See": {
            "type": "Also",
            "description": "--------"
          },
          "n_samples": {
            "type": "int, default=None",
            "description": ""
          },
          "Number": {
            "type": "of samples to generate. If left to None this is",
            "description": ""
          },
          "automatically": {
            "type": "set to the first dimension of the arrays.  It should",
            "description": ""
          },
          "not": {
            "type": "be larger than the length of arrays.",
            "description": "Returns\n-------"
          },
          "shuffled_arrays": {
            "type": "sequence of indexable data",
            "description": "structures"
          },
          "Sequence": {
            "type": "of shuffled copies of the collections. The original arrays",
            "description": ""
          },
          "are": {
            "type": "not impacted.",
            "description": ""
          },
          "resample": {
            "type": "Resample arrays or sparse matrices in a consistent way.",
            "description": "Examples\n--------"
          },
          "It": {
            "type": "is possible to mix sparse and dense arrays in the same run::",
            "description": ">>> import numpy as np\n>>> X = np.array([[1., 0.], [2., 1.], [0., 0.]])\n>>> y = np.array([0, 1, 2])\n>>> from scipy.sparse import coo_matrix\n>>> X_sparse = coo_matrix(X)\n>>> from sklearn.utils import shuffle\n>>> X, X_sparse, y = shuffle(X, X_sparse, y, random_state=0)\n>>> X\narray([[0., 0.],\n[2., 1.],\n[1., 0.]])\n>>> X_sparse\n<Compressed Sparse Row sparse matrix of dtype 'float64'"
          },
          "with": {
            "type": "3 stored elements and shape (3, 2)>",
            "description": ">>> X_sparse.toarray()\narray([[0., 0.],\n[2., 1.],\n[1., 0.]])\n>>> y"
          },
          "array": {
            "type": "[0, 1]",
            "description": ""
          }
        },
        "returns": "-------\n    shuffled_arrays : sequence of indexable data-structures\n        Sequence of shuffled copies of the collections. The original arrays\n        are not impacted.\n\n    See Also\n    --------\n    resample : Resample arrays or sparse matrices in a consistent way.\n\n    Examples\n    --------\n    It is possible to mix sparse and dense arrays in the same run::\n\n      >>> import numpy as np\n      >>> X = np.array([[1., 0.], [2., 1.], [0., 0.]])\n      >>> y = np.array([0, 1, 2])\n\n      >>> from scipy.sparse import coo_matrix\n      >>> X_sparse = coo_matrix(X)\n\n      >>> from sklearn.utils import shuffle\n      >>> X, X_sparse, y = shuffle(X, X_sparse, y, random_state=0)\n      >>> X\n      array([[0., 0.],\n             [2., 1.],\n             [1., 0.]])\n\n      >>> X_sparse\n      <Compressed Sparse Row sparse matrix of dtype 'float64'\n          with 3 stored elements and shape (3, 2)>\n\n      >>> X_sparse.toarray()\n      array([[0., 0.],\n             [2., 1.],\n             [1., 0.]])\n\n      >>> y\n      array([2, 1, 0])\n\n      >>> shuffle(y, n_samples=2, random_state=0)\n      array([0, 1])",
        "raises": "",
        "see_also": "--------\n    resample : Resample arrays or sparse matrices in a consistent way.\n\n    Examples\n    --------\n    It is possible to mix sparse and dense arrays in the same run::\n\n      >>> import numpy as np\n      >>> X = np.array([[1., 0.], [2., 1.], [0., 0.]])\n      >>> y = np.array([0, 1, 2])\n\n      >>> from scipy.sparse import coo_matrix\n      >>> X_sparse = coo_matrix(X)\n\n      >>> from sklearn.utils import shuffle\n      >>> X, X_sparse, y = shuffle(X, X_sparse, y, random_state=0)\n      >>> X\n      array([[0., 0.],\n             [2., 1.],\n             [1., 0.]])\n\n      >>> X_sparse\n      <Compressed Sparse Row sparse matrix of dtype 'float64'\n          with 3 stored elements and shape (3, 2)>\n\n      >>> X_sparse.toarray()\n      array([[0., 0.],\n             [2., 1.],\n             [1., 0.]])\n\n      >>> y\n      array([2, 1, 0])\n\n      >>> shuffle(y, n_samples=2, random_state=0)\n      array([0, 1])",
        "notes": "",
        "examples": "--------\n    It is possible to mix sparse and dense arrays in the same run::\n\n      >>> import numpy as np\n      >>> X = np.array([[1., 0.], [2., 1.], [0., 0.]])\n      >>> y = np.array([0, 1, 2])\n\n      >>> from scipy.sparse import coo_matrix\n      >>> X_sparse = coo_matrix(X)\n\n      >>> from sklearn.utils import shuffle\n      >>> X, X_sparse, y = shuffle(X, X_sparse, y, random_state=0)\n      >>> X\n      array([[0., 0.],\n             [2., 1.],\n             [1., 0.]])\n\n      >>> X_sparse\n      <Compressed Sparse Row sparse matrix of dtype 'float64'\n          with 3 stored elements and shape (3, 2)>\n\n      >>> X_sparse.toarray()\n      array([[0., 0.],\n             [2., 1.],\n             [1., 0.]])\n\n      >>> y\n      array([2, 1, 0])\n\n      >>> shuffle(y, n_samples=2, random_state=0)\n      array([0, 1])"
      }
    },
    {
      "name": "tosequence",
      "signature": "tosequence(x)",
      "documentation": {
        "description": "Cast iterable x to a Sequence, avoiding a copy if possible.\n\n    Parameters\n    ----------\n    x : iterable\n        The iterable to be converted.",
        "parameters": {
          "x": {
            "type": "Sequence",
            "description": ""
          },
          "The": {
            "type": "iterable to be converted.",
            "description": "Returns\n-------"
          },
          "If": {
            "type": "`x` is a NumPy array, it returns it as a `ndarray`. If `x`",
            "description": ""
          },
          "is": {
            "type": "a `Sequence`, `x` is returned as-is. If `x` is from any other",
            "description": "type, `x` is returned casted as a list."
          }
        },
        "returns": "-------\n    x : Sequence\n        If `x` is a NumPy array, it returns it as a `ndarray`. If `x`\n        is a `Sequence`, `x` is returned as-is. If `x` is from any other\n        type, `x` is returned casted as a list.",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      }
    }
  ],
  "classes": [
    {
      "name": "Bunch",
      "documentation": {
        "description": "Container object exposing keys as attributes.\n\n    Bunch objects are sometimes used as an output for functions and methods.\n    They extend dictionaries by enabling values to be accessed by key,\n    `bunch[\"value_key\"]`, or by an attribute, `bunch.value_key`.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils import Bunch\n    >>> b = Bunch(a=1, b=2)\n    >>> b['b']\n    2\n    >>> b.b\n    2\n    >>> b.a = 3\n    >>> b['a']\n    3\n    >>> b.c = 6\n    >>> b['c']\n    6"
      },
      "methods": [
        {
          "name": "clear",
          "signature": "clear()",
          "documentation": {
            "description": "D.clear() -> None.  Remove all items from D.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "copy",
          "signature": "copy()",
          "documentation": {
            "description": "D.copy() -> a shallow copy of D",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "fromkeys",
          "signature": "fromkeys(iterable, value=None, /)",
          "documentation": {
            "description": "Create a new dictionary with keys from iterable and values set to value.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "get",
          "signature": "get(self, key, default=None, /)",
          "documentation": {
            "description": "Return the value for key if key is in the dictionary, else default.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "items",
          "signature": "items()",
          "documentation": {
            "description": "D.items() -> a set-like object providing a view on D's items",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "keys",
          "signature": "keys()",
          "documentation": {
            "description": "D.keys() -> a set-like object providing a view on D's keys",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "pop",
          "signature": "pop(k[,d])",
          "documentation": {
            "description": "D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\n\nIf the key is not found, return the default if given; otherwise,\nraise a KeyError.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "popitem",
          "signature": "popitem(self, /)",
          "documentation": {
            "description": "Remove and return a (key, value) pair as a 2-tuple.\n\nPairs are returned in LIFO (last-in, first-out) order.",
            "parameters": {},
            "returns": "",
            "raises": "KeyError if the dict is empty.",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "setdefault",
          "signature": "setdefault(self, key, default=None, /)",
          "documentation": {
            "description": "Insert key with a value of default if key is not in the dictionary.",
            "parameters": {},
            "returns": "the value for key if key is in the dictionary, else default.",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "update",
          "signature": "update([E, ]**F)",
          "documentation": {
            "description": "D.update([E, ]**F) -> None.  Update D from dict/iterable E and F.\nIf E is present and has a .keys() method, then does:  for k in E: D[k] = E[k]\nIf E is present and lacks a .keys() method, then does:  for k, v in E: D[k] = v\nIn either case, this is followed by: for k in F:  D[k] = F[k]",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "values",
          "signature": "values()",
          "documentation": {
            "description": "D.values() -> an object providing a view on D's values",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "ClassifierTags",
      "documentation": {
        "description": "Tags for the classifier.",
        "parameters": {
          "poor_score": {
            "type": "bool, default=False",
            "description": ""
          },
          "Whether": {
            "type": "the classifier supports multi-label output: a data point can",
            "description": ""
          },
          "datasets": {
            "type": "and values are based on current estimators in scikit-learn",
            "description": ""
          },
          "and": {
            "type": "might be replaced by something more systematic.",
            "description": ""
          },
          "multi_class": {
            "type": "bool, default=True",
            "description": ""
          },
          "classifier": {
            "type": "is a binary-classifier-only or not.",
            "description": ""
          },
          "See": {
            "type": "term:`multi",
            "description": "label` in the glossary."
          },
          "multi_label": {
            "type": "bool, default=False",
            "description": ""
          },
          "be": {
            "type": "predicted to belong to a variable number of classes.",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": []
    },
    {
      "name": "DataConversionWarning",
      "documentation": {
        "description": "Warning used to notify implicit data conversions happening in the code.\n\n    This warning occurs when some input data needs to be converted or\n    interpreted in a way that may not match the user's expectations.\n\n    For example, this warning may occur when the user\n        - passes an integer array to a function which expects float input and\n          will convert the input\n        - requests a non-copying operation, but a copy is required to meet the\n          implementation's data-type expectations;\n        - passes an input whose shape can be interpreted ambiguously.\n\n    .. versionchanged:: 0.18\n       Moved from sklearn.utils.validation.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "add_note",
          "signature": "add_note(note)",
          "documentation": {
            "description": "Exception.add_note(note) --\n    add a note to the exception",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "with_traceback",
          "signature": "with_traceback(tb)",
          "documentation": {
            "description": "Exception.with_traceback(tb) --\n    set self.__traceback__ to tb and return self.",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "InputTags",
      "documentation": {
        "description": "Tags for the input data.\n\n    Parameters\n    ----------\n    one_d_array : bool, default=False\n        Whether the input can be a 1D array.\n\n    two_d_array : bool, default=True\n        Whether the input can be a 2D array. Note that most common\n        tests currently run only if this flag is set to ``True``.\n\n    three_d_array : bool, default=False\n        Whether the input can be a 3D array.\n\n    sparse : bool, default=False\n        Whether the input can be a sparse matrix.\n\n    categorical : bool, default=False\n        Whether the input can be categorical.\n\n    string : bool, default=False\n        Whether the input can be an array-like of strings.\n\n    dict : bool, default=False\n        Whether the input can be a dictionary.\n\n    positive_only : bool, default=False\n        Whether the estimator requires positive X.\n\n    allow_nan : bool, default=False\n        Whether the estimator supports data with missing values encoded as `np.nan`.\n\n    pairwise : bool, default=False\n        This boolean attribute indicates whether the data (`X`),\n        :term:`fit` and similar methods consists of pairwise measures\n        over samples rather than a feature representation for each\n        sample.  It is usually `True` where an estimator has a\n        `metric` or `affinity` or `kernel` parameter with value\n        'precomputed'. Its primary purpose is to support a\n        :term:`meta-estimator` or a cross validation procedure that\n        extracts a sub-sample of data intended for a pairwise\n        estimator, where the data needs to be indexed on both axes.\n        Specifically, this tag is used by\n        `sklearn.utils.metaestimators._safe_split` to slice rows and\n        columns.",
        "parameters": {
          "one_d_array": {
            "type": "bool, default=False",
            "description": ""
          },
          "Whether": {
            "type": "the estimator supports data with missing values encoded as `np.nan`.",
            "description": ""
          },
          "two_d_array": {
            "type": "bool, default=True",
            "description": ""
          },
          "tests": {
            "type": "currently run only if this flag is set to ``True``.",
            "description": ""
          },
          "three_d_array": {
            "type": "bool, default=False",
            "description": ""
          },
          "sparse": {
            "type": "bool, default=False",
            "description": ""
          },
          "categorical": {
            "type": "bool, default=False",
            "description": ""
          },
          "string": {
            "type": "bool, default=False",
            "description": ""
          },
          "dict": {
            "type": "bool, default=False",
            "description": ""
          },
          "positive_only": {
            "type": "bool, default=False",
            "description": ""
          },
          "allow_nan": {
            "type": "bool, default=False",
            "description": ""
          },
          "pairwise": {
            "type": "bool, default=False",
            "description": ""
          },
          "This": {
            "type": "boolean attribute indicates whether the data (`X`),",
            "description": ":term:`fit` and similar methods consists of pairwise measures"
          },
          "over": {
            "type": "samples rather than a feature representation for each",
            "description": "sample.  It is usually `True` where an estimator has a\n`metric` or `affinity` or `kernel` parameter with value\n'precomputed'. Its primary purpose is to support a\n:term:`meta-estimator` or a cross validation procedure that"
          },
          "extracts": {
            "type": "a sub-sample of data intended for a pairwise",
            "description": "estimator, where the data needs to be indexed on both axes.\nSpecifically, this tag is used by\n`sklearn.utils.metaestimators._safe_split` to slice rows and\ncolumns."
          },
          "Note": {
            "type": "that if setting this tag to ``True`` means the estimator can take only",
            "description": ""
          },
          "positive": {
            "type": "values, the `positive_only` tag must reflect it and also be set to",
            "description": "``True``."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "that if setting this tag to ``True`` means the estimator can take only\n        positive values, the `positive_only` tag must reflect it and also be set to\n        ``True``.",
        "examples": ""
      },
      "methods": []
    },
    {
      "name": "RegressorTags",
      "documentation": {
        "description": "Tags for the regressor.",
        "parameters": {
          "poor_score": {
            "type": "bool, default=False",
            "description": ""
          },
          "Whether": {
            "type": "the estimator fails to provide a \"reasonable\" test-set",
            "description": "score, which currently for regression is an R2 of 0.5 on\n``make_regression(n_samples=200, n_features=10,\nn_informative=1, bias=5.0, noise=20, random_state=42)``. The"
          },
          "dataset": {
            "type": "and values are based on current estimators in scikit-learn",
            "description": ""
          },
          "and": {
            "type": "might be replaced by something more systematic.",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": []
    },
    {
      "name": "Sequence",
      "documentation": {
        "description": "All the operations on a read-only sequence.\n\n    Concrete subclasses must override __new__ or __init__,\n    __getitem__, and __len__.",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "count",
          "signature": "count(self, value)",
          "documentation": {
            "description": "S.count(value) -> integer -- return number of occurrences of value",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        },
        {
          "name": "index",
          "signature": "index(self, value, start=0, stop=None)",
          "documentation": {
            "description": "S.index(value, [start, [stop]]) -> integer -- return first index of value.",
            "parameters": {},
            "returns": "",
            "raises": "ValueError if the value is not present.\n\n           Supporting start and stop arguments is optional, but\n           recommended.",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    },
    {
      "name": "Tags",
      "documentation": {
        "description": "Tags for the estimator.\n\n    See :ref:`estimator_tags` for more information.",
        "parameters": {
          "estimator_type": {
            "type": "str or None",
            "description": ""
          },
          "The": {
            "type": "input data(X) tags.",
            "description": ""
          },
          "target_tags": {
            "type": ":class:`TargetTags`",
            "description": ""
          },
          "transformer_tags": {
            "type": ":class:`TransformerTags` or None",
            "description": ""
          },
          "classifier_tags": {
            "type": ":class:`ClassifierTags` or None",
            "description": ""
          },
          "regressor_tags": {
            "type": ":class:`RegressorTags` or None",
            "description": ""
          },
          "array_api_support": {
            "type": "bool, default=False",
            "description": ""
          },
          "Whether": {
            "type": "to skip common tests entirely. Don't use this unless",
            "description": ""
          },
          "no_validation": {
            "type": "bool, default=False",
            "description": ""
          },
          "stateless": {
            "type": "and dummy transformers!",
            "description": ""
          },
          "non_deterministic": {
            "type": "bool, default=False",
            "description": ""
          },
          "requires_fit": {
            "type": "bool, default=True",
            "description": ""
          },
          "_skip_test": {
            "type": "bool, default=False",
            "description": ""
          },
          "you": {
            "type": "have a *very good* reason.",
            "description": ""
          },
          "input_tags": {
            "type": ":class:`InputTags`",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": []
    },
    {
      "name": "TargetTags",
      "documentation": {
        "description": "Tags for the target data.",
        "parameters": {
          "required": {
            "type": "bool",
            "description": ""
          },
          "Whether": {
            "type": "the target can be single-output. This can be ``False`` if the",
            "description": ""
          },
          "for": {
            "type": "regression).",
            "description": ""
          },
          "and": {
            "type": "`~sklearn.base.ClassifierMixin`.",
            "description": ""
          },
          "one_d_labels": {
            "type": "bool, default=False",
            "description": ""
          },
          "two_d_labels": {
            "type": "bool, default=False",
            "description": ""
          },
          "positive_only": {
            "type": "bool, default=False",
            "description": ""
          },
          "multi_output": {
            "type": "bool, default=False",
            "description": ""
          },
          "See": {
            "type": "term:`multi",
            "description": "output` in the glossary."
          },
          "single_output": {
            "type": "bool, default=True",
            "description": ""
          },
          "estimator": {
            "type": "supports only multi-output cases.",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": []
    },
    {
      "name": "TransformerTags",
      "documentation": {
        "description": "Tags for the transformer.",
        "parameters": {
          "preserves_dtype": {
            "type": "list[str], default=[\"float64\"]",
            "description": ""
          },
          "Applies": {
            "type": "only on transformers. It corresponds to the data types",
            "description": ""
          },
          "which": {
            "type": "will be preserved such that `X_trans.dtype` is the same",
            "description": ""
          },
          "as": {
            "type": "`X.dtype` after calling `transformer.transform(X)`. If this",
            "description": ""
          },
          "list": {
            "type": "is empty, then the transformer is not expected to",
            "description": ""
          },
          "preserve": {
            "type": "the data type. The first value in the list is",
            "description": ""
          },
          "considered": {
            "type": "as the default data type, corresponding to the data",
            "description": ""
          },
          "type": {
            "type": "of the output when the input data type is not going to be",
            "description": "preserved."
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": []
    },
    {
      "name": "deprecated",
      "documentation": {
        "description": "Decorator to mark a function or class as deprecated.\n\n    Issue a warning when the function is called/the class is instantiated and\n    adds a warning to the docstring.\n\n    The optional extra argument will be appended to the deprecation message\n    and the docstring. Note: to use this with the default value for extra, put\n    in an empty of parentheses:",
        "parameters": {
          "extra": {
            "type": "str, default=''",
            "description": ""
          },
          "To": {
            "type": "be added to the deprecation messages.",
            "description": ""
          }
        },
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": "--------\n    >>> from sklearn.utils import deprecated\n    >>> deprecated()\n    <sklearn.utils.deprecation.deprecated object at ...>\n    >>> @deprecated()\n    ... def some_function(): pass\n\n    Parameters\n    ----------\n    extra : str, default=''\n          To be added to the deprecation messages."
      },
      "methods": []
    },
    {
      "name": "parallel_backend",
      "documentation": {
        "description": "",
        "parameters": {},
        "returns": "",
        "raises": "",
        "see_also": "",
        "notes": "",
        "examples": ""
      },
      "methods": [
        {
          "name": "unregister",
          "signature": "unregister(self)",
          "documentation": {
            "description": "",
            "parameters": {},
            "returns": "",
            "raises": "",
            "see_also": "",
            "notes": "",
            "examples": ""
          }
        }
      ]
    }
  ]
}